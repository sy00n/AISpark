{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9148f671",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-04-07T07:37:24.742737Z",
          "start_time": "2022-04-07T07:37:22.833654Z"
        },
        "id": "9148f671"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from kobert.utils import get_tokenizer\n",
        "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c158d92c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-04-07T07:37:26.035205Z",
          "start_time": "2022-04-07T07:37:26.031546Z"
        },
        "id": "c158d92c"
      },
      "outputs": [],
      "source": [
        "#GPU 사용\n",
        "device = torch.device(\"cuda:0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62cf2d6b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-04-07T07:37:32.321427Z",
          "start_time": "2022-04-07T07:37:26.371136Z"
        },
        "id": "62cf2d6b",
        "outputId": "dfc8697a-d2da-4f5c-f11f-5a03420a02b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using cached model. /workspace/Juwan/UROP_help/.cache/kobert_v1.zip\n",
            "using cached model. /workspace/Juwan/UROP_help/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ],
      "source": [
        "#BERT 모델, Vocabulary 불러오기\n",
        "bertmodel, vocab = get_pytorch_kobert_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1f121cb",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-04-07T07:41:18.004521Z",
          "start_time": "2022-04-07T07:41:17.991433Z"
        },
        "id": "a1f121cb"
      },
      "outputs": [],
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))\n",
        "    \n",
        "    def get_labels(self):\n",
        "        return self.labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2df75509",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-04-07T07:40:35.927466Z",
          "start_time": "2022-04-07T07:40:35.921139Z"
        },
        "id": "2df75509"
      },
      "outputs": [],
      "source": [
        "## Setting parameters\n",
        "max_len = 64\n",
        "batch_size = 64\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 50 \n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate =  5e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93a7f95d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-04-07T07:40:36.229497Z",
          "start_time": "2022-04-07T07:40:36.225902Z"
        },
        "id": "93a7f95d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a82c0b90",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-04-07T07:40:36.709555Z",
          "start_time": "2022-04-07T07:40:36.525433Z"
        },
        "id": "a82c0b90"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('train.csv', encoding = 'cp949')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a91f6ac5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-04-07T07:40:37.000191Z",
          "start_time": "2022-04-07T07:40:36.985345Z"
        },
        "id": "a91f6ac5",
        "outputId": "46b2684f-8045-40a8-8ae1-b49981fb9e26"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>번호</th>\n",
              "      <th>연령</th>\n",
              "      <th>성별</th>\n",
              "      <th>상황키워드</th>\n",
              "      <th>신체질환</th>\n",
              "      <th>감정_대분류</th>\n",
              "      <th>감정_소분류</th>\n",
              "      <th>사람문장1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>44164</td>\n",
              "      <td>청년</td>\n",
              "      <td>남성</td>\n",
              "      <td>연애, 결혼, 출산</td>\n",
              "      <td>해당없음</td>\n",
              "      <td>기쁨</td>\n",
              "      <td>신이 난</td>\n",
              "      <td>아내가 드디어 출산하게 되어서 정말 신이 나.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3926</td>\n",
              "      <td>노년</td>\n",
              "      <td>남성</td>\n",
              "      <td>건강, 죽음</td>\n",
              "      <td>만성질환 유</td>\n",
              "      <td>불안</td>\n",
              "      <td>스트레스 받는</td>\n",
              "      <td>당뇨랑 합병증 때문에 먹어야 할 약이 열 가지가 넘어가니까 스트레스야.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50882</td>\n",
              "      <td>청소년</td>\n",
              "      <td>여성</td>\n",
              "      <td>학업 및 진로</td>\n",
              "      <td>해당없음</td>\n",
              "      <td>당황</td>\n",
              "      <td>당황</td>\n",
              "      <td>고등학교에 올라오니 중학교 때보다 수업이 갑자기 어려워져서 당황스러워.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31303</td>\n",
              "      <td>노년</td>\n",
              "      <td>남성</td>\n",
              "      <td>재정</td>\n",
              "      <td>만성질환 무</td>\n",
              "      <td>기쁨</td>\n",
              "      <td>신이 난</td>\n",
              "      <td>재취업이 돼서 받게 된 첫 월급으로 온 가족이 외식을 할 예정이야. 너무 행복해.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>47200</td>\n",
              "      <td>노년</td>\n",
              "      <td>여성</td>\n",
              "      <td>재정</td>\n",
              "      <td>만성질환 유</td>\n",
              "      <td>기쁨</td>\n",
              "      <td>안도</td>\n",
              "      <td>빚을 드디어 다 갚게 되어서 이제야 안도감이 들어.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>48610</td>\n",
              "      <td>중년</td>\n",
              "      <td>여성</td>\n",
              "      <td>재정, 은퇴, 노후준비</td>\n",
              "      <td>해당없음</td>\n",
              "      <td>불안</td>\n",
              "      <td>취약한</td>\n",
              "      <td>이제 곧 은퇴할 시기가 되었어. 내가 먼저 은퇴를 하고 육 개월 후에 남편도 은퇴를...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>17198</td>\n",
              "      <td>중년</td>\n",
              "      <td>남성</td>\n",
              "      <td>건강</td>\n",
              "      <td>해당없음</td>\n",
              "      <td>슬픔</td>\n",
              "      <td>우울한</td>\n",
              "      <td>사십 대에 접어들면서 머리카락이 많이 빠져 고민이야.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>12186</td>\n",
              "      <td>노년</td>\n",
              "      <td>남성</td>\n",
              "      <td>재정</td>\n",
              "      <td>만성질환 무</td>\n",
              "      <td>분노</td>\n",
              "      <td>구역질 나는</td>\n",
              "      <td>이제 돈이라면 지긋지긋해.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>35975</td>\n",
              "      <td>청소년</td>\n",
              "      <td>남성</td>\n",
              "      <td>학교폭력/따돌림</td>\n",
              "      <td>해당없음</td>\n",
              "      <td>분노</td>\n",
              "      <td>좌절한</td>\n",
              "      <td>친구들이 나를 괴롭혀. 부모님과 선생님께 얘기했는데도 믿어주지 않아.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>12551</td>\n",
              "      <td>노년</td>\n",
              "      <td>여성</td>\n",
              "      <td>대인관계</td>\n",
              "      <td>만성질환 무</td>\n",
              "      <td>슬픔</td>\n",
              "      <td>눈물이 나는</td>\n",
              "      <td>친구 때문에 눈물 나.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      번호   연령  성별         상황키워드    신체질환 감정_대분류   감정_소분류  \\\n",
              "0  44164   청년  남성    연애, 결혼, 출산    해당없음     기쁨     신이 난   \n",
              "1   3926   노년  남성        건강, 죽음  만성질환 유     불안  스트레스 받는   \n",
              "2  50882  청소년  여성       학업 및 진로    해당없음     당황       당황   \n",
              "3  31303   노년  남성            재정  만성질환 무     기쁨     신이 난   \n",
              "4  47200   노년  여성            재정  만성질환 유     기쁨       안도   \n",
              "5  48610   중년  여성  재정, 은퇴, 노후준비    해당없음     불안      취약한   \n",
              "6  17198   중년  남성            건강    해당없음     슬픔      우울한   \n",
              "7  12186   노년  남성            재정  만성질환 무     분노   구역질 나는   \n",
              "8  35975  청소년  남성      학교폭력/따돌림    해당없음     분노      좌절한   \n",
              "9  12551   노년  여성          대인관계  만성질환 무     슬픔   눈물이 나는   \n",
              "\n",
              "                                               사람문장1  \n",
              "0                          아내가 드디어 출산하게 되어서 정말 신이 나.  \n",
              "1            당뇨랑 합병증 때문에 먹어야 할 약이 열 가지가 넘어가니까 스트레스야.  \n",
              "2            고등학교에 올라오니 중학교 때보다 수업이 갑자기 어려워져서 당황스러워.  \n",
              "3      재취업이 돼서 받게 된 첫 월급으로 온 가족이 외식을 할 예정이야. 너무 행복해.  \n",
              "4                       빚을 드디어 다 갚게 되어서 이제야 안도감이 들어.  \n",
              "5  이제 곧 은퇴할 시기가 되었어. 내가 먼저 은퇴를 하고 육 개월 후에 남편도 은퇴를...  \n",
              "6                      사십 대에 접어들면서 머리카락이 많이 빠져 고민이야.  \n",
              "7                                     이제 돈이라면 지긋지긋해.  \n",
              "8             친구들이 나를 괴롭혀. 부모님과 선생님께 얘기했는데도 믿어주지 않아.  \n",
              "9                                       친구 때문에 눈물 나.  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7726725",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-04-07T08:47:16.390296Z",
          "start_time": "2022-04-07T08:47:16.377043Z"
        },
        "id": "f7726725",
        "outputId": "ad3f5031-43c2-4b26-ddc6-9bf0ba8de364"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
              "       51, 52, 53, 54, 55, 56, 57])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocessor = LabelEncoder()\n",
        "preprocessor.fit(data['감정_소분류'])\n",
        "data['감정_소분류'] = preprocessor.transform(data['감정_소분류'])\n",
        "preprocessor.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e999ec4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-04-07T07:40:49.456525Z",
          "start_time": "2022-04-07T07:40:49.398141Z"
        },
        "id": "4e999ec4"
      },
      "outputs": [],
      "source": [
        "data_list = []\n",
        "for q, label in zip(data['사람문장1'], data['감정_소분류'])  :\n",
        "    element = []\n",
        "    element.append(q)\n",
        "    element.append(label)\n",
        "    data_list.append(element)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac36483f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-04-07T07:40:50.472638Z",
          "start_time": "2022-04-07T07:40:50.447186Z"
        },
        "id": "ac36483f"
      },
      "outputs": [],
      "source": [
        "#train & test 데이터로 나누기\n",
        "from sklearn.model_selection import train_test_split\n",
        "                                                         \n",
        "dataset_train, dataset_test = train_test_split(data_list, test_size=0.2, random_state=99, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ffc53d4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-04-07T07:40:50.958544Z",
          "start_time": "2022-04-07T07:40:50.951007Z"
        },
        "id": "8ffc53d4",
        "outputId": "a21d3d62-103c-49e6-da88-7855756e367b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using cached model. /workspace/Juwan/UROP_help/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ],
      "source": [
        "#토큰화\n",
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e630ddd9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-04-07T07:41:36.684091Z",
          "start_time": "2022-04-07T07:41:30.431425Z"
        },
        "id": "e630ddd9"
      },
      "outputs": [],
      "source": [
        "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
        "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5bf8afc",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-04-07T07:40:18.040253Z",
          "start_time": "2022-04-07T07:40:17.940457Z"
        },
        "id": "b5bf8afc",
        "outputId": "1246436b-3f00-4048-a77e-8078aa51c2b2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/UROP/lib/python3.7/site-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array(64, dtype=int32)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "max(np.array(list(data_train.sentences))[:,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c29d413",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-04-07T07:41:37.043917Z",
          "start_time": "2022-04-07T07:41:36.953586Z"
        },
        "id": "5c29d413"
      },
      "outputs": [],
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size,sampler=ImbalancedDatasetSampler(data_train), num_workers=5)\n",
        "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size,sampler=ImbalancedDatasetSampler(data_test), num_workers=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d428dde",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-04-07T07:41:42.887467Z",
          "start_time": "2022-04-07T07:41:42.872613Z"
        },
        "id": "6d428dde"
      },
      "outputs": [],
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=len(preprocessor.classes_), \n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "\n",
        "            \n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6873fa81",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-04-07T07:41:48.355559Z",
          "start_time": "2022-04-07T07:41:43.397783Z"
        },
        "id": "6873fa81"
      },
      "outputs": [],
      "source": [
        "model = BERTClassifier(bertmodel,  dr_rate=0.3).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cc6830b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-04-07T07:41:48.655091Z",
          "start_time": "2022-04-07T07:41:48.647393Z"
        },
        "id": "8cc6830b"
      },
      "outputs": [],
      "source": [
        "# Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10468cc6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-04-07T07:41:55.475777Z",
          "start_time": "2022-04-07T07:41:55.468631Z"
        },
        "id": "10468cc6",
        "outputId": "6578b87f-4f7e-439f-dbe2-a1fed3c0ea5e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/UROP/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd7825cd",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-04-07T07:42:02.169397Z",
          "start_time": "2022-04-07T07:42:02.166037Z"
        },
        "id": "fd7825cd"
      },
      "outputs": [],
      "source": [
        "t_total = len(train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c7ffa1b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-04-07T07:42:08.962951Z",
          "start_time": "2022-04-07T07:42:08.959244Z"
        },
        "id": "2c7ffa1b"
      },
      "outputs": [],
      "source": [
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68292e94",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-04-07T07:42:15.742136Z",
          "start_time": "2022-04-07T07:42:15.737871Z"
        },
        "id": "68292e94"
      },
      "outputs": [],
      "source": [
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c359a18b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-04-07T08:38:36.929594Z",
          "start_time": "2022-04-07T07:42:22.509068Z"
        },
        "scrolled": true,
        "id": "c359a18b",
        "outputId": "4123cffa-a841-4d9a-bb52-01716541ecd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1 loss 4.1547369956970215 train acc 0.015625\n",
            "epoch 1 batch id 2 loss 4.133150100708008 train acc 0.015625\n",
            "epoch 1 batch id 3 loss 4.11295747756958 train acc 0.010416666666666666\n",
            "epoch 1 batch id 4 loss 4.086395740509033 train acc 0.01171875\n",
            "epoch 1 batch id 5 loss 4.146578788757324 train acc 0.015625\n",
            "epoch 1 batch id 6 loss 4.087337970733643 train acc 0.018229166666666668\n",
            "epoch 1 batch id 7 loss 4.039854526519775 train acc 0.020089285714285716\n",
            "epoch 1 batch id 8 loss 4.121728420257568 train acc 0.021484375\n",
            "epoch 1 batch id 9 loss 4.182212829589844 train acc 0.022569444444444444\n",
            "epoch 1 batch id 10 loss 4.10418701171875 train acc 0.0203125\n",
            "epoch 1 batch id 11 loss 4.168939113616943 train acc 0.019886363636363636\n",
            "epoch 1 batch id 12 loss 4.092654705047607 train acc 0.01953125\n",
            "epoch 1 batch id 13 loss 4.117129802703857 train acc 0.019230769230769232\n",
            "epoch 1 batch id 14 loss 4.163125514984131 train acc 0.020089285714285716\n",
            "epoch 1 batch id 15 loss 4.1105265617370605 train acc 0.019791666666666666\n",
            "epoch 1 batch id 16 loss 4.107869625091553 train acc 0.01953125\n",
            "epoch 1 batch id 17 loss 4.058100700378418 train acc 0.019301470588235295\n",
            "epoch 1 batch id 18 loss 4.127899169921875 train acc 0.020833333333333332\n",
            "epoch 1 batch id 19 loss 4.080392837524414 train acc 0.02055921052631579\n",
            "epoch 1 batch id 20 loss 4.075933933258057 train acc 0.0203125\n",
            "epoch 1 batch id 21 loss 4.127779006958008 train acc 0.019345238095238096\n",
            "epoch 1 batch id 22 loss 4.056603908538818 train acc 0.019886363636363636\n",
            "epoch 1 batch id 23 loss 4.111531734466553 train acc 0.021059782608695652\n",
            "epoch 1 batch id 24 loss 4.112744331359863 train acc 0.020182291666666668\n",
            "epoch 1 batch id 25 loss 4.149621963500977 train acc 0.019375\n",
            "epoch 1 batch id 26 loss 4.173695087432861 train acc 0.019230769230769232\n",
            "epoch 1 batch id 27 loss 4.06753396987915 train acc 0.019097222222222224\n",
            "epoch 1 batch id 28 loss 4.135275840759277 train acc 0.01953125\n",
            "epoch 1 batch id 29 loss 4.10877799987793 train acc 0.018857758620689655\n",
            "epoch 1 batch id 30 loss 4.17025089263916 train acc 0.01875\n",
            "epoch 1 batch id 31 loss 4.140634059906006 train acc 0.018649193548387098\n",
            "epoch 1 batch id 32 loss 4.0666728019714355 train acc 0.0185546875\n",
            "epoch 1 batch id 33 loss 4.128698348999023 train acc 0.018465909090909092\n",
            "epoch 1 batch id 34 loss 4.1338958740234375 train acc 0.017922794117647058\n",
            "epoch 1 batch id 35 loss 4.080499649047852 train acc 0.017857142857142856\n",
            "epoch 1 batch id 36 loss 4.136418342590332 train acc 0.017361111111111112\n",
            "epoch 1 batch id 37 loss 4.071592807769775 train acc 0.01731418918918919\n",
            "epoch 1 batch id 38 loss 4.141671180725098 train acc 0.016858552631578948\n",
            "epoch 1 batch id 39 loss 4.203296661376953 train acc 0.016826923076923076\n",
            "epoch 1 batch id 40 loss 4.109771251678467 train acc 0.016796875\n",
            "epoch 1 batch id 41 loss 4.160361289978027 train acc 0.01676829268292683\n",
            "epoch 1 batch id 42 loss 4.127490520477295 train acc 0.016741071428571428\n",
            "epoch 1 batch id 43 loss 4.132181167602539 train acc 0.016715116279069766\n",
            "epoch 1 batch id 44 loss 4.114681720733643 train acc 0.016690340909090908\n",
            "epoch 1 batch id 45 loss 4.065812110900879 train acc 0.017013888888888887\n",
            "epoch 1 batch id 46 loss 4.13982629776001 train acc 0.016983695652173912\n",
            "epoch 1 batch id 47 loss 4.15436315536499 train acc 0.01695478723404255\n",
            "epoch 1 batch id 48 loss 4.074740886688232 train acc 0.0166015625\n",
            "epoch 1 batch id 49 loss 4.090248107910156 train acc 0.016262755102040817\n",
            "epoch 1 batch id 50 loss 4.15146541595459 train acc 0.01625\n",
            "epoch 1 batch id 51 loss 4.127365589141846 train acc 0.015931372549019607\n",
            "epoch 1 batch id 52 loss 4.100010395050049 train acc 0.015925480769230768\n",
            "epoch 1 batch id 53 loss 4.128619194030762 train acc 0.015625\n",
            "epoch 1 batch id 54 loss 4.0928521156311035 train acc 0.015914351851851853\n",
            "epoch 1 batch id 55 loss 4.113286018371582 train acc 0.01619318181818182\n",
            "epoch 1 batch id 56 loss 4.105659484863281 train acc 0.016183035714285716\n",
            "epoch 1 batch id 57 loss 4.142279148101807 train acc 0.015899122807017545\n",
            "epoch 1 batch id 58 loss 4.181528091430664 train acc 0.015625\n",
            "epoch 1 batch id 59 loss 4.080970287322998 train acc 0.015889830508474576\n",
            "epoch 1 batch id 60 loss 4.18898344039917 train acc 0.015625\n",
            "epoch 1 batch id 61 loss 3.9802465438842773 train acc 0.016905737704918034\n",
            "epoch 1 batch id 62 loss 4.238553524017334 train acc 0.01663306451612903\n",
            "epoch 1 batch id 63 loss 4.050408363342285 train acc 0.01711309523809524\n",
            "epoch 1 batch id 64 loss 4.093742847442627 train acc 0.01708984375\n",
            "epoch 1 batch id 65 loss 4.101066589355469 train acc 0.016826923076923076\n",
            "epoch 1 batch id 66 loss 4.104335308074951 train acc 0.017045454545454544\n",
            "epoch 1 batch id 67 loss 4.129840850830078 train acc 0.016791044776119403\n",
            "epoch 1 batch id 68 loss 4.141541481018066 train acc 0.016544117647058824\n",
            "epoch 1 batch id 69 loss 4.095755100250244 train acc 0.016304347826086956\n",
            "epoch 1 batch id 70 loss 4.089719772338867 train acc 0.01607142857142857\n",
            "epoch 1 batch id 71 loss 4.128739356994629 train acc 0.016065140845070422\n",
            "epoch 1 batch id 72 loss 4.077721118927002 train acc 0.016059027777777776\n",
            "epoch 1 batch id 73 loss 4.071096897125244 train acc 0.016267123287671232\n",
            "epoch 1 batch id 74 loss 4.032782077789307 train acc 0.016891891891891893\n",
            "epoch 1 batch id 75 loss 4.090108871459961 train acc 0.016875\n",
            "epoch 1 batch id 76 loss 4.152798175811768 train acc 0.017064144736842105\n",
            "epoch 1 batch id 77 loss 4.1570305824279785 train acc 0.016842532467532468\n",
            "epoch 1 batch id 78 loss 4.057474136352539 train acc 0.016626602564102564\n",
            "epoch 1 batch id 79 loss 4.038142681121826 train acc 0.01641613924050633\n",
            "epoch 1 batch id 80 loss 4.1410980224609375 train acc 0.0162109375\n",
            "epoch 1 batch id 81 loss 4.176060676574707 train acc 0.016203703703703703\n",
            "epoch 1 batch id 82 loss 4.017495155334473 train acc 0.016196646341463415\n",
            "epoch 1 batch id 83 loss 4.103270530700684 train acc 0.016001506024096387\n",
            "epoch 1 batch id 84 loss 4.124716281890869 train acc 0.015811011904761904\n",
            "epoch 1 batch id 85 loss 4.061301231384277 train acc 0.015808823529411764\n",
            "epoch 1 batch id 86 loss 4.090547561645508 train acc 0.015988372093023256\n",
            "epoch 1 batch id 87 loss 4.147388935089111 train acc 0.015804597701149427\n",
            "epoch 1 batch id 88 loss 4.128284454345703 train acc 0.015980113636363636\n",
            "epoch 1 batch id 89 loss 4.171508312225342 train acc 0.01580056179775281\n",
            "epoch 1 batch id 90 loss 4.1490888595581055 train acc 0.01597222222222222\n",
            "epoch 1 batch id 91 loss 4.074485778808594 train acc 0.015968406593406592\n",
            "epoch 1 batch id 92 loss 4.155102729797363 train acc 0.01579483695652174\n",
            "epoch 1 batch id 93 loss 4.122884750366211 train acc 0.015793010752688172\n",
            "epoch 1 batch id 94 loss 4.102409839630127 train acc 0.015957446808510637\n",
            "epoch 1 batch id 95 loss 4.08852481842041 train acc 0.015953947368421054\n",
            "epoch 1 batch id 96 loss 4.092734336853027 train acc 0.015950520833333332\n",
            "epoch 1 batch id 97 loss 4.087233543395996 train acc 0.01610824742268041\n",
            "epoch 1 batch id 98 loss 3.998771905899048 train acc 0.01642219387755102\n",
            "epoch 1 batch id 99 loss 4.072399616241455 train acc 0.016887626262626264\n",
            "epoch 1 batch id 100 loss 4.076313495635986 train acc 0.016875\n",
            "epoch 1 batch id 101 loss 4.149204730987549 train acc 0.01670792079207921\n",
            "epoch 1 batch id 102 loss 4.102226257324219 train acc 0.016544117647058824\n",
            "epoch 1 batch id 103 loss 4.13014030456543 train acc 0.01653519417475728\n",
            "epoch 1 batch id 104 loss 4.130074977874756 train acc 0.016526442307692308\n",
            "epoch 1 batch id 105 loss 4.119381904602051 train acc 0.01636904761904762\n",
            "epoch 1 batch id 106 loss 4.03890323638916 train acc 0.01650943396226415\n",
            "epoch 1 batch id 107 loss 4.086082458496094 train acc 0.016501168224299066\n",
            "epoch 1 batch id 108 loss 4.102972507476807 train acc 0.016637731481481483\n",
            "epoch 1 batch id 109 loss 4.100501537322998 train acc 0.016771788990825688\n",
            "epoch 1 batch id 110 loss 4.054252624511719 train acc 0.016619318181818183\n",
            "epoch 1 batch id 111 loss 4.088700294494629 train acc 0.016469594594594593\n",
            "epoch 1 batch id 112 loss 4.114192008972168 train acc 0.016741071428571428\n",
            "epoch 1 batch id 113 loss 4.122818946838379 train acc 0.01686946902654867\n",
            "epoch 1 batch id 114 loss 4.07916259765625 train acc 0.016858552631578948\n",
            "epoch 1 batch id 115 loss 4.068639755249023 train acc 0.017119565217391303\n",
            "epoch 1 batch id 116 loss 4.0821332931518555 train acc 0.017645474137931036\n",
            "epoch 1 batch id 117 loss 4.089457988739014 train acc 0.017895299145299144\n",
            "epoch 1 batch id 118 loss 4.056214809417725 train acc 0.0178760593220339\n",
            "epoch 1 batch id 119 loss 4.098598480224609 train acc 0.017725840336134453\n",
            "epoch 1 batch id 120 loss 4.1088547706604 train acc 0.017578125\n",
            "epoch 1 batch id 121 loss 4.1091413497924805 train acc 0.01756198347107438\n",
            "epoch 1 batch id 122 loss 4.101886749267578 train acc 0.017418032786885244\n",
            "epoch 1 batch id 123 loss 4.083320617675781 train acc 0.017403455284552845\n",
            "epoch 1 batch id 124 loss 4.126718521118164 train acc 0.017263104838709676\n",
            "epoch 1 batch id 125 loss 4.0828166007995605 train acc 0.01725\n",
            "epoch 1 batch id 126 loss 4.085510730743408 train acc 0.017609126984126984\n",
            "epoch 1 batch id 127 loss 4.069968223571777 train acc 0.017593503937007874\n",
            "epoch 1 batch id 128 loss 4.076457977294922 train acc 0.017822265625\n",
            "epoch 1 batch id 129 loss 4.054816722869873 train acc 0.017926356589147287\n",
            "epoch 1 batch id 130 loss 4.015992164611816 train acc 0.018028846153846152\n",
            "epoch 1 batch id 131 loss 4.077106952667236 train acc 0.01812977099236641\n",
            "epoch 1 batch id 132 loss 4.050096035003662 train acc 0.018110795454545456\n",
            "epoch 1 batch id 133 loss 4.045689582824707 train acc 0.018092105263157895\n",
            "epoch 1 batch id 134 loss 4.094320774078369 train acc 0.018073694029850745\n",
            "epoch 1 batch id 135 loss 4.088180065155029 train acc 0.018055555555555554\n",
            "epoch 1 batch id 136 loss 4.07545804977417 train acc 0.017922794117647058\n",
            "epoch 1 batch id 137 loss 4.076467990875244 train acc 0.01790602189781022\n",
            "epoch 1 batch id 138 loss 4.136048793792725 train acc 0.017776268115942028\n",
            "epoch 1 batch id 139 loss 4.133328437805176 train acc 0.01764838129496403\n",
            "epoch 1 batch id 140 loss 4.0639777183532715 train acc 0.017745535714285714\n",
            "epoch 1 batch id 141 loss 4.042999744415283 train acc 0.01784131205673759\n",
            "epoch 1 batch id 142 loss 4.027563095092773 train acc 0.018045774647887324\n",
            "epoch 1 batch id 143 loss 4.092268466949463 train acc 0.018247377622377624\n",
            "epoch 1 batch id 144 loss 4.06723165512085 train acc 0.018337673611111112\n",
            "epoch 1 batch id 145 loss 4.118799209594727 train acc 0.018211206896551726\n",
            "epoch 1 batch id 146 loss 4.067822456359863 train acc 0.018300513698630137\n",
            "epoch 1 batch id 147 loss 4.093242645263672 train acc 0.018176020408163265\n",
            "epoch 1 batch id 148 loss 4.0750508308410645 train acc 0.01805320945945946\n",
            "epoch 1 batch id 149 loss 4.053197383880615 train acc 0.018036912751677854\n",
            "epoch 1 batch id 150 loss 4.082517623901367 train acc 0.018125\n",
            "epoch 1 batch id 151 loss 4.080626487731934 train acc 0.018004966887417217\n",
            "epoch 1 batch id 152 loss 4.099860668182373 train acc 0.017989309210526317\n",
            "epoch 1 batch id 153 loss 4.125143051147461 train acc 0.01787173202614379\n",
            "epoch 1 batch id 154 loss 4.017068862915039 train acc 0.017857142857142856\n",
            "epoch 1 batch id 155 loss 4.0788960456848145 train acc 0.01784274193548387\n",
            "epoch 1 batch id 156 loss 4.065366744995117 train acc 0.01782852564102564\n",
            "epoch 1 batch id 157 loss 4.059531211853027 train acc 0.017814490445859872\n",
            "epoch 1 batch id 158 loss 4.109216690063477 train acc 0.017701740506329115\n",
            "epoch 1 batch id 159 loss 4.158249855041504 train acc 0.017590408805031446\n",
            "epoch 1 batch id 160 loss 4.084893226623535 train acc 0.01767578125\n",
            "epoch 1 batch id 161 loss 4.090716361999512 train acc 0.017663043478260868\n",
            "epoch 1 batch id 162 loss 4.083656311035156 train acc 0.017843364197530864\n",
            "epoch 1 batch id 163 loss 4.113402843475342 train acc 0.017925613496932516\n",
            "epoch 1 batch id 164 loss 4.099032878875732 train acc 0.017816310975609755\n",
            "epoch 1 batch id 165 loss 4.077718257904053 train acc 0.017803030303030303\n",
            "epoch 1 batch id 166 loss 4.071089267730713 train acc 0.017695783132530122\n",
            "epoch 1 batch id 167 loss 4.075981616973877 train acc 0.017589820359281437\n",
            "epoch 1 batch id 168 loss 4.086877822875977 train acc 0.017578125\n",
            "epoch 1 batch id 169 loss 4.114854335784912 train acc 0.017474112426035502\n",
            "epoch 1 batch id 170 loss 4.06977653503418 train acc 0.017463235294117647\n",
            "epoch 1 batch id 171 loss 4.053995132446289 train acc 0.01745248538011696\n",
            "epoch 1 batch id 172 loss 4.051910400390625 train acc 0.017623546511627907\n",
            "epoch 1 batch id 173 loss 4.064811706542969 train acc 0.017702312138728325\n",
            "epoch 1 batch id 174 loss 4.044610023498535 train acc 0.01769037356321839\n",
            "epoch 1 batch id 175 loss 4.070296287536621 train acc 0.017767857142857144\n",
            "epoch 1 batch id 176 loss 4.043057441711426 train acc 0.017844460227272728\n",
            "epoch 1 batch id 177 loss 4.138897895812988 train acc 0.0178319209039548\n",
            "epoch 1 batch id 178 loss 4.0816802978515625 train acc 0.017907303370786515\n",
            "epoch 1 batch id 179 loss 4.063814640045166 train acc 0.017894553072625698\n",
            "epoch 1 batch id 180 loss 4.123653888702393 train acc 0.017795138888888888\n",
            "epoch 1 batch id 181 loss 4.099785804748535 train acc 0.017783149171270718\n",
            "epoch 1 batch id 182 loss 4.042592525482178 train acc 0.017771291208791208\n",
            "epoch 1 batch id 183 loss 4.0225443840026855 train acc 0.017759562841530054\n",
            "epoch 1 batch id 184 loss 4.106494903564453 train acc 0.01774796195652174\n",
            "epoch 1 batch id 185 loss 4.096123218536377 train acc 0.017736486486486486\n",
            "epoch 1 batch id 186 loss 4.06866979598999 train acc 0.017641129032258066\n",
            "epoch 1 batch id 187 loss 4.058282375335693 train acc 0.01771390374331551\n",
            "epoch 1 batch id 188 loss 4.044926166534424 train acc 0.01778590425531915\n",
            "epoch 1 batch id 189 loss 4.082756519317627 train acc 0.017691798941798943\n",
            "epoch 1 batch id 190 loss 4.0485358238220215 train acc 0.017763157894736842\n",
            "epoch 1 batch id 191 loss 4.102908134460449 train acc 0.01767015706806283\n",
            "epoch 1 batch id 192 loss 4.0524396896362305 train acc 0.017822265625\n",
            "epoch 1 batch id 193 loss 4.062732219696045 train acc 0.017810880829015545\n",
            "epoch 1 batch id 194 loss 4.10724401473999 train acc 0.017799613402061855\n",
            "epoch 1 batch id 195 loss 4.06168794631958 train acc 0.017868589743589743\n",
            "epoch 1 batch id 196 loss 4.097275257110596 train acc 0.017777423469387755\n",
            "epoch 1 batch id 197 loss 4.118011951446533 train acc 0.01768718274111675\n",
            "epoch 1 batch id 198 loss 4.054787635803223 train acc 0.017676767676767676\n",
            "epoch 1 batch id 199 loss 4.085705757141113 train acc 0.01774497487437186\n",
            "epoch 1 batch id 200 loss 3.9971673488616943 train acc 0.01796875\n",
            "epoch 1 batch id 201 loss 4.121809005737305 train acc 0.017879353233830844\n",
            "epoch 1 batch id 202 loss 4.054579257965088 train acc 0.017945544554455444\n",
            "epoch 1 batch id 203 loss 4.016311168670654 train acc 0.01793411330049261\n",
            "epoch 1 batch id 204 loss 4.060474872589111 train acc 0.018075980392156864\n",
            "epoch 1 batch id 205 loss 4.080239295959473 train acc 0.01798780487804878\n",
            "epoch 1 batch id 206 loss 4.085750102996826 train acc 0.017900485436893203\n",
            "epoch 1 batch id 207 loss 4.012000560760498 train acc 0.018040458937198068\n",
            "epoch 1 batch id 208 loss 4.068871974945068 train acc 0.018028846153846152\n",
            "epoch 1 batch id 209 loss 4.079366683959961 train acc 0.018092105263157895\n",
            "epoch 1 batch id 210 loss 4.068872928619385 train acc 0.018154761904761906\n",
            "epoch 1 batch id 211 loss 4.073127746582031 train acc 0.018142772511848343\n",
            "epoch 1 batch id 212 loss 4.113359451293945 train acc 0.018130896226415096\n",
            "epoch 1 batch id 213 loss 4.046362400054932 train acc 0.018119131455399062\n",
            "epoch 1 batch id 214 loss 4.074682235717773 train acc 0.018180490654205607\n",
            "epoch 1 batch id 215 loss 4.06984806060791 train acc 0.01824127906976744\n",
            "epoch 1 batch id 216 loss 4.043439865112305 train acc 0.01837384259259259\n",
            "epoch 1 batch id 217 loss 4.0547356605529785 train acc 0.018289170506912443\n",
            "epoch 1 batch id 218 loss 4.071369647979736 train acc 0.01834862385321101\n",
            "epoch 1 batch id 219 loss 4.070209980010986 train acc 0.0182648401826484\n",
            "epoch 1 batch id 220 loss 4.039434909820557 train acc 0.01818181818181818\n",
            "epoch 1 batch id 221 loss 4.023276329040527 train acc 0.018170248868778282\n",
            "epoch 1 batch id 222 loss 4.00959587097168 train acc 0.01829954954954955\n",
            "epoch 1 batch id 223 loss 4.059140682220459 train acc 0.01821748878923767\n",
            "epoch 1 batch id 224 loss 4.011168956756592 train acc 0.018205915178571428\n",
            "epoch 1 batch id 225 loss 4.086839199066162 train acc 0.018125\n",
            "epoch 1 batch id 226 loss 4.07560396194458 train acc 0.018113938053097346\n",
            "epoch 1 batch id 227 loss 4.053888320922852 train acc 0.018102973568281937\n",
            "epoch 1 batch id 228 loss 4.045226573944092 train acc 0.018023574561403508\n",
            "epoch 1 batch id 229 loss 4.057735443115234 train acc 0.018013100436681223\n",
            "epoch 1 batch id 230 loss 4.0269551277160645 train acc 0.018002717391304348\n",
            "epoch 1 batch id 231 loss 4.031562328338623 train acc 0.018127705627705628\n",
            "epoch 1 batch id 232 loss 4.071559906005859 train acc 0.018251616379310345\n",
            "epoch 1 batch id 233 loss 4.064464092254639 train acc 0.018307403433476394\n",
            "epoch 1 batch id 234 loss 4.071462154388428 train acc 0.018229166666666668\n",
            "epoch 1 batch id 235 loss 4.0503740310668945 train acc 0.018284574468085107\n",
            "epoch 1 batch id 236 loss 4.046619415283203 train acc 0.01820709745762712\n",
            "epoch 1 batch id 237 loss 4.0287861824035645 train acc 0.01819620253164557\n",
            "epoch 1 batch id 238 loss 4.080619812011719 train acc 0.01831670168067227\n",
            "epoch 1 batch id 239 loss 4.053390979766846 train acc 0.018305439330543932\n",
            "epoch 1 batch id 240 loss 4.081669807434082 train acc 0.018359375\n",
            "epoch 1 batch id 241 loss 4.085134506225586 train acc 0.01841286307053942\n",
            "epoch 1 batch id 242 loss 4.025420188903809 train acc 0.01840134297520661\n",
            "epoch 1 batch id 243 loss 4.134340286254883 train acc 0.018454218106995886\n",
            "epoch 1 batch id 244 loss 4.009118556976318 train acc 0.018570696721311477\n",
            "epoch 1 batch id 245 loss 4.095993995666504 train acc 0.018558673469387756\n",
            "epoch 1 batch id 246 loss 4.081167697906494 train acc 0.018483231707317072\n",
            "epoch 1 batch id 247 loss 4.102467060089111 train acc 0.018408400809716598\n",
            "epoch 1 batch id 248 loss 4.088325500488281 train acc 0.01839717741935484\n",
            "epoch 1 batch id 249 loss 4.068392276763916 train acc 0.018323293172690762\n",
            "epoch 1 batch id 250 loss 4.074503421783447 train acc 0.0183125\n",
            "epoch 1 batch id 251 loss 4.05543327331543 train acc 0.018239541832669324\n",
            "epoch 1 batch id 252 loss 4.038977146148682 train acc 0.018229166666666668\n",
            "epoch 1 batch id 253 loss 4.067678451538086 train acc 0.018157114624505928\n",
            "epoch 1 batch id 254 loss 4.047289848327637 train acc 0.018147145669291338\n",
            "epoch 1 batch id 255 loss 4.051766872406006 train acc 0.018075980392156864\n",
            "epoch 1 batch id 256 loss 4.010614395141602 train acc 0.01812744140625\n",
            "epoch 1 batch id 257 loss 4.069145679473877 train acc 0.018178501945525293\n",
            "epoch 1 batch id 258 loss 4.028659343719482 train acc 0.018108042635658916\n",
            "epoch 1 batch id 259 loss 4.108266353607178 train acc 0.018038127413127412\n",
            "epoch 1 batch id 260 loss 4.091887474060059 train acc 0.01796875\n",
            "epoch 1 batch id 261 loss 4.07057523727417 train acc 0.017899904214559385\n",
            "epoch 1 batch id 262 loss 4.027857303619385 train acc 0.0178912213740458\n",
            "epoch 1 batch id 263 loss 4.042096138000488 train acc 0.01788260456273764\n",
            "epoch 1 batch id 264 loss 4.027698993682861 train acc 0.017933238636363636\n",
            "epoch 1 batch id 265 loss 4.076751708984375 train acc 0.017924528301886792\n",
            "epoch 1 batch id 266 loss 4.0272064208984375 train acc 0.017974624060150376\n",
            "epoch 1 batch id 267 loss 4.067296028137207 train acc 0.017907303370786515\n",
            "epoch 1 batch id 268 loss 4.060351848602295 train acc 0.017840485074626867\n",
            "epoch 1 batch id 269 loss 4.0529093742370605 train acc 0.01783224907063197\n",
            "epoch 1 batch id 270 loss 4.072443008422852 train acc 0.017766203703703704\n",
            "epoch 1 batch id 271 loss 4.03577995300293 train acc 0.017815959409594097\n",
            "epoch 1 batch id 272 loss 4.032292366027832 train acc 0.01786534926470588\n",
            "epoch 1 batch id 273 loss 4.081550121307373 train acc 0.017857142857142856\n",
            "epoch 1 batch id 274 loss 4.0958356857299805 train acc 0.017791970802919707\n",
            "epoch 1 batch id 275 loss 4.006767749786377 train acc 0.018011363636363638\n",
            "epoch 1 batch id 276 loss 4.065211772918701 train acc 0.018172554347826088\n",
            "epoch 1 batch id 277 loss 4.063998699188232 train acc 0.018163357400722023\n",
            "epoch 1 batch id 278 loss 4.040178298950195 train acc 0.01809802158273381\n",
            "epoch 1 batch id 279 loss 4.013507843017578 train acc 0.01825716845878136\n",
            "epoch 1 batch id 280 loss 4.075554847717285 train acc 0.018415178571428572\n",
            "epoch 1 batch id 281 loss 4.065280437469482 train acc 0.018405249110320286\n",
            "epoch 1 batch id 282 loss 4.030124187469482 train acc 0.018395390070921985\n",
            "epoch 1 batch id 283 loss 4.01369571685791 train acc 0.018551236749116608\n",
            "epoch 1 batch id 284 loss 4.036341190338135 train acc 0.01854093309859155\n",
            "epoch 1 batch id 285 loss 4.07304048538208 train acc 0.018530701754385964\n",
            "epoch 1 batch id 286 loss 4.053154945373535 train acc 0.01852054195804196\n",
            "epoch 1 batch id 287 loss 4.048423767089844 train acc 0.018456010452961674\n",
            "epoch 1 batch id 288 loss 4.039616584777832 train acc 0.018500434027777776\n",
            "epoch 1 batch id 289 loss 4.05473518371582 train acc 0.01854455017301038\n",
            "epoch 1 batch id 290 loss 4.061618804931641 train acc 0.018588362068965518\n",
            "epoch 1 batch id 291 loss 4.042868137359619 train acc 0.018578178694158076\n",
            "epoch 1 batch id 292 loss 4.072622299194336 train acc 0.01851455479452055\n",
            "epoch 1 batch id 293 loss 4.089361667633057 train acc 0.018558020477815698\n",
            "epoch 1 batch id 294 loss 4.066598415374756 train acc 0.018494897959183673\n",
            "epoch 1 batch id 295 loss 4.068722724914551 train acc 0.018485169491525424\n",
            "epoch 1 batch id 296 loss 4.061663627624512 train acc 0.018475506756756757\n",
            "epoch 1 batch id 297 loss 4.034340858459473 train acc 0.018571127946127947\n",
            "epoch 1 batch id 298 loss 4.0228400230407715 train acc 0.018666107382550336\n",
            "epoch 1 batch id 299 loss 4.056066513061523 train acc 0.018603678929765888\n",
            "epoch 1 batch id 300 loss 4.030765056610107 train acc 0.01859375\n",
            "epoch 1 batch id 301 loss 4.041266441345215 train acc 0.018531976744186048\n",
            "epoch 1 batch id 302 loss 4.046606063842773 train acc 0.01857408940397351\n",
            "epoch 1 batch id 303 loss 4.038851737976074 train acc 0.018564356435643563\n",
            "epoch 1 batch id 304 loss 4.054628849029541 train acc 0.0185546875\n",
            "epoch 1 batch id 305 loss 4.053965091705322 train acc 0.018596311475409837\n",
            "epoch 1 batch id 306 loss 4.0640974044799805 train acc 0.018535539215686275\n",
            "epoch 1 batch id 307 loss 4.0826592445373535 train acc 0.018526058631921825\n",
            "epoch 1 batch id 308 loss 4.010373592376709 train acc 0.018516639610389612\n",
            "epoch 1 batch id 309 loss 3.991107940673828 train acc 0.018760113268608415\n",
            "epoch 1 batch id 310 loss 4.074623107910156 train acc 0.018850806451612905\n",
            "epoch 1 batch id 311 loss 4.049334526062012 train acc 0.018840434083601285\n",
            "epoch 1 batch id 312 loss 4.059333801269531 train acc 0.018780048076923076\n",
            "epoch 1 batch id 313 loss 4.049412250518799 train acc 0.018769968051118212\n",
            "epoch 1 batch id 314 loss 4.070757865905762 train acc 0.018809713375796178\n",
            "epoch 1 batch id 315 loss 4.033111572265625 train acc 0.018849206349206348\n",
            "epoch 1 batch id 316 loss 4.07087516784668 train acc 0.018888449367088608\n",
            "epoch 1 batch id 317 loss 4.0092597007751465 train acc 0.01892744479495268\n",
            "epoch 1 batch id 318 loss 4.050965785980225 train acc 0.01911360062893082\n",
            "epoch 1 batch id 319 loss 4.039580821990967 train acc 0.01929858934169279\n",
            "epoch 1 batch id 320 loss 4.0301899909973145 train acc 0.019287109375\n",
            "epoch 1 batch id 321 loss 4.074047565460205 train acc 0.0193243769470405\n",
            "epoch 1 batch id 322 loss 3.994462013244629 train acc 0.019458462732919256\n",
            "epoch 1 batch id 323 loss 4.048757553100586 train acc 0.01944659442724458\n",
            "epoch 1 batch id 324 loss 4.054715633392334 train acc 0.01943479938271605\n",
            "epoch 1 batch id 325 loss 4.084743022918701 train acc 0.019375\n",
            "epoch 1 batch id 326 loss 4.052649974822998 train acc 0.019315567484662576\n",
            "epoch 1 batch id 327 loss 4.041193962097168 train acc 0.01944762996941896\n",
            "epoch 1 batch id 328 loss 4.022144794464111 train acc 0.019435975609756097\n",
            "epoch 1 batch id 329 loss 4.080153465270996 train acc 0.019424392097264438\n",
            "epoch 1 batch id 330 loss 4.051684856414795 train acc 0.01946022727272727\n",
            "epoch 1 batch id 331 loss 4.046825408935547 train acc 0.01949584592145015\n",
            "epoch 1 batch id 332 loss 4.059225082397461 train acc 0.01957831325301205\n",
            "epoch 1 batch id 333 loss 4.014357089996338 train acc 0.019613363363363362\n",
            "epoch 1 batch id 334 loss 4.035996437072754 train acc 0.019601422155688622\n",
            "epoch 1 batch id 335 loss 4.057897090911865 train acc 0.0197294776119403\n",
            "epoch 1 batch id 336 loss 4.036098957061768 train acc 0.019670758928571428\n",
            "epoch 1 batch id 337 loss 3.9926981925964355 train acc 0.01975148367952522\n",
            "epoch 1 batch id 338 loss 4.0077805519104 train acc 0.019831730769230768\n",
            "epoch 1 batch id 339 loss 4.002845287322998 train acc 0.019773230088495575\n",
            "epoch 1 batch id 340 loss 4.001842498779297 train acc 0.019715073529411764\n",
            "epoch 1 batch id 341 loss 4.0343918800354 train acc 0.019794721407624633\n",
            "epoch 1 batch id 342 loss 4.059844493865967 train acc 0.019782529239766082\n",
            "epoch 1 batch id 343 loss 4.04168176651001 train acc 0.019861516034985423\n",
            "epoch 1 batch id 344 loss 3.9620022773742676 train acc 0.01998546511627907\n",
            "epoch 1 batch id 345 loss 4.042832851409912 train acc 0.020018115942028986\n",
            "epoch 1 batch id 346 loss 4.0243964195251465 train acc 0.020095736994219654\n",
            "epoch 1 batch id 347 loss 3.9984469413757324 train acc 0.020217939481268012\n",
            "epoch 1 batch id 348 loss 4.0186662673950195 train acc 0.02038433908045977\n",
            "epoch 1 batch id 349 loss 3.981717586517334 train acc 0.020460243553008597\n",
            "epoch 1 batch id 350 loss 4.017361640930176 train acc 0.02044642857142857\n",
            "epoch 1 batch id 351 loss 4.067070484161377 train acc 0.020388176638176637\n",
            "epoch 1 batch id 352 loss 4.017603397369385 train acc 0.020552201704545456\n",
            "epoch 1 batch id 353 loss 4.023940086364746 train acc 0.020582507082152975\n",
            "epoch 1 batch id 354 loss 4.0414347648620605 train acc 0.020568502824858757\n",
            "epoch 1 batch id 355 loss 4.037871360778809 train acc 0.02068661971830986\n",
            "epoch 1 batch id 356 loss 4.007117748260498 train acc 0.02067240168539326\n",
            "epoch 1 batch id 357 loss 3.947178602218628 train acc 0.02078956582633053\n",
            "epoch 1 batch id 358 loss 3.9972522258758545 train acc 0.02081878491620112\n",
            "epoch 1 batch id 359 loss 4.0175909996032715 train acc 0.020847841225626742\n",
            "epoch 1 batch id 360 loss 4.01926851272583 train acc 0.020963541666666665\n",
            "epoch 1 batch id 361 loss 4.015092372894287 train acc 0.02107860110803324\n",
            "epoch 1 batch id 362 loss 4.005742073059082 train acc 0.02123618784530387\n",
            "epoch 1 batch id 363 loss 4.00163459777832 train acc 0.02130681818181818\n",
            "epoch 1 batch id 364 loss 3.9623422622680664 train acc 0.021462912087912088\n",
            "epoch 1 batch id 365 loss 4.002937316894531 train acc 0.02148972602739726\n",
            "epoch 1 batch id 366 loss 4.030722141265869 train acc 0.021559084699453553\n",
            "epoch 1 batch id 367 loss 4.004573345184326 train acc 0.02158549046321526\n",
            "epoch 1 batch id 368 loss 3.9495034217834473 train acc 0.021696671195652172\n",
            "epoch 1 batch id 369 loss 4.097528457641602 train acc 0.02168021680216802\n",
            "epoch 1 batch id 370 loss 4.019787788391113 train acc 0.02174831081081081\n",
            "epoch 1 batch id 371 loss 4.029330253601074 train acc 0.021816037735849055\n",
            "epoch 1 batch id 372 loss 4.043888568878174 train acc 0.02188340053763441\n",
            "epoch 1 batch id 373 loss 3.978728771209717 train acc 0.021992292225201073\n",
            "epoch 1 batch id 374 loss 3.984973192214966 train acc 0.022184157754010694\n",
            "epoch 1 batch id 375 loss 3.971825361251831 train acc 0.02225\n",
            "epoch 1 batch id 376 loss 4.014436721801758 train acc 0.022357047872340427\n",
            "epoch 1 batch id 377 loss 3.97745418548584 train acc 0.022380636604774535\n",
            "epoch 1 batch id 378 loss 3.9430837631225586 train acc 0.022445436507936508\n",
            "epoch 1 batch id 379 loss 4.0154337882995605 train acc 0.022551121372031663\n",
            "epoch 1 batch id 380 loss 3.966219186782837 train acc 0.022738486842105263\n",
            "epoch 1 batch id 381 loss 4.006665229797363 train acc 0.02271981627296588\n",
            "epoch 1 batch id 382 loss 3.9342710971832275 train acc 0.022946662303664923\n",
            "epoch 1 batch id 383 loss 3.9450390338897705 train acc 0.023131527415143602\n",
            "epoch 1 batch id 384 loss 3.985353469848633 train acc 0.023193359375\n",
            "epoch 1 batch id 385 loss 3.9524378776550293 train acc 0.023376623376623377\n",
            "epoch 1 batch id 386 loss 3.996290922164917 train acc 0.0234375\n",
            "epoch 1 batch id 387 loss 3.9725658893585205 train acc 0.02345768733850129\n",
            "epoch 1 batch id 388 loss 3.963707447052002 train acc 0.023638853092783504\n",
            "epoch 1 batch id 389 loss 3.964426279067993 train acc 0.023658419023136246\n",
            "epoch 1 batch id 390 loss 3.9591259956359863 train acc 0.02375801282051282\n",
            "epoch 1 batch id 391 loss 3.9436933994293213 train acc 0.02377717391304348\n",
            "epoch 1 batch id 392 loss 3.956425428390503 train acc 0.023995535714285716\n",
            "epoch 1 batch id 393 loss 3.960860252380371 train acc 0.024053753180661577\n",
            "epoch 1 batch id 394 loss 3.9657323360443115 train acc 0.024111675126903553\n",
            "epoch 1 batch id 395 loss 4.0088701248168945 train acc 0.024129746835443038\n",
            "epoch 1 batch id 396 loss 3.9763247966766357 train acc 0.024266098484848484\n",
            "epoch 1 batch id 397 loss 3.9034786224365234 train acc 0.02455919395465995\n",
            "epoch 1 batch id 398 loss 3.8968241214752197 train acc 0.024772298994974875\n",
            "epoch 1 batch id 399 loss 4.005792140960693 train acc 0.024788533834586467\n",
            "epoch 1 batch id 400 loss 3.953368663787842 train acc 0.024921875\n",
            "epoch 1 batch id 401 loss 3.977567434310913 train acc 0.024976620947630923\n",
            "epoch 1 batch id 402 loss 3.940345287322998 train acc 0.025069962686567165\n",
            "epoch 1 batch id 403 loss 3.9807560443878174 train acc 0.02512406947890819\n",
            "epoch 1 batch id 404 loss 3.9650485515594482 train acc 0.025139232673267328\n",
            "epoch 1 batch id 405 loss 3.974365711212158 train acc 0.02515432098765432\n",
            "epoch 1 batch id 406 loss 3.9716596603393555 train acc 0.025130849753694583\n",
            "epoch 1 batch id 407 loss 4.032414436340332 train acc 0.025184275184275184\n",
            "epoch 1 batch id 408 loss 3.9520020484924316 train acc 0.025199142156862746\n",
            "epoch 1 batch id 409 loss 3.930842638015747 train acc 0.025252139364303178\n",
            "epoch 1 batch id 410 loss 3.953359365463257 train acc 0.02534298780487805\n",
            "epoch 1 batch id 411 loss 3.9890575408935547 train acc 0.0253573600973236\n",
            "epoch 1 batch id 412 loss 4.010824680328369 train acc 0.02533373786407767\n",
            "epoch 1 batch id 413 loss 3.959484577178955 train acc 0.02538589588377724\n",
            "epoch 1 batch id 414 loss 3.9185285568237305 train acc 0.025437801932367148\n",
            "epoch 1 batch id 415 loss 3.927236795425415 train acc 0.02552710843373494\n",
            "epoch 1 batch id 416 loss 3.9600954055786133 train acc 0.025615985576923076\n",
            "epoch 1 batch id 417 loss 3.9165682792663574 train acc 0.025741906474820143\n",
            "epoch 1 batch id 418 loss 3.866852283477783 train acc 0.025941985645933013\n",
            "epoch 1 batch id 419 loss 3.9061083793640137 train acc 0.026252983293556086\n",
            "epoch 1 batch id 420 loss 3.9429192543029785 train acc 0.026450892857142857\n",
            "epoch 1 batch id 421 loss 3.933110237121582 train acc 0.026573634204275533\n",
            "epoch 1 batch id 422 loss 3.926664352416992 train acc 0.026769845971563982\n",
            "epoch 1 batch id 423 loss 3.929130792617798 train acc 0.02685431442080378\n",
            "epoch 1 batch id 424 loss 3.9085848331451416 train acc 0.026901533018867923\n",
            "epoch 1 batch id 425 loss 3.8960540294647217 train acc 0.027095588235294118\n",
            "epoch 1 batch id 426 loss 3.9168591499328613 train acc 0.027142018779342723\n",
            "epoch 1 batch id 427 loss 3.8887200355529785 train acc 0.027224824355971896\n",
            "epoch 1 batch id 428 loss 3.8592488765716553 train acc 0.02741676401869159\n",
            "epoch 1 batch id 429 loss 3.8992443084716797 train acc 0.027498543123543124\n",
            "epoch 1 batch id 430 loss 3.9347493648529053 train acc 0.02754360465116279\n",
            "epoch 1 batch id 431 loss 3.9063773155212402 train acc 0.027624709976798143\n",
            "epoch 1 batch id 432 loss 3.951488733291626 train acc 0.027705439814814815\n",
            "epoch 1 batch id 433 loss 3.9198291301727295 train acc 0.02800230946882217\n",
            "epoch 1 batch id 434 loss 3.930053949356079 train acc 0.02808179723502304\n",
            "epoch 1 batch id 435 loss 3.8934130668640137 train acc 0.028232758620689656\n",
            "epoch 1 batch id 436 loss 3.950868606567383 train acc 0.028454701834862386\n",
            "epoch 1 batch id 437 loss 3.8617537021636963 train acc 0.028818649885583525\n",
            "epoch 1 batch id 438 loss 3.8814189434051514 train acc 0.029002568493150686\n",
            "epoch 1 batch id 439 loss 3.8352651596069336 train acc 0.02922124145785877\n",
            "epoch 1 batch id 440 loss 3.9546146392822266 train acc 0.029332386363636363\n",
            "epoch 1 batch id 441 loss 3.9063076972961426 train acc 0.02947845804988662\n",
            "epoch 1 batch id 442 loss 3.899005889892578 train acc 0.02955316742081448\n",
            "epoch 1 batch id 443 loss 3.905097484588623 train acc 0.029803893905191874\n",
            "epoch 1 batch id 444 loss 3.8335165977478027 train acc 0.029947916666666668\n",
            "epoch 1 batch id 445 loss 3.88889217376709 train acc 0.030196629213483147\n",
            "epoch 1 batch id 446 loss 3.877870559692383 train acc 0.030198991031390135\n",
            "epoch 1 batch id 447 loss 3.899312734603882 train acc 0.03034116331096197\n",
            "epoch 1 batch id 448 loss 3.8496153354644775 train acc 0.030552455357142856\n",
            "epoch 1 batch id 449 loss 3.834153413772583 train acc 0.03076280623608018\n",
            "epoch 1 batch id 450 loss 3.9175758361816406 train acc 0.030833333333333334\n",
            "epoch 1 batch id 451 loss 3.807067632675171 train acc 0.031111419068736143\n",
            "epoch 1 batch id 452 loss 3.8538451194763184 train acc 0.03125\n",
            "epoch 1 batch id 453 loss 3.8217854499816895 train acc 0.03145695364238411\n",
            "epoch 1 batch id 454 loss 3.8646011352539062 train acc 0.031490914096916296\n",
            "epoch 1 batch id 455 loss 3.832364082336426 train acc 0.03166208791208791\n",
            "epoch 1 batch id 456 loss 3.940775156021118 train acc 0.03179824561403509\n",
            "epoch 1 batch id 457 loss 3.8237433433532715 train acc 0.031899617067833695\n",
            "epoch 1 batch id 458 loss 3.868175983428955 train acc 0.03200054585152838\n",
            "epoch 1 batch id 459 loss 3.8786442279815674 train acc 0.03203295206971678\n",
            "epoch 1 batch id 460 loss 3.8648416996002197 train acc 0.03220108695652174\n",
            "epoch 1 batch id 461 loss 3.8447165489196777 train acc 0.03243627982646421\n",
            "epoch 1 batch id 462 loss 3.8136990070343018 train acc 0.032771915584415584\n",
            "epoch 1 batch id 463 loss 3.8542873859405518 train acc 0.03297111231101512\n",
            "epoch 1 batch id 464 loss 3.8447256088256836 train acc 0.03303475215517242\n",
            "epoch 1 batch id 465 loss 3.90718674659729 train acc 0.03313172043010753\n",
            "epoch 1 batch id 466 loss 3.8697874546051025 train acc 0.0333288626609442\n",
            "epoch 1 batch id 467 loss 3.9033353328704834 train acc 0.03329095289079229\n",
            "epoch 1 batch id 468 loss 3.8236806392669678 train acc 0.03331997863247863\n",
            "epoch 1 batch id 469 loss 3.819673538208008 train acc 0.03341551172707889\n",
            "epoch 1 batch id 470 loss 3.889552593231201 train acc 0.033543882978723405\n",
            "epoch 1 batch id 471 loss 3.8305628299713135 train acc 0.03373805732484077\n",
            "epoch 1 batch id 472 loss 3.7826287746429443 train acc 0.03386520127118644\n",
            "epoch 1 batch id 473 loss 3.8075082302093506 train acc 0.03409090909090909\n",
            "epoch 1 batch id 474 loss 3.7810757160186768 train acc 0.03431566455696203\n",
            "epoch 1 batch id 475 loss 3.7849459648132324 train acc 0.03444078947368421\n",
            "epoch 1 batch id 476 loss 3.8621673583984375 train acc 0.034499737394957986\n",
            "epoch 1 batch id 477 loss 3.8336987495422363 train acc 0.03465670859538784\n",
            "epoch 1 batch id 478 loss 3.910673141479492 train acc 0.034682269874476986\n",
            "epoch 1 batch id 479 loss 3.7896392345428467 train acc 0.03487082463465553\n",
            "epoch 1 batch id 480 loss 3.7368836402893066 train acc 0.034895833333333334\n",
            "epoch 1 batch id 481 loss 3.8680219650268555 train acc 0.034920738045738045\n",
            "epoch 1 batch id 482 loss 3.7878098487854004 train acc 0.035042790456431536\n",
            "epoch 1 batch id 483 loss 3.798638343811035 train acc 0.03529373706004141\n",
            "epoch 1 batch id 484 loss 3.8583950996398926 train acc 0.03538223140495868\n",
            "epoch 1 batch id 485 loss 3.8259527683258057 train acc 0.03547036082474227\n",
            "epoch 1 batch id 486 loss 3.77909255027771 train acc 0.035622427983539096\n",
            "epoch 1 batch id 487 loss 3.8429811000823975 train acc 0.0357097022587269\n",
            "epoch 1 batch id 488 loss 3.8433806896209717 train acc 0.035796618852459015\n",
            "epoch 1 batch id 489 loss 3.8699426651000977 train acc 0.035819274028629854\n",
            "epoch 1 batch id 490 loss 3.7903783321380615 train acc 0.036033163265306124\n",
            "epoch 1 batch id 491 loss 3.730665445327759 train acc 0.036278004073319756\n",
            "epoch 1 batch id 492 loss 3.825821876525879 train acc 0.03633130081300813\n",
            "epoch 1 batch id 493 loss 3.8447225093841553 train acc 0.03644776876267748\n",
            "epoch 1 batch id 494 loss 3.827868938446045 train acc 0.036595394736842105\n",
            "epoch 1 batch id 495 loss 3.8672173023223877 train acc 0.036616161616161616\n",
            "epoch 1 batch id 496 loss 3.7649502754211426 train acc 0.03673135080645161\n",
            "epoch 1 batch id 497 loss 3.75714373588562 train acc 0.036940392354124746\n",
            "epoch 1 batch id 498 loss 3.7650415897369385 train acc 0.03699171686746988\n",
            "epoch 1 batch id 499 loss 3.8575031757354736 train acc 0.03723071142284569\n",
            "epoch 1 batch id 500 loss 3.778801441192627 train acc 0.03721875\n",
            "epoch 1 batch id 501 loss 3.7839324474334717 train acc 0.03730039920159681\n",
            "epoch 1 batch id 502 loss 3.772913932800293 train acc 0.0375996015936255\n",
            "epoch 1 batch id 503 loss 3.736398220062256 train acc 0.037804423459244535\n",
            "epoch 1 batch id 504 loss 3.718928575515747 train acc 0.038070436507936505\n",
            "epoch 1 batch id 505 loss 3.7504420280456543 train acc 0.03818069306930693\n",
            "epoch 1 batch id 506 loss 3.8063511848449707 train acc 0.03835227272727273\n",
            "epoch 1 batch id 507 loss 3.6728286743164062 train acc 0.038553994082840236\n",
            "epoch 1 batch id 508 loss 3.800459861755371 train acc 0.038662647637795276\n",
            "epoch 1 batch id 509 loss 3.72190260887146 train acc 0.0387401768172888\n",
            "epoch 1 batch id 510 loss 3.7521815299987793 train acc 0.03893995098039216\n",
            "epoch 1 batch id 511 loss 3.770773410797119 train acc 0.039081186127419\n",
            "epoch 1 train acc 0.039081186127419\n",
            "epoch 1 test acc 0.14432779947916666\n",
            "epoch 2 batch id 1 loss 3.753918409347534 train acc 0.109375\n",
            "epoch 2 batch id 2 loss 3.927593946456909 train acc 0.09375\n",
            "epoch 2 batch id 3 loss 3.827523708343506 train acc 0.10416666666666667\n",
            "epoch 2 batch id 4 loss 3.7797789573669434 train acc 0.10546875\n",
            "epoch 2 batch id 5 loss 3.7033047676086426 train acc 0.109375\n",
            "epoch 2 batch id 6 loss 3.6852004528045654 train acc 0.11197916666666667\n",
            "epoch 2 batch id 7 loss 3.7725508213043213 train acc 0.11607142857142858\n",
            "epoch 2 batch id 8 loss 3.760228157043457 train acc 0.12109375\n",
            "epoch 2 batch id 9 loss 3.7101941108703613 train acc 0.125\n",
            "epoch 2 batch id 10 loss 3.802273988723755 train acc 0.121875\n",
            "epoch 2 batch id 11 loss 3.774209976196289 train acc 0.12215909090909091\n",
            "epoch 2 batch id 12 loss 3.780416250228882 train acc 0.11979166666666667\n",
            "epoch 2 batch id 13 loss 3.736485719680786 train acc 0.12620192307692307\n",
            "epoch 2 batch id 14 loss 3.737637519836426 train acc 0.12723214285714285\n",
            "epoch 2 batch id 15 loss 3.7490713596343994 train acc 0.13125\n",
            "epoch 2 batch id 16 loss 3.8041934967041016 train acc 0.126953125\n",
            "epoch 2 batch id 17 loss 3.762434244155884 train acc 0.12591911764705882\n",
            "epoch 2 batch id 18 loss 3.625636339187622 train acc 0.1345486111111111\n",
            "epoch 2 batch id 19 loss 3.6919777393341064 train acc 0.13157894736842105\n",
            "epoch 2 batch id 20 loss 3.752992630004883 train acc 0.13046875\n",
            "epoch 2 batch id 21 loss 3.723738670349121 train acc 0.13169642857142858\n",
            "epoch 2 batch id 22 loss 3.782351493835449 train acc 0.1328125\n",
            "epoch 2 batch id 23 loss 3.7479588985443115 train acc 0.13451086956521738\n",
            "epoch 2 batch id 24 loss 3.7612640857696533 train acc 0.13606770833333334\n",
            "epoch 2 batch id 25 loss 3.7843477725982666 train acc 0.13375\n",
            "epoch 2 batch id 26 loss 3.710439443588257 train acc 0.13401442307692307\n",
            "epoch 2 batch id 27 loss 3.6885995864868164 train acc 0.13541666666666666\n",
            "epoch 2 batch id 28 loss 3.7871146202087402 train acc 0.13392857142857142\n",
            "epoch 2 batch id 29 loss 3.773637533187866 train acc 0.13308189655172414\n",
            "epoch 2 batch id 30 loss 3.748647928237915 train acc 0.13229166666666667\n",
            "epoch 2 batch id 31 loss 3.7356650829315186 train acc 0.13205645161290322\n",
            "epoch 2 batch id 32 loss 3.7049405574798584 train acc 0.1337890625\n",
            "epoch 2 batch id 33 loss 3.709639549255371 train acc 0.13162878787878787\n",
            "epoch 2 batch id 34 loss 3.5886168479919434 train acc 0.13511029411764705\n",
            "epoch 2 batch id 35 loss 3.7028591632843018 train acc 0.13392857142857142\n",
            "epoch 2 batch id 36 loss 3.770170211791992 train acc 0.13411458333333334\n",
            "epoch 2 batch id 37 loss 3.684197425842285 train acc 0.13471283783783783\n",
            "epoch 2 batch id 38 loss 3.641308546066284 train acc 0.13610197368421054\n",
            "epoch 2 batch id 39 loss 3.5753259658813477 train acc 0.13982371794871795\n",
            "epoch 2 batch id 40 loss 3.76096773147583 train acc 0.1390625\n",
            "epoch 2 batch id 41 loss 3.7133712768554688 train acc 0.13833841463414634\n",
            "epoch 2 batch id 42 loss 3.719562292098999 train acc 0.13764880952380953\n",
            "epoch 2 batch id 43 loss 3.756143569946289 train acc 0.13662790697674418\n",
            "epoch 2 batch id 44 loss 3.7221224308013916 train acc 0.13600852272727273\n",
            "epoch 2 batch id 45 loss 3.6305055618286133 train acc 0.1371527777777778\n",
            "epoch 2 batch id 46 loss 3.6943764686584473 train acc 0.13654891304347827\n",
            "epoch 2 batch id 47 loss 3.667820692062378 train acc 0.1363031914893617\n",
            "epoch 2 batch id 48 loss 3.6424238681793213 train acc 0.13606770833333334\n",
            "epoch 2 batch id 49 loss 3.736171245574951 train acc 0.13584183673469388\n",
            "epoch 2 batch id 50 loss 3.6986212730407715 train acc 0.1353125\n",
            "epoch 2 batch id 51 loss 3.6579198837280273 train acc 0.13572303921568626\n",
            "epoch 2 batch id 52 loss 3.7973790168762207 train acc 0.1346153846153846\n",
            "epoch 2 batch id 53 loss 3.684154510498047 train acc 0.13502358490566038\n",
            "epoch 2 batch id 54 loss 3.7400593757629395 train acc 0.13483796296296297\n",
            "epoch 2 batch id 55 loss 3.7580959796905518 train acc 0.13551136363636362\n",
            "epoch 2 batch id 56 loss 3.7217562198638916 train acc 0.13588169642857142\n",
            "epoch 2 batch id 57 loss 3.710188150405884 train acc 0.1367872807017544\n",
            "epoch 2 batch id 58 loss 3.626880168914795 train acc 0.13712284482758622\n",
            "epoch 2 batch id 59 loss 3.7211415767669678 train acc 0.13665254237288135\n",
            "epoch 2 batch id 60 loss 3.5972046852111816 train acc 0.13802083333333334\n",
            "epoch 2 batch id 61 loss 3.617783308029175 train acc 0.13831967213114754\n",
            "epoch 2 batch id 62 loss 3.758455514907837 train acc 0.1381048387096774\n",
            "epoch 2 batch id 63 loss 3.65437650680542 train acc 0.1378968253968254\n",
            "epoch 2 batch id 64 loss 3.6770248413085938 train acc 0.137939453125\n",
            "epoch 2 batch id 65 loss 3.627199411392212 train acc 0.13870192307692308\n",
            "epoch 2 batch id 66 loss 3.6854422092437744 train acc 0.1387310606060606\n",
            "epoch 2 batch id 67 loss 3.702932357788086 train acc 0.13922574626865672\n",
            "epoch 2 batch id 68 loss 3.5494372844696045 train acc 0.140625\n",
            "epoch 2 batch id 69 loss 3.6596546173095703 train acc 0.13971920289855072\n",
            "epoch 2 batch id 70 loss 3.7041690349578857 train acc 0.140625\n",
            "epoch 2 batch id 71 loss 3.6592040061950684 train acc 0.13952464788732394\n",
            "epoch 2 batch id 72 loss 3.7104616165161133 train acc 0.13932291666666666\n",
            "epoch 2 batch id 73 loss 3.6280596256256104 train acc 0.1401969178082192\n",
            "epoch 2 batch id 74 loss 3.6591484546661377 train acc 0.13999155405405406\n",
            "epoch 2 batch id 75 loss 3.664038896560669 train acc 0.14\n",
            "epoch 2 batch id 76 loss 3.7014777660369873 train acc 0.13980263157894737\n",
            "epoch 2 batch id 77 loss 3.708289861679077 train acc 0.13981331168831168\n",
            "epoch 2 batch id 78 loss 3.4954025745391846 train acc 0.14102564102564102\n",
            "epoch 2 batch id 79 loss 3.5823464393615723 train acc 0.1418117088607595\n",
            "epoch 2 batch id 80 loss 3.5999271869659424 train acc 0.143359375\n",
            "epoch 2 batch id 81 loss 3.5320515632629395 train acc 0.1440972222222222\n",
            "epoch 2 batch id 82 loss 3.635364532470703 train acc 0.14405487804878048\n",
            "epoch 2 batch id 83 loss 3.638461112976074 train acc 0.14495481927710843\n",
            "epoch 2 batch id 84 loss 3.6754262447357178 train acc 0.14583333333333334\n",
            "epoch 2 batch id 85 loss 3.5326991081237793 train acc 0.14761029411764706\n",
            "epoch 2 batch id 86 loss 3.6189231872558594 train acc 0.1484375\n",
            "epoch 2 batch id 87 loss 3.5689401626586914 train acc 0.1492456896551724\n",
            "epoch 2 batch id 88 loss 3.575026750564575 train acc 0.15021306818181818\n",
            "epoch 2 batch id 89 loss 3.6079905033111572 train acc 0.15098314606741572\n",
            "epoch 2 batch id 90 loss 3.693622350692749 train acc 0.15086805555555555\n",
            "epoch 2 batch id 91 loss 3.6181857585906982 train acc 0.1507554945054945\n",
            "epoch 2 batch id 92 loss 3.671485185623169 train acc 0.15098505434782608\n",
            "epoch 2 batch id 93 loss 3.7326457500457764 train acc 0.15003360215053763\n",
            "epoch 2 batch id 94 loss 3.738309144973755 train acc 0.15093085106382978\n",
            "epoch 2 batch id 95 loss 3.557771921157837 train acc 0.15098684210526317\n",
            "epoch 2 batch id 96 loss 3.596985340118408 train acc 0.15152994791666666\n",
            "epoch 2 batch id 97 loss 3.5693628787994385 train acc 0.15206185567010308\n",
            "epoch 2 batch id 98 loss 3.5887064933776855 train acc 0.1519451530612245\n",
            "epoch 2 batch id 99 loss 3.659653902053833 train acc 0.15198863636363635\n",
            "epoch 2 batch id 100 loss 3.6099836826324463 train acc 0.15203125\n",
            "epoch 2 batch id 101 loss 3.64902400970459 train acc 0.15269183168316833\n",
            "epoch 2 batch id 102 loss 3.7226545810699463 train acc 0.15226715686274508\n",
            "epoch 2 batch id 103 loss 3.6881134510040283 train acc 0.15230582524271843\n",
            "epoch 2 batch id 104 loss 3.549553155899048 train acc 0.15294471153846154\n",
            "epoch 2 batch id 105 loss 3.59793758392334 train acc 0.15342261904761906\n",
            "epoch 2 batch id 106 loss 3.6246068477630615 train acc 0.15359669811320756\n",
            "epoch 2 batch id 107 loss 3.621363878250122 train acc 0.15391355140186916\n",
            "epoch 2 batch id 108 loss 3.5332396030426025 train acc 0.15465856481481483\n",
            "epoch 2 batch id 109 loss 3.5456490516662598 train acc 0.15524655963302753\n",
            "epoch 2 batch id 110 loss 3.5468039512634277 train acc 0.15582386363636364\n",
            "epoch 2 batch id 111 loss 3.626418352127075 train acc 0.15582770270270271\n",
            "epoch 2 batch id 112 loss 3.4274890422821045 train acc 0.15625\n",
            "epoch 2 batch id 113 loss 3.5219948291778564 train acc 0.15680309734513273\n",
            "epoch 2 batch id 114 loss 3.5804708003997803 train acc 0.15762061403508773\n",
            "epoch 2 batch id 115 loss 3.593787670135498 train acc 0.1580163043478261\n",
            "epoch 2 batch id 116 loss 3.4684879779815674 train acc 0.1584051724137931\n",
            "epoch 2 batch id 117 loss 3.5068581104278564 train acc 0.15878739316239315\n",
            "epoch 2 batch id 118 loss 3.5937724113464355 train acc 0.15916313559322035\n",
            "epoch 2 batch id 119 loss 3.5647096633911133 train acc 0.15979516806722688\n",
            "epoch 2 batch id 120 loss 3.49992036819458 train acc 0.160546875\n",
            "epoch 2 batch id 121 loss 3.609617233276367 train acc 0.16102789256198347\n",
            "epoch 2 batch id 122 loss 3.5735557079315186 train acc 0.16086065573770492\n",
            "epoch 2 batch id 123 loss 3.549297332763672 train acc 0.16082317073170732\n",
            "epoch 2 batch id 124 loss 3.5459325313568115 train acc 0.16129032258064516\n",
            "epoch 2 batch id 125 loss 3.6703200340270996 train acc 0.16125\n",
            "epoch 2 batch id 126 loss 3.6956756114959717 train acc 0.16145833333333334\n",
            "epoch 2 batch id 127 loss 3.640631914138794 train acc 0.16154035433070865\n",
            "epoch 2 batch id 128 loss 3.510763168334961 train acc 0.1612548828125\n",
            "epoch 2 batch id 129 loss 3.5092759132385254 train acc 0.1615794573643411\n",
            "epoch 2 batch id 130 loss 3.6188247203826904 train acc 0.16177884615384616\n",
            "epoch 2 batch id 131 loss 3.470114231109619 train acc 0.16257156488549618\n",
            "epoch 2 batch id 132 loss 3.5432422161102295 train acc 0.1629971590909091\n",
            "epoch 2 batch id 133 loss 3.6265909671783447 train acc 0.1631813909774436\n",
            "epoch 2 batch id 134 loss 3.513988733291626 train acc 0.16394589552238806\n",
            "epoch 2 batch id 135 loss 3.5487325191497803 train acc 0.16435185185185186\n",
            "epoch 2 batch id 136 loss 3.6199305057525635 train acc 0.16463694852941177\n",
            "epoch 2 batch id 137 loss 3.5671160221099854 train acc 0.1645757299270073\n",
            "epoch 2 batch id 138 loss 3.5410757064819336 train acc 0.16496829710144928\n",
            "epoch 2 batch id 139 loss 3.506355047225952 train acc 0.16569244604316546\n",
            "epoch 2 batch id 140 loss 3.530927896499634 train acc 0.16551339285714287\n",
            "epoch 2 batch id 141 loss 3.5413944721221924 train acc 0.16566932624113476\n",
            "epoch 2 batch id 142 loss 3.3862826824188232 train acc 0.1660431338028169\n",
            "epoch 2 batch id 143 loss 3.494058132171631 train acc 0.16641171328671328\n",
            "epoch 2 batch id 144 loss 3.4940268993377686 train acc 0.16688368055555555\n",
            "epoch 2 batch id 145 loss 3.5318644046783447 train acc 0.16734913793103448\n",
            "epoch 2 batch id 146 loss 3.4370028972625732 train acc 0.167701198630137\n",
            "epoch 2 batch id 147 loss 3.439345359802246 train acc 0.1682610544217687\n",
            "epoch 2 batch id 148 loss 3.5301477909088135 train acc 0.16828547297297297\n",
            "epoch 2 batch id 149 loss 3.4353599548339844 train acc 0.16904362416107382\n",
            "epoch 2 batch id 150 loss 3.5013599395751953 train acc 0.169375\n",
            "epoch 2 batch id 151 loss 3.4950411319732666 train acc 0.16980546357615894\n",
            "epoch 2 batch id 152 loss 3.5460500717163086 train acc 0.16981907894736842\n",
            "epoch 2 batch id 153 loss 3.499743700027466 train acc 0.1698325163398693\n",
            "epoch 2 batch id 154 loss 3.607212543487549 train acc 0.1700487012987013\n",
            "epoch 2 batch id 155 loss 3.465615749359131 train acc 0.17026209677419354\n",
            "epoch 2 batch id 156 loss 3.460861921310425 train acc 0.17057291666666666\n",
            "epoch 2 batch id 157 loss 3.4589333534240723 train acc 0.1702826433121019\n",
            "epoch 2 batch id 158 loss 3.513622522354126 train acc 0.17039161392405064\n",
            "epoch 2 batch id 159 loss 3.4913997650146484 train acc 0.17069575471698112\n",
            "epoch 2 batch id 160 loss 3.401468276977539 train acc 0.17109375\n",
            "epoch 2 batch id 161 loss 3.561338424682617 train acc 0.17148680124223603\n",
            "epoch 2 batch id 162 loss 3.5534133911132812 train acc 0.1716820987654321\n",
            "epoch 2 batch id 163 loss 3.5156195163726807 train acc 0.17206671779141106\n",
            "epoch 2 batch id 164 loss 3.4765379428863525 train acc 0.17235137195121952\n",
            "epoch 2 batch id 165 loss 3.548020362854004 train acc 0.17196969696969697\n",
            "epoch 2 batch id 166 loss 3.446218252182007 train acc 0.17234563253012047\n",
            "epoch 2 batch id 167 loss 3.4691689014434814 train acc 0.17271706586826346\n",
            "epoch 2 batch id 168 loss 3.443869113922119 train acc 0.17252604166666666\n",
            "epoch 2 batch id 169 loss 3.415628671646118 train acc 0.1726146449704142\n",
            "epoch 2 batch id 170 loss 3.472254514694214 train acc 0.17306985294117647\n",
            "epoch 2 batch id 171 loss 3.4190165996551514 train acc 0.1736111111111111\n",
            "epoch 2 batch id 172 loss 3.4427459239959717 train acc 0.1738735465116279\n",
            "epoch 2 batch id 173 loss 3.6934614181518555 train acc 0.17359104046242774\n",
            "epoch 2 batch id 174 loss 3.4007887840270996 train acc 0.17358117816091953\n",
            "epoch 2 batch id 175 loss 3.412302017211914 train acc 0.17366071428571428\n",
            "epoch 2 batch id 176 loss 3.5961263179779053 train acc 0.1737393465909091\n",
            "epoch 2 batch id 177 loss 3.5128333568573 train acc 0.1742584745762712\n",
            "epoch 2 batch id 178 loss 3.382049560546875 train acc 0.17503511235955055\n",
            "epoch 2 batch id 179 loss 3.472025156021118 train acc 0.17562849162011174\n",
            "epoch 2 batch id 180 loss 3.4417500495910645 train acc 0.17578125\n",
            "epoch 2 batch id 181 loss 3.480027914047241 train acc 0.17558701657458564\n",
            "epoch 2 batch id 182 loss 3.420255184173584 train acc 0.17539491758241757\n",
            "epoch 2 batch id 183 loss 3.4759161472320557 train acc 0.17520491803278687\n",
            "epoch 2 batch id 184 loss 3.5657734870910645 train acc 0.17510190217391305\n",
            "epoch 2 batch id 185 loss 3.4702775478363037 train acc 0.1755912162162162\n",
            "epoch 2 batch id 186 loss 3.356090545654297 train acc 0.17615927419354838\n",
            "epoch 2 batch id 187 loss 3.545557737350464 train acc 0.17655414438502673\n",
            "epoch 2 batch id 188 loss 3.369347333908081 train acc 0.17677859042553193\n",
            "epoch 2 batch id 189 loss 3.589047431945801 train acc 0.17683531746031747\n",
            "epoch 2 batch id 190 loss 3.475395917892456 train acc 0.1769736842105263\n",
            "epoch 2 batch id 191 loss 3.4024417400360107 train acc 0.17735602094240838\n",
            "epoch 2 batch id 192 loss 3.5933749675750732 train acc 0.17724609375\n",
            "epoch 2 batch id 193 loss 3.5893874168395996 train acc 0.17713730569948186\n",
            "epoch 2 batch id 194 loss 3.5537030696868896 train acc 0.17702963917525774\n",
            "epoch 2 batch id 195 loss 3.400428533554077 train acc 0.17764423076923078\n",
            "epoch 2 batch id 196 loss 3.413177251815796 train acc 0.17801339285714285\n",
            "epoch 2 batch id 197 loss 3.5510168075561523 train acc 0.17837880710659898\n",
            "epoch 2 batch id 198 loss 3.6042940616607666 train acc 0.17858270202020202\n",
            "epoch 2 batch id 199 loss 3.4646408557891846 train acc 0.17886306532663315\n",
            "epoch 2 batch id 200 loss 3.396674156188965 train acc 0.179140625\n",
            "epoch 2 batch id 201 loss 3.404757261276245 train acc 0.1794931592039801\n",
            "epoch 2 batch id 202 loss 3.5496673583984375 train acc 0.17945544554455445\n",
            "epoch 2 batch id 203 loss 3.50350022315979 train acc 0.17964901477832512\n",
            "epoch 2 batch id 204 loss 3.4065496921539307 train acc 0.17961090686274508\n",
            "epoch 2 batch id 205 loss 3.5262374877929688 train acc 0.1794969512195122\n",
            "epoch 2 batch id 206 loss 3.1940882205963135 train acc 0.18052184466019416\n",
            "epoch 2 batch id 207 loss 3.338899612426758 train acc 0.18093297101449277\n",
            "epoch 2 batch id 208 loss 3.4472880363464355 train acc 0.18103966346153846\n",
            "epoch 2 batch id 209 loss 3.306420087814331 train acc 0.18136961722488038\n",
            "epoch 2 batch id 210 loss 3.3457419872283936 train acc 0.18132440476190476\n",
            "epoch 2 batch id 211 loss 3.3359646797180176 train acc 0.1817239336492891\n",
            "epoch 2 batch id 212 loss 3.542318105697632 train acc 0.18175117924528303\n",
            "epoch 2 batch id 213 loss 3.51435923576355 train acc 0.18192488262910797\n",
            "epoch 2 batch id 214 loss 3.554034948348999 train acc 0.18202394859813084\n",
            "epoch 2 batch id 215 loss 3.3210201263427734 train acc 0.18255813953488373\n",
            "epoch 2 batch id 216 loss 3.420790910720825 train acc 0.1830150462962963\n",
            "epoch 2 batch id 217 loss 3.5371387004852295 train acc 0.18296370967741934\n",
            "epoch 2 batch id 218 loss 3.5468196868896484 train acc 0.18305619266055045\n",
            "epoch 2 batch id 219 loss 3.40864896774292 train acc 0.1831478310502283\n",
            "epoch 2 batch id 220 loss 3.316347599029541 train acc 0.18366477272727272\n",
            "epoch 2 batch id 221 loss 3.4206831455230713 train acc 0.18347002262443438\n",
            "epoch 2 batch id 222 loss 3.5056610107421875 train acc 0.18348817567567569\n",
            "epoch 2 batch id 223 loss 3.5028140544891357 train acc 0.18385650224215247\n",
            "epoch 2 batch id 224 loss 3.2972443103790283 train acc 0.18450055803571427\n",
            "epoch 2 batch id 225 loss 3.563187837600708 train acc 0.18458333333333332\n",
            "epoch 2 batch id 226 loss 3.265253782272339 train acc 0.18508019911504425\n",
            "epoch 2 batch id 227 loss 3.320472478866577 train acc 0.18564151982378854\n",
            "epoch 2 batch id 228 loss 3.4506711959838867 train acc 0.18564967105263158\n",
            "epoch 2 batch id 229 loss 3.4529764652252197 train acc 0.1859306768558952\n",
            "epoch 2 batch id 230 loss 3.3747575283050537 train acc 0.18620923913043477\n",
            "epoch 2 batch id 231 loss 3.502070665359497 train acc 0.18628246753246752\n",
            "epoch 2 batch id 232 loss 3.3968558311462402 train acc 0.18648976293103448\n",
            "epoch 2 batch id 233 loss 3.3701581954956055 train acc 0.18676233905579398\n",
            "epoch 2 batch id 234 loss 3.4902865886688232 train acc 0.18683226495726496\n",
            "epoch 2 batch id 235 loss 3.5169241428375244 train acc 0.18683510638297873\n",
            "epoch 2 batch id 236 loss 3.4091005325317383 train acc 0.1869041313559322\n",
            "epoch 2 batch id 237 loss 3.4510717391967773 train acc 0.18677478902953587\n",
            "epoch 2 batch id 238 loss 3.435373306274414 train acc 0.187171743697479\n",
            "epoch 2 batch id 239 loss 3.3847577571868896 train acc 0.18723849372384938\n",
            "epoch 2 batch id 240 loss 3.4372589588165283 train acc 0.18756510416666666\n",
            "epoch 2 batch id 241 loss 3.3381898403167725 train acc 0.18782417012448133\n",
            "epoch 2 batch id 242 loss 3.3980178833007812 train acc 0.1880810950413223\n",
            "epoch 2 batch id 243 loss 3.40228009223938 train acc 0.1884645061728395\n",
            "epoch 2 batch id 244 loss 3.3852829933166504 train acc 0.18871670081967212\n",
            "epoch 2 batch id 245 loss 3.272003650665283 train acc 0.1889668367346939\n",
            "epoch 2 batch id 246 loss 3.4868345260620117 train acc 0.18902439024390244\n",
            "epoch 2 batch id 247 loss 3.4958691596984863 train acc 0.1888917004048583\n",
            "epoch 2 batch id 248 loss 3.2987890243530273 train acc 0.1892641129032258\n",
            "epoch 2 batch id 249 loss 3.3635010719299316 train acc 0.18950803212851405\n",
            "epoch 2 batch id 250 loss 3.432103157043457 train acc 0.18975\n",
            "epoch 2 batch id 251 loss 3.205010414123535 train acc 0.19011454183266932\n",
            "epoch 2 batch id 252 loss 3.3609530925750732 train acc 0.1904141865079365\n",
            "epoch 2 batch id 253 loss 3.3597710132598877 train acc 0.1907732213438735\n",
            "epoch 2 batch id 254 loss 3.378553867340088 train acc 0.19094488188976377\n",
            "epoch 2 batch id 255 loss 3.3380839824676514 train acc 0.19136029411764705\n",
            "epoch 2 batch id 256 loss 3.381273031234741 train acc 0.19140625\n",
            "epoch 2 batch id 257 loss 3.3840715885162354 train acc 0.19169503891050585\n",
            "epoch 2 batch id 258 loss 3.3111143112182617 train acc 0.19192102713178294\n",
            "epoch 2 batch id 259 loss 3.5386102199554443 train acc 0.19190395752895753\n",
            "epoch 2 batch id 260 loss 3.3882699012756348 train acc 0.1920673076923077\n",
            "epoch 2 batch id 261 loss 3.449483871459961 train acc 0.19216954022988506\n",
            "epoch 2 batch id 262 loss 3.406134843826294 train acc 0.19239026717557253\n",
            "epoch 2 batch id 263 loss 3.3629379272460938 train acc 0.19254990494296578\n",
            "epoch 2 batch id 264 loss 3.4054617881774902 train acc 0.19258996212121213\n",
            "epoch 2 batch id 265 loss 3.332824468612671 train acc 0.1929245283018868\n",
            "epoch 2 batch id 266 loss 3.3282968997955322 train acc 0.19308035714285715\n",
            "epoch 2 batch id 267 loss 3.4561431407928467 train acc 0.19323501872659177\n",
            "epoch 2 batch id 268 loss 3.2700560092926025 train acc 0.19362173507462688\n",
            "epoch 2 batch id 269 loss 3.329469680786133 train acc 0.19371514869888476\n",
            "epoch 2 batch id 270 loss 3.327766180038452 train acc 0.19392361111111112\n",
            "epoch 2 batch id 271 loss 3.366786003112793 train acc 0.19418819188191883\n",
            "epoch 2 batch id 272 loss 3.2939000129699707 train acc 0.1943359375\n",
            "epoch 2 batch id 273 loss 3.345979928970337 train acc 0.1944253663003663\n",
            "epoch 2 batch id 274 loss 3.44380259513855 train acc 0.19451414233576642\n",
            "epoch 2 batch id 275 loss 3.129460334777832 train acc 0.19522727272727272\n",
            "epoch 2 batch id 276 loss 3.394763469696045 train acc 0.1955955615942029\n",
            "epoch 2 batch id 277 loss 3.379289150238037 train acc 0.19579196750902528\n",
            "epoch 2 batch id 278 loss 3.30934476852417 train acc 0.1960431654676259\n",
            "epoch 2 batch id 279 loss 3.260457992553711 train acc 0.1964605734767025\n",
            "epoch 2 batch id 280 loss 3.3147387504577637 train acc 0.19670758928571427\n",
            "epoch 2 batch id 281 loss 3.33756947517395 train acc 0.19673042704626334\n",
            "epoch 2 batch id 282 loss 3.2989182472229004 train acc 0.19680851063829788\n",
            "epoch 2 batch id 283 loss 3.424694776535034 train acc 0.19694125441696114\n",
            "epoch 2 batch id 284 loss 3.2650458812713623 train acc 0.1972931338028169\n",
            "epoch 2 batch id 285 loss 3.3066396713256836 train acc 0.19758771929824562\n",
            "epoch 2 batch id 286 loss 3.3191444873809814 train acc 0.197770979020979\n",
            "epoch 2 batch id 287 loss 3.342362880706787 train acc 0.19789851916376305\n",
            "epoch 2 batch id 288 loss 3.409945487976074 train acc 0.19786241319444445\n",
            "epoch 2 batch id 289 loss 3.6087005138397217 train acc 0.1976643598615917\n",
            "epoch 2 batch id 290 loss 3.3691704273223877 train acc 0.19795258620689654\n",
            "epoch 2 batch id 291 loss 3.3466384410858154 train acc 0.19829252577319587\n",
            "epoch 2 batch id 292 loss 3.360198497772217 train acc 0.19841609589041095\n",
            "epoch 2 batch id 293 loss 3.3099865913391113 train acc 0.19859215017064846\n",
            "epoch 2 batch id 294 loss 3.424408435821533 train acc 0.19866071428571427\n",
            "epoch 2 batch id 295 loss 3.355181932449341 train acc 0.1988877118644068\n",
            "epoch 2 batch id 296 loss 3.3522863388061523 train acc 0.19890202702702703\n",
            "epoch 2 batch id 297 loss 3.2722651958465576 train acc 0.19917929292929293\n",
            "epoch 2 batch id 298 loss 3.4598634243011475 train acc 0.19924496644295303\n",
            "epoch 2 batch id 299 loss 3.454064130783081 train acc 0.19951923076923078\n",
            "epoch 2 batch id 300 loss 3.4448390007019043 train acc 0.19942708333333334\n",
            "epoch 2 batch id 301 loss 3.278881788253784 train acc 0.19980274086378738\n",
            "epoch 2 batch id 302 loss 3.4949355125427246 train acc 0.20007243377483444\n",
            "epoch 2 batch id 303 loss 3.382366180419922 train acc 0.20023721122112212\n",
            "epoch 2 batch id 304 loss 3.189244031906128 train acc 0.20060649671052633\n",
            "epoch 2 batch id 305 loss 3.34246563911438 train acc 0.20092213114754098\n",
            "epoch 2 batch id 306 loss 3.299654245376587 train acc 0.20098039215686275\n",
            "epoch 2 batch id 307 loss 3.4653491973876953 train acc 0.20088558631921824\n",
            "epoch 2 batch id 308 loss 3.2255020141601562 train acc 0.2012987012987013\n",
            "epoch 2 batch id 309 loss 3.4094512462615967 train acc 0.20130461165048544\n",
            "epoch 2 batch id 310 loss 3.294921398162842 train acc 0.20161290322580644\n",
            "epoch 2 batch id 311 loss 3.498682737350464 train acc 0.20171824758842444\n",
            "epoch 2 batch id 312 loss 3.303358554840088 train acc 0.20207331730769232\n",
            "epoch 2 batch id 313 loss 3.2171151638031006 train acc 0.20242611821086262\n",
            "epoch 2 batch id 314 loss 3.459503650665283 train acc 0.20242834394904458\n",
            "epoch 2 batch id 315 loss 3.2130770683288574 train acc 0.20262896825396826\n",
            "epoch 2 batch id 316 loss 3.1956493854522705 train acc 0.20277887658227847\n",
            "epoch 2 batch id 317 loss 3.1982016563415527 train acc 0.20327287066246058\n",
            "epoch 2 batch id 318 loss 3.315314531326294 train acc 0.2035672169811321\n",
            "epoch 2 batch id 319 loss 3.215902090072632 train acc 0.2036637931034483\n",
            "epoch 2 batch id 320 loss 3.404423952102661 train acc 0.203759765625\n",
            "epoch 2 batch id 321 loss 3.2478926181793213 train acc 0.20380646417445483\n",
            "epoch 2 batch id 322 loss 3.1024043560028076 train acc 0.20424107142857142\n",
            "epoch 2 batch id 323 loss 3.348259449005127 train acc 0.20438273993808048\n",
            "epoch 2 batch id 324 loss 3.224378824234009 train acc 0.2045235339506173\n",
            "epoch 2 batch id 325 loss 3.2934682369232178 train acc 0.20466346153846154\n",
            "epoch 2 batch id 326 loss 3.1414637565612793 train acc 0.20504217791411042\n",
            "epoch 2 batch id 327 loss 3.11600923538208 train acc 0.2053230122324159\n",
            "epoch 2 batch id 328 loss 3.341531753540039 train acc 0.2053639481707317\n",
            "epoch 2 batch id 329 loss 3.2655811309814453 train acc 0.2056420972644377\n",
            "epoch 2 batch id 330 loss 3.297971487045288 train acc 0.2059659090909091\n",
            "epoch 2 batch id 331 loss 3.3065383434295654 train acc 0.20586291540785498\n",
            "epoch 2 batch id 332 loss 3.2953591346740723 train acc 0.20604292168674698\n",
            "epoch 2 batch id 333 loss 3.4173192977905273 train acc 0.20603415915915915\n",
            "epoch 2 batch id 334 loss 3.4257419109344482 train acc 0.2060254491017964\n",
            "epoch 2 batch id 335 loss 3.2422311305999756 train acc 0.20611007462686567\n",
            "epoch 2 batch id 336 loss 3.3388707637786865 train acc 0.20628720238095238\n",
            "epoch 2 batch id 337 loss 3.3211312294006348 train acc 0.20650964391691395\n",
            "epoch 2 batch id 338 loss 3.448335886001587 train acc 0.20668454142011836\n",
            "epoch 2 batch id 339 loss 3.151087522506714 train acc 0.20704277286135694\n",
            "epoch 2 batch id 340 loss 3.3073437213897705 train acc 0.20730698529411765\n",
            "epoch 2 batch id 341 loss 3.2868196964263916 train acc 0.20729472140762464\n",
            "epoch 2 batch id 342 loss 3.1140499114990234 train acc 0.20760233918128654\n",
            "epoch 2 batch id 343 loss 2.9701240062713623 train acc 0.20809037900874636\n",
            "epoch 2 batch id 344 loss 3.208482027053833 train acc 0.20830305232558138\n",
            "epoch 2 batch id 345 loss 3.4130733013153076 train acc 0.2083786231884058\n",
            "epoch 2 batch id 346 loss 3.321972608566284 train acc 0.20845375722543352\n",
            "epoch 2 batch id 347 loss 3.2499139308929443 train acc 0.20857348703170028\n",
            "epoch 2 batch id 348 loss 3.1078662872314453 train acc 0.2087823275862069\n",
            "epoch 2 batch id 349 loss 3.1271257400512695 train acc 0.2089452005730659\n",
            "epoch 2 batch id 350 loss 3.4245166778564453 train acc 0.20892857142857144\n",
            "epoch 2 batch id 351 loss 3.089979887008667 train acc 0.20931267806267806\n",
            "epoch 2 batch id 352 loss 3.1626100540161133 train acc 0.20965021306818182\n",
            "epoch 2 batch id 353 loss 3.4469099044799805 train acc 0.2096317280453258\n",
            "epoch 2 batch id 354 loss 3.2946908473968506 train acc 0.2099223163841808\n",
            "epoch 2 batch id 355 loss 3.1832363605499268 train acc 0.21007922535211268\n",
            "epoch 2 batch id 356 loss 3.1746814250946045 train acc 0.21032303370786518\n",
            "epoch 2 batch id 357 loss 3.210695266723633 train acc 0.2105654761904762\n",
            "epoch 2 batch id 358 loss 3.1974682807922363 train acc 0.21071927374301677\n",
            "epoch 2 batch id 359 loss 3.263617753982544 train acc 0.21100278551532034\n",
            "epoch 2 batch id 360 loss 3.263157844543457 train acc 0.21128472222222222\n",
            "epoch 2 batch id 361 loss 3.2300193309783936 train acc 0.21147853185595566\n",
            "epoch 2 batch id 362 loss 3.4921841621398926 train acc 0.2115849447513812\n",
            "epoch 2 batch id 363 loss 3.263680934906006 train acc 0.21177685950413222\n",
            "epoch 2 batch id 364 loss 3.2865614891052246 train acc 0.21196771978021978\n",
            "epoch 2 batch id 365 loss 3.1105594635009766 train acc 0.21220034246575342\n",
            "epoch 2 batch id 366 loss 3.221083879470825 train acc 0.21234631147540983\n",
            "epoch 2 batch id 367 loss 3.2407500743865967 train acc 0.21244891008174388\n",
            "epoch 2 batch id 368 loss 3.3052828311920166 train acc 0.21242357336956522\n",
            "epoch 2 batch id 369 loss 3.1491520404815674 train acc 0.21256775067750677\n",
            "epoch 2 batch id 370 loss 3.021940231323242 train acc 0.21300675675675676\n",
            "epoch 2 batch id 371 loss 3.3366024494171143 train acc 0.21306435309973046\n",
            "epoch 2 batch id 372 loss 3.1384174823760986 train acc 0.21333165322580644\n",
            "epoch 2 batch id 373 loss 3.3868203163146973 train acc 0.2135137399463807\n",
            "epoch 2 batch id 374 loss 3.2454886436462402 train acc 0.2137784090909091\n",
            "epoch 2 batch id 375 loss 3.4042813777923584 train acc 0.21375\n",
            "epoch 2 batch id 376 loss 3.2419345378875732 train acc 0.21388796542553193\n",
            "epoch 2 batch id 377 loss 3.036794424057007 train acc 0.2142738726790451\n",
            "epoch 2 batch id 378 loss 3.379978656768799 train acc 0.21428571428571427\n",
            "epoch 2 batch id 379 loss 3.2688333988189697 train acc 0.21437994722955145\n",
            "epoch 2 batch id 380 loss 3.314443826675415 train acc 0.21447368421052632\n",
            "epoch 2 batch id 381 loss 3.2905917167663574 train acc 0.21456692913385828\n",
            "epoch 2 batch id 382 loss 3.140577793121338 train acc 0.21482329842931938\n",
            "epoch 2 batch id 383 loss 3.080178737640381 train acc 0.21515992167101827\n",
            "epoch 2 batch id 384 loss 3.056945562362671 train acc 0.21553548177083334\n",
            "epoch 2 batch id 385 loss 3.0873758792877197 train acc 0.21574675324675324\n",
            "epoch 2 batch id 386 loss 3.1710076332092285 train acc 0.21583549222797926\n",
            "epoch 2 batch id 387 loss 3.1405270099639893 train acc 0.21604489664082688\n",
            "epoch 2 batch id 388 loss 3.3795993328094482 train acc 0.21625322164948454\n",
            "epoch 2 batch id 389 loss 3.328453302383423 train acc 0.2163801413881748\n",
            "epoch 2 batch id 390 loss 3.124281167984009 train acc 0.21662660256410257\n",
            "epoch 2 batch id 391 loss 3.379242181777954 train acc 0.21655210997442456\n",
            "epoch 2 batch id 392 loss 3.1536240577697754 train acc 0.21647799744897958\n",
            "epoch 2 batch id 393 loss 3.2274270057678223 train acc 0.2166428117048346\n",
            "epoch 2 batch id 394 loss 3.2000880241394043 train acc 0.21676713197969544\n",
            "epoch 2 batch id 395 loss 3.1177749633789062 train acc 0.21700949367088607\n",
            "epoch 2 batch id 396 loss 3.165911912918091 train acc 0.21709280303030304\n",
            "epoch 2 batch id 397 loss 3.209665536880493 train acc 0.21729376574307305\n",
            "epoch 2 batch id 398 loss 2.9532148838043213 train acc 0.21761149497487436\n",
            "epoch 2 batch id 399 loss 3.3149843215942383 train acc 0.2175751879699248\n",
            "epoch 2 batch id 400 loss 3.159126043319702 train acc 0.2178515625\n",
            "epoch 2 batch id 401 loss 3.127985715866089 train acc 0.2180875935162095\n",
            "epoch 2 batch id 402 loss 3.1828017234802246 train acc 0.21828358208955223\n",
            "epoch 2 batch id 403 loss 3.1845083236694336 train acc 0.21851736972704713\n",
            "epoch 2 batch id 404 loss 3.1964964866638184 train acc 0.21863397277227722\n",
            "epoch 2 batch id 405 loss 3.18951153755188 train acc 0.21875\n",
            "epoch 2 batch id 406 loss 3.109797239303589 train acc 0.2189424261083744\n",
            "epoch 2 batch id 407 loss 3.1120550632476807 train acc 0.21921068796068796\n",
            "epoch 2 batch id 408 loss 3.3137624263763428 train acc 0.21932444852941177\n",
            "epoch 2 batch id 409 loss 3.20790958404541 train acc 0.2195140586797066\n",
            "epoch 2 batch id 410 loss 3.068061113357544 train acc 0.21970274390243902\n",
            "epoch 2 batch id 411 loss 3.2191498279571533 train acc 0.21992852798053528\n",
            "epoch 2 batch id 412 loss 3.2062487602233887 train acc 0.21992566747572814\n",
            "epoch 2 batch id 413 loss 3.28049635887146 train acc 0.22014981840193704\n",
            "epoch 2 batch id 414 loss 3.3071320056915283 train acc 0.22014643719806765\n",
            "epoch 2 batch id 415 loss 3.0935442447662354 train acc 0.22036897590361446\n",
            "epoch 2 batch id 416 loss 3.2118420600891113 train acc 0.2205528846153846\n",
            "epoch 2 batch id 417 loss 3.123701333999634 train acc 0.22084832134292565\n",
            "epoch 2 batch id 418 loss 3.1266298294067383 train acc 0.2211797248803828\n",
            "epoch 2 batch id 419 loss 3.1121017932891846 train acc 0.2213230906921241\n",
            "epoch 2 batch id 420 loss 3.0648224353790283 train acc 0.2214657738095238\n",
            "epoch 2 batch id 421 loss 3.1715846061706543 train acc 0.2217562351543943\n",
            "epoch 2 batch id 422 loss 3.2075865268707275 train acc 0.22197126777251186\n",
            "epoch 2 batch id 423 loss 3.1431515216827393 train acc 0.22218528368794327\n",
            "epoch 2 batch id 424 loss 3.249549150466919 train acc 0.22232458726415094\n",
            "epoch 2 batch id 425 loss 3.1642181873321533 train acc 0.2223529411764706\n",
            "epoch 2 batch id 426 loss 3.396426200866699 train acc 0.22241784037558684\n",
            "epoch 2 batch id 427 loss 3.060434341430664 train acc 0.2227751756440281\n",
            "epoch 2 batch id 428 loss 2.997415781021118 train acc 0.22294830607476634\n",
            "epoch 2 batch id 429 loss 3.155897378921509 train acc 0.22304778554778554\n",
            "epoch 2 batch id 430 loss 2.9299542903900146 train acc 0.2234375\n",
            "epoch 2 batch id 431 loss 3.0668513774871826 train acc 0.2236441415313225\n",
            "epoch 2 batch id 432 loss 3.160935878753662 train acc 0.22374131944444445\n",
            "epoch 2 batch id 433 loss 2.989654064178467 train acc 0.2240545612009238\n",
            "epoch 2 batch id 434 loss 2.9634673595428467 train acc 0.22451036866359447\n",
            "epoch 2 batch id 435 loss 2.975532293319702 train acc 0.22474856321839082\n",
            "epoch 2 batch id 436 loss 3.2662534713745117 train acc 0.22477064220183487\n",
            "epoch 2 batch id 437 loss 3.1603894233703613 train acc 0.22489988558352403\n",
            "epoch 2 batch id 438 loss 3.198519229888916 train acc 0.2248501712328767\n",
            "epoch 2 batch id 439 loss 3.1907289028167725 train acc 0.2250498291571754\n",
            "epoch 2 batch id 440 loss 3.177931308746338 train acc 0.22524857954545455\n",
            "epoch 2 batch id 441 loss 2.9992311000823975 train acc 0.22541099773242632\n",
            "epoch 2 batch id 442 loss 3.210242748260498 train acc 0.22564338235294118\n",
            "epoch 2 batch id 443 loss 3.1581149101257324 train acc 0.22594525959367945\n",
            "epoch 2 batch id 444 loss 3.0174190998077393 train acc 0.22610501126126126\n",
            "epoch 2 batch id 445 loss 3.1077980995178223 train acc 0.2261938202247191\n",
            "epoch 2 batch id 446 loss 3.13337779045105 train acc 0.22628223094170405\n",
            "epoch 2 batch id 447 loss 3.180203437805176 train acc 0.2262653803131991\n",
            "epoch 2 batch id 448 loss 3.1678531169891357 train acc 0.2265625\n",
            "epoch 2 batch id 449 loss 3.176657199859619 train acc 0.22685829621380846\n",
            "epoch 2 batch id 450 loss 3.0874149799346924 train acc 0.22697916666666668\n",
            "epoch 2 batch id 451 loss 3.088102340698242 train acc 0.22720343680709534\n",
            "epoch 2 batch id 452 loss 3.012432336807251 train acc 0.2273575774336283\n",
            "epoch 2 batch id 453 loss 3.090578079223633 train acc 0.22771799116997793\n",
            "epoch 2 batch id 454 loss 3.269029140472412 train acc 0.22769823788546256\n",
            "epoch 2 batch id 455 loss 3.3415377140045166 train acc 0.22767857142857142\n",
            "epoch 2 batch id 456 loss 3.1523079872131348 train acc 0.22793311403508773\n",
            "epoch 2 batch id 457 loss 2.870342493057251 train acc 0.22811816192560175\n",
            "epoch 2 batch id 458 loss 3.1537885665893555 train acc 0.2283024017467249\n",
            "epoch 2 batch id 459 loss 2.943382978439331 train acc 0.22858796296296297\n",
            "epoch 2 batch id 460 loss 3.2767174243927 train acc 0.2286345108695652\n",
            "epoch 2 batch id 461 loss 2.9305975437164307 train acc 0.22898590021691975\n",
            "epoch 2 batch id 462 loss 3.0698885917663574 train acc 0.22923430735930736\n",
            "epoch 2 batch id 463 loss 3.1876213550567627 train acc 0.22934665226781858\n",
            "epoch 2 batch id 464 loss 3.119513988494873 train acc 0.22955953663793102\n",
            "epoch 2 batch id 465 loss 3.1981778144836426 train acc 0.22963709677419356\n",
            "epoch 2 batch id 466 loss 3.2310092449188232 train acc 0.22978138412017168\n",
            "epoch 2 batch id 467 loss 3.055753469467163 train acc 0.23009234475374732\n",
            "epoch 2 batch id 468 loss 3.1742911338806152 train acc 0.2300347222222222\n",
            "epoch 2 batch id 469 loss 3.056939125061035 train acc 0.23021055437100213\n",
            "epoch 2 batch id 470 loss 3.150344133377075 train acc 0.23035239361702128\n",
            "epoch 2 batch id 471 loss 3.0166704654693604 train acc 0.23052680467091294\n",
            "epoch 2 batch id 472 loss 3.253075122833252 train acc 0.23056806144067796\n",
            "epoch 2 batch id 473 loss 3.1464767456054688 train acc 0.23070824524312897\n",
            "epoch 2 batch id 474 loss 3.1498255729675293 train acc 0.23071598101265822\n",
            "epoch 2 batch id 475 loss 2.8899519443511963 train acc 0.23095394736842106\n",
            "epoch 2 batch id 476 loss 3.133479595184326 train acc 0.23112526260504201\n",
            "epoch 2 batch id 477 loss 3.5144922733306885 train acc 0.23093553459119498\n",
            "epoch 2 batch id 478 loss 3.0706350803375244 train acc 0.2310407949790795\n",
            "epoch 2 batch id 479 loss 3.0232677459716797 train acc 0.23124347599164927\n",
            "epoch 2 batch id 480 loss 3.0309805870056152 train acc 0.23147786458333333\n",
            "epoch 2 batch id 481 loss 3.2313077449798584 train acc 0.23158134095634095\n",
            "epoch 2 batch id 482 loss 3.197598695755005 train acc 0.23165197095435686\n",
            "epoch 2 batch id 483 loss 3.150993585586548 train acc 0.23165760869565216\n",
            "epoch 2 batch id 484 loss 3.0205464363098145 train acc 0.23182463842975207\n",
            "epoch 2 batch id 485 loss 2.84851336479187 train acc 0.2322487113402062\n",
            "epoch 2 batch id 486 loss 3.1443707942962646 train acc 0.23231738683127573\n",
            "epoch 2 batch id 487 loss 3.07676362991333 train acc 0.23251411704312114\n",
            "epoch 2 batch id 488 loss 2.940185546875 train acc 0.23283811475409835\n",
            "epoch 2 batch id 489 loss 2.9394266605377197 train acc 0.23322469325153375\n",
            "epoch 2 batch id 490 loss 2.910571336746216 train acc 0.2335140306122449\n",
            "epoch 2 batch id 491 loss 3.238675832748413 train acc 0.23364307535641549\n",
            "epoch 2 batch id 492 loss 3.1273512840270996 train acc 0.23389862804878048\n",
            "epoch 2 batch id 493 loss 3.0418663024902344 train acc 0.23412145030425963\n",
            "epoch 2 batch id 494 loss 3.0879323482513428 train acc 0.23434337044534412\n",
            "epoch 2 batch id 495 loss 3.16390323638916 train acc 0.23446969696969697\n",
            "epoch 2 batch id 496 loss 2.7193517684936523 train acc 0.23487903225806453\n",
            "epoch 2 batch id 497 loss 3.1000609397888184 train acc 0.23497233400402415\n",
            "epoch 2 batch id 498 loss 3.217543363571167 train acc 0.23509663654618473\n",
            "epoch 2 batch id 499 loss 3.0496487617492676 train acc 0.23528306613226452\n",
            "epoch 2 batch id 500 loss 2.997382402420044 train acc 0.23553125\n",
            "epoch 2 batch id 501 loss 2.975836753845215 train acc 0.23577844311377247\n",
            "epoch 2 batch id 502 loss 3.01699161529541 train acc 0.23577564741035856\n",
            "epoch 2 batch id 503 loss 3.1119513511657715 train acc 0.23589711729622267\n",
            "epoch 2 batch id 504 loss 3.127485513687134 train acc 0.23604910714285715\n",
            "epoch 2 batch id 505 loss 2.8286612033843994 train acc 0.23632425742574256\n",
            "epoch 2 batch id 506 loss 2.9645822048187256 train acc 0.23653656126482214\n",
            "epoch 2 batch id 507 loss 2.92868709564209 train acc 0.23680966469428008\n",
            "epoch 2 batch id 508 loss 2.8594772815704346 train acc 0.23702017716535434\n",
            "epoch 2 batch id 509 loss 3.1279892921447754 train acc 0.23719916502946956\n",
            "epoch 2 batch id 510 loss 3.2897820472717285 train acc 0.23713235294117646\n",
            "epoch 2 batch id 511 loss 2.980087995529175 train acc 0.23738273848352126\n",
            "epoch 2 train acc 0.23738273848352126\n",
            "epoch 2 test acc 0.3011474609375\n",
            "epoch 3 batch id 1 loss 3.039100408554077 train acc 0.3125\n",
            "epoch 3 batch id 2 loss 2.948239326477051 train acc 0.359375\n",
            "epoch 3 batch id 3 loss 3.1508848667144775 train acc 0.3385416666666667\n",
            "epoch 3 batch id 4 loss 3.0273447036743164 train acc 0.31640625\n",
            "epoch 3 batch id 5 loss 2.8614349365234375 train acc 0.328125\n",
            "epoch 3 batch id 6 loss 3.128887176513672 train acc 0.3125\n",
            "epoch 3 batch id 7 loss 3.148047924041748 train acc 0.3013392857142857\n",
            "epoch 3 batch id 8 loss 3.1873083114624023 train acc 0.291015625\n",
            "epoch 3 batch id 9 loss 3.246950387954712 train acc 0.2881944444444444\n",
            "epoch 3 batch id 10 loss 3.121403932571411 train acc 0.2859375\n",
            "epoch 3 batch id 11 loss 3.127326488494873 train acc 0.27698863636363635\n",
            "epoch 3 batch id 12 loss 3.039410352706909 train acc 0.2760416666666667\n",
            "epoch 3 batch id 13 loss 2.8493714332580566 train acc 0.2848557692307692\n",
            "epoch 3 batch id 14 loss 3.241457939147949 train acc 0.28013392857142855\n",
            "epoch 3 batch id 15 loss 2.7203550338745117 train acc 0.29375\n",
            "epoch 3 batch id 16 loss 2.9869441986083984 train acc 0.2958984375\n",
            "epoch 3 batch id 17 loss 3.3205089569091797 train acc 0.29503676470588236\n",
            "epoch 3 batch id 18 loss 2.851445198059082 train acc 0.3003472222222222\n",
            "epoch 3 batch id 19 loss 3.1006722450256348 train acc 0.2993421052631579\n",
            "epoch 3 batch id 20 loss 2.9952635765075684 train acc 0.30078125\n",
            "epoch 3 batch id 21 loss 2.8891992568969727 train acc 0.30505952380952384\n",
            "epoch 3 batch id 22 loss 2.9377050399780273 train acc 0.30823863636363635\n",
            "epoch 3 batch id 23 loss 3.1425156593322754 train acc 0.30570652173913043\n",
            "epoch 3 batch id 24 loss 3.279468297958374 train acc 0.30078125\n",
            "epoch 3 batch id 25 loss 2.852902889251709 train acc 0.30375\n",
            "epoch 3 batch id 26 loss 3.14245343208313 train acc 0.3004807692307692\n",
            "epoch 3 batch id 27 loss 2.9691479206085205 train acc 0.30324074074074076\n",
            "epoch 3 batch id 28 loss 3.0731616020202637 train acc 0.3041294642857143\n",
            "epoch 3 batch id 29 loss 3.0654640197753906 train acc 0.30334051724137934\n",
            "epoch 3 batch id 30 loss 2.942416191101074 train acc 0.30416666666666664\n",
            "epoch 3 batch id 31 loss 2.814483404159546 train acc 0.30544354838709675\n",
            "epoch 3 batch id 32 loss 2.8792524337768555 train acc 0.30810546875\n",
            "epoch 3 batch id 33 loss 3.271360397338867 train acc 0.3035037878787879\n",
            "epoch 3 batch id 34 loss 3.10591983795166 train acc 0.30284926470588236\n",
            "epoch 3 batch id 35 loss 3.158905506134033 train acc 0.30089285714285713\n",
            "epoch 3 batch id 36 loss 2.882225513458252 train acc 0.3012152777777778\n",
            "epoch 3 batch id 37 loss 3.3225648403167725 train acc 0.29940878378378377\n",
            "epoch 3 batch id 38 loss 3.080183744430542 train acc 0.29851973684210525\n",
            "epoch 3 batch id 39 loss 3.1232988834381104 train acc 0.2980769230769231\n",
            "epoch 3 batch id 40 loss 2.9694442749023438 train acc 0.2984375\n",
            "epoch 3 batch id 41 loss 3.1250126361846924 train acc 0.2995426829268293\n",
            "epoch 3 batch id 42 loss 2.9397616386413574 train acc 0.3013392857142857\n",
            "epoch 3 batch id 43 loss 3.0887115001678467 train acc 0.30305232558139533\n",
            "epoch 3 batch id 44 loss 3.132448434829712 train acc 0.3025568181818182\n",
            "epoch 3 batch id 45 loss 2.8389694690704346 train acc 0.3055555555555556\n",
            "epoch 3 batch id 46 loss 2.840430974960327 train acc 0.3060461956521739\n",
            "epoch 3 batch id 47 loss 3.2223024368286133 train acc 0.30518617021276595\n",
            "epoch 3 batch id 48 loss 2.787827730178833 train acc 0.3072916666666667\n",
            "epoch 3 batch id 49 loss 3.02717661857605 train acc 0.30739795918367346\n",
            "epoch 3 batch id 50 loss 3.089298963546753 train acc 0.30625\n",
            "epoch 3 batch id 51 loss 3.151886224746704 train acc 0.30575980392156865\n",
            "epoch 3 batch id 52 loss 2.8296401500701904 train acc 0.3076923076923077\n",
            "epoch 3 batch id 53 loss 3.077681064605713 train acc 0.30807783018867924\n",
            "epoch 3 batch id 54 loss 3.0481629371643066 train acc 0.3081597222222222\n",
            "epoch 3 batch id 55 loss 3.1328210830688477 train acc 0.30823863636363635\n",
            "epoch 3 batch id 56 loss 2.981031894683838 train acc 0.30887276785714285\n",
            "epoch 3 batch id 57 loss 3.0706849098205566 train acc 0.30783991228070173\n",
            "epoch 3 batch id 58 loss 3.18904185295105 train acc 0.3073814655172414\n",
            "epoch 3 batch id 59 loss 3.033313751220703 train acc 0.3064088983050847\n",
            "epoch 3 batch id 60 loss 2.681723117828369 train acc 0.309375\n",
            "epoch 3 batch id 61 loss 3.016580581665039 train acc 0.3089139344262295\n",
            "epoch 3 batch id 62 loss 3.193323850631714 train acc 0.30720766129032256\n",
            "epoch 3 batch id 63 loss 3.0657193660736084 train acc 0.3070436507936508\n",
            "epoch 3 batch id 64 loss 2.992770195007324 train acc 0.306640625\n",
            "epoch 3 batch id 65 loss 3.015406608581543 train acc 0.3074519230769231\n",
            "epoch 3 batch id 66 loss 3.045313835144043 train acc 0.3077651515151515\n",
            "epoch 3 batch id 67 loss 3.180351734161377 train acc 0.3069029850746269\n",
            "epoch 3 batch id 68 loss 3.0987672805786133 train acc 0.3062959558823529\n",
            "epoch 3 batch id 69 loss 2.9424078464508057 train acc 0.3066123188405797\n",
            "epoch 3 batch id 70 loss 2.779179334640503 train acc 0.30758928571428573\n",
            "epoch 3 batch id 71 loss 2.881012439727783 train acc 0.3076584507042254\n",
            "epoch 3 batch id 72 loss 3.054295539855957 train acc 0.3072916666666667\n",
            "epoch 3 batch id 73 loss 3.1004045009613037 train acc 0.3067208904109589\n",
            "epoch 3 batch id 74 loss 3.0490472316741943 train acc 0.3067989864864865\n",
            "epoch 3 batch id 75 loss 2.781771183013916 train acc 0.30791666666666667\n",
            "epoch 3 batch id 76 loss 2.892159938812256 train acc 0.30879934210526316\n",
            "epoch 3 batch id 77 loss 3.035008192062378 train acc 0.30823863636363635\n",
            "epoch 3 batch id 78 loss 2.949686050415039 train acc 0.3088942307692308\n",
            "epoch 3 batch id 79 loss 2.9300143718719482 train acc 0.30933544303797467\n",
            "epoch 3 batch id 80 loss 2.866549491882324 train acc 0.3091796875\n",
            "epoch 3 batch id 81 loss 3.0137882232666016 train acc 0.30941358024691357\n",
            "epoch 3 batch id 82 loss 3.10099458694458 train acc 0.3094512195121951\n",
            "epoch 3 batch id 83 loss 3.0622270107269287 train acc 0.30835843373493976\n",
            "epoch 3 batch id 84 loss 2.7289533615112305 train acc 0.3087797619047619\n",
            "epoch 3 batch id 85 loss 2.901472330093384 train acc 0.3090073529411765\n",
            "epoch 3 batch id 86 loss 2.627539873123169 train acc 0.3101380813953488\n",
            "epoch 3 batch id 87 loss 2.909597158432007 train acc 0.3098060344827586\n",
            "epoch 3 batch id 88 loss 2.957242965698242 train acc 0.31019176136363635\n",
            "epoch 3 batch id 89 loss 3.1211659908294678 train acc 0.3105688202247191\n",
            "epoch 3 batch id 90 loss 3.006488561630249 train acc 0.3098958333333333\n",
            "epoch 3 batch id 91 loss 2.902768611907959 train acc 0.31061126373626374\n",
            "epoch 3 batch id 92 loss 2.8690590858459473 train acc 0.3109714673913043\n",
            "epoch 3 batch id 93 loss 2.8972179889678955 train acc 0.31149193548387094\n",
            "epoch 3 batch id 94 loss 2.888218402862549 train acc 0.3123337765957447\n",
            "epoch 3 batch id 95 loss 3.0633795261383057 train acc 0.31217105263157896\n",
            "epoch 3 batch id 96 loss 2.9976134300231934 train acc 0.3125\n",
            "epoch 3 batch id 97 loss 2.7228333950042725 train acc 0.3136275773195876\n",
            "epoch 3 batch id 98 loss 2.9597809314727783 train acc 0.31345663265306123\n",
            "epoch 3 batch id 99 loss 2.9997267723083496 train acc 0.31297348484848486\n",
            "epoch 3 batch id 100 loss 3.0900936126708984 train acc 0.313125\n",
            "epoch 3 batch id 101 loss 3.171008825302124 train acc 0.3131188118811881\n",
            "epoch 3 batch id 102 loss 2.9138476848602295 train acc 0.31326593137254904\n",
            "epoch 3 batch id 103 loss 2.8463902473449707 train acc 0.3132584951456311\n",
            "epoch 3 batch id 104 loss 2.921053171157837 train acc 0.31295072115384615\n",
            "epoch 3 batch id 105 loss 2.683561325073242 train acc 0.31354166666666666\n",
            "epoch 3 batch id 106 loss 2.9981625080108643 train acc 0.3136792452830189\n",
            "epoch 3 batch id 107 loss 2.964041233062744 train acc 0.3138142523364486\n",
            "epoch 3 batch id 108 loss 2.8358852863311768 train acc 0.31495949074074076\n",
            "epoch 3 batch id 109 loss 2.761819362640381 train acc 0.31594036697247707\n",
            "epoch 3 batch id 110 loss 2.8895201683044434 train acc 0.31661931818181815\n",
            "epoch 3 batch id 111 loss 2.992469310760498 train acc 0.3161599099099099\n",
            "epoch 3 batch id 112 loss 3.0522449016571045 train acc 0.31612723214285715\n",
            "epoch 3 batch id 113 loss 2.884127378463745 train acc 0.31623340707964603\n",
            "epoch 3 batch id 114 loss 2.739504337310791 train acc 0.31674890350877194\n",
            "epoch 3 batch id 115 loss 3.067014694213867 train acc 0.31630434782608696\n",
            "epoch 3 batch id 116 loss 2.7101755142211914 train acc 0.31654094827586204\n",
            "epoch 3 batch id 117 loss 2.672778606414795 train acc 0.3173076923076923\n",
            "epoch 3 batch id 118 loss 2.941058874130249 train acc 0.3173993644067797\n",
            "epoch 3 batch id 119 loss 3.086942672729492 train acc 0.3168329831932773\n",
            "epoch 3 batch id 120 loss 2.688830614089966 train acc 0.317578125\n",
            "epoch 3 batch id 121 loss 2.933535575866699 train acc 0.3175361570247934\n",
            "epoch 3 batch id 122 loss 3.0708587169647217 train acc 0.3167264344262295\n",
            "epoch 3 batch id 123 loss 2.932359218597412 train acc 0.3165650406504065\n",
            "epoch 3 batch id 124 loss 2.7742693424224854 train acc 0.31640625\n",
            "epoch 3 batch id 125 loss 2.902916431427002 train acc 0.3165\n",
            "epoch 3 batch id 126 loss 2.92468523979187 train acc 0.3167162698412698\n",
            "epoch 3 batch id 127 loss 3.078979969024658 train acc 0.3166830708661417\n",
            "epoch 3 batch id 128 loss 2.9626777172088623 train acc 0.316650390625\n",
            "epoch 3 batch id 129 loss 2.9415693283081055 train acc 0.3168604651162791\n",
            "epoch 3 batch id 130 loss 3.08666729927063 train acc 0.31658653846153845\n",
            "epoch 3 batch id 131 loss 3.142918586730957 train acc 0.3163167938931298\n",
            "epoch 3 batch id 132 loss 2.9458155632019043 train acc 0.3165246212121212\n",
            "epoch 3 batch id 133 loss 3.041450262069702 train acc 0.3167293233082707\n",
            "epoch 3 batch id 134 loss 2.639356851577759 train acc 0.3177472014925373\n",
            "epoch 3 batch id 135 loss 2.765110969543457 train acc 0.31805555555555554\n",
            "epoch 3 batch id 136 loss 2.8255467414855957 train acc 0.31847426470588236\n",
            "epoch 3 batch id 137 loss 3.145097494125366 train acc 0.31763229927007297\n",
            "epoch 3 batch id 138 loss 2.863186836242676 train acc 0.31782155797101447\n",
            "epoch 3 batch id 139 loss 2.859072685241699 train acc 0.3176708633093525\n",
            "epoch 3 batch id 140 loss 2.93546986579895 train acc 0.3176339285714286\n",
            "epoch 3 batch id 141 loss 3.0503883361816406 train acc 0.31704343971631205\n",
            "epoch 3 batch id 142 loss 2.981987714767456 train acc 0.31690140845070425\n",
            "epoch 3 batch id 143 loss 2.840625047683716 train acc 0.3169798951048951\n",
            "epoch 3 batch id 144 loss 2.9154856204986572 train acc 0.3167317708333333\n",
            "epoch 3 batch id 145 loss 2.834113597869873 train acc 0.3165948275862069\n",
            "epoch 3 batch id 146 loss 2.8418800830841064 train acc 0.3167808219178082\n",
            "epoch 3 batch id 147 loss 3.1274783611297607 train acc 0.3163265306122449\n",
            "epoch 3 batch id 148 loss 2.9132490158081055 train acc 0.31640625\n",
            "epoch 3 batch id 149 loss 2.693401575088501 train acc 0.31658976510067116\n",
            "epoch 3 batch id 150 loss 2.7685554027557373 train acc 0.3171875\n",
            "epoch 3 batch id 151 loss 3.0168094635009766 train acc 0.31715645695364236\n",
            "epoch 3 batch id 152 loss 2.9825899600982666 train acc 0.31722861842105265\n",
            "epoch 3 batch id 153 loss 2.9083597660064697 train acc 0.3172998366013072\n",
            "epoch 3 batch id 154 loss 2.905613422393799 train acc 0.31726866883116883\n",
            "epoch 3 batch id 155 loss 2.926395893096924 train acc 0.3170362903225806\n",
            "epoch 3 batch id 156 loss 2.8961682319641113 train acc 0.3167067307692308\n",
            "epoch 3 batch id 157 loss 2.893198013305664 train acc 0.31648089171974525\n",
            "epoch 3 batch id 158 loss 2.9796886444091797 train acc 0.31645569620253167\n",
            "epoch 3 batch id 159 loss 2.9264132976531982 train acc 0.3168238993710692\n",
            "epoch 3 batch id 160 loss 2.8837523460388184 train acc 0.3171875\n",
            "epoch 3 batch id 161 loss 3.005204200744629 train acc 0.31667313664596275\n",
            "epoch 3 batch id 162 loss 2.916508197784424 train acc 0.3166473765432099\n",
            "epoch 3 batch id 163 loss 2.725247383117676 train acc 0.31671779141104295\n",
            "epoch 3 batch id 164 loss 2.887261390686035 train acc 0.3167873475609756\n",
            "epoch 3 batch id 165 loss 2.6543023586273193 train acc 0.3175189393939394\n",
            "epoch 3 batch id 166 loss 2.742262363433838 train acc 0.3180534638554217\n",
            "epoch 3 batch id 167 loss 2.69700026512146 train acc 0.3184880239520958\n",
            "epoch 3 batch id 168 loss 2.7063794136047363 train acc 0.3189174107142857\n",
            "epoch 3 batch id 169 loss 2.6722373962402344 train acc 0.3193417159763314\n",
            "epoch 3 batch id 170 loss 2.9019129276275635 train acc 0.31985294117647056\n",
            "epoch 3 batch id 171 loss 2.7347211837768555 train acc 0.3203581871345029\n",
            "epoch 3 batch id 172 loss 3.191866159439087 train acc 0.3203125\n",
            "epoch 3 batch id 173 loss 3.0012102127075195 train acc 0.32035765895953755\n",
            "epoch 3 batch id 174 loss 2.8806777000427246 train acc 0.32076149425287354\n",
            "epoch 3 batch id 175 loss 2.6392478942871094 train acc 0.32160714285714287\n",
            "epoch 3 batch id 176 loss 2.7385902404785156 train acc 0.3221768465909091\n",
            "epoch 3 batch id 177 loss 2.4256813526153564 train acc 0.3231814971751412\n",
            "epoch 3 batch id 178 loss 2.8730459213256836 train acc 0.32320926966292135\n",
            "epoch 3 batch id 179 loss 2.531830310821533 train acc 0.3238477653631285\n",
            "epoch 3 batch id 180 loss 2.768770694732666 train acc 0.32395833333333335\n",
            "epoch 3 batch id 181 loss 2.709758996963501 train acc 0.32432665745856354\n",
            "epoch 3 batch id 182 loss 2.879509449005127 train acc 0.3241758241758242\n",
            "epoch 3 batch id 183 loss 2.989511728286743 train acc 0.3240266393442623\n",
            "epoch 3 batch id 184 loss 2.6605119705200195 train acc 0.32438858695652173\n",
            "epoch 3 batch id 185 loss 2.8256266117095947 train acc 0.32449324324324325\n",
            "epoch 3 batch id 186 loss 2.7659571170806885 train acc 0.32476478494623656\n",
            "epoch 3 batch id 187 loss 2.9152188301086426 train acc 0.3251169786096257\n",
            "epoch 3 batch id 188 loss 2.7771923542022705 train acc 0.3253823138297872\n",
            "epoch 3 batch id 189 loss 3.0819625854492188 train acc 0.3249834656084656\n",
            "epoch 3 batch id 190 loss 2.6352357864379883 train acc 0.32541118421052634\n",
            "epoch 3 batch id 191 loss 2.679591417312622 train acc 0.3261616492146597\n",
            "epoch 3 batch id 192 loss 3.074535369873047 train acc 0.3260091145833333\n",
            "epoch 3 batch id 193 loss 2.6988377571105957 train acc 0.32658678756476683\n",
            "epoch 3 batch id 194 loss 2.7340822219848633 train acc 0.32683634020618557\n",
            "epoch 3 batch id 195 loss 2.9173784255981445 train acc 0.3266826923076923\n",
            "epoch 3 batch id 196 loss 2.663036823272705 train acc 0.3268494897959184\n",
            "epoch 3 batch id 197 loss 2.837601900100708 train acc 0.32669733502538073\n",
            "epoch 3 batch id 198 loss 3.026567220687866 train acc 0.3265467171717172\n",
            "epoch 3 batch id 199 loss 2.829097270965576 train acc 0.3263976130653266\n",
            "epoch 3 batch id 200 loss 2.6901910305023193 train acc 0.32671875\n",
            "epoch 3 batch id 201 loss 2.645806074142456 train acc 0.32703669154228854\n",
            "epoch 3 batch id 202 loss 2.8388588428497314 train acc 0.3270420792079208\n",
            "epoch 3 batch id 203 loss 2.847238540649414 train acc 0.3271243842364532\n",
            "epoch 3 batch id 204 loss 2.691150665283203 train acc 0.32735906862745096\n",
            "epoch 3 batch id 205 loss 2.940051794052124 train acc 0.32728658536585364\n",
            "epoch 3 batch id 206 loss 2.67669415473938 train acc 0.32789745145631066\n",
            "epoch 3 batch id 207 loss 2.897977828979492 train acc 0.32804951690821255\n",
            "epoch 3 batch id 208 loss 2.714221477508545 train acc 0.32797475961538464\n",
            "epoch 3 batch id 209 loss 2.828761100769043 train acc 0.32782595693779903\n",
            "epoch 3 batch id 210 loss 2.654075860977173 train acc 0.3279761904761905\n",
            "epoch 3 batch id 211 loss 2.6526904106140137 train acc 0.3281990521327014\n",
            "epoch 3 batch id 212 loss 2.6402029991149902 train acc 0.32834610849056606\n",
            "epoch 3 batch id 213 loss 2.71736478805542 train acc 0.32856514084507044\n",
            "epoch 3 batch id 214 loss 2.8244476318359375 train acc 0.32834404205607476\n",
            "epoch 3 batch id 215 loss 2.740724563598633 train acc 0.32790697674418606\n",
            "epoch 3 batch id 216 loss 2.610783576965332 train acc 0.32798032407407407\n",
            "epoch 3 batch id 217 loss 2.7628564834594727 train acc 0.32819700460829493\n",
            "epoch 3 batch id 218 loss 2.6389777660369873 train acc 0.32855504587155965\n",
            "epoch 3 batch id 219 loss 2.9207842350006104 train acc 0.3286244292237443\n",
            "epoch 3 batch id 220 loss 2.777315378189087 train acc 0.3287642045454545\n",
            "epoch 3 batch id 221 loss 2.822880744934082 train acc 0.3286906108597285\n",
            "epoch 3 batch id 222 loss 3.0598201751708984 train acc 0.32861768018018017\n",
            "epoch 3 batch id 223 loss 2.634140729904175 train acc 0.3288957399103139\n",
            "epoch 3 batch id 224 loss 2.8070361614227295 train acc 0.3291015625\n",
            "epoch 3 batch id 225 loss 2.7091727256774902 train acc 0.3293055555555556\n",
            "epoch 3 batch id 226 loss 2.767808675765991 train acc 0.32923119469026546\n",
            "epoch 3 batch id 227 loss 2.6740758419036865 train acc 0.32929515418502203\n",
            "epoch 3 batch id 228 loss 2.618753671646118 train acc 0.3296326754385965\n",
            "epoch 3 batch id 229 loss 2.9895741939544678 train acc 0.3296260917030568\n",
            "epoch 3 batch id 230 loss 2.8789942264556885 train acc 0.3293478260869565\n",
            "epoch 3 batch id 231 loss 2.531536340713501 train acc 0.32981601731601734\n",
            "epoch 3 batch id 232 loss 2.931798219680786 train acc 0.32980872844827586\n",
            "epoch 3 batch id 233 loss 2.9743733406066895 train acc 0.32966738197424894\n",
            "epoch 3 batch id 234 loss 2.964677095413208 train acc 0.3294604700854701\n",
            "epoch 3 batch id 235 loss 2.771923065185547 train acc 0.3293882978723404\n",
            "epoch 3 batch id 236 loss 2.5287811756134033 train acc 0.329978813559322\n",
            "epoch 3 batch id 237 loss 2.681095600128174 train acc 0.33010284810126583\n",
            "epoch 3 batch id 238 loss 3.01665997505188 train acc 0.33002888655462187\n",
            "epoch 3 batch id 239 loss 2.9050042629241943 train acc 0.3299555439330544\n",
            "epoch 3 batch id 240 loss 2.8362629413604736 train acc 0.3298828125\n",
            "epoch 3 batch id 241 loss 2.8478715419769287 train acc 0.32987551867219916\n",
            "epoch 3 batch id 242 loss 2.614030122756958 train acc 0.3299328512396694\n",
            "epoch 3 batch id 243 loss 2.784214973449707 train acc 0.33024691358024694\n",
            "epoch 3 batch id 244 loss 2.540964365005493 train acc 0.3306864754098361\n",
            "epoch 3 batch id 245 loss 2.6462602615356445 train acc 0.3313137755102041\n",
            "epoch 3 batch id 246 loss 2.8212196826934814 train acc 0.3314913617886179\n",
            "epoch 3 batch id 247 loss 2.7558093070983887 train acc 0.33160425101214575\n",
            "epoch 3 batch id 248 loss 2.876909017562866 train acc 0.3314012096774194\n",
            "epoch 3 batch id 249 loss 2.8118643760681152 train acc 0.33119979919678716\n",
            "epoch 3 batch id 250 loss 2.972653388977051 train acc 0.3311875\n",
            "epoch 3 batch id 251 loss 2.7637314796447754 train acc 0.33117529880478086\n",
            "epoch 3 batch id 252 loss 2.8363230228424072 train acc 0.33097718253968256\n",
            "epoch 3 batch id 253 loss 2.615586757659912 train acc 0.3310276679841897\n",
            "epoch 3 batch id 254 loss 3.022613525390625 train acc 0.3308932086614173\n",
            "epoch 3 batch id 255 loss 2.90240740776062 train acc 0.33082107843137254\n",
            "epoch 3 batch id 256 loss 2.7612051963806152 train acc 0.33099365234375\n",
            "epoch 3 batch id 257 loss 2.754714012145996 train acc 0.3311648832684825\n",
            "epoch 3 batch id 258 loss 2.8901422023773193 train acc 0.33103197674418605\n",
            "epoch 3 batch id 259 loss 2.614499807357788 train acc 0.3310207528957529\n",
            "epoch 3 batch id 260 loss 2.538341760635376 train acc 0.33155048076923077\n",
            "epoch 3 batch id 261 loss 2.900101661682129 train acc 0.3312978927203065\n",
            "epoch 3 batch id 262 loss 2.52032208442688 train acc 0.33164360687022904\n",
            "epoch 3 batch id 263 loss 2.403557777404785 train acc 0.33204610266159695\n",
            "epoch 3 batch id 264 loss 2.653815984725952 train acc 0.3322088068181818\n",
            "epoch 3 batch id 265 loss 2.6861274242401123 train acc 0.332311320754717\n",
            "epoch 3 batch id 266 loss 2.8346173763275146 train acc 0.3320606203007519\n",
            "epoch 3 batch id 267 loss 2.7651450634002686 train acc 0.33204588014981273\n",
            "epoch 3 batch id 268 loss 2.701737642288208 train acc 0.3323810634328358\n",
            "epoch 3 batch id 269 loss 2.7293014526367188 train acc 0.33277184014869887\n",
            "epoch 3 batch id 270 loss 2.691383123397827 train acc 0.33304398148148145\n",
            "epoch 3 batch id 271 loss 2.7774441242218018 train acc 0.3331411439114391\n",
            "epoch 3 batch id 272 loss 2.5508484840393066 train acc 0.3333524816176471\n",
            "epoch 3 batch id 273 loss 2.413773775100708 train acc 0.3338484432234432\n",
            "epoch 3 batch id 274 loss 2.853586435317993 train acc 0.33371350364963503\n",
            "epoch 3 batch id 275 loss 2.7907540798187256 train acc 0.33386363636363636\n",
            "epoch 3 batch id 276 loss 2.914849042892456 train acc 0.33367300724637683\n",
            "epoch 3 batch id 277 loss 2.7472877502441406 train acc 0.33399142599277976\n",
            "epoch 3 batch id 278 loss 2.6837735176086426 train acc 0.3339703237410072\n",
            "epoch 3 batch id 279 loss 3.024752378463745 train acc 0.33383736559139787\n",
            "epoch 3 batch id 280 loss 2.9273059368133545 train acc 0.3338169642857143\n",
            "epoch 3 batch id 281 loss 2.84782338142395 train acc 0.3336854982206406\n",
            "epoch 3 batch id 282 loss 2.7761383056640625 train acc 0.33383200354609927\n",
            "epoch 3 batch id 283 loss 2.8601510524749756 train acc 0.3338118374558304\n",
            "epoch 3 batch id 284 loss 2.682424306869507 train acc 0.3339568661971831\n",
            "epoch 3 batch id 285 loss 2.7521612644195557 train acc 0.33382675438596493\n",
            "epoch 3 batch id 286 loss 2.658935785293579 train acc 0.3342438811188811\n",
            "epoch 3 batch id 287 loss 2.663963794708252 train acc 0.3344947735191638\n",
            "epoch 3 batch id 288 loss 2.860985279083252 train acc 0.3342013888888889\n",
            "epoch 3 batch id 289 loss 2.7316062450408936 train acc 0.3343966262975779\n",
            "epoch 3 batch id 290 loss 2.566525936126709 train acc 0.3346443965517241\n",
            "epoch 3 batch id 291 loss 2.7624213695526123 train acc 0.33462199312714774\n",
            "epoch 3 batch id 292 loss 2.9400734901428223 train acc 0.3342251712328767\n",
            "epoch 3 batch id 293 loss 2.54229998588562 train acc 0.33452431740614336\n",
            "epoch 3 batch id 294 loss 2.6999027729034424 train acc 0.33471513605442177\n",
            "epoch 3 batch id 295 loss 2.8116703033447266 train acc 0.33490466101694916\n",
            "epoch 3 batch id 296 loss 2.7155022621154785 train acc 0.3349873310810811\n",
            "epoch 3 batch id 297 loss 2.5394978523254395 train acc 0.335385101010101\n",
            "epoch 3 batch id 298 loss 2.861941337585449 train acc 0.3354131711409396\n",
            "epoch 3 batch id 299 loss 2.7612271308898926 train acc 0.3353887959866221\n",
            "epoch 3 batch id 300 loss 2.7036819458007812 train acc 0.33557291666666667\n",
            "epoch 3 batch id 301 loss 2.7030787467956543 train acc 0.33565199335548174\n",
            "epoch 3 batch id 302 loss 3.035003185272217 train acc 0.33542011589403975\n",
            "epoch 3 batch id 303 loss 2.828235149383545 train acc 0.335292904290429\n",
            "epoch 3 batch id 304 loss 2.4545695781707764 train acc 0.33562911184210525\n",
            "epoch 3 batch id 305 loss 2.9165124893188477 train acc 0.33560450819672133\n",
            "epoch 3 batch id 306 loss 2.683248519897461 train acc 0.33583537581699346\n",
            "epoch 3 batch id 307 loss 2.681504011154175 train acc 0.3361156351791531\n",
            "epoch 3 batch id 308 loss 2.782851219177246 train acc 0.33634334415584416\n",
            "epoch 3 batch id 309 loss 2.853062391281128 train acc 0.3364178802588997\n",
            "epoch 3 batch id 310 loss 2.789487600326538 train acc 0.3365927419354839\n",
            "epoch 3 batch id 311 loss 2.9800772666931152 train acc 0.3365152733118971\n",
            "epoch 3 batch id 312 loss 2.7355616092681885 train acc 0.3366887019230769\n",
            "epoch 3 batch id 313 loss 2.3629276752471924 train acc 0.3370107827476038\n",
            "epoch 3 batch id 314 loss 2.7674262523651123 train acc 0.33703224522292996\n",
            "epoch 3 batch id 315 loss 2.56886887550354 train acc 0.33725198412698415\n",
            "epoch 3 batch id 316 loss 2.434232473373413 train acc 0.3373714398734177\n",
            "epoch 3 batch id 317 loss 2.796278238296509 train acc 0.337490141955836\n",
            "epoch 3 batch id 318 loss 3.0693254470825195 train acc 0.3371167452830189\n",
            "epoch 3 batch id 319 loss 3.021489143371582 train acc 0.33703957680250785\n",
            "epoch 3 batch id 320 loss 2.5646872520446777 train acc 0.337353515625\n",
            "epoch 3 batch id 321 loss 2.6426260471343994 train acc 0.3375194704049844\n",
            "epoch 3 batch id 322 loss 2.611255168914795 train acc 0.3376358695652174\n",
            "epoch 3 batch id 323 loss 2.742201328277588 train acc 0.3377999226006192\n",
            "epoch 3 batch id 324 loss 2.5593860149383545 train acc 0.337914737654321\n",
            "epoch 3 batch id 325 loss 2.724357843399048 train acc 0.3378846153846154\n",
            "epoch 3 batch id 326 loss 2.6668624877929688 train acc 0.3379984662576687\n",
            "epoch 3 batch id 327 loss 2.5137405395507812 train acc 0.33801605504587157\n",
            "epoch 3 batch id 328 loss 2.7092854976654053 train acc 0.33812881097560976\n",
            "epoch 3 batch id 329 loss 2.6469593048095703 train acc 0.338383358662614\n",
            "epoch 3 batch id 330 loss 3.082789897918701 train acc 0.33816287878787876\n",
            "epoch 3 batch id 331 loss 2.899540662765503 train acc 0.3382269637462236\n",
            "epoch 3 batch id 332 loss 2.7761380672454834 train acc 0.3382906626506024\n",
            "epoch 3 batch id 333 loss 2.8934803009033203 train acc 0.33811936936936937\n",
            "epoch 3 batch id 334 loss 2.894151210784912 train acc 0.3379958832335329\n",
            "epoch 3 batch id 335 loss 2.6279520988464355 train acc 0.33805970149253733\n",
            "epoch 3 batch id 336 loss 3.0582377910614014 train acc 0.33779761904761907\n",
            "epoch 3 batch id 337 loss 3.0843300819396973 train acc 0.33772255192878337\n",
            "epoch 3 batch id 338 loss 2.8892743587493896 train acc 0.3374630177514793\n",
            "epoch 3 batch id 339 loss 2.6927382946014404 train acc 0.3375737463126844\n",
            "epoch 3 batch id 340 loss 2.4218506813049316 train acc 0.3376838235294118\n",
            "epoch 3 batch id 341 loss 2.3698625564575195 train acc 0.33793071847507333\n",
            "epoch 3 batch id 342 loss 2.701793909072876 train acc 0.3380391081871345\n",
            "epoch 3 batch id 343 loss 2.8574602603912354 train acc 0.33810131195335275\n",
            "epoch 3 batch id 344 loss 2.6052637100219727 train acc 0.33825399709302323\n",
            "epoch 3 batch id 345 loss 2.765615224838257 train acc 0.3383605072463768\n",
            "epoch 3 batch id 346 loss 2.60996150970459 train acc 0.33851156069364163\n",
            "epoch 3 batch id 347 loss 2.7710862159729004 train acc 0.33848162824207495\n",
            "epoch 3 batch id 348 loss 2.46301007270813 train acc 0.33867636494252873\n",
            "epoch 3 batch id 349 loss 2.965320110321045 train acc 0.33864613180515757\n",
            "epoch 3 batch id 350 loss 2.691063642501831 train acc 0.33875\n",
            "epoch 3 batch id 351 loss 2.9809956550598145 train acc 0.3385861823361823\n",
            "epoch 3 batch id 352 loss 2.6801602840423584 train acc 0.3386008522727273\n",
            "epoch 3 batch id 353 loss 2.7872209548950195 train acc 0.33834985835694054\n",
            "epoch 3 batch id 354 loss 2.6818883419036865 train acc 0.3384092514124294\n",
            "epoch 3 batch id 355 loss 2.649496078491211 train acc 0.33829225352112674\n",
            "epoch 3 batch id 356 loss 2.619215726852417 train acc 0.33839536516853935\n",
            "epoch 3 batch id 357 loss 2.874119758605957 train acc 0.3383228291316527\n",
            "epoch 3 batch id 358 loss 2.576597213745117 train acc 0.33851256983240224\n",
            "epoch 3 batch id 359 loss 2.6160264015197754 train acc 0.33870125348189417\n",
            "epoch 3 batch id 360 loss 2.7589731216430664 train acc 0.338671875\n",
            "epoch 3 batch id 361 loss 2.8188929557800293 train acc 0.3384262465373961\n",
            "epoch 3 batch id 362 loss 2.855964422225952 train acc 0.33826830110497236\n",
            "epoch 3 batch id 363 loss 2.8612329959869385 train acc 0.3381542699724518\n",
            "epoch 3 batch id 364 loss 2.705972194671631 train acc 0.3382554945054945\n",
            "epoch 3 batch id 365 loss 2.8930318355560303 train acc 0.33814212328767124\n",
            "epoch 3 batch id 366 loss 2.8579070568084717 train acc 0.3380720628415301\n",
            "epoch 3 batch id 367 loss 2.632788896560669 train acc 0.3381301089918256\n",
            "epoch 3 batch id 368 loss 2.5180325508117676 train acc 0.3384425951086957\n",
            "epoch 3 batch id 369 loss 2.419050931930542 train acc 0.33900745257452575\n",
            "epoch 3 batch id 370 loss 2.45576548576355 train acc 0.33918918918918917\n",
            "epoch 3 batch id 371 loss 2.5609629154205322 train acc 0.33911725067385445\n",
            "epoch 3 batch id 372 loss 2.572380304336548 train acc 0.3394657258064516\n",
            "epoch 3 batch id 373 loss 2.530956506729126 train acc 0.33968666219839144\n",
            "epoch 3 batch id 374 loss 2.6156458854675293 train acc 0.33969752673796794\n",
            "epoch 3 batch id 375 loss 2.5799062252044678 train acc 0.33991666666666664\n",
            "epoch 3 batch id 376 loss 2.424860954284668 train acc 0.3402177526595745\n",
            "epoch 3 batch id 377 loss 2.569878101348877 train acc 0.34031001326259946\n",
            "epoch 3 batch id 378 loss 2.778658390045166 train acc 0.3402364417989418\n",
            "epoch 3 batch id 379 loss 2.7895543575286865 train acc 0.3402457124010554\n",
            "epoch 3 batch id 380 loss 2.844137191772461 train acc 0.34017269736842104\n",
            "epoch 3 batch id 381 loss 2.6488778591156006 train acc 0.3401820866141732\n",
            "epoch 3 batch id 382 loss 2.571388006210327 train acc 0.3403550392670157\n",
            "epoch 3 batch id 383 loss 2.6024394035339355 train acc 0.34032310704960833\n",
            "epoch 3 batch id 384 loss 2.7542200088500977 train acc 0.3404134114583333\n",
            "epoch 3 batch id 385 loss 3.0485072135925293 train acc 0.34017857142857144\n",
            "epoch 3 batch id 386 loss 2.9248876571655273 train acc 0.3399854274611399\n",
            "epoch 3 batch id 387 loss 2.575716972351074 train acc 0.34007590439276486\n",
            "epoch 3 batch id 388 loss 2.581164598464966 train acc 0.34024645618556704\n",
            "epoch 3 batch id 389 loss 2.71734619140625 train acc 0.3401751285347044\n",
            "epoch 3 batch id 390 loss 2.742469310760498 train acc 0.340224358974359\n",
            "epoch 3 batch id 391 loss 2.5646438598632812 train acc 0.34039322250639387\n",
            "epoch 3 batch id 392 loss 2.4696080684661865 train acc 0.34080038265306123\n",
            "epoch 3 batch id 393 loss 2.6448371410369873 train acc 0.34088740458015265\n",
            "epoch 3 batch id 394 loss 2.694251537322998 train acc 0.34065672588832485\n",
            "epoch 3 batch id 395 loss 2.769542932510376 train acc 0.3407832278481013\n",
            "epoch 3 batch id 396 loss 2.8239526748657227 train acc 0.34063289141414144\n",
            "epoch 3 batch id 397 loss 2.7159392833709717 train acc 0.3405620277078086\n",
            "epoch 3 batch id 398 loss 2.841400146484375 train acc 0.3402559673366834\n",
            "epoch 3 batch id 399 loss 2.8046815395355225 train acc 0.3400689223057644\n",
            "epoch 3 batch id 400 loss 2.724289655685425 train acc 0.34\n",
            "epoch 3 batch id 401 loss 2.615471601486206 train acc 0.34000935162094764\n",
            "epoch 3 batch id 402 loss 2.6703696250915527 train acc 0.34009639303482586\n",
            "epoch 3 batch id 403 loss 2.479261875152588 train acc 0.34041563275434245\n",
            "epoch 3 batch id 404 loss 3.282229423522949 train acc 0.3401918316831683\n",
            "epoch 3 batch id 405 loss 2.7402539253234863 train acc 0.34012345679012346\n",
            "epoch 3 batch id 406 loss 2.5572595596313477 train acc 0.3402093596059113\n",
            "epoch 3 batch id 407 loss 2.70611834526062 train acc 0.3401796683046683\n",
            "epoch 3 batch id 408 loss 2.492861747741699 train acc 0.3403799019607843\n",
            "epoch 3 batch id 409 loss 2.860161304473877 train acc 0.340273533007335\n",
            "epoch 3 batch id 410 loss 2.6009817123413086 train acc 0.34035823170731705\n",
            "epoch 3 batch id 411 loss 2.8423216342926025 train acc 0.3402904501216545\n",
            "epoch 3 batch id 412 loss 2.8367369174957275 train acc 0.3402988470873786\n",
            "epoch 3 batch id 413 loss 3.3376615047454834 train acc 0.33996670702179177\n",
            "epoch 3 batch id 414 loss 2.6441948413848877 train acc 0.3400890700483092\n",
            "epoch 3 batch id 415 loss 2.9501521587371826 train acc 0.33990963855421685\n",
            "epoch 3 batch id 416 loss 2.483548164367676 train acc 0.3401066706730769\n",
            "epoch 3 batch id 417 loss 2.4525136947631836 train acc 0.3404151678657074\n",
            "epoch 3 batch id 418 loss 2.4484307765960693 train acc 0.34057266746411485\n",
            "epoch 3 batch id 419 loss 2.833199977874756 train acc 0.3404310859188544\n",
            "epoch 3 batch id 420 loss 2.7052125930786133 train acc 0.3404761904761905\n",
            "epoch 3 batch id 421 loss 2.91237211227417 train acc 0.34048396674584325\n",
            "epoch 3 batch id 422 loss 2.572253942489624 train acc 0.34049170616113744\n",
            "epoch 3 batch id 423 loss 2.6667983531951904 train acc 0.3405732860520095\n",
            "epoch 3 batch id 424 loss 2.4960508346557617 train acc 0.34076503537735847\n",
            "epoch 3 batch id 425 loss 2.1902761459350586 train acc 0.3411029411764706\n",
            "epoch 3 batch id 426 loss 2.658529281616211 train acc 0.3411825117370892\n",
            "epoch 3 batch id 427 loss 2.3145687580108643 train acc 0.34144467213114754\n",
            "epoch 3 batch id 428 loss 2.6741838455200195 train acc 0.34137704439252337\n",
            "epoch 3 batch id 429 loss 2.513521909713745 train acc 0.3415282634032634\n",
            "epoch 3 batch id 430 loss 2.9719643592834473 train acc 0.34153343023255817\n",
            "epoch 3 batch id 431 loss 2.667188882827759 train acc 0.3415023201856148\n",
            "epoch 3 batch id 432 loss 2.62335205078125 train acc 0.3415798611111111\n",
            "epoch 3 batch id 433 loss 2.324641704559326 train acc 0.3418374711316397\n",
            "epoch 3 batch id 434 loss 2.6854746341705322 train acc 0.34184187788018433\n",
            "epoch 3 batch id 435 loss 2.619842052459717 train acc 0.3417744252873563\n",
            "epoch 3 batch id 436 loss 2.545900344848633 train acc 0.3421014908256881\n",
            "epoch 3 batch id 437 loss 2.7162020206451416 train acc 0.34210526315789475\n",
            "epoch 3 batch id 438 loss 2.5300986766815186 train acc 0.3422873858447489\n",
            "epoch 3 batch id 439 loss 2.506742238998413 train acc 0.3423619020501139\n",
            "epoch 3 batch id 440 loss 2.607006788253784 train acc 0.3422940340909091\n",
            "epoch 3 batch id 441 loss 2.5789804458618164 train acc 0.34250992063492064\n",
            "epoch 3 batch id 442 loss 2.4426681995391846 train acc 0.342654128959276\n",
            "epoch 3 batch id 443 loss 2.7275664806365967 train acc 0.3427624153498871\n",
            "epoch 3 batch id 444 loss 2.6566262245178223 train acc 0.3427998310810811\n",
            "epoch 3 batch id 445 loss 2.287646770477295 train acc 0.343188202247191\n",
            "epoch 3 batch id 446 loss 2.618666887283325 train acc 0.34329456278026904\n",
            "epoch 3 batch id 447 loss 2.6302499771118164 train acc 0.34343540268456374\n",
            "epoch 3 batch id 448 loss 2.532397508621216 train acc 0.34354073660714285\n",
            "epoch 3 batch id 449 loss 2.529927968978882 train acc 0.3437152004454343\n",
            "epoch 3 batch id 450 loss 2.5184619426727295 train acc 0.34392361111111114\n",
            "epoch 3 batch id 451 loss 2.556971311569214 train acc 0.34399251662971175\n",
            "epoch 3 batch id 452 loss 2.6540393829345703 train acc 0.34413025442477874\n",
            "epoch 3 batch id 453 loss 2.654405355453491 train acc 0.3439569536423841\n",
            "epoch 3 batch id 454 loss 2.5484399795532227 train acc 0.34402533039647576\n",
            "epoch 3 batch id 455 loss 2.475834369659424 train acc 0.3441620879120879\n",
            "epoch 3 batch id 456 loss 2.6283440589904785 train acc 0.34412691885964913\n",
            "epoch 3 batch id 457 loss 2.4398739337921143 train acc 0.34443380743982493\n",
            "epoch 3 batch id 458 loss 2.7750344276428223 train acc 0.34436408296943233\n",
            "epoch 3 batch id 459 loss 2.5119686126708984 train acc 0.3446010348583878\n",
            "epoch 3 batch id 460 loss 2.461174249649048 train acc 0.34476902173913043\n",
            "epoch 3 batch id 461 loss 2.7391769886016846 train acc 0.34469902386117135\n",
            "epoch 3 batch id 462 loss 2.464777946472168 train acc 0.3449337121212121\n",
            "epoch 3 batch id 463 loss 2.553776264190674 train acc 0.34499865010799136\n",
            "epoch 3 batch id 464 loss 2.442051410675049 train acc 0.3451643318965517\n",
            "epoch 3 batch id 465 loss 2.8504042625427246 train acc 0.3450940860215054\n",
            "epoch 3 batch id 466 loss 2.3907132148742676 train acc 0.34529238197424894\n",
            "epoch 3 batch id 467 loss 2.5665628910064697 train acc 0.3452556209850107\n",
            "epoch 3 batch id 468 loss 2.681303024291992 train acc 0.3452190170940171\n",
            "epoch 3 batch id 469 loss 2.6069161891937256 train acc 0.3453158315565032\n",
            "epoch 3 batch id 470 loss 2.783704996109009 train acc 0.34527925531914894\n",
            "epoch 3 batch id 471 loss 2.655880928039551 train acc 0.34524283439490444\n",
            "epoch 3 batch id 472 loss 2.573662519454956 train acc 0.3453720868644068\n",
            "epoch 3 batch id 473 loss 2.742048501968384 train acc 0.34533562367864695\n",
            "epoch 3 batch id 474 loss 2.7131214141845703 train acc 0.34533227848101267\n",
            "epoch 3 batch id 475 loss 2.4414048194885254 train acc 0.3454605263157895\n",
            "epoch 3 batch id 476 loss 2.593885660171509 train acc 0.34552258403361347\n",
            "epoch 3 batch id 477 loss 2.712890386581421 train acc 0.3455188679245283\n",
            "epoch 3 batch id 478 loss 2.549466848373413 train acc 0.34574398535564854\n",
            "epoch 3 batch id 479 loss 2.560295820236206 train acc 0.34580506263048016\n",
            "epoch 3 batch id 480 loss 2.4753715991973877 train acc 0.34596354166666665\n",
            "epoch 3 batch id 481 loss 2.6342103481292725 train acc 0.34599142411642414\n",
            "epoch 3 batch id 482 loss 2.4763028621673584 train acc 0.34605160788381745\n",
            "epoch 3 batch id 483 loss 2.513545036315918 train acc 0.34624094202898553\n",
            "epoch 3 batch id 484 loss 2.7800161838531494 train acc 0.3461066632231405\n",
            "epoch 3 batch id 485 loss 2.428487539291382 train acc 0.34632731958762886\n",
            "epoch 3 batch id 486 loss 2.7531545162200928 train acc 0.346386316872428\n",
            "epoch 3 batch id 487 loss 2.692647695541382 train acc 0.34647715605749485\n",
            "epoch 3 batch id 488 loss 2.4834065437316895 train acc 0.34656762295081966\n",
            "epoch 3 batch id 489 loss 2.5048787593841553 train acc 0.34662576687116564\n",
            "epoch 3 batch id 490 loss 2.6097965240478516 train acc 0.3464923469387755\n",
            "epoch 3 batch id 491 loss 2.8130712509155273 train acc 0.346423116089613\n",
            "epoch 3 batch id 492 loss 2.4335553646087646 train acc 0.34644944105691056\n",
            "epoch 3 batch id 493 loss 2.5995066165924072 train acc 0.34634888438133876\n",
            "epoch 3 batch id 494 loss 2.7032907009124756 train acc 0.3464068825910931\n",
            "epoch 3 batch id 495 loss 2.3105475902557373 train acc 0.3465593434343434\n",
            "epoch 3 batch id 496 loss 2.733302116394043 train acc 0.3465851814516129\n",
            "epoch 3 batch id 497 loss 2.354541301727295 train acc 0.3467366700201207\n",
            "epoch 3 batch id 498 loss 2.923609495162964 train acc 0.3467934236947791\n",
            "epoch 3 batch id 499 loss 2.5449440479278564 train acc 0.3469125751503006\n",
            "epoch 3 batch id 500 loss 2.8093698024749756 train acc 0.3468125\n",
            "epoch 3 batch id 501 loss 2.4875917434692383 train acc 0.3470247005988024\n",
            "epoch 3 batch id 502 loss 2.3399932384490967 train acc 0.3472671812749004\n",
            "epoch 3 batch id 503 loss 2.7048721313476562 train acc 0.3472601888667992\n",
            "epoch 3 batch id 504 loss 2.698640823364258 train acc 0.34719122023809523\n",
            "epoch 3 batch id 505 loss 2.7483747005462646 train acc 0.34709158415841584\n",
            "epoch 3 batch id 506 loss 2.604388952255249 train acc 0.3472393774703557\n",
            "epoch 3 batch id 507 loss 2.3834831714630127 train acc 0.347448224852071\n",
            "epoch 3 batch id 508 loss 2.568904161453247 train acc 0.3475947342519685\n",
            "epoch 3 batch id 509 loss 2.7632291316986084 train acc 0.3477099705304519\n",
            "epoch 3 batch id 510 loss 2.7664196491241455 train acc 0.34767156862745097\n",
            "epoch 3 batch id 511 loss 2.3976147174835205 train acc 0.3477366974186935\n",
            "epoch 3 train acc 0.3477366974186935\n",
            "epoch 3 test acc 0.3561197916666667\n",
            "epoch 4 batch id 1 loss 2.6502573490142822 train acc 0.453125\n",
            "epoch 4 batch id 2 loss 2.7563586235046387 train acc 0.390625\n",
            "epoch 4 batch id 3 loss 2.611569881439209 train acc 0.3854166666666667\n",
            "epoch 4 batch id 4 loss 2.7079179286956787 train acc 0.37890625\n",
            "epoch 4 batch id 5 loss 2.790471315383911 train acc 0.36875\n",
            "epoch 4 batch id 6 loss 2.5578556060791016 train acc 0.359375\n",
            "epoch 4 batch id 7 loss 2.3141961097717285 train acc 0.36830357142857145\n",
            "epoch 4 batch id 8 loss 2.6238608360290527 train acc 0.37109375\n",
            "epoch 4 batch id 9 loss 2.5293169021606445 train acc 0.3715277777777778\n",
            "epoch 4 batch id 10 loss 2.4991281032562256 train acc 0.3796875\n",
            "epoch 4 batch id 11 loss 2.430600881576538 train acc 0.3821022727272727\n",
            "epoch 4 batch id 12 loss 2.5042524337768555 train acc 0.3815104166666667\n",
            "epoch 4 batch id 13 loss 2.821305274963379 train acc 0.3786057692307692\n",
            "epoch 4 batch id 14 loss 2.5720784664154053 train acc 0.3794642857142857\n",
            "epoch 4 batch id 15 loss 2.8065707683563232 train acc 0.37604166666666666\n",
            "epoch 4 batch id 16 loss 2.42508602142334 train acc 0.380859375\n",
            "epoch 4 batch id 17 loss 2.6293892860412598 train acc 0.3805147058823529\n",
            "epoch 4 batch id 18 loss 2.6119587421417236 train acc 0.3845486111111111\n",
            "epoch 4 batch id 19 loss 2.4485013484954834 train acc 0.38569078947368424\n",
            "epoch 4 batch id 20 loss 2.3395156860351562 train acc 0.38828125\n",
            "epoch 4 batch id 21 loss 2.5956039428710938 train acc 0.38764880952380953\n",
            "epoch 4 batch id 22 loss 2.7327945232391357 train acc 0.3835227272727273\n",
            "epoch 4 batch id 23 loss 2.6913514137268066 train acc 0.38315217391304346\n",
            "epoch 4 batch id 24 loss 2.561410427093506 train acc 0.3828125\n",
            "epoch 4 batch id 25 loss 2.720790147781372 train acc 0.380625\n",
            "epoch 4 batch id 26 loss 2.6334640979766846 train acc 0.38461538461538464\n",
            "epoch 4 batch id 27 loss 2.644218683242798 train acc 0.38310185185185186\n",
            "epoch 4 batch id 28 loss 2.5484914779663086 train acc 0.38113839285714285\n",
            "epoch 4 batch id 29 loss 2.341780662536621 train acc 0.3863146551724138\n",
            "epoch 4 batch id 30 loss 2.4871127605438232 train acc 0.3875\n",
            "epoch 4 batch id 31 loss 2.276455879211426 train acc 0.38810483870967744\n",
            "epoch 4 batch id 32 loss 2.6752371788024902 train acc 0.38818359375\n",
            "epoch 4 batch id 33 loss 2.382260322570801 train acc 0.38920454545454547\n",
            "epoch 4 batch id 34 loss 2.4659361839294434 train acc 0.38924632352941174\n",
            "epoch 4 batch id 35 loss 2.4549920558929443 train acc 0.3892857142857143\n",
            "epoch 4 batch id 36 loss 2.3269994258880615 train acc 0.3932291666666667\n",
            "epoch 4 batch id 37 loss 2.362595796585083 train acc 0.39611486486486486\n",
            "epoch 4 batch id 38 loss 2.5757381916046143 train acc 0.39555921052631576\n",
            "epoch 4 batch id 39 loss 2.698254108428955 train acc 0.39342948717948717\n",
            "epoch 4 batch id 40 loss 2.6331946849823 train acc 0.394140625\n",
            "epoch 4 batch id 41 loss 2.5212490558624268 train acc 0.3948170731707317\n",
            "epoch 4 batch id 42 loss 2.7744107246398926 train acc 0.3947172619047619\n",
            "epoch 4 batch id 43 loss 2.6575207710266113 train acc 0.39280523255813954\n",
            "epoch 4 batch id 44 loss 2.59299373626709 train acc 0.3934659090909091\n",
            "epoch 4 batch id 45 loss 2.4986350536346436 train acc 0.39444444444444443\n",
            "epoch 4 batch id 46 loss 2.4912073612213135 train acc 0.39334239130434784\n",
            "epoch 4 batch id 47 loss 2.322179079055786 train acc 0.3949468085106383\n",
            "epoch 4 batch id 48 loss 3.0174508094787598 train acc 0.3909505208333333\n",
            "epoch 4 batch id 49 loss 2.4466552734375 train acc 0.38998724489795916\n",
            "epoch 4 batch id 50 loss 2.4021499156951904 train acc 0.389375\n",
            "epoch 4 batch id 51 loss 2.529581069946289 train acc 0.38878676470588236\n",
            "epoch 4 batch id 52 loss 2.521324396133423 train acc 0.3897235576923077\n",
            "epoch 4 batch id 53 loss 2.674863576889038 train acc 0.3897405660377358\n",
            "epoch 4 batch id 54 loss 2.317760705947876 train acc 0.39207175925925924\n",
            "epoch 4 batch id 55 loss 2.557467460632324 train acc 0.3931818181818182\n",
            "epoch 4 batch id 56 loss 2.397472381591797 train acc 0.392578125\n",
            "epoch 4 batch id 57 loss 2.526125431060791 train acc 0.39172149122807015\n",
            "epoch 4 batch id 58 loss 2.5041663646698 train acc 0.39143318965517243\n",
            "epoch 4 batch id 59 loss 2.4640588760375977 train acc 0.3916843220338983\n",
            "epoch 4 batch id 60 loss 2.682009696960449 train acc 0.39140625\n",
            "epoch 4 batch id 61 loss 2.5528926849365234 train acc 0.3921618852459016\n",
            "epoch 4 batch id 62 loss 2.466533899307251 train acc 0.39264112903225806\n",
            "epoch 4 batch id 63 loss 2.545666217803955 train acc 0.39186507936507936\n",
            "epoch 4 batch id 64 loss 2.488892078399658 train acc 0.3935546875\n",
            "epoch 4 batch id 65 loss 2.5193169116973877 train acc 0.3935096153846154\n",
            "epoch 4 batch id 66 loss 2.690690517425537 train acc 0.39228219696969696\n",
            "epoch 4 batch id 67 loss 2.4330146312713623 train acc 0.39225746268656714\n",
            "epoch 4 batch id 68 loss 2.4197700023651123 train acc 0.39200367647058826\n",
            "epoch 4 batch id 69 loss 2.5113158226013184 train acc 0.39266304347826086\n",
            "epoch 4 batch id 70 loss 2.6271448135375977 train acc 0.39285714285714285\n",
            "epoch 4 batch id 71 loss 2.2273027896881104 train acc 0.3941461267605634\n",
            "epoch 4 batch id 72 loss 2.7316813468933105 train acc 0.3930121527777778\n",
            "epoch 4 batch id 73 loss 2.376269817352295 train acc 0.3938356164383562\n",
            "epoch 4 batch id 74 loss 2.7893178462982178 train acc 0.3940033783783784\n",
            "epoch 4 batch id 75 loss 2.295243978500366 train acc 0.39416666666666667\n",
            "epoch 4 batch id 76 loss 2.699631929397583 train acc 0.3932976973684211\n",
            "epoch 4 batch id 77 loss 2.5590643882751465 train acc 0.39306006493506496\n",
            "epoch 4 batch id 78 loss 2.3792624473571777 train acc 0.39443108974358976\n",
            "epoch 4 batch id 79 loss 2.5801854133605957 train acc 0.3947784810126582\n",
            "epoch 4 batch id 80 loss 2.713780641555786 train acc 0.3939453125\n",
            "epoch 4 batch id 81 loss 2.5212252140045166 train acc 0.3940972222222222\n",
            "epoch 4 batch id 82 loss 2.799724578857422 train acc 0.3940548780487805\n",
            "epoch 4 batch id 83 loss 2.7947351932525635 train acc 0.3930722891566265\n",
            "epoch 4 batch id 84 loss 2.384037971496582 train acc 0.39267113095238093\n",
            "epoch 4 batch id 85 loss 2.5090551376342773 train acc 0.39283088235294117\n",
            "epoch 4 batch id 86 loss 2.320403575897217 train acc 0.3933502906976744\n",
            "epoch 4 batch id 87 loss 2.4801807403564453 train acc 0.3933189655172414\n",
            "epoch 4 batch id 88 loss 2.694573402404785 train acc 0.39293323863636365\n",
            "epoch 4 batch id 89 loss 2.474331855773926 train acc 0.3922050561797753\n",
            "epoch 4 batch id 90 loss 2.4307522773742676 train acc 0.3923611111111111\n",
            "epoch 4 batch id 91 loss 2.4762372970581055 train acc 0.39234203296703296\n",
            "epoch 4 batch id 92 loss 2.5519165992736816 train acc 0.3923233695652174\n",
            "epoch 4 batch id 93 loss 2.28438401222229 train acc 0.3941532258064516\n",
            "epoch 4 batch id 94 loss 2.538902997970581 train acc 0.3941156914893617\n",
            "epoch 4 batch id 95 loss 2.6922380924224854 train acc 0.39407894736842103\n",
            "epoch 4 batch id 96 loss 2.4967496395111084 train acc 0.3937174479166667\n",
            "epoch 4 batch id 97 loss 2.5644240379333496 train acc 0.3940077319587629\n",
            "epoch 4 batch id 98 loss 2.506005048751831 train acc 0.3938137755102041\n",
            "epoch 4 batch id 99 loss 2.2875750064849854 train acc 0.39457070707070707\n",
            "epoch 4 batch id 100 loss 2.3774666786193848 train acc 0.39515625\n",
            "epoch 4 batch id 101 loss 2.582491159439087 train acc 0.39464727722772275\n",
            "epoch 4 batch id 102 loss 2.488154411315918 train acc 0.3950674019607843\n",
            "epoch 4 batch id 103 loss 2.352701425552368 train acc 0.39578276699029125\n",
            "epoch 4 batch id 104 loss 2.2722818851470947 train acc 0.39663461538461536\n",
            "epoch 4 batch id 105 loss 2.518679618835449 train acc 0.3958333333333333\n",
            "epoch 4 batch id 106 loss 2.602781295776367 train acc 0.3959316037735849\n",
            "epoch 4 batch id 107 loss 2.4273767471313477 train acc 0.39602803738317754\n",
            "epoch 4 batch id 108 loss 2.1653120517730713 train acc 0.3971354166666667\n",
            "epoch 4 batch id 109 loss 2.1858978271484375 train acc 0.39807912844036697\n",
            "epoch 4 batch id 110 loss 2.628187656402588 train acc 0.39815340909090907\n",
            "epoch 4 batch id 111 loss 2.254122257232666 train acc 0.3987894144144144\n",
            "epoch 4 batch id 112 loss 2.3891899585723877 train acc 0.39871651785714285\n",
            "epoch 4 batch id 113 loss 2.779430389404297 train acc 0.3975387168141593\n",
            "epoch 4 batch id 114 loss 2.376538038253784 train acc 0.3978892543859649\n",
            "epoch 4 batch id 115 loss 2.5881309509277344 train acc 0.3972826086956522\n",
            "epoch 4 batch id 116 loss 2.4413206577301025 train acc 0.39762931034482757\n",
            "epoch 4 batch id 117 loss 2.4495720863342285 train acc 0.3974358974358974\n",
            "epoch 4 batch id 118 loss 2.485373020172119 train acc 0.397510593220339\n",
            "epoch 4 batch id 119 loss 2.3209900856018066 train acc 0.39758403361344535\n",
            "epoch 4 batch id 120 loss 2.421048879623413 train acc 0.3977864583333333\n",
            "epoch 4 batch id 121 loss 2.396216630935669 train acc 0.3974690082644628\n",
            "epoch 4 batch id 122 loss 2.4104881286621094 train acc 0.3974129098360656\n",
            "epoch 4 batch id 123 loss 2.648327350616455 train acc 0.39684959349593496\n",
            "epoch 4 batch id 124 loss 2.2854604721069336 train acc 0.3971774193548387\n",
            "epoch 4 batch id 125 loss 2.5682413578033447 train acc 0.396875\n",
            "epoch 4 batch id 126 loss 2.6904311180114746 train acc 0.39620535714285715\n",
            "epoch 4 batch id 127 loss 2.4534354209899902 train acc 0.39603838582677164\n",
            "epoch 4 batch id 128 loss 2.3524551391601562 train acc 0.3966064453125\n",
            "epoch 4 batch id 129 loss 2.060790538787842 train acc 0.39789244186046513\n",
            "epoch 4 batch id 130 loss 2.5151352882385254 train acc 0.39795673076923077\n",
            "epoch 4 batch id 131 loss 2.2659053802490234 train acc 0.39849713740458015\n",
            "epoch 4 batch id 132 loss 2.8588037490844727 train acc 0.39820075757575757\n",
            "epoch 4 batch id 133 loss 2.4573469161987305 train acc 0.39790883458646614\n",
            "epoch 4 batch id 134 loss 2.6797876358032227 train acc 0.39750466417910446\n",
            "epoch 4 batch id 135 loss 2.415264129638672 train acc 0.3972222222222222\n",
            "epoch 4 batch id 136 loss 2.3399322032928467 train acc 0.39763327205882354\n",
            "epoch 4 batch id 137 loss 2.636233329772949 train acc 0.39735401459854014\n",
            "epoch 4 batch id 138 loss 2.470858097076416 train acc 0.3969655797101449\n",
            "epoch 4 batch id 139 loss 2.393754482269287 train acc 0.39748201438848924\n",
            "epoch 4 batch id 140 loss 2.3388867378234863 train acc 0.39810267857142856\n",
            "epoch 4 batch id 141 loss 2.858610153198242 train acc 0.3976063829787234\n",
            "epoch 4 batch id 142 loss 2.448317527770996 train acc 0.397887323943662\n",
            "epoch 4 batch id 143 loss 2.406881332397461 train acc 0.39849213286713286\n",
            "epoch 4 batch id 144 loss 2.36183500289917 train acc 0.3988715277777778\n",
            "epoch 4 batch id 145 loss 2.294335126876831 train acc 0.39935344827586206\n",
            "epoch 4 batch id 146 loss 2.4828872680664062 train acc 0.3990796232876712\n",
            "epoch 4 batch id 147 loss 2.5789425373077393 train acc 0.398703231292517\n",
            "epoch 4 batch id 148 loss 2.6372056007385254 train acc 0.39854307432432434\n",
            "epoch 4 batch id 149 loss 2.5302441120147705 train acc 0.39786073825503354\n",
            "epoch 4 batch id 150 loss 2.3281586170196533 train acc 0.3982291666666667\n",
            "epoch 4 batch id 151 loss 2.7181406021118164 train acc 0.3980753311258278\n",
            "epoch 4 batch id 152 loss 2.480448007583618 train acc 0.39823190789473684\n",
            "epoch 4 batch id 153 loss 2.8227133750915527 train acc 0.39767156862745096\n",
            "epoch 4 batch id 154 loss 2.46589994430542 train acc 0.39752435064935066\n",
            "epoch 4 batch id 155 loss 2.5969057083129883 train acc 0.3971774193548387\n",
            "epoch 4 batch id 156 loss 2.477571725845337 train acc 0.3974358974358974\n",
            "epoch 4 batch id 157 loss 2.4742822647094727 train acc 0.39729299363057324\n",
            "epoch 4 batch id 158 loss 2.4485557079315186 train acc 0.39685522151898733\n",
            "epoch 4 batch id 159 loss 2.4378840923309326 train acc 0.3967177672955975\n",
            "epoch 4 batch id 160 loss 2.2863707542419434 train acc 0.396875\n",
            "epoch 4 batch id 161 loss 2.6503818035125732 train acc 0.39644798136645965\n",
            "epoch 4 batch id 162 loss 2.7404167652130127 train acc 0.3961226851851852\n",
            "epoch 4 batch id 163 loss 2.5155258178710938 train acc 0.39580138036809814\n",
            "epoch 4 batch id 164 loss 2.6164119243621826 train acc 0.3952934451219512\n",
            "epoch 4 batch id 165 loss 2.2126388549804688 train acc 0.39545454545454545\n",
            "epoch 4 batch id 166 loss 2.536672353744507 train acc 0.3953313253012048\n",
            "epoch 4 batch id 167 loss 2.3938682079315186 train acc 0.39549026946107785\n",
            "epoch 4 batch id 168 loss 2.362020492553711 train acc 0.39564732142857145\n",
            "epoch 4 batch id 169 loss 2.464931011199951 train acc 0.39571005917159763\n",
            "epoch 4 batch id 170 loss 2.6642277240753174 train acc 0.3957720588235294\n",
            "epoch 4 batch id 171 loss 2.6877713203430176 train acc 0.3956505847953216\n",
            "epoch 4 batch id 172 loss 2.3045735359191895 train acc 0.39625726744186046\n",
            "epoch 4 batch id 173 loss 2.605703592300415 train acc 0.3960440751445087\n",
            "epoch 4 batch id 174 loss 2.435994863510132 train acc 0.39601293103448276\n",
            "epoch 4 batch id 175 loss 2.807211399078369 train acc 0.3958035714285714\n",
            "epoch 4 batch id 176 loss 2.375924587249756 train acc 0.39595170454545453\n",
            "epoch 4 batch id 177 loss 2.3252298831939697 train acc 0.3960981638418079\n",
            "epoch 4 batch id 178 loss 2.454484224319458 train acc 0.3962429775280899\n",
            "epoch 4 batch id 179 loss 2.5606067180633545 train acc 0.39621159217877094\n",
            "epoch 4 batch id 180 loss 2.757220506668091 train acc 0.3957465277777778\n",
            "epoch 4 batch id 181 loss 2.5071587562561035 train acc 0.39571823204419887\n",
            "epoch 4 batch id 182 loss 2.484215259552002 train acc 0.3956043956043956\n",
            "epoch 4 batch id 183 loss 2.6402053833007812 train acc 0.3952356557377049\n",
            "epoch 4 batch id 184 loss 2.3542041778564453 train acc 0.395210597826087\n",
            "epoch 4 batch id 185 loss 2.3172829151153564 train acc 0.39518581081081083\n",
            "epoch 4 batch id 186 loss 2.5098605155944824 train acc 0.3954133064516129\n",
            "epoch 4 batch id 187 loss 2.3621222972869873 train acc 0.39547125668449196\n",
            "epoch 4 batch id 188 loss 2.6280407905578613 train acc 0.39544547872340424\n",
            "epoch 4 batch id 189 loss 2.330612897872925 train acc 0.3957506613756614\n",
            "epoch 4 batch id 190 loss 2.5494260787963867 train acc 0.39547697368421053\n",
            "epoch 4 batch id 191 loss 2.560786724090576 train acc 0.39528795811518325\n",
            "epoch 4 batch id 192 loss 2.742678642272949 train acc 0.39501953125\n",
            "epoch 4 batch id 193 loss 2.6055989265441895 train acc 0.3945110103626943\n",
            "epoch 4 batch id 194 loss 2.383474826812744 train acc 0.3948131443298969\n",
            "epoch 4 batch id 195 loss 2.554992914199829 train acc 0.39455128205128204\n",
            "epoch 4 batch id 196 loss 2.453162431716919 train acc 0.39453125\n",
            "epoch 4 batch id 197 loss 2.6926074028015137 train acc 0.3939562182741117\n",
            "epoch 4 batch id 198 loss 2.431342840194702 train acc 0.39378156565656564\n",
            "epoch 4 batch id 199 loss 2.5574305057525635 train acc 0.39384422110552764\n",
            "epoch 4 batch id 200 loss 2.3975157737731934 train acc 0.394140625\n",
            "epoch 4 batch id 201 loss 2.53208065032959 train acc 0.3942008706467662\n",
            "epoch 4 batch id 202 loss 1.940657377243042 train acc 0.3947246287128713\n",
            "epoch 4 batch id 203 loss 2.3933916091918945 train acc 0.39462746305418717\n",
            "epoch 4 batch id 204 loss 2.303428888320923 train acc 0.39453125\n",
            "epoch 4 batch id 205 loss 2.2493321895599365 train acc 0.3954268292682927\n",
            "epoch 4 batch id 206 loss 2.570415735244751 train acc 0.3952518203883495\n",
            "epoch 4 batch id 207 loss 2.5763041973114014 train acc 0.3951539855072464\n",
            "epoch 4 batch id 208 loss 2.5977847576141357 train acc 0.39513221153846156\n",
            "epoch 4 batch id 209 loss 2.327423095703125 train acc 0.39488636363636365\n",
            "epoch 4 batch id 210 loss 2.3265106678009033 train acc 0.3947172619047619\n",
            "epoch 4 batch id 211 loss 2.2042269706726074 train acc 0.39521623222748814\n",
            "epoch 4 batch id 212 loss 2.359537363052368 train acc 0.3951208726415094\n",
            "epoch 4 batch id 213 loss 2.411007881164551 train acc 0.39524647887323944\n",
            "epoch 4 batch id 214 loss 2.5101118087768555 train acc 0.3951518691588785\n",
            "epoch 4 batch id 215 loss 2.4252641201019287 train acc 0.3949854651162791\n",
            "epoch 4 batch id 216 loss 2.568364381790161 train acc 0.3947482638888889\n",
            "epoch 4 batch id 217 loss 2.460927724838257 train acc 0.3948732718894009\n",
            "epoch 4 batch id 218 loss 2.4775373935699463 train acc 0.39478211009174313\n",
            "epoch 4 batch id 219 loss 2.4134955406188965 train acc 0.3945490867579909\n",
            "epoch 4 batch id 220 loss 2.1616461277008057 train acc 0.39488636363636365\n",
            "epoch 4 batch id 221 loss 2.3365283012390137 train acc 0.3948670814479638\n",
            "epoch 4 batch id 222 loss 2.5371153354644775 train acc 0.39456644144144143\n",
            "epoch 4 batch id 223 loss 2.4686777591705322 train acc 0.3944086322869955\n",
            "epoch 4 batch id 224 loss 2.3399343490600586 train acc 0.39439174107142855\n",
            "epoch 4 batch id 225 loss 2.0407543182373047 train acc 0.3948611111111111\n",
            "epoch 4 batch id 226 loss 2.4694437980651855 train acc 0.3947732300884956\n",
            "epoch 4 batch id 227 loss 1.9794708490371704 train acc 0.3951679515418502\n",
            "epoch 4 batch id 228 loss 2.69777512550354 train acc 0.3946683114035088\n",
            "epoch 4 batch id 229 loss 2.254957437515259 train acc 0.39506004366812225\n",
            "epoch 4 batch id 230 loss 2.4814999103546143 train acc 0.39510869565217394\n",
            "epoch 4 batch id 231 loss 2.25852632522583 train acc 0.3952922077922078\n",
            "epoch 4 batch id 232 loss 2.312143087387085 train acc 0.3955414870689655\n",
            "epoch 4 batch id 233 loss 2.3651251792907715 train acc 0.3955203862660944\n",
            "epoch 4 batch id 234 loss 2.2985799312591553 train acc 0.3955662393162393\n",
            "epoch 4 batch id 235 loss 2.6773929595947266 train acc 0.3952127659574468\n",
            "epoch 4 batch id 236 loss 2.3720250129699707 train acc 0.3953257415254237\n",
            "epoch 4 batch id 237 loss 2.5052239894866943 train acc 0.3951740506329114\n",
            "epoch 4 batch id 238 loss 2.542438268661499 train acc 0.3953518907563025\n",
            "epoch 4 batch id 239 loss 2.382972002029419 train acc 0.3955936192468619\n",
            "epoch 4 batch id 240 loss 2.4728493690490723 train acc 0.3955078125\n",
            "epoch 4 batch id 241 loss 2.3412840366363525 train acc 0.3954875518672199\n",
            "epoch 4 batch id 242 loss 2.3305306434631348 train acc 0.39572572314049587\n",
            "epoch 4 batch id 243 loss 2.446009397506714 train acc 0.395897633744856\n",
            "epoch 4 batch id 244 loss 2.537230968475342 train acc 0.3957479508196721\n",
            "epoch 4 batch id 245 loss 2.1618802547454834 train acc 0.3961734693877551\n",
            "epoch 4 batch id 246 loss 2.481459379196167 train acc 0.39621443089430897\n",
            "epoch 4 batch id 247 loss 2.764514923095703 train acc 0.396002024291498\n",
            "epoch 4 batch id 248 loss 2.8252391815185547 train acc 0.3957913306451613\n",
            "epoch 4 batch id 249 loss 2.3505454063415527 train acc 0.3960843373493976\n",
            "epoch 4 batch id 250 loss 2.420046806335449 train acc 0.396125\n",
            "epoch 4 batch id 251 loss 2.8829643726348877 train acc 0.3956050796812749\n",
            "epoch 4 batch id 252 loss 2.309565782546997 train acc 0.39546130952380953\n",
            "epoch 4 batch id 253 loss 2.5530614852905273 train acc 0.3952569169960474\n",
            "epoch 4 batch id 254 loss 2.2107436656951904 train acc 0.3954847440944882\n",
            "epoch 4 batch id 255 loss 2.3651556968688965 train acc 0.3954656862745098\n",
            "epoch 4 batch id 256 loss 2.558546543121338 train acc 0.39544677734375\n",
            "epoch 4 batch id 257 loss 2.367434024810791 train acc 0.395306420233463\n",
            "epoch 4 batch id 258 loss 2.5147557258605957 train acc 0.3951065891472868\n",
            "epoch 4 batch id 259 loss 2.3181488513946533 train acc 0.3951496138996139\n",
            "epoch 4 batch id 260 loss 2.581052303314209 train acc 0.39513221153846156\n",
            "epoch 4 batch id 261 loss 1.9664424657821655 train acc 0.39571360153256707\n",
            "epoch 4 batch id 262 loss 2.5533316135406494 train acc 0.3958134541984733\n",
            "epoch 4 batch id 263 loss 2.4301185607910156 train acc 0.39585313688212925\n",
            "epoch 4 batch id 264 loss 2.3435451984405518 train acc 0.39601089015151514\n",
            "epoch 4 batch id 265 loss 2.358232021331787 train acc 0.39640330188679246\n",
            "epoch 4 batch id 266 loss 2.348858594894409 train acc 0.3963228383458647\n",
            "epoch 4 batch id 267 loss 2.434351682662964 train acc 0.3964185393258427\n",
            "epoch 4 batch id 268 loss 2.3914899826049805 train acc 0.396513526119403\n",
            "epoch 4 batch id 269 loss 2.168900966644287 train acc 0.39672397769516726\n",
            "epoch 4 batch id 270 loss 2.198190927505493 train acc 0.3968171296296296\n",
            "epoch 4 batch id 271 loss 2.235084056854248 train acc 0.3970825645756458\n",
            "epoch 4 batch id 272 loss 2.242325782775879 train acc 0.3971737132352941\n",
            "epoch 4 batch id 273 loss 2.480581283569336 train acc 0.3970924908424908\n",
            "epoch 4 batch id 274 loss 2.5135726928710938 train acc 0.3968978102189781\n",
            "epoch 4 batch id 275 loss 2.4676904678344727 train acc 0.39693181818181816\n",
            "epoch 4 batch id 276 loss 2.2114968299865723 train acc 0.39724864130434784\n",
            "epoch 4 batch id 277 loss 2.264751434326172 train acc 0.3973375451263538\n",
            "epoch 4 batch id 278 loss 2.011577844619751 train acc 0.3976506294964029\n",
            "epoch 4 batch id 279 loss 2.5516998767852783 train acc 0.3972894265232975\n",
            "epoch 4 batch id 280 loss 2.890176773071289 train acc 0.396875\n",
            "epoch 4 batch id 281 loss 2.6085891723632812 train acc 0.3966303380782918\n",
            "epoch 4 batch id 282 loss 2.368692398071289 train acc 0.39677526595744683\n",
            "epoch 4 batch id 283 loss 2.4529457092285156 train acc 0.3969191696113074\n",
            "epoch 4 batch id 284 loss 2.2816054821014404 train acc 0.3969520246478873\n",
            "epoch 4 batch id 285 loss 2.210092544555664 train acc 0.3972039473684211\n",
            "epoch 4 batch id 286 loss 2.558488130569458 train acc 0.3968531468531469\n",
            "epoch 4 batch id 287 loss 2.492243528366089 train acc 0.39677700348432055\n",
            "epoch 4 batch id 288 loss 2.344480514526367 train acc 0.3965928819444444\n",
            "epoch 4 batch id 289 loss 2.213810920715332 train acc 0.3968425605536332\n",
            "epoch 4 batch id 290 loss 2.245317220687866 train acc 0.39709051724137934\n",
            "epoch 4 batch id 291 loss 2.350583553314209 train acc 0.39701460481099654\n",
            "epoch 4 batch id 292 loss 1.978247880935669 train acc 0.3977418664383562\n",
            "epoch 4 batch id 293 loss 2.5046334266662598 train acc 0.3978775597269625\n",
            "epoch 4 batch id 294 loss 2.3118674755096436 train acc 0.397906037414966\n",
            "epoch 4 batch id 295 loss 2.143045663833618 train acc 0.39809322033898303\n",
            "epoch 4 batch id 296 loss 2.435563087463379 train acc 0.3982791385135135\n",
            "epoch 4 batch id 297 loss 2.4018237590789795 train acc 0.3980955387205387\n",
            "epoch 4 batch id 298 loss 2.395458698272705 train acc 0.39822776845637586\n",
            "epoch 4 batch id 299 loss 2.1377835273742676 train acc 0.3984636287625418\n",
            "epoch 4 batch id 300 loss 2.288219451904297 train acc 0.39880208333333333\n",
            "epoch 4 batch id 301 loss 2.3266451358795166 train acc 0.39887873754152825\n",
            "epoch 4 batch id 302 loss 2.7675838470458984 train acc 0.3985927152317881\n",
            "epoch 4 batch id 303 loss 2.561020612716675 train acc 0.3985664191419142\n",
            "epoch 4 batch id 304 loss 2.0730950832366943 train acc 0.3986944901315789\n",
            "epoch 4 batch id 305 loss 2.387860059738159 train acc 0.3985655737704918\n",
            "epoch 4 batch id 306 loss 2.6228575706481934 train acc 0.3987438725490196\n",
            "epoch 4 batch id 307 loss 1.9891979694366455 train acc 0.39912459283387625\n",
            "epoch 4 batch id 308 loss 2.19881534576416 train acc 0.3990969967532468\n",
            "epoch 4 batch id 309 loss 1.889831304550171 train acc 0.39942354368932037\n",
            "epoch 4 batch id 310 loss 2.3319320678710938 train acc 0.3995967741935484\n",
            "epoch 4 batch id 311 loss 2.4936482906341553 train acc 0.39961816720257237\n",
            "epoch 4 batch id 312 loss 1.9937106370925903 train acc 0.4000400641025641\n",
            "epoch 4 batch id 313 loss 2.228721857070923 train acc 0.4000099840255591\n",
            "epoch 4 batch id 314 loss 2.7039883136749268 train acc 0.39988057324840764\n",
            "epoch 4 batch id 315 loss 2.3160150051116943 train acc 0.3998511904761905\n",
            "epoch 4 batch id 316 loss 1.9151065349578857 train acc 0.40031645569620256\n",
            "epoch 4 batch id 317 loss 2.3494863510131836 train acc 0.4003844637223975\n",
            "epoch 4 batch id 318 loss 2.4429869651794434 train acc 0.4004520440251572\n",
            "epoch 4 batch id 319 loss 2.412943124771118 train acc 0.40037225705329155\n",
            "epoch 4 batch id 320 loss 2.468214750289917 train acc 0.40029296875\n",
            "epoch 4 batch id 321 loss 2.523864984512329 train acc 0.40021417445482865\n",
            "epoch 4 batch id 322 loss 2.6271963119506836 train acc 0.3998447204968944\n",
            "epoch 4 batch id 323 loss 2.2750284671783447 train acc 0.4000580495356037\n",
            "epoch 4 batch id 324 loss 2.3233611583709717 train acc 0.40031828703703703\n",
            "epoch 4 batch id 325 loss 2.1975903511047363 train acc 0.4006730769230769\n",
            "epoch 4 batch id 326 loss 2.3656563758850098 train acc 0.40078604294478526\n",
            "epoch 4 batch id 327 loss 2.229860544204712 train acc 0.40089831804281345\n",
            "epoch 4 batch id 328 loss 2.3031227588653564 train acc 0.4011051829268293\n",
            "epoch 4 batch id 329 loss 2.906996250152588 train acc 0.40078837386018235\n",
            "epoch 4 batch id 330 loss 2.185138702392578 train acc 0.4008996212121212\n",
            "epoch 4 batch id 331 loss 2.1378684043884277 train acc 0.4011518126888218\n",
            "epoch 4 batch id 332 loss 2.4239585399627686 train acc 0.40102597891566266\n",
            "epoch 4 batch id 333 loss 2.304001569747925 train acc 0.4010885885885886\n",
            "epoch 4 batch id 334 loss 2.3286571502685547 train acc 0.40119760479041916\n",
            "epoch 4 batch id 335 loss 2.1156909465789795 train acc 0.40167910447761196\n",
            "epoch 4 batch id 336 loss 2.430896520614624 train acc 0.40164620535714285\n",
            "epoch 4 batch id 337 loss 2.259244203567505 train acc 0.40189169139465875\n",
            "epoch 4 batch id 338 loss 2.3124327659606934 train acc 0.40181213017751477\n",
            "epoch 4 batch id 339 loss 2.3986990451812744 train acc 0.40187131268436577\n",
            "epoch 4 batch id 340 loss 2.419346332550049 train acc 0.4019301470588235\n",
            "epoch 4 batch id 341 loss 2.4870340824127197 train acc 0.40198863636363635\n",
            "epoch 4 batch id 342 loss 2.312786340713501 train acc 0.40195540935672514\n",
            "epoch 4 batch id 343 loss 2.240204334259033 train acc 0.4021045918367347\n",
            "epoch 4 batch id 344 loss 2.4024441242218018 train acc 0.40202579941860467\n",
            "epoch 4 batch id 345 loss 2.291621685028076 train acc 0.4019927536231884\n",
            "epoch 4 batch id 346 loss 2.2270941734313965 train acc 0.40195989884393063\n",
            "epoch 4 batch id 347 loss 2.50105619430542 train acc 0.40188220461095103\n",
            "epoch 4 batch id 348 loss 2.2600996494293213 train acc 0.4021192528735632\n",
            "epoch 4 batch id 349 loss 2.3971288204193115 train acc 0.40204154727793695\n",
            "epoch 4 batch id 350 loss 2.2475175857543945 train acc 0.4022767857142857\n",
            "epoch 4 batch id 351 loss 2.1217589378356934 train acc 0.4027332621082621\n",
            "epoch 4 batch id 352 loss 2.177704334259033 train acc 0.40296519886363635\n",
            "epoch 4 batch id 353 loss 2.1186859607696533 train acc 0.40319582152974504\n",
            "epoch 4 batch id 354 loss 2.3068137168884277 train acc 0.4033368644067797\n",
            "epoch 4 batch id 355 loss 2.459113836288452 train acc 0.4034330985915493\n",
            "epoch 4 batch id 356 loss 2.5435988903045654 train acc 0.40339712078651685\n",
            "epoch 4 batch id 357 loss 2.382465124130249 train acc 0.40353641456582634\n",
            "epoch 4 batch id 358 loss 2.2473936080932617 train acc 0.4036312849162011\n",
            "epoch 4 batch id 359 loss 2.1438138484954834 train acc 0.403899721448468\n",
            "epoch 4 batch id 360 loss 2.6991677284240723 train acc 0.40360243055555556\n",
            "epoch 4 batch id 361 loss 2.4384982585906982 train acc 0.40335006925207756\n",
            "epoch 4 batch id 362 loss 2.1759543418884277 train acc 0.40353073204419887\n",
            "epoch 4 batch id 363 loss 1.9494192600250244 train acc 0.4037103994490358\n",
            "epoch 4 batch id 364 loss 2.534389019012451 train acc 0.4035885989010989\n",
            "epoch 4 batch id 365 loss 2.224170684814453 train acc 0.4038099315068493\n",
            "epoch 4 batch id 366 loss 2.3256547451019287 train acc 0.40377390710382516\n",
            "epoch 4 batch id 367 loss 2.547884702682495 train acc 0.40356777929155313\n",
            "epoch 4 batch id 368 loss 2.2239012718200684 train acc 0.40365998641304346\n",
            "epoch 4 batch id 369 loss 2.3783793449401855 train acc 0.4035823170731707\n",
            "epoch 4 batch id 370 loss 2.4037282466888428 train acc 0.40371621621621623\n",
            "epoch 4 batch id 371 loss 2.4641857147216797 train acc 0.4036388140161725\n",
            "epoch 4 batch id 372 loss 2.5352425575256348 train acc 0.4036038306451613\n",
            "epoch 4 batch id 373 loss 2.1732003688812256 train acc 0.4038622654155496\n",
            "epoch 4 batch id 374 loss 1.976115345954895 train acc 0.40436998663101603\n",
            "epoch 4 batch id 375 loss 2.803290367126465 train acc 0.4040416666666667\n",
            "epoch 4 batch id 376 loss 2.2868874073028564 train acc 0.4040890957446808\n",
            "epoch 4 batch id 377 loss 2.449033498764038 train acc 0.4040948275862069\n",
            "epoch 4 batch id 378 loss 2.3047165870666504 train acc 0.404348544973545\n",
            "epoch 4 batch id 379 loss 1.9695185422897339 train acc 0.4046833773087071\n",
            "epoch 4 batch id 380 loss 2.374678373336792 train acc 0.4046463815789474\n",
            "epoch 4 batch id 381 loss 2.2626240253448486 train acc 0.40473261154855644\n",
            "epoch 4 batch id 382 loss 2.4580366611480713 train acc 0.4047365837696335\n",
            "epoch 4 batch id 383 loss 2.4930546283721924 train acc 0.4046997389033943\n",
            "epoch 4 batch id 384 loss 2.4572458267211914 train acc 0.4047037760416667\n",
            "epoch 4 batch id 385 loss 2.3209266662597656 train acc 0.4049918831168831\n",
            "epoch 4 batch id 386 loss 2.580519914627075 train acc 0.405035621761658\n",
            "epoch 4 batch id 387 loss 2.314971923828125 train acc 0.40511950904392763\n",
            "epoch 4 batch id 388 loss 2.2026572227478027 train acc 0.40536404639175255\n",
            "epoch 4 batch id 389 loss 2.43528151512146 train acc 0.40524582262210795\n",
            "epoch 4 batch id 390 loss 2.2311389446258545 train acc 0.40536858974358975\n",
            "epoch 4 batch id 391 loss 2.155243158340454 train acc 0.4054108056265985\n",
            "epoch 4 batch id 392 loss 2.273660659790039 train acc 0.4055723852040816\n",
            "epoch 4 batch id 393 loss 2.599987745285034 train acc 0.40533555979643765\n",
            "epoch 4 batch id 394 loss 2.3518571853637695 train acc 0.4054171954314721\n",
            "epoch 4 batch id 395 loss 2.249958038330078 train acc 0.40569620253164557\n",
            "epoch 4 batch id 396 loss 2.1619977951049805 train acc 0.4058554292929293\n",
            "epoch 4 batch id 397 loss 2.3547399044036865 train acc 0.4058170654911839\n",
            "epoch 4 batch id 398 loss 2.56730580329895 train acc 0.40550408291457285\n",
            "epoch 4 batch id 399 loss 2.2482247352600098 train acc 0.4054667919799499\n",
            "epoch 4 batch id 400 loss 2.1124606132507324 train acc 0.405703125\n",
            "epoch 4 batch id 401 loss 2.4272940158843994 train acc 0.40574345386533667\n",
            "epoch 4 batch id 402 loss 2.4582512378692627 train acc 0.4055115049751244\n",
            "epoch 4 batch id 403 loss 2.3310177326202393 train acc 0.40566842431761785\n",
            "epoch 4 batch id 404 loss 2.372114896774292 train acc 0.40574721534653463\n",
            "epoch 4 batch id 405 loss 2.456613540649414 train acc 0.4056327160493827\n",
            "epoch 4 batch id 406 loss 1.8868181705474854 train acc 0.40613454433497537\n",
            "epoch 4 batch id 407 loss 2.1650331020355225 train acc 0.40632678132678135\n",
            "epoch 4 batch id 408 loss 2.3092119693756104 train acc 0.40628829656862747\n",
            "epoch 4 batch id 409 loss 2.021559953689575 train acc 0.406593826405868\n",
            "epoch 4 batch id 410 loss 2.772190809249878 train acc 0.4062881097560976\n",
            "epoch 4 batch id 411 loss 2.4906527996063232 train acc 0.4061359489051095\n",
            "epoch 4 batch id 412 loss 2.498080253601074 train acc 0.40613622572815533\n",
            "epoch 4 batch id 413 loss 2.127650260925293 train acc 0.40636349878934624\n",
            "epoch 4 batch id 414 loss 2.0716471672058105 train acc 0.40655193236714976\n",
            "epoch 4 batch id 415 loss 2.4546313285827637 train acc 0.40651355421686747\n",
            "epoch 4 batch id 416 loss 2.481794834136963 train acc 0.4063251201923077\n",
            "epoch 4 batch id 417 loss 2.478881359100342 train acc 0.40639988009592326\n",
            "epoch 4 batch id 418 loss 2.0842936038970947 train acc 0.40669856459330145\n",
            "epoch 4 batch id 419 loss 2.439582109451294 train acc 0.40673478520286394\n",
            "epoch 4 batch id 420 loss 2.2828431129455566 train acc 0.4068452380952381\n",
            "epoch 4 batch id 421 loss 2.57259464263916 train acc 0.40673248218527314\n",
            "epoch 4 batch id 422 loss 2.203965902328491 train acc 0.40669431279620855\n",
            "epoch 4 batch id 423 loss 2.466325521469116 train acc 0.4068040780141844\n",
            "epoch 4 batch id 424 loss 2.2740352153778076 train acc 0.40698702830188677\n",
            "epoch 4 batch id 425 loss 2.0794429779052734 train acc 0.4071691176470588\n",
            "epoch 4 batch id 426 loss 2.1126413345336914 train acc 0.4074237089201878\n",
            "epoch 4 batch id 427 loss 2.133930206298828 train acc 0.4073843676814988\n",
            "epoch 4 batch id 428 loss 2.2385356426239014 train acc 0.4074547313084112\n",
            "epoch 4 batch id 429 loss 2.1284186840057373 train acc 0.40763403263403264\n",
            "epoch 4 batch id 430 loss 2.1397626399993896 train acc 0.4077398255813954\n",
            "epoch 4 batch id 431 loss 2.2119953632354736 train acc 0.4076276102088167\n",
            "epoch 4 batch id 432 loss 2.279271125793457 train acc 0.4075882523148148\n",
            "epoch 4 batch id 433 loss 2.3292410373687744 train acc 0.40769341801385683\n",
            "epoch 4 batch id 434 loss 2.4938971996307373 train acc 0.4075460829493088\n",
            "epoch 4 batch id 435 loss 2.407505512237549 train acc 0.4075431034482759\n",
            "epoch 4 batch id 436 loss 2.329899787902832 train acc 0.4076834862385321\n",
            "epoch 4 batch id 437 loss 2.0492398738861084 train acc 0.40782322654462244\n",
            "epoch 4 batch id 438 loss 2.4056808948516846 train acc 0.4076769406392694\n",
            "epoch 4 batch id 439 loss 2.43049693107605 train acc 0.40788724373576307\n",
            "epoch 4 batch id 440 loss 2.2023487091064453 train acc 0.40806107954545456\n",
            "epoch 4 batch id 441 loss 2.690701484680176 train acc 0.4079861111111111\n",
            "epoch 4 batch id 442 loss 2.2757890224456787 train acc 0.4081589366515837\n",
            "epoch 4 batch id 443 loss 2.2182607650756836 train acc 0.4080488148984199\n",
            "epoch 4 batch id 444 loss 1.957370638847351 train acc 0.40832629504504503\n",
            "epoch 4 batch id 445 loss 2.363339900970459 train acc 0.40832162921348314\n",
            "epoch 4 batch id 446 loss 2.327875852584839 train acc 0.40835201793721976\n",
            "epoch 4 batch id 447 loss 2.47646164894104 train acc 0.40831236017897093\n",
            "epoch 4 batch id 448 loss 2.3083043098449707 train acc 0.408203125\n",
            "epoch 4 batch id 449 loss 2.467583417892456 train acc 0.4081987750556793\n",
            "epoch 4 batch id 450 loss 2.276275873184204 train acc 0.408125\n",
            "epoch 4 batch id 451 loss 1.9617369174957275 train acc 0.4083980044345898\n",
            "epoch 4 batch id 452 loss 2.127016067504883 train acc 0.4085315265486726\n",
            "epoch 4 batch id 453 loss 2.361933708190918 train acc 0.4086644591611479\n",
            "epoch 4 batch id 454 loss 2.0376126766204834 train acc 0.4089000550660793\n",
            "epoch 4 batch id 455 loss 2.277738332748413 train acc 0.4087912087912088\n",
            "epoch 4 batch id 456 loss 2.0685839653015137 train acc 0.40899122807017546\n",
            "epoch 4 batch id 457 loss 2.3947975635528564 train acc 0.40901942013129106\n",
            "epoch 4 batch id 458 loss 2.2641162872314453 train acc 0.4091839519650655\n",
            "epoch 4 batch id 459 loss 2.587460517883301 train acc 0.409041394335512\n",
            "epoch 4 batch id 460 loss 2.101195812225342 train acc 0.40913722826086957\n",
            "epoch 4 batch id 461 loss 2.030269145965576 train acc 0.40933432754880694\n",
            "epoch 4 batch id 462 loss 2.039426803588867 train acc 0.4094291125541126\n",
            "epoch 4 batch id 463 loss 2.598320245742798 train acc 0.40928725701943847\n",
            "epoch 4 batch id 464 loss 2.414325475692749 train acc 0.4092807112068966\n",
            "epoch 4 batch id 465 loss 2.204508066177368 train acc 0.4095094086021505\n",
            "epoch 4 batch id 466 loss 2.557619094848633 train acc 0.4096030042918455\n",
            "epoch 4 batch id 467 loss 2.3469972610473633 train acc 0.40976311563169165\n",
            "epoch 4 batch id 468 loss 2.3745198249816895 train acc 0.4097222222222222\n",
            "epoch 4 batch id 469 loss 2.45611572265625 train acc 0.4097148187633262\n",
            "epoch 4 batch id 470 loss 2.1349704265594482 train acc 0.4097739361702128\n",
            "epoch 4 batch id 471 loss 2.2771403789520264 train acc 0.40979962845010615\n",
            "epoch 4 batch id 472 loss 2.457458019256592 train acc 0.4097590042372881\n",
            "epoch 4 batch id 473 loss 2.5671803951263428 train acc 0.40971855179704014\n",
            "epoch 4 batch id 474 loss 2.303431987762451 train acc 0.4096782700421941\n",
            "epoch 4 batch id 475 loss 2.190641164779663 train acc 0.4097368421052632\n",
            "epoch 4 batch id 476 loss 2.3493854999542236 train acc 0.4099264705882353\n",
            "epoch 4 batch id 477 loss 2.77761173248291 train acc 0.40962395178197064\n",
            "epoch 4 batch id 478 loss 2.59741473197937 train acc 0.40942076359832635\n",
            "epoch 4 batch id 479 loss 2.3119208812713623 train acc 0.40944676409185804\n",
            "epoch 4 batch id 480 loss 2.3640172481536865 train acc 0.4095377604166667\n",
            "epoch 4 batch id 481 loss 2.4200546741485596 train acc 0.4094984407484408\n",
            "epoch 4 batch id 482 loss 2.279242515563965 train acc 0.4095241182572614\n",
            "epoch 4 batch id 483 loss 2.6490814685821533 train acc 0.40929089026915116\n",
            "epoch 4 batch id 484 loss 2.0451736450195312 train acc 0.4095105888429752\n",
            "epoch 4 batch id 485 loss 2.1610844135284424 train acc 0.40950386597938143\n",
            "epoch 4 batch id 486 loss 2.459289073944092 train acc 0.40959362139917693\n",
            "epoch 4 batch id 487 loss 2.1478960514068604 train acc 0.40968300821355236\n",
            "epoch 4 batch id 488 loss 2.0196285247802734 train acc 0.40990010245901637\n",
            "epoch 4 batch id 489 loss 2.384829044342041 train acc 0.4098926380368098\n",
            "epoch 4 batch id 490 loss 2.530211925506592 train acc 0.40975765306122447\n",
            "epoch 4 batch id 491 loss 2.198819637298584 train acc 0.4097186863543788\n",
            "epoch 4 batch id 492 loss 1.985073447227478 train acc 0.4099657012195122\n",
            "epoch 4 batch id 493 loss 2.1880085468292236 train acc 0.41008493914807304\n",
            "epoch 4 batch id 494 loss 2.4523916244506836 train acc 0.4099822874493927\n",
            "epoch 4 batch id 495 loss 2.5039305686950684 train acc 0.4100378787878788\n",
            "epoch 4 batch id 496 loss 2.265162944793701 train acc 0.4102507560483871\n",
            "epoch 4 batch id 497 loss 2.01545786857605 train acc 0.41052565392354123\n",
            "epoch 4 batch id 498 loss 2.16091251373291 train acc 0.41051706827309237\n",
            "epoch 4 batch id 499 loss 2.177279233932495 train acc 0.41066508016032066\n",
            "epoch 4 batch id 500 loss 2.2921934127807617 train acc 0.41065625\n",
            "epoch 4 batch id 501 loss 2.2318274974823 train acc 0.41070983033932135\n",
            "epoch 4 batch id 502 loss 2.417076349258423 train acc 0.41051419322709165\n",
            "epoch 4 batch id 503 loss 1.902034044265747 train acc 0.4107542246520875\n",
            "epoch 4 batch id 504 loss 2.0952582359313965 train acc 0.4110243055555556\n",
            "epoch 4 batch id 505 loss 2.3081676959991455 train acc 0.4110148514851485\n",
            "epoch 4 batch id 506 loss 2.336655378341675 train acc 0.411036314229249\n",
            "epoch 4 batch id 507 loss 2.1803247928619385 train acc 0.41118096646942803\n",
            "epoch 4 batch id 508 loss 2.148420572280884 train acc 0.41126353346456695\n",
            "epoch 4 batch id 509 loss 2.1969869136810303 train acc 0.4112843811394892\n",
            "epoch 4 batch id 510 loss 2.053614616394043 train acc 0.41136642156862746\n",
            "epoch 4 batch id 511 loss 2.0129785537719727 train acc 0.411431153511633\n",
            "epoch 4 train acc 0.411431153511633\n",
            "epoch 4 test acc 0.3623453776041667\n",
            "epoch 5 batch id 1 loss 2.304004430770874 train acc 0.4375\n",
            "epoch 5 batch id 2 loss 2.515204668045044 train acc 0.421875\n",
            "epoch 5 batch id 3 loss 2.3992903232574463 train acc 0.4010416666666667\n",
            "epoch 5 batch id 4 loss 2.2019989490509033 train acc 0.421875\n",
            "epoch 5 batch id 5 loss 2.545077323913574 train acc 0.409375\n",
            "epoch 5 batch id 6 loss 2.63665771484375 train acc 0.4036458333333333\n",
            "epoch 5 batch id 7 loss 1.7842597961425781 train acc 0.41964285714285715\n",
            "epoch 5 batch id 8 loss 1.8463727235794067 train acc 0.44140625\n",
            "epoch 5 batch id 9 loss 2.5086240768432617 train acc 0.4288194444444444\n",
            "epoch 5 batch id 10 loss 2.5008974075317383 train acc 0.428125\n",
            "epoch 5 batch id 11 loss 1.821997046470642 train acc 0.4375\n",
            "epoch 5 batch id 12 loss 2.497955560684204 train acc 0.4309895833333333\n",
            "epoch 5 batch id 13 loss 2.109145402908325 train acc 0.4326923076923077\n",
            "epoch 5 batch id 14 loss 2.2849881649017334 train acc 0.4341517857142857\n",
            "epoch 5 batch id 15 loss 2.2067551612854004 train acc 0.434375\n",
            "epoch 5 batch id 16 loss 2.31689453125 train acc 0.43359375\n",
            "epoch 5 batch id 17 loss 2.1260437965393066 train acc 0.4365808823529412\n",
            "epoch 5 batch id 18 loss 2.273332357406616 train acc 0.4331597222222222\n",
            "epoch 5 batch id 19 loss 2.435250997543335 train acc 0.4300986842105263\n",
            "epoch 5 batch id 20 loss 2.48712420463562 train acc 0.425\n",
            "epoch 5 batch id 21 loss 2.3356945514678955 train acc 0.4226190476190476\n",
            "epoch 5 batch id 22 loss 2.0023436546325684 train acc 0.4211647727272727\n",
            "epoch 5 batch id 23 loss 1.9988126754760742 train acc 0.42391304347826086\n",
            "epoch 5 batch id 24 loss 2.4627177715301514 train acc 0.421875\n",
            "epoch 5 batch id 25 loss 2.3601670265197754 train acc 0.41875\n",
            "epoch 5 batch id 26 loss 2.422837495803833 train acc 0.4182692307692308\n",
            "epoch 5 batch id 27 loss 1.933834433555603 train acc 0.4212962962962963\n",
            "epoch 5 batch id 28 loss 2.006678342819214 train acc 0.42354910714285715\n",
            "epoch 5 batch id 29 loss 2.5137133598327637 train acc 0.4240301724137931\n",
            "epoch 5 batch id 30 loss 2.3283298015594482 train acc 0.425\n",
            "epoch 5 batch id 31 loss 1.8860877752304077 train acc 0.4274193548387097\n",
            "epoch 5 batch id 32 loss 1.95295250415802 train acc 0.431640625\n",
            "epoch 5 batch id 33 loss 2.373056173324585 train acc 0.43134469696969696\n",
            "epoch 5 batch id 34 loss 2.4616990089416504 train acc 0.4287683823529412\n",
            "epoch 5 batch id 35 loss 2.385441541671753 train acc 0.4290178571428571\n",
            "epoch 5 batch id 36 loss 2.4134891033172607 train acc 0.4266493055555556\n",
            "epoch 5 batch id 37 loss 2.0299625396728516 train acc 0.42905405405405406\n",
            "epoch 5 batch id 38 loss 1.9768892526626587 train acc 0.4317434210526316\n",
            "epoch 5 batch id 39 loss 1.7720012664794922 train acc 0.4358974358974359\n",
            "epoch 5 batch id 40 loss 2.3568546772003174 train acc 0.43671875\n",
            "epoch 5 batch id 41 loss 2.1104843616485596 train acc 0.4382621951219512\n",
            "epoch 5 batch id 42 loss 2.1680872440338135 train acc 0.4382440476190476\n",
            "epoch 5 batch id 43 loss 2.324587345123291 train acc 0.438953488372093\n",
            "epoch 5 batch id 44 loss 2.455479860305786 train acc 0.43785511363636365\n",
            "epoch 5 batch id 45 loss 2.1080129146575928 train acc 0.4388888888888889\n",
            "epoch 5 batch id 46 loss 2.4769861698150635 train acc 0.4358016304347826\n",
            "epoch 5 batch id 47 loss 2.241910934448242 train acc 0.43716755319148937\n",
            "epoch 5 batch id 48 loss 2.062051773071289 train acc 0.4381510416666667\n",
            "epoch 5 batch id 49 loss 2.5692596435546875 train acc 0.4362244897959184\n",
            "epoch 5 batch id 50 loss 2.0500617027282715 train acc 0.4375\n",
            "epoch 5 batch id 51 loss 2.455583095550537 train acc 0.4362745098039216\n",
            "epoch 5 batch id 52 loss 1.9828708171844482 train acc 0.4365985576923077\n",
            "epoch 5 batch id 53 loss 2.295397996902466 train acc 0.4366155660377358\n",
            "epoch 5 batch id 54 loss 2.200972318649292 train acc 0.4348958333333333\n",
            "epoch 5 batch id 55 loss 2.243086814880371 train acc 0.4346590909090909\n",
            "epoch 5 batch id 56 loss 2.264583110809326 train acc 0.4349888392857143\n",
            "epoch 5 batch id 57 loss 2.4474387168884277 train acc 0.4350328947368421\n",
            "epoch 5 batch id 58 loss 2.365039825439453 train acc 0.43426724137931033\n",
            "epoch 5 batch id 59 loss 2.091698169708252 train acc 0.4343220338983051\n",
            "epoch 5 batch id 60 loss 2.210536479949951 train acc 0.434375\n",
            "epoch 5 batch id 61 loss 1.9100158214569092 train acc 0.43673155737704916\n",
            "epoch 5 batch id 62 loss 2.4057834148406982 train acc 0.4369959677419355\n",
            "epoch 5 batch id 63 loss 1.9682505130767822 train acc 0.4382440476190476\n",
            "epoch 5 batch id 64 loss 2.4524576663970947 train acc 0.43798828125\n",
            "epoch 5 batch id 65 loss 2.1533827781677246 train acc 0.4389423076923077\n",
            "epoch 5 batch id 66 loss 2.2256879806518555 train acc 0.43915719696969696\n",
            "epoch 5 batch id 67 loss 2.443845272064209 train acc 0.43796641791044777\n",
            "epoch 5 batch id 68 loss 2.565736770629883 train acc 0.4365808823529412\n",
            "epoch 5 batch id 69 loss 2.2643883228302 train acc 0.4363677536231884\n",
            "epoch 5 batch id 70 loss 2.239356517791748 train acc 0.43660714285714286\n",
            "epoch 5 batch id 71 loss 2.1243855953216553 train acc 0.4372799295774648\n",
            "epoch 5 batch id 72 loss 1.7929641008377075 train acc 0.4385850694444444\n",
            "epoch 5 batch id 73 loss 2.551780939102173 train acc 0.4372859589041096\n",
            "epoch 5 batch id 74 loss 2.139300584793091 train acc 0.4379222972972973\n",
            "epoch 5 batch id 75 loss 2.0163283348083496 train acc 0.43875\n",
            "epoch 5 batch id 76 loss 1.940015435218811 train acc 0.44058388157894735\n",
            "epoch 5 batch id 77 loss 2.2652747631073 train acc 0.44054383116883117\n",
            "epoch 5 batch id 78 loss 2.138869047164917 train acc 0.4411057692307692\n",
            "epoch 5 batch id 79 loss 2.0792906284332275 train acc 0.44185126582278483\n",
            "epoch 5 batch id 80 loss 2.6375272274017334 train acc 0.441015625\n",
            "epoch 5 batch id 81 loss 1.9572092294692993 train acc 0.4407793209876543\n",
            "epoch 5 batch id 82 loss 2.3941221237182617 train acc 0.4405487804878049\n",
            "epoch 5 batch id 83 loss 2.1631152629852295 train acc 0.44088855421686746\n",
            "epoch 5 batch id 84 loss 1.9603677988052368 train acc 0.44177827380952384\n",
            "epoch 5 batch id 85 loss 2.5196595191955566 train acc 0.4417279411764706\n",
            "epoch 5 batch id 86 loss 2.381209135055542 train acc 0.4418604651162791\n",
            "epoch 5 batch id 87 loss 2.1673765182495117 train acc 0.44127155172413796\n",
            "epoch 5 batch id 88 loss 2.339564561843872 train acc 0.4401633522727273\n",
            "epoch 5 batch id 89 loss 2.362884283065796 train acc 0.43995786516853935\n",
            "epoch 5 batch id 90 loss 2.4140336513519287 train acc 0.4388888888888889\n",
            "epoch 5 batch id 91 loss 1.9473015069961548 train acc 0.43990384615384615\n",
            "epoch 5 batch id 92 loss 2.363581657409668 train acc 0.43953804347826086\n",
            "epoch 5 batch id 93 loss 2.522430419921875 train acc 0.43783602150537637\n",
            "epoch 5 batch id 94 loss 2.1086173057556152 train acc 0.43816489361702127\n",
            "epoch 5 batch id 95 loss 2.4096412658691406 train acc 0.4365131578947368\n",
            "epoch 5 batch id 96 loss 2.071657180786133 train acc 0.43701171875\n",
            "epoch 5 batch id 97 loss 2.225710153579712 train acc 0.4363724226804124\n",
            "epoch 5 batch id 98 loss 1.8351490497589111 train acc 0.4375\n",
            "epoch 5 batch id 99 loss 2.3517842292785645 train acc 0.43702651515151514\n",
            "epoch 5 batch id 100 loss 2.255526542663574 train acc 0.43671875\n",
            "epoch 5 batch id 101 loss 2.210935115814209 train acc 0.4375\n",
            "epoch 5 batch id 102 loss 1.846125602722168 train acc 0.4387254901960784\n",
            "epoch 5 batch id 103 loss 2.1602213382720947 train acc 0.4393203883495146\n",
            "epoch 5 batch id 104 loss 2.0907278060913086 train acc 0.4403545673076923\n",
            "epoch 5 batch id 105 loss 1.9179997444152832 train acc 0.4413690476190476\n",
            "epoch 5 batch id 106 loss 2.102059841156006 train acc 0.44162735849056606\n",
            "epoch 5 batch id 107 loss 2.043609380722046 train acc 0.4420268691588785\n",
            "epoch 5 batch id 108 loss 2.0058751106262207 train acc 0.4431423611111111\n",
            "epoch 5 batch id 109 loss 2.453867197036743 train acc 0.4426605504587156\n",
            "epoch 5 batch id 110 loss 2.230288505554199 train acc 0.4426136363636364\n",
            "epoch 5 batch id 111 loss 2.2835943698883057 train acc 0.44256756756756754\n",
            "epoch 5 batch id 112 loss 1.9541956186294556 train acc 0.44363839285714285\n",
            "epoch 5 batch id 113 loss 1.9770160913467407 train acc 0.4444137168141593\n",
            "epoch 5 batch id 114 loss 2.0936436653137207 train acc 0.4447642543859649\n",
            "epoch 5 batch id 115 loss 2.0665626525878906 train acc 0.4451086956521739\n",
            "epoch 5 batch id 116 loss 1.805484414100647 train acc 0.4465247844827586\n",
            "epoch 5 batch id 117 loss 1.6605393886566162 train acc 0.4477831196581197\n",
            "epoch 5 batch id 118 loss 2.040421485900879 train acc 0.4483580508474576\n",
            "epoch 5 batch id 119 loss 2.356066942214966 train acc 0.4482668067226891\n",
            "epoch 5 batch id 120 loss 2.216050386428833 train acc 0.4484375\n",
            "epoch 5 batch id 121 loss 2.254889488220215 train acc 0.44860537190082644\n",
            "epoch 5 batch id 122 loss 2.0774803161621094 train acc 0.44864241803278687\n",
            "epoch 5 batch id 123 loss 2.197279214859009 train acc 0.4488058943089431\n",
            "epoch 5 batch id 124 loss 2.4851038455963135 train acc 0.4488407258064516\n",
            "epoch 5 batch id 125 loss 2.04801082611084 train acc 0.44925\n",
            "epoch 5 batch id 126 loss 2.242525100708008 train acc 0.4486607142857143\n",
            "epoch 5 batch id 127 loss 2.385993719100952 train acc 0.44795767716535434\n",
            "epoch 5 batch id 128 loss 2.398308277130127 train acc 0.4476318359375\n",
            "epoch 5 batch id 129 loss 2.0042829513549805 train acc 0.4476744186046512\n",
            "epoch 5 batch id 130 loss 1.9023398160934448 train acc 0.4480769230769231\n",
            "epoch 5 batch id 131 loss 2.2427725791931152 train acc 0.4484732824427481\n",
            "epoch 5 batch id 132 loss 2.0279769897460938 train acc 0.4493371212121212\n",
            "epoch 5 batch id 133 loss 2.386688470840454 train acc 0.4494830827067669\n",
            "epoch 5 batch id 134 loss 1.9866348505020142 train acc 0.44997667910447764\n",
            "epoch 5 batch id 135 loss 2.3210067749023438 train acc 0.4497685185185185\n",
            "epoch 5 batch id 136 loss 2.070925235748291 train acc 0.45002297794117646\n",
            "epoch 5 batch id 137 loss 2.125201940536499 train acc 0.4501596715328467\n",
            "epoch 5 batch id 138 loss 1.9798601865768433 train acc 0.45040760869565216\n",
            "epoch 5 batch id 139 loss 1.9486839771270752 train acc 0.4504271582733813\n",
            "epoch 5 batch id 140 loss 2.3269755840301514 train acc 0.45\n",
            "epoch 5 batch id 141 loss 2.464888572692871 train acc 0.44902482269503546\n",
            "epoch 5 batch id 142 loss 2.2267162799835205 train acc 0.44872359154929575\n",
            "epoch 5 batch id 143 loss 2.6513757705688477 train acc 0.44798951048951047\n",
            "epoch 5 batch id 144 loss 2.113330841064453 train acc 0.4478081597222222\n",
            "epoch 5 batch id 145 loss 2.150134563446045 train acc 0.4478448275862069\n",
            "epoch 5 batch id 146 loss 2.399862766265869 train acc 0.4477739726027397\n",
            "epoch 5 batch id 147 loss 2.140695333480835 train acc 0.4479166666666667\n",
            "epoch 5 batch id 148 loss 2.100278615951538 train acc 0.44816300675675674\n",
            "epoch 5 batch id 149 loss 2.3670108318328857 train acc 0.4483011744966443\n",
            "epoch 5 batch id 150 loss 1.834507703781128 train acc 0.44916666666666666\n",
            "epoch 5 batch id 151 loss 2.3448572158813477 train acc 0.449192880794702\n",
            "epoch 5 batch id 152 loss 2.133680582046509 train acc 0.4491159539473684\n",
            "epoch 5 batch id 153 loss 2.1372623443603516 train acc 0.4494485294117647\n",
            "epoch 5 batch id 154 loss 2.083446741104126 train acc 0.4496753246753247\n",
            "epoch 5 batch id 155 loss 2.294283866882324 train acc 0.4496975806451613\n",
            "epoch 5 batch id 156 loss 2.47379207611084 train acc 0.44901842948717946\n",
            "epoch 5 batch id 157 loss 2.29548716545105 train acc 0.4486464968152866\n",
            "epoch 5 batch id 158 loss 2.2942590713500977 train acc 0.4486748417721519\n",
            "epoch 5 batch id 159 loss 2.333216667175293 train acc 0.44840801886792453\n",
            "epoch 5 batch id 160 loss 2.3427534103393555 train acc 0.448046875\n",
            "epoch 5 batch id 161 loss 2.0678446292877197 train acc 0.44827251552795033\n",
            "epoch 5 batch id 162 loss 2.157968282699585 train acc 0.44839891975308643\n",
            "epoch 5 batch id 163 loss 2.0914366245269775 train acc 0.448523773006135\n",
            "epoch 5 batch id 164 loss 2.15537691116333 train acc 0.4490282012195122\n",
            "epoch 5 batch id 165 loss 1.89754319190979 train acc 0.4497159090909091\n",
            "epoch 5 batch id 166 loss 2.154240131378174 train acc 0.44945406626506024\n",
            "epoch 5 batch id 167 loss 2.137927293777466 train acc 0.4496631736526946\n",
            "epoch 5 batch id 168 loss 2.0505306720733643 train acc 0.4498697916666667\n",
            "epoch 5 batch id 169 loss 2.094558000564575 train acc 0.44988905325443784\n",
            "epoch 5 batch id 170 loss 2.3705434799194336 train acc 0.4494485294117647\n",
            "epoch 5 batch id 171 loss 2.406017541885376 train acc 0.4494700292397661\n",
            "epoch 5 batch id 172 loss 2.2375590801239014 train acc 0.44921875\n",
            "epoch 5 batch id 173 loss 1.848960518836975 train acc 0.44960260115606937\n",
            "epoch 5 batch id 174 loss 2.0236172676086426 train acc 0.4495330459770115\n",
            "epoch 5 batch id 175 loss 2.187675714492798 train acc 0.4494642857142857\n",
            "epoch 5 batch id 176 loss 2.0214807987213135 train acc 0.44975142045454547\n",
            "epoch 5 batch id 177 loss 1.9067912101745605 train acc 0.4504766949152542\n",
            "epoch 5 batch id 178 loss 1.9400357007980347 train acc 0.4512816011235955\n",
            "epoch 5 batch id 179 loss 2.19529390335083 train acc 0.4510300279329609\n",
            "epoch 5 batch id 180 loss 2.3739659786224365 train acc 0.45086805555555554\n",
            "epoch 5 batch id 181 loss 2.524779796600342 train acc 0.45018991712707185\n",
            "epoch 5 batch id 182 loss 1.6683844327926636 train acc 0.4508070054945055\n",
            "epoch 5 batch id 183 loss 2.1657018661499023 train acc 0.4509904371584699\n",
            "epoch 5 batch id 184 loss 2.003305435180664 train acc 0.451171875\n",
            "epoch 5 batch id 185 loss 2.1235270500183105 train acc 0.4514358108108108\n",
            "epoch 5 batch id 186 loss 2.1905996799468994 train acc 0.45102486559139787\n",
            "epoch 5 batch id 187 loss 2.439628839492798 train acc 0.450701871657754\n",
            "epoch 5 batch id 188 loss 1.8845508098602295 train acc 0.45121343085106386\n",
            "epoch 5 batch id 189 loss 2.3021512031555176 train acc 0.45089285714285715\n",
            "epoch 5 batch id 190 loss 2.1684858798980713 train acc 0.4509046052631579\n",
            "epoch 5 batch id 191 loss 1.8264415264129639 train acc 0.4514070680628272\n",
            "epoch 5 batch id 192 loss 2.562291145324707 train acc 0.4507649739583333\n",
            "epoch 5 batch id 193 loss 2.209743022918701 train acc 0.45037240932642486\n",
            "epoch 5 batch id 194 loss 2.052567481994629 train acc 0.4503060567010309\n",
            "epoch 5 batch id 195 loss 2.4850451946258545 train acc 0.4499198717948718\n",
            "epoch 5 batch id 196 loss 1.9756463766098022 train acc 0.45017538265306123\n",
            "epoch 5 batch id 197 loss 2.274325132369995 train acc 0.449635152284264\n",
            "epoch 5 batch id 198 loss 2.1442415714263916 train acc 0.44957386363636365\n",
            "epoch 5 batch id 199 loss 2.389171600341797 train acc 0.4495131909547739\n",
            "epoch 5 batch id 200 loss 1.9950517416000366 train acc 0.44953125\n",
            "epoch 5 batch id 201 loss 2.4426429271698 train acc 0.4490049751243781\n",
            "epoch 5 batch id 202 loss 2.2383081912994385 train acc 0.44871596534653463\n",
            "epoch 5 batch id 203 loss 2.177309513092041 train acc 0.4486607142857143\n",
            "epoch 5 batch id 204 loss 2.2472739219665527 train acc 0.4482230392156863\n",
            "epoch 5 batch id 205 loss 1.9323972463607788 train acc 0.4485518292682927\n",
            "epoch 5 batch id 206 loss 2.151982545852661 train acc 0.44827063106796117\n",
            "epoch 5 batch id 207 loss 2.220588445663452 train acc 0.4483695652173913\n",
            "epoch 5 batch id 208 loss 2.006355047225952 train acc 0.44839242788461536\n",
            "epoch 5 batch id 209 loss 2.104748249053955 train acc 0.44863935406698563\n",
            "epoch 5 batch id 210 loss 1.982606291770935 train acc 0.44888392857142856\n",
            "epoch 5 batch id 211 loss 2.20646071434021 train acc 0.4486818720379147\n",
            "epoch 5 batch id 212 loss 2.138251304626465 train acc 0.44848172169811323\n",
            "epoch 5 batch id 213 loss 2.281348943710327 train acc 0.44865023474178406\n",
            "epoch 5 batch id 214 loss 2.2615811824798584 train acc 0.44881717289719625\n",
            "epoch 5 batch id 215 loss 2.1266183853149414 train acc 0.44905523255813956\n",
            "epoch 5 batch id 216 loss 2.3298988342285156 train acc 0.4490017361111111\n",
            "epoch 5 batch id 217 loss 2.2863621711730957 train acc 0.44880472350230416\n",
            "epoch 5 batch id 218 loss 2.396184206008911 train acc 0.44860951834862384\n",
            "epoch 5 batch id 219 loss 2.100411891937256 train acc 0.4488441780821918\n",
            "epoch 5 batch id 220 loss 2.130405902862549 train acc 0.44879261363636364\n",
            "epoch 5 batch id 221 loss 2.200235366821289 train acc 0.44881221719457015\n",
            "epoch 5 batch id 222 loss 1.8986010551452637 train acc 0.44918355855855857\n",
            "epoch 5 batch id 223 loss 1.9624630212783813 train acc 0.4495515695067265\n",
            "epoch 5 batch id 224 loss 1.9344239234924316 train acc 0.4496372767857143\n",
            "epoch 5 batch id 225 loss 2.0875468254089355 train acc 0.44972222222222225\n",
            "epoch 5 batch id 226 loss 1.977867603302002 train acc 0.4500829646017699\n",
            "epoch 5 batch id 227 loss 1.8130269050598145 train acc 0.4505093612334802\n",
            "epoch 5 batch id 228 loss 2.2855112552642822 train acc 0.4505208333333333\n",
            "epoch 5 batch id 229 loss 2.087752103805542 train acc 0.4504639737991266\n",
            "epoch 5 batch id 230 loss 2.2715401649475098 train acc 0.4500679347826087\n",
            "epoch 5 batch id 231 loss 1.975196361541748 train acc 0.45021645021645024\n",
            "epoch 5 batch id 232 loss 1.9444389343261719 train acc 0.4506330818965517\n",
            "epoch 5 batch id 233 loss 2.1165099143981934 train acc 0.45057671673819744\n",
            "epoch 5 batch id 234 loss 2.2629873752593994 train acc 0.45058760683760685\n",
            "epoch 5 batch id 235 loss 2.3097481727600098 train acc 0.45039893617021276\n",
            "epoch 5 batch id 236 loss 2.4711389541625977 train acc 0.450145656779661\n",
            "epoch 5 batch id 237 loss 2.2395265102386475 train acc 0.44996044303797467\n",
            "epoch 5 batch id 238 loss 2.1355974674224854 train acc 0.44997373949579833\n",
            "epoch 5 batch id 239 loss 2.191176414489746 train acc 0.44998692468619245\n",
            "epoch 5 batch id 240 loss 2.06376576423645 train acc 0.45\n",
            "epoch 5 batch id 241 loss 2.0710041522979736 train acc 0.44981846473029047\n",
            "epoch 5 batch id 242 loss 2.0725035667419434 train acc 0.450025826446281\n",
            "epoch 5 batch id 243 loss 1.863387107849121 train acc 0.450488683127572\n",
            "epoch 5 batch id 244 loss 2.1904971599578857 train acc 0.45017930327868855\n",
            "epoch 5 batch id 245 loss 2.032614231109619 train acc 0.4501913265306122\n",
            "epoch 5 batch id 246 loss 2.335531234741211 train acc 0.4500127032520325\n",
            "epoch 5 batch id 247 loss 2.385101079940796 train acc 0.4498987854251012\n",
            "epoch 5 batch id 248 loss 1.8342798948287964 train acc 0.4504788306451613\n",
            "epoch 5 batch id 249 loss 1.9911887645721436 train acc 0.4504894578313253\n",
            "epoch 5 batch id 250 loss 2.376267433166504 train acc 0.45025\n",
            "epoch 5 batch id 251 loss 2.1081430912017822 train acc 0.45051045816733065\n",
            "epoch 5 batch id 252 loss 2.288698196411133 train acc 0.45033482142857145\n",
            "epoch 5 batch id 253 loss 2.2408905029296875 train acc 0.45040760869565216\n",
            "epoch 5 batch id 254 loss 2.1403863430023193 train acc 0.45054133858267714\n",
            "epoch 5 batch id 255 loss 2.0801711082458496 train acc 0.4506127450980392\n",
            "epoch 5 batch id 256 loss 1.9254454374313354 train acc 0.45068359375\n",
            "epoch 5 batch id 257 loss 1.8106814622879028 train acc 0.4510578793774319\n",
            "epoch 5 batch id 258 loss 2.226562976837158 train acc 0.45106589147286824\n",
            "epoch 5 batch id 259 loss 2.4226629734039307 train acc 0.45089285714285715\n",
            "epoch 5 batch id 260 loss 1.8009113073349 train acc 0.4515625\n",
            "epoch 5 batch id 261 loss 2.290658473968506 train acc 0.4515684865900383\n",
            "epoch 5 batch id 262 loss 2.3504674434661865 train acc 0.4513955152671756\n",
            "epoch 5 batch id 263 loss 2.3035786151885986 train acc 0.4511644486692015\n",
            "epoch 5 batch id 264 loss 2.104795217514038 train acc 0.4512310606060606\n",
            "epoch 5 batch id 265 loss 2.147519826889038 train acc 0.4511202830188679\n",
            "epoch 5 batch id 266 loss 1.8552464246749878 train acc 0.4513627819548872\n",
            "epoch 5 batch id 267 loss 1.9073721170425415 train acc 0.4515449438202247\n",
            "epoch 5 batch id 268 loss 2.236603021621704 train acc 0.4515508395522388\n",
            "epoch 5 batch id 269 loss 2.0789411067962646 train acc 0.45155669144981414\n",
            "epoch 5 batch id 270 loss 2.1007354259490967 train acc 0.4516203703703704\n",
            "epoch 5 batch id 271 loss 2.3151397705078125 train acc 0.4514529520295203\n",
            "epoch 5 batch id 272 loss 2.0527451038360596 train acc 0.4514590992647059\n",
            "epoch 5 batch id 273 loss 1.8669419288635254 train acc 0.4518658424908425\n",
            "epoch 5 batch id 274 loss 1.9831531047821045 train acc 0.4520985401459854\n",
            "epoch 5 batch id 275 loss 2.0420737266540527 train acc 0.4521022727272727\n",
            "epoch 5 batch id 276 loss 2.2591631412506104 train acc 0.452049365942029\n",
            "epoch 5 batch id 277 loss 2.194284200668335 train acc 0.4518840252707581\n",
            "epoch 5 batch id 278 loss 2.0565876960754395 train acc 0.45183228417266186\n",
            "epoch 5 batch id 279 loss 2.0780982971191406 train acc 0.4519489247311828\n",
            "epoch 5 batch id 280 loss 2.080960273742676 train acc 0.45200892857142855\n",
            "epoch 5 batch id 281 loss 1.9377353191375732 train acc 0.4522909252669039\n",
            "epoch 5 batch id 282 loss 1.8032162189483643 train acc 0.4524046985815603\n",
            "epoch 5 batch id 283 loss 2.2655630111694336 train acc 0.45229681978798586\n",
            "epoch 5 batch id 284 loss 1.8483219146728516 train acc 0.45262984154929575\n",
            "epoch 5 batch id 285 loss 2.0503437519073486 train acc 0.4527412280701754\n",
            "epoch 5 batch id 286 loss 1.974419116973877 train acc 0.4528518356643357\n",
            "epoch 5 batch id 287 loss 2.3025083541870117 train acc 0.4527439024390244\n",
            "epoch 5 batch id 288 loss 2.1988353729248047 train acc 0.4527452256944444\n",
            "epoch 5 batch id 289 loss 1.817962884902954 train acc 0.453125\n",
            "epoch 5 batch id 290 loss 2.8565943241119385 train acc 0.452801724137931\n",
            "epoch 5 batch id 291 loss 2.3052778244018555 train acc 0.4526417525773196\n",
            "epoch 5 batch id 292 loss 2.025587320327759 train acc 0.452589897260274\n",
            "epoch 5 batch id 293 loss 2.1893820762634277 train acc 0.45264505119453924\n",
            "epoch 5 batch id 294 loss 2.323108434677124 train acc 0.4526466836734694\n",
            "epoch 5 batch id 295 loss 2.201805591583252 train acc 0.4525953389830508\n",
            "epoch 5 batch id 296 loss 1.7696864604949951 train acc 0.45275548986486486\n",
            "epoch 5 batch id 297 loss 2.0333216190338135 train acc 0.45286195286195285\n",
            "epoch 5 batch id 298 loss 2.187570095062256 train acc 0.4528628355704698\n",
            "epoch 5 batch id 299 loss 1.9840600490570068 train acc 0.4529682274247492\n",
            "epoch 5 batch id 300 loss 1.937208652496338 train acc 0.45317708333333334\n",
            "epoch 5 batch id 301 loss 2.4752209186553955 train acc 0.453125\n",
            "epoch 5 batch id 302 loss 1.843198537826538 train acc 0.4533836920529801\n",
            "epoch 5 batch id 303 loss 2.290696859359741 train acc 0.4533312706270627\n",
            "epoch 5 batch id 304 loss 2.189937114715576 train acc 0.4533819901315789\n",
            "epoch 5 batch id 305 loss 2.0834298133850098 train acc 0.45338114754098363\n",
            "epoch 5 batch id 306 loss 1.9202492237091064 train acc 0.45358455882352944\n",
            "epoch 5 batch id 307 loss 1.7655576467514038 train acc 0.45383754071661236\n",
            "epoch 5 batch id 308 loss 2.1791741847991943 train acc 0.4535815746753247\n",
            "epoch 5 batch id 309 loss 2.2850489616394043 train acc 0.4535800970873786\n",
            "epoch 5 batch id 310 loss 1.9041162729263306 train acc 0.4537802419354839\n",
            "epoch 5 batch id 311 loss 1.7153561115264893 train acc 0.4542805466237942\n",
            "epoch 5 batch id 312 loss 1.7443428039550781 train acc 0.45482772435897434\n",
            "epoch 5 batch id 313 loss 2.135072946548462 train acc 0.45487220447284343\n",
            "epoch 5 batch id 314 loss 1.8253096342086792 train acc 0.4551652070063694\n",
            "epoch 5 batch id 315 loss 2.0626468658447266 train acc 0.4553075396825397\n",
            "epoch 5 batch id 316 loss 2.1075799465179443 train acc 0.4553995253164557\n",
            "epoch 5 batch id 317 loss 2.0275368690490723 train acc 0.45519518927444796\n",
            "epoch 5 batch id 318 loss 2.3853843212127686 train acc 0.45509040880503143\n",
            "epoch 5 batch id 319 loss 1.885765552520752 train acc 0.4551332288401254\n",
            "epoch 5 batch id 320 loss 2.18369460105896 train acc 0.4548828125\n",
            "epoch 5 batch id 321 loss 1.9083201885223389 train acc 0.4550233644859813\n",
            "epoch 5 batch id 322 loss 1.9023014307022095 train acc 0.4550659937888199\n",
            "epoch 5 batch id 323 loss 2.186119318008423 train acc 0.4548664860681115\n",
            "epoch 5 batch id 324 loss 1.9112110137939453 train acc 0.455102237654321\n",
            "epoch 5 batch id 325 loss 2.118195056915283 train acc 0.45528846153846153\n",
            "epoch 5 batch id 326 loss 1.8496484756469727 train acc 0.455521472392638\n",
            "epoch 5 batch id 327 loss 2.214186906814575 train acc 0.4556097094801223\n",
            "epoch 5 batch id 328 loss 1.9750343561172485 train acc 0.4556497713414634\n",
            "epoch 5 batch id 329 loss 1.924439549446106 train acc 0.4558320668693009\n",
            "epoch 5 batch id 330 loss 1.668626070022583 train acc 0.45615530303030305\n",
            "epoch 5 batch id 331 loss 2.1690351963043213 train acc 0.45628776435045315\n",
            "epoch 5 batch id 332 loss 2.026611804962158 train acc 0.4563723644578313\n",
            "epoch 5 batch id 333 loss 2.0782926082611084 train acc 0.45645645645645644\n",
            "epoch 5 batch id 334 loss 2.0589284896850586 train acc 0.4565868263473054\n",
            "epoch 5 batch id 335 loss 1.8943045139312744 train acc 0.45671641791044776\n",
            "epoch 5 batch id 336 loss 1.8873710632324219 train acc 0.45693824404761907\n",
            "epoch 5 batch id 337 loss 1.7869399785995483 train acc 0.45725148367952523\n",
            "epoch 5 batch id 338 loss 2.130784273147583 train acc 0.4572855029585799\n",
            "epoch 5 batch id 339 loss 2.4147560596466064 train acc 0.4569966814159292\n",
            "epoch 5 batch id 340 loss 2.1991071701049805 train acc 0.4569393382352941\n",
            "epoch 5 batch id 341 loss 2.1944031715393066 train acc 0.45688233137829914\n",
            "epoch 5 batch id 342 loss 2.087615728378296 train acc 0.45705409356725146\n",
            "epoch 5 batch id 343 loss 2.2014570236206055 train acc 0.4568604227405248\n",
            "epoch 5 batch id 344 loss 1.9864364862442017 train acc 0.4569404069767442\n",
            "epoch 5 batch id 345 loss 2.1027369499206543 train acc 0.45706521739130435\n",
            "epoch 5 batch id 346 loss 1.9603697061538696 train acc 0.45736994219653176\n",
            "epoch 5 batch id 347 loss 2.315141439437866 train acc 0.45717759365994237\n",
            "epoch 5 batch id 348 loss 2.4225354194641113 train acc 0.45707614942528735\n",
            "epoch 5 batch id 349 loss 2.081892251968384 train acc 0.4571991404011461\n",
            "epoch 5 batch id 350 loss 2.0246706008911133 train acc 0.4572767857142857\n",
            "epoch 5 batch id 351 loss 2.181353807449341 train acc 0.45726495726495725\n",
            "epoch 5 batch id 352 loss 1.8405826091766357 train acc 0.45747514204545453\n",
            "epoch 5 batch id 353 loss 1.837893009185791 train acc 0.45781692634560905\n",
            "epoch 5 batch id 354 loss 2.1305694580078125 train acc 0.4578036723163842\n",
            "epoch 5 batch id 355 loss 1.8696759939193726 train acc 0.4578785211267606\n",
            "epoch 5 batch id 356 loss 1.710553765296936 train acc 0.45821629213483145\n",
            "epoch 5 batch id 357 loss 2.2526347637176514 train acc 0.4578956582633053\n",
            "epoch 5 batch id 358 loss 2.038468599319458 train acc 0.457838687150838\n",
            "epoch 5 batch id 359 loss 1.9975922107696533 train acc 0.4580431754874652\n",
            "epoch 5 batch id 360 loss 2.1047184467315674 train acc 0.4581163194444444\n",
            "epoch 5 batch id 361 loss 1.8534241914749146 train acc 0.4583189058171745\n",
            "epoch 5 batch id 362 loss 2.018691301345825 train acc 0.45839088397790057\n",
            "epoch 5 batch id 363 loss 2.1812782287597656 train acc 0.4583333333333333\n",
            "epoch 5 batch id 364 loss 1.9345190525054932 train acc 0.45849072802197804\n",
            "epoch 5 batch id 365 loss 2.344373941421509 train acc 0.45830479452054795\n",
            "epoch 5 batch id 366 loss 2.307722568511963 train acc 0.4582479508196721\n",
            "epoch 5 batch id 367 loss 1.8457934856414795 train acc 0.458574591280654\n",
            "epoch 5 batch id 368 loss 2.017336368560791 train acc 0.4585597826086957\n",
            "epoch 5 batch id 369 loss 2.385134696960449 train acc 0.45850271002710025\n",
            "epoch 5 batch id 370 loss 2.097327947616577 train acc 0.45844594594594595\n",
            "epoch 5 batch id 371 loss 2.2741315364837646 train acc 0.4582210242587601\n",
            "epoch 5 batch id 372 loss 2.0049667358398438 train acc 0.4582073252688172\n",
            "epoch 5 batch id 373 loss 2.028839111328125 train acc 0.4581936997319035\n",
            "epoch 5 batch id 374 loss 2.0171499252319336 train acc 0.45826370320855614\n",
            "epoch 5 batch id 375 loss 2.2901971340179443 train acc 0.458125\n",
            "epoch 5 batch id 376 loss 2.0776398181915283 train acc 0.4581532579787234\n",
            "epoch 5 batch id 377 loss 1.8932733535766602 train acc 0.4583057029177719\n",
            "epoch 5 batch id 378 loss 2.219681739807129 train acc 0.4582506613756614\n",
            "epoch 5 batch id 379 loss 1.9956138134002686 train acc 0.4583608179419525\n",
            "epoch 5 batch id 380 loss 2.0314130783081055 train acc 0.45838815789473686\n",
            "epoch 5 batch id 381 loss 2.010019063949585 train acc 0.458497375328084\n",
            "epoch 5 batch id 382 loss 2.178158760070801 train acc 0.45852421465968585\n",
            "epoch 5 batch id 383 loss 1.7227122783660889 train acc 0.45883648825065276\n",
            "epoch 5 batch id 384 loss 2.105229377746582 train acc 0.4589436848958333\n",
            "epoch 5 batch id 385 loss 2.293640613555908 train acc 0.45868506493506495\n",
            "epoch 5 batch id 386 loss 2.017695903778076 train acc 0.4587920984455959\n",
            "epoch 5 batch id 387 loss 1.9119112491607666 train acc 0.4591812015503876\n",
            "epoch 5 batch id 388 loss 2.196338415145874 train acc 0.45912532216494845\n",
            "epoch 5 batch id 389 loss 1.821868658065796 train acc 0.45947140102827766\n",
            "epoch 5 batch id 390 loss 2.0433242321014404 train acc 0.4596153846153846\n",
            "epoch 5 batch id 391 loss 2.099203586578369 train acc 0.4594389386189258\n",
            "epoch 5 batch id 392 loss 2.04703688621521 train acc 0.45958227040816324\n",
            "epoch 5 batch id 393 loss 2.1047616004943848 train acc 0.459764631043257\n",
            "epoch 5 batch id 394 loss 1.9395017623901367 train acc 0.4599460659898477\n",
            "epoch 5 batch id 395 loss 2.023073434829712 train acc 0.45996835443037976\n",
            "epoch 5 batch id 396 loss 1.778592824935913 train acc 0.46018781565656564\n",
            "epoch 5 batch id 397 loss 2.423293352127075 train acc 0.4600913098236776\n",
            "epoch 5 batch id 398 loss 2.4681925773620605 train acc 0.45991677135678394\n",
            "epoch 5 batch id 399 loss 1.8463679552078247 train acc 0.46017387218045114\n",
            "epoch 5 batch id 400 loss 2.011164665222168 train acc 0.460234375\n",
            "epoch 5 batch id 401 loss 2.4314966201782227 train acc 0.4601387157107232\n",
            "epoch 5 batch id 402 loss 1.677036166191101 train acc 0.46050995024875624\n",
            "epoch 5 batch id 403 loss 1.7471370697021484 train acc 0.4607242555831266\n",
            "epoch 5 batch id 404 loss 2.1682240962982178 train acc 0.4607441212871287\n",
            "epoch 5 batch id 405 loss 2.230607748031616 train acc 0.46068672839506175\n",
            "epoch 5 batch id 406 loss 1.797876238822937 train acc 0.46101447044334976\n",
            "epoch 5 batch id 407 loss 2.0834507942199707 train acc 0.4609183046683047\n",
            "epoch 5 batch id 408 loss 2.1661534309387207 train acc 0.4608609068627451\n",
            "epoch 5 batch id 409 loss 2.1152379512786865 train acc 0.46110941320293397\n",
            "epoch 5 batch id 410 loss 2.2046351432800293 train acc 0.4611280487804878\n",
            "epoch 5 batch id 411 loss 2.2959187030792236 train acc 0.4612986618004866\n",
            "epoch 5 batch id 412 loss 2.3194539546966553 train acc 0.46116504854368934\n",
            "epoch 5 batch id 413 loss 2.503542423248291 train acc 0.46091858353510895\n",
            "epoch 5 batch id 414 loss 2.092127561569214 train acc 0.4609752415458937\n",
            "epoch 5 batch id 415 loss 2.087087631225586 train acc 0.46095632530120484\n",
            "epoch 5 batch id 416 loss 1.8739285469055176 train acc 0.46105018028846156\n",
            "epoch 5 batch id 417 loss 2.049300193786621 train acc 0.4612185251798561\n",
            "epoch 5 batch id 418 loss 2.3396830558776855 train acc 0.4610870215311005\n",
            "epoch 5 batch id 419 loss 2.157909631729126 train acc 0.4610307279236277\n",
            "epoch 5 batch id 420 loss 1.879323124885559 train acc 0.46104910714285713\n",
            "epoch 5 batch id 421 loss 1.8962281942367554 train acc 0.46121585510688834\n",
            "epoch 5 batch id 422 loss 2.180253505706787 train acc 0.46108560426540285\n",
            "epoch 5 batch id 423 loss 2.3259310722351074 train acc 0.4610667848699764\n",
            "epoch 5 batch id 424 loss 2.227968215942383 train acc 0.46126916273584906\n",
            "epoch 5 batch id 425 loss 1.958420991897583 train acc 0.46143382352941176\n",
            "epoch 5 batch id 426 loss 2.1127212047576904 train acc 0.46156103286384975\n",
            "epoch 5 batch id 427 loss 2.1576101779937744 train acc 0.461577868852459\n",
            "epoch 5 batch id 428 loss 2.0006203651428223 train acc 0.4615946261682243\n",
            "epoch 5 batch id 429 loss 2.3312156200408936 train acc 0.4614291958041958\n",
            "epoch 5 batch id 430 loss 1.7867934703826904 train acc 0.4615552325581395\n",
            "epoch 5 batch id 431 loss 2.1494104862213135 train acc 0.4614994199535963\n",
            "epoch 5 batch id 432 loss 1.8820891380310059 train acc 0.46166087962962965\n",
            "epoch 5 batch id 433 loss 2.4205706119537354 train acc 0.4614968244803695\n",
            "epoch 5 batch id 434 loss 1.945887804031372 train acc 0.46180155529953915\n",
            "epoch 5 batch id 435 loss 1.994738221168518 train acc 0.4618175287356322\n",
            "epoch 5 batch id 436 loss 1.8350273370742798 train acc 0.462120126146789\n",
            "epoch 5 batch id 437 loss 2.044367790222168 train acc 0.4622425629290618\n",
            "epoch 5 batch id 438 loss 1.650742530822754 train acc 0.4626498287671233\n",
            "epoch 5 batch id 439 loss 2.086829662322998 train acc 0.46262813211845105\n",
            "epoch 5 batch id 440 loss 2.1427674293518066 train acc 0.46260653409090907\n",
            "epoch 5 batch id 441 loss 2.1346702575683594 train acc 0.4626204648526077\n",
            "epoch 5 batch id 442 loss 2.177320957183838 train acc 0.4626696832579186\n",
            "epoch 5 batch id 443 loss 2.1842055320739746 train acc 0.46250705417607224\n",
            "epoch 5 batch id 444 loss 2.1730806827545166 train acc 0.46248592342342343\n",
            "epoch 5 batch id 445 loss 1.9938395023345947 train acc 0.4623595505617977\n",
            "epoch 5 batch id 446 loss 2.00404953956604 train acc 0.4623038116591928\n",
            "epoch 5 batch id 447 loss 2.127542495727539 train acc 0.46217841163310963\n",
            "epoch 5 batch id 448 loss 1.8036177158355713 train acc 0.4624720982142857\n",
            "epoch 5 batch id 449 loss 1.74994957447052 train acc 0.4627644766146993\n",
            "epoch 5 batch id 450 loss 2.0070924758911133 train acc 0.46284722222222224\n",
            "epoch 5 batch id 451 loss 1.8757325410842896 train acc 0.4629642461197339\n",
            "epoch 5 batch id 452 loss 2.1201484203338623 train acc 0.462804203539823\n",
            "epoch 5 batch id 453 loss 2.4288454055786133 train acc 0.4628173289183223\n",
            "epoch 5 batch id 454 loss 2.1335136890411377 train acc 0.46276156387665196\n",
            "epoch 5 batch id 455 loss 2.1743669509887695 train acc 0.462706043956044\n",
            "epoch 5 batch id 456 loss 2.2229437828063965 train acc 0.46254797149122806\n",
            "epoch 5 batch id 457 loss 2.473992347717285 train acc 0.4624247811816193\n",
            "epoch 5 batch id 458 loss 1.8319995403289795 train acc 0.46264328602620086\n",
            "epoch 5 batch id 459 loss 2.177438497543335 train acc 0.46262254901960786\n",
            "epoch 5 batch id 460 loss 2.164808988571167 train acc 0.4625679347826087\n",
            "epoch 5 batch id 461 loss 1.714173674583435 train acc 0.46268302603036876\n",
            "epoch 5 batch id 462 loss 2.2581231594085693 train acc 0.46252705627705626\n",
            "epoch 5 batch id 463 loss 1.9009230136871338 train acc 0.4626754859611231\n",
            "epoch 5 batch id 464 loss 1.8169686794281006 train acc 0.46282327586206895\n",
            "epoch 5 batch id 465 loss 1.7847189903259277 train acc 0.46297043010752686\n",
            "epoch 5 batch id 466 loss 1.6970878839492798 train acc 0.46318401287553645\n",
            "epoch 5 batch id 467 loss 2.038564682006836 train acc 0.4631624732334047\n",
            "epoch 5 batch id 468 loss 1.6457507610321045 train acc 0.46347489316239315\n",
            "epoch 5 batch id 469 loss 2.1337223052978516 train acc 0.46338619402985076\n",
            "epoch 5 batch id 470 loss 2.0518486499786377 train acc 0.4632646276595745\n",
            "epoch 5 batch id 471 loss 2.038203239440918 train acc 0.4632430997876858\n",
            "epoch 5 batch id 472 loss 1.8187541961669922 train acc 0.4633209745762712\n",
            "epoch 5 batch id 473 loss 1.9748287200927734 train acc 0.46349762156448204\n",
            "epoch 5 batch id 474 loss 2.30965256690979 train acc 0.4634098101265823\n",
            "epoch 5 batch id 475 loss 2.3599131107330322 train acc 0.46325657894736844\n",
            "epoch 5 batch id 476 loss 1.9932234287261963 train acc 0.46330094537815125\n",
            "epoch 5 batch id 477 loss 1.6472301483154297 train acc 0.46360718029350106\n",
            "epoch 5 batch id 478 loss 1.9544721841812134 train acc 0.46361793933054396\n",
            "epoch 5 batch id 479 loss 2.184565544128418 train acc 0.4636286534446764\n",
            "epoch 5 batch id 480 loss 2.0197386741638184 train acc 0.4637044270833333\n",
            "epoch 5 batch id 481 loss 2.0785138607025146 train acc 0.46371491683991684\n",
            "epoch 5 batch id 482 loss 1.829142689704895 train acc 0.46385503112033194\n",
            "epoch 5 batch id 483 loss 1.7691391706466675 train acc 0.46405926501035194\n",
            "epoch 5 batch id 484 loss 1.838985562324524 train acc 0.46423037190082644\n",
            "epoch 5 batch id 485 loss 2.1691980361938477 train acc 0.46427190721649486\n",
            "epoch 5 batch id 486 loss 2.069960117340088 train acc 0.4643132716049383\n",
            "epoch 5 batch id 487 loss 2.3629491329193115 train acc 0.4642902977412731\n",
            "epoch 5 batch id 488 loss 1.7415205240249634 train acc 0.4644275102459016\n",
            "epoch 5 batch id 489 loss 1.818621277809143 train acc 0.46462806748466257\n",
            "epoch 5 batch id 490 loss 2.0976932048797607 train acc 0.4644132653061224\n",
            "epoch 5 batch id 491 loss 1.8740719556808472 train acc 0.46464485743380857\n",
            "epoch 5 batch id 492 loss 1.647350549697876 train acc 0.4649072662601626\n",
            "epoch 5 batch id 493 loss 2.165527105331421 train acc 0.4649467545638945\n",
            "epoch 5 batch id 494 loss 1.9119672775268555 train acc 0.4650177125506073\n",
            "epoch 5 batch id 495 loss 1.6975553035736084 train acc 0.46521464646464644\n",
            "epoch 5 batch id 496 loss 2.021022081375122 train acc 0.46525327620967744\n",
            "epoch 5 batch id 497 loss 1.768131136894226 train acc 0.4653546277665996\n",
            "epoch 5 batch id 498 loss 2.127885103225708 train acc 0.4653300702811245\n",
            "epoch 5 batch id 499 loss 2.0524489879608154 train acc 0.4652116733466934\n",
            "epoch 5 batch id 500 loss 2.1628823280334473 train acc 0.46515625\n",
            "epoch 5 batch id 501 loss 1.9158991575241089 train acc 0.4654129241516966\n",
            "epoch 5 batch id 502 loss 1.831048607826233 train acc 0.46566857569721115\n",
            "epoch 5 batch id 503 loss 1.8706828355789185 train acc 0.4657678926441352\n",
            "epoch 5 batch id 504 loss 1.8057081699371338 train acc 0.4659288194444444\n",
            "epoch 5 batch id 505 loss 2.223254680633545 train acc 0.46584158415841587\n",
            "epoch 5 batch id 506 loss 1.8340497016906738 train acc 0.4659399703557312\n",
            "epoch 5 batch id 507 loss 1.938538908958435 train acc 0.46600714990138065\n",
            "epoch 5 batch id 508 loss 1.5751160383224487 train acc 0.46635088582677164\n",
            "epoch 5 batch id 509 loss 1.897704005241394 train acc 0.4663249017681729\n",
            "epoch 5 batch id 510 loss 2.025193929672241 train acc 0.46654411764705883\n",
            "epoch 5 batch id 511 loss 1.691173791885376 train acc 0.4666872456745255\n",
            "epoch 5 train acc 0.4666872456745255\n",
            "epoch 5 test acc 0.3855387369791667\n",
            "epoch 6 batch id 1 loss 1.8394261598587036 train acc 0.515625\n",
            "epoch 6 batch id 2 loss 1.8527129888534546 train acc 0.5078125\n",
            "epoch 6 batch id 3 loss 1.7974615097045898 train acc 0.5104166666666666\n",
            "epoch 6 batch id 4 loss 1.8063446283340454 train acc 0.51171875\n",
            "epoch 6 batch id 5 loss 1.916326880455017 train acc 0.5125\n",
            "epoch 6 batch id 6 loss 1.8384658098220825 train acc 0.5130208333333334\n",
            "epoch 6 batch id 7 loss 1.9719772338867188 train acc 0.5089285714285714\n",
            "epoch 6 batch id 8 loss 1.73271906375885 train acc 0.505859375\n",
            "epoch 6 batch id 9 loss 2.10292649269104 train acc 0.4947916666666667\n",
            "epoch 6 batch id 10 loss 1.900743007659912 train acc 0.4984375\n",
            "epoch 6 batch id 11 loss 2.187124490737915 train acc 0.4928977272727273\n",
            "epoch 6 batch id 12 loss 2.339249610900879 train acc 0.484375\n",
            "epoch 6 batch id 13 loss 1.8881628513336182 train acc 0.48677884615384615\n",
            "epoch 6 batch id 14 loss 1.8635178804397583 train acc 0.48660714285714285\n",
            "epoch 6 batch id 15 loss 2.109391689300537 train acc 0.48020833333333335\n",
            "epoch 6 batch id 16 loss 1.8371410369873047 train acc 0.48046875\n",
            "epoch 6 batch id 17 loss 1.7896883487701416 train acc 0.4852941176470588\n",
            "epoch 6 batch id 18 loss 1.7996622323989868 train acc 0.4895833333333333\n",
            "epoch 6 batch id 19 loss 2.0380702018737793 train acc 0.4901315789473684\n",
            "epoch 6 batch id 20 loss 1.8592451810836792 train acc 0.49453125\n",
            "epoch 6 batch id 21 loss 1.7955378293991089 train acc 0.4947916666666667\n",
            "epoch 6 batch id 22 loss 2.2043440341949463 train acc 0.4914772727272727\n",
            "epoch 6 batch id 23 loss 1.5286794900894165 train acc 0.4986413043478261\n",
            "epoch 6 batch id 24 loss 1.8722609281539917 train acc 0.4973958333333333\n",
            "epoch 6 batch id 25 loss 2.0602617263793945 train acc 0.498125\n",
            "epoch 6 batch id 26 loss 2.0065650939941406 train acc 0.4963942307692308\n",
            "epoch 6 batch id 27 loss 2.029834747314453 train acc 0.4965277777777778\n",
            "epoch 6 batch id 28 loss 2.122509002685547 train acc 0.4921875\n",
            "epoch 6 batch id 29 loss 1.983130931854248 train acc 0.49191810344827586\n",
            "epoch 6 batch id 30 loss 2.0627360343933105 train acc 0.49166666666666664\n",
            "epoch 6 batch id 31 loss 2.0070865154266357 train acc 0.49294354838709675\n",
            "epoch 6 batch id 32 loss 1.8154321908950806 train acc 0.49609375\n",
            "epoch 6 batch id 33 loss 1.9824672937393188 train acc 0.4943181818181818\n",
            "epoch 6 batch id 34 loss 2.0486435890197754 train acc 0.4944852941176471\n",
            "epoch 6 batch id 35 loss 2.083374500274658 train acc 0.49375\n",
            "epoch 6 batch id 36 loss 1.9564437866210938 train acc 0.4939236111111111\n",
            "epoch 6 batch id 37 loss 1.7620223760604858 train acc 0.49408783783783783\n",
            "epoch 6 batch id 38 loss 1.903588891029358 train acc 0.49588815789473684\n",
            "epoch 6 batch id 39 loss 2.029294967651367 train acc 0.49439102564102566\n",
            "epoch 6 batch id 40 loss 1.9853533506393433 train acc 0.494921875\n",
            "epoch 6 batch id 41 loss 1.7826627492904663 train acc 0.4973323170731707\n",
            "epoch 6 batch id 42 loss 2.3284261226654053 train acc 0.49516369047619047\n",
            "epoch 6 batch id 43 loss 1.7870055437088013 train acc 0.4967296511627907\n",
            "epoch 6 batch id 44 loss 1.9333772659301758 train acc 0.4968039772727273\n",
            "epoch 6 batch id 45 loss 2.3732826709747314 train acc 0.49375\n",
            "epoch 6 batch id 46 loss 2.183246612548828 train acc 0.4935461956521739\n",
            "epoch 6 batch id 47 loss 2.040639877319336 train acc 0.4933510638297872\n",
            "epoch 6 batch id 48 loss 1.661521315574646 train acc 0.4951171875\n",
            "epoch 6 batch id 49 loss 2.371861219406128 train acc 0.49394132653061223\n",
            "epoch 6 batch id 50 loss 1.8908144235610962 train acc 0.494375\n",
            "epoch 6 batch id 51 loss 1.9972398281097412 train acc 0.49387254901960786\n",
            "epoch 6 batch id 52 loss 2.159721851348877 train acc 0.4930889423076923\n",
            "epoch 6 batch id 53 loss 1.6848948001861572 train acc 0.49528301886792453\n",
            "epoch 6 batch id 54 loss 1.760862112045288 train acc 0.49623842592592593\n",
            "epoch 6 batch id 55 loss 2.0139055252075195 train acc 0.4948863636363636\n",
            "epoch 6 batch id 56 loss 1.9619927406311035 train acc 0.49497767857142855\n",
            "epoch 6 batch id 57 loss 1.8576247692108154 train acc 0.49643640350877194\n",
            "epoch 6 batch id 58 loss 1.9833791255950928 train acc 0.49811422413793105\n",
            "epoch 6 batch id 59 loss 1.6661227941513062 train acc 0.4989406779661017\n",
            "epoch 6 batch id 60 loss 1.6459604501724243 train acc 0.49947916666666664\n",
            "epoch 6 batch id 61 loss 1.68452787399292 train acc 0.49974385245901637\n",
            "epoch 6 batch id 62 loss 2.2235422134399414 train acc 0.49747983870967744\n",
            "epoch 6 batch id 63 loss 1.6710478067398071 train acc 0.4982638888888889\n",
            "epoch 6 batch id 64 loss 1.7502610683441162 train acc 0.4990234375\n",
            "epoch 6 batch id 65 loss 1.7157241106033325 train acc 0.49927884615384616\n",
            "epoch 6 batch id 66 loss 2.0044777393341064 train acc 0.4981060606060606\n",
            "epoch 6 batch id 67 loss 1.7857240438461304 train acc 0.49906716417910446\n",
            "epoch 6 batch id 68 loss 1.5841288566589355 train acc 0.5006893382352942\n",
            "epoch 6 batch id 69 loss 1.9425163269042969 train acc 0.5011322463768116\n",
            "epoch 6 batch id 70 loss 2.1717453002929688 train acc 0.49955357142857143\n",
            "epoch 6 batch id 71 loss 2.0735933780670166 train acc 0.49867957746478875\n",
            "epoch 6 batch id 72 loss 1.972272276878357 train acc 0.4982638888888889\n",
            "epoch 6 batch id 73 loss 1.9663636684417725 train acc 0.4982876712328767\n",
            "epoch 6 batch id 74 loss 1.6163791418075562 train acc 0.5002111486486487\n",
            "epoch 6 batch id 75 loss 1.9196370840072632 train acc 0.5010416666666667\n",
            "epoch 6 batch id 76 loss 2.2002978324890137 train acc 0.5\n",
            "epoch 6 batch id 77 loss 2.133328437805176 train acc 0.500202922077922\n",
            "epoch 6 batch id 78 loss 1.902770757675171 train acc 0.5002003205128205\n",
            "epoch 6 batch id 79 loss 1.9639843702316284 train acc 0.5001977848101266\n",
            "epoch 6 batch id 80 loss 1.725110650062561 train acc 0.5005859375\n",
            "epoch 6 batch id 81 loss 1.9015711545944214 train acc 0.5\n",
            "epoch 6 batch id 82 loss 1.8877732753753662 train acc 0.5003810975609756\n",
            "epoch 6 batch id 83 loss 1.7034581899642944 train acc 0.5016942771084337\n",
            "epoch 6 batch id 84 loss 1.925161361694336 train acc 0.5016741071428571\n",
            "epoch 6 batch id 85 loss 2.0759682655334473 train acc 0.5016544117647059\n",
            "epoch 6 batch id 86 loss 2.0683231353759766 train acc 0.5016351744186046\n",
            "epoch 6 batch id 87 loss 2.047849655151367 train acc 0.5014367816091954\n",
            "epoch 6 batch id 88 loss 2.1477365493774414 train acc 0.5012428977272727\n",
            "epoch 6 batch id 89 loss 1.8955072164535522 train acc 0.500877808988764\n",
            "epoch 6 batch id 90 loss 1.8661248683929443 train acc 0.5017361111111112\n",
            "epoch 6 batch id 91 loss 1.7283005714416504 train acc 0.5018887362637363\n",
            "epoch 6 batch id 92 loss 1.9257805347442627 train acc 0.502547554347826\n",
            "epoch 6 batch id 93 loss 2.174433469772339 train acc 0.5023521505376344\n",
            "epoch 6 batch id 94 loss 1.5748741626739502 train acc 0.5038231382978723\n",
            "epoch 6 batch id 95 loss 2.133054256439209 train acc 0.5034539473684211\n",
            "epoch 6 batch id 96 loss 2.3404757976531982 train acc 0.5029296875\n",
            "epoch 6 batch id 97 loss 1.927183747291565 train acc 0.5040270618556701\n",
            "epoch 6 batch id 98 loss 2.2748076915740967 train acc 0.5033482142857143\n",
            "epoch 6 batch id 99 loss 1.9303447008132935 train acc 0.5037878787878788\n",
            "epoch 6 batch id 100 loss 1.8607407808303833 train acc 0.5040625\n",
            "epoch 6 batch id 101 loss 1.8728737831115723 train acc 0.5043316831683168\n",
            "epoch 6 batch id 102 loss 1.8510115146636963 train acc 0.5045955882352942\n",
            "epoch 6 batch id 103 loss 1.8583422899246216 train acc 0.504247572815534\n",
            "epoch 6 batch id 104 loss 1.7268404960632324 train acc 0.5048076923076923\n",
            "epoch 6 batch id 105 loss 1.9748148918151855 train acc 0.5047619047619047\n",
            "epoch 6 batch id 106 loss 1.851525902748108 train acc 0.5050117924528302\n",
            "epoch 6 batch id 107 loss 2.1463463306427 train acc 0.5046728971962616\n",
            "epoch 6 batch id 108 loss 1.7111029624938965 train acc 0.5060763888888888\n",
            "epoch 6 batch id 109 loss 2.0563745498657227 train acc 0.5055905963302753\n",
            "epoch 6 batch id 110 loss 1.4160642623901367 train acc 0.5075284090909091\n",
            "epoch 6 batch id 111 loss 1.6162060499191284 train acc 0.5083051801801802\n",
            "epoch 6 batch id 112 loss 1.8700560331344604 train acc 0.5087890625\n",
            "epoch 6 batch id 113 loss 1.7938470840454102 train acc 0.5092643805309734\n",
            "epoch 6 batch id 114 loss 1.8109116554260254 train acc 0.5095942982456141\n",
            "epoch 6 batch id 115 loss 1.9461232423782349 train acc 0.509375\n",
            "epoch 6 batch id 116 loss 1.6158937215805054 train acc 0.5099676724137931\n",
            "epoch 6 batch id 117 loss 1.763781189918518 train acc 0.5106837606837606\n",
            "epoch 6 batch id 118 loss 1.7946085929870605 train acc 0.5111228813559322\n",
            "epoch 6 batch id 119 loss 2.0055856704711914 train acc 0.5115546218487395\n",
            "epoch 6 batch id 120 loss 1.8487974405288696 train acc 0.511328125\n",
            "epoch 6 batch id 121 loss 1.803478717803955 train acc 0.5112345041322314\n",
            "epoch 6 batch id 122 loss 1.9135757684707642 train acc 0.5111424180327869\n",
            "epoch 6 batch id 123 loss 1.6700215339660645 train acc 0.5119410569105691\n",
            "epoch 6 batch id 124 loss 1.9492117166519165 train acc 0.5120967741935484\n",
            "epoch 6 batch id 125 loss 1.908538579940796 train acc 0.51175\n",
            "epoch 6 batch id 126 loss 1.983816146850586 train acc 0.5115327380952381\n",
            "epoch 6 batch id 127 loss 2.3884334564208984 train acc 0.5111958661417323\n",
            "epoch 6 batch id 128 loss 1.8706426620483398 train acc 0.510986328125\n",
            "epoch 6 batch id 129 loss 1.723510503768921 train acc 0.5110222868217055\n",
            "epoch 6 batch id 130 loss 1.7019888162612915 train acc 0.5110576923076923\n",
            "epoch 6 batch id 131 loss 1.7509143352508545 train acc 0.5120467557251909\n",
            "epoch 6 batch id 132 loss 1.7416106462478638 train acc 0.5124289772727273\n",
            "epoch 6 batch id 133 loss 2.154646396636963 train acc 0.5123355263157895\n",
            "epoch 6 batch id 134 loss 2.0974583625793457 train acc 0.5123600746268657\n",
            "epoch 6 batch id 135 loss 2.1192634105682373 train acc 0.5116898148148148\n",
            "epoch 6 batch id 136 loss 2.1027448177337646 train acc 0.5107996323529411\n",
            "epoch 6 batch id 137 loss 1.958152413368225 train acc 0.510720802919708\n",
            "epoch 6 batch id 138 loss 1.8064252138137817 train acc 0.5109827898550725\n",
            "epoch 6 batch id 139 loss 1.8561543226242065 train acc 0.5109037769784173\n",
            "epoch 6 batch id 140 loss 2.047619342803955 train acc 0.5106026785714286\n",
            "epoch 6 batch id 141 loss 2.0214312076568604 train acc 0.5101950354609929\n",
            "epoch 6 batch id 142 loss 1.8076112270355225 train acc 0.5107834507042254\n",
            "epoch 6 batch id 143 loss 1.8470369577407837 train acc 0.5109265734265734\n",
            "epoch 6 batch id 144 loss 2.0438144207000732 train acc 0.5105251736111112\n",
            "epoch 6 batch id 145 loss 2.130688190460205 train acc 0.5103448275862069\n",
            "epoch 6 batch id 146 loss 2.1401963233947754 train acc 0.509845890410959\n",
            "epoch 6 batch id 147 loss 1.6400585174560547 train acc 0.5099914965986394\n",
            "epoch 6 batch id 148 loss 2.2839934825897217 train acc 0.5095016891891891\n",
            "epoch 6 batch id 149 loss 1.7889378070831299 train acc 0.5099622483221476\n",
            "epoch 6 batch id 150 loss 1.9586739540100098 train acc 0.51\n",
            "epoch 6 batch id 151 loss 2.0493242740631104 train acc 0.5100372516556292\n",
            "epoch 6 batch id 152 loss 1.9020068645477295 train acc 0.5103824013157895\n",
            "epoch 6 batch id 153 loss 2.0225985050201416 train acc 0.5104166666666666\n",
            "epoch 6 batch id 154 loss 2.0062549114227295 train acc 0.510450487012987\n",
            "epoch 6 batch id 155 loss 1.9880390167236328 train acc 0.5105846774193549\n",
            "epoch 6 batch id 156 loss 2.0145628452301025 train acc 0.5104166666666666\n",
            "epoch 6 batch id 157 loss 1.948569416999817 train acc 0.5106488853503185\n",
            "epoch 6 batch id 158 loss 2.1164073944091797 train acc 0.5105814873417721\n",
            "epoch 6 batch id 159 loss 2.017115831375122 train acc 0.5104166666666666\n",
            "epoch 6 batch id 160 loss 1.8771852254867554 train acc 0.5107421875\n",
            "epoch 6 batch id 161 loss 2.2422313690185547 train acc 0.5100931677018633\n",
            "epoch 6 batch id 162 loss 1.8210169076919556 train acc 0.5103202160493827\n",
            "epoch 6 batch id 163 loss 1.6169986724853516 train acc 0.5102569018404908\n",
            "epoch 6 batch id 164 loss 1.9594025611877441 train acc 0.5103849085365854\n",
            "epoch 6 batch id 165 loss 1.6457816362380981 train acc 0.5108901515151515\n",
            "epoch 6 batch id 166 loss 1.6799452304840088 train acc 0.5110128012048193\n",
            "epoch 6 batch id 167 loss 1.9616203308105469 train acc 0.5106661676646707\n",
            "epoch 6 batch id 168 loss 2.1877431869506836 train acc 0.5101376488095238\n",
            "epoch 6 batch id 169 loss 1.7599622011184692 train acc 0.5108173076923077\n",
            "epoch 6 batch id 170 loss 2.1775262355804443 train acc 0.5097426470588236\n",
            "epoch 6 batch id 171 loss 1.7319263219833374 train acc 0.5097770467836257\n",
            "epoch 6 batch id 172 loss 1.879593014717102 train acc 0.5101744186046512\n",
            "epoch 6 batch id 173 loss 1.814217209815979 train acc 0.5097543352601156\n",
            "epoch 6 batch id 174 loss 1.7179102897644043 train acc 0.5100574712643678\n",
            "epoch 6 batch id 175 loss 2.2478904724121094 train acc 0.5097321428571429\n",
            "epoch 6 batch id 176 loss 1.839091420173645 train acc 0.509765625\n",
            "epoch 6 batch id 177 loss 1.7678885459899902 train acc 0.5099752824858758\n",
            "epoch 6 batch id 178 loss 2.0821712017059326 train acc 0.5096558988764045\n",
            "epoch 6 batch id 179 loss 2.059551477432251 train acc 0.5098638268156425\n",
            "epoch 6 batch id 180 loss 1.798237919807434 train acc 0.5096354166666667\n",
            "epoch 6 batch id 181 loss 1.8912582397460938 train acc 0.5099274861878453\n",
            "epoch 6 batch id 182 loss 1.8410866260528564 train acc 0.5097870879120879\n",
            "epoch 6 batch id 183 loss 1.6575006246566772 train acc 0.5102459016393442\n",
            "epoch 6 batch id 184 loss 2.039017677307129 train acc 0.5100203804347826\n",
            "epoch 6 batch id 185 loss 1.9501241445541382 train acc 0.5097128378378378\n",
            "epoch 6 batch id 186 loss 1.751003384590149 train acc 0.5096606182795699\n",
            "epoch 6 batch id 187 loss 2.012819528579712 train acc 0.5093582887700535\n",
            "epoch 6 batch id 188 loss 2.262382984161377 train acc 0.5092253989361702\n",
            "epoch 6 batch id 189 loss 1.7728040218353271 train acc 0.5096726190476191\n",
            "epoch 6 batch id 190 loss 2.394887924194336 train acc 0.5087993421052631\n",
            "epoch 6 batch id 191 loss 2.262208938598633 train acc 0.5085078534031413\n",
            "epoch 6 batch id 192 loss 1.788810133934021 train acc 0.508544921875\n",
            "epoch 6 batch id 193 loss 1.5527758598327637 train acc 0.509229274611399\n",
            "epoch 6 batch id 194 loss 1.9195890426635742 train acc 0.5093427835051546\n",
            "epoch 6 batch id 195 loss 1.8825740814208984 train acc 0.5090544871794872\n",
            "epoch 6 batch id 196 loss 1.8515180349349976 train acc 0.5090082908163265\n",
            "epoch 6 batch id 197 loss 2.222994804382324 train acc 0.5087246192893401\n",
            "epoch 6 batch id 198 loss 1.7777496576309204 train acc 0.5088383838383839\n",
            "epoch 6 batch id 199 loss 2.0768609046936035 train acc 0.508322864321608\n",
            "epoch 6 batch id 200 loss 1.8762873411178589 train acc 0.50828125\n",
            "epoch 6 batch id 201 loss 2.041895627975464 train acc 0.5082400497512438\n",
            "epoch 6 batch id 202 loss 1.8708250522613525 train acc 0.5084313118811881\n",
            "epoch 6 batch id 203 loss 1.9936689138412476 train acc 0.5082358374384236\n",
            "epoch 6 batch id 204 loss 1.6740342378616333 train acc 0.5083486519607843\n",
            "epoch 6 batch id 205 loss 1.8800394535064697 train acc 0.5084603658536585\n",
            "epoch 6 batch id 206 loss 1.886868953704834 train acc 0.5087985436893204\n",
            "epoch 6 batch id 207 loss 1.7858080863952637 train acc 0.5088315217391305\n",
            "epoch 6 batch id 208 loss 1.9835563898086548 train acc 0.5086388221153846\n",
            "epoch 6 batch id 209 loss 2.00950288772583 train acc 0.5083732057416268\n",
            "epoch 6 batch id 210 loss 1.5528782606124878 train acc 0.5087797619047619\n",
            "epoch 6 batch id 211 loss 1.6241459846496582 train acc 0.5088862559241706\n",
            "epoch 6 batch id 212 loss 1.86400306224823 train acc 0.5091391509433962\n",
            "epoch 6 batch id 213 loss 1.600222110748291 train acc 0.5093163145539906\n",
            "epoch 6 batch id 214 loss 1.6010007858276367 train acc 0.5097838785046729\n",
            "epoch 6 batch id 215 loss 1.7728548049926758 train acc 0.5097383720930233\n",
            "epoch 6 batch id 216 loss 1.7657357454299927 train acc 0.5099103009259259\n",
            "epoch 6 batch id 217 loss 1.7178770303726196 train acc 0.5099366359447005\n",
            "epoch 6 batch id 218 loss 1.886611819267273 train acc 0.509819380733945\n",
            "epoch 6 batch id 219 loss 1.8445097208023071 train acc 0.5099172374429224\n",
            "epoch 6 batch id 220 loss 1.81121027469635 train acc 0.51015625\n",
            "epoch 6 batch id 221 loss 1.7663006782531738 train acc 0.5104638009049773\n",
            "epoch 6 batch id 222 loss 1.7574636936187744 train acc 0.5104166666666666\n",
            "epoch 6 batch id 223 loss 1.8581069707870483 train acc 0.5106502242152466\n",
            "epoch 6 batch id 224 loss 1.4035015106201172 train acc 0.5110909598214286\n",
            "epoch 6 batch id 225 loss 1.7881269454956055 train acc 0.5109027777777778\n",
            "epoch 6 batch id 226 loss 1.8687458038330078 train acc 0.5107853982300885\n",
            "epoch 6 batch id 227 loss 1.8498958349227905 train acc 0.5110820484581498\n",
            "epoch 6 batch id 228 loss 1.9733519554138184 train acc 0.5109649122807017\n",
            "epoch 6 batch id 229 loss 1.8877060413360596 train acc 0.5108487991266376\n",
            "epoch 6 batch id 230 loss 1.8021489381790161 train acc 0.5107336956521739\n",
            "epoch 6 batch id 231 loss 1.7926057577133179 train acc 0.5107548701298701\n",
            "epoch 6 batch id 232 loss 1.7540662288665771 train acc 0.5108432112068966\n",
            "epoch 6 batch id 233 loss 1.5941944122314453 train acc 0.511199034334764\n",
            "epoch 6 batch id 234 loss 1.681050419807434 train acc 0.5111511752136753\n",
            "epoch 6 batch id 235 loss 2.2045557498931885 train acc 0.5110372340425532\n",
            "epoch 6 batch id 236 loss 1.8960803747177124 train acc 0.5110566737288136\n",
            "epoch 6 batch id 237 loss 1.9403008222579956 train acc 0.5109440928270043\n",
            "epoch 6 batch id 238 loss 1.7417305707931519 train acc 0.5109637605042017\n",
            "epoch 6 batch id 239 loss 1.9138665199279785 train acc 0.5107871338912134\n",
            "epoch 6 batch id 240 loss 1.9871996641159058 train acc 0.5107421875\n",
            "epoch 6 batch id 241 loss 1.6353297233581543 train acc 0.5108272821576764\n",
            "epoch 6 batch id 242 loss 2.1502270698547363 train acc 0.5106534090909091\n",
            "epoch 6 batch id 243 loss 1.8850549459457397 train acc 0.510545267489712\n",
            "epoch 6 batch id 244 loss 2.126906633377075 train acc 0.5101178278688525\n",
            "epoch 6 batch id 245 loss 1.746899127960205 train acc 0.5102040816326531\n",
            "epoch 6 batch id 246 loss 2.263439178466797 train acc 0.5099720528455285\n",
            "epoch 6 batch id 247 loss 1.7841665744781494 train acc 0.5103744939271255\n",
            "epoch 6 batch id 248 loss 1.5903750658035278 train acc 0.510773689516129\n",
            "epoch 6 batch id 249 loss 1.9800302982330322 train acc 0.5106676706827309\n",
            "epoch 6 batch id 250 loss 2.1356630325317383 train acc 0.5105\n",
            "epoch 6 batch id 251 loss 1.6363426446914673 train acc 0.5108939243027888\n",
            "epoch 6 batch id 252 loss 1.7297194004058838 train acc 0.5109126984126984\n",
            "epoch 6 batch id 253 loss 1.7618942260742188 train acc 0.5110548418972332\n",
            "epoch 6 batch id 254 loss 1.751876950263977 train acc 0.5110728346456693\n",
            "epoch 6 batch id 255 loss 1.8948675394058228 train acc 0.5113357843137255\n",
            "epoch 6 batch id 256 loss 1.7325888872146606 train acc 0.511474609375\n",
            "epoch 6 batch id 257 loss 1.8606683015823364 train acc 0.5115515564202334\n",
            "epoch 6 batch id 258 loss 1.8068827390670776 train acc 0.5117490310077519\n",
            "epoch 6 batch id 259 loss 1.9433807134628296 train acc 0.5115830115830116\n",
            "epoch 6 batch id 260 loss 1.9762415885925293 train acc 0.5114182692307693\n",
            "epoch 6 batch id 261 loss 1.8190464973449707 train acc 0.5114343869731801\n",
            "epoch 6 batch id 262 loss 1.5875790119171143 train acc 0.5116292938931297\n",
            "epoch 6 batch id 263 loss 1.570583701133728 train acc 0.5118821292775665\n",
            "epoch 6 batch id 264 loss 1.899350881576538 train acc 0.512014678030303\n",
            "epoch 6 batch id 265 loss 1.7010165452957153 train acc 0.512441037735849\n",
            "epoch 6 batch id 266 loss 1.8503895998001099 train acc 0.5122180451127819\n",
            "epoch 6 batch id 267 loss 1.734088659286499 train acc 0.5125819288389513\n",
            "epoch 6 batch id 268 loss 2.206655263900757 train acc 0.5124183768656716\n",
            "epoch 6 batch id 269 loss 1.660503625869751 train acc 0.5128368959107806\n",
            "epoch 6 batch id 270 loss 2.0047800540924072 train acc 0.5126157407407408\n",
            "epoch 6 batch id 271 loss 1.8823729753494263 train acc 0.5125691881918819\n",
            "epoch 6 batch id 272 loss 1.7815697193145752 train acc 0.5126378676470589\n",
            "epoch 6 batch id 273 loss 1.889251470565796 train acc 0.5127632783882784\n",
            "epoch 6 batch id 274 loss 1.8934600353240967 train acc 0.512716697080292\n",
            "epoch 6 batch id 275 loss 1.9256327152252197 train acc 0.5125568181818182\n",
            "epoch 6 batch id 276 loss 2.163637161254883 train acc 0.5123980978260869\n",
            "epoch 6 batch id 277 loss 1.8364741802215576 train acc 0.5122405234657039\n",
            "epoch 6 batch id 278 loss 2.0341532230377197 train acc 0.5121964928057554\n",
            "epoch 6 batch id 279 loss 1.9456439018249512 train acc 0.5120967741935484\n",
            "epoch 6 batch id 280 loss 1.8006446361541748 train acc 0.5122767857142857\n",
            "epoch 6 batch id 281 loss 1.6487374305725098 train acc 0.5123999110320284\n",
            "epoch 6 batch id 282 loss 1.6995443105697632 train acc 0.5125775709219859\n",
            "epoch 6 batch id 283 loss 1.5084426403045654 train acc 0.5126987632508834\n",
            "epoch 6 batch id 284 loss 2.1513588428497314 train acc 0.5127090669014085\n",
            "epoch 6 batch id 285 loss 1.8598051071166992 train acc 0.5128289473684211\n",
            "epoch 6 batch id 286 loss 1.7082397937774658 train acc 0.5130026223776224\n",
            "epoch 6 batch id 287 loss 1.757773756980896 train acc 0.5131206445993032\n",
            "epoch 6 batch id 288 loss 1.9253015518188477 train acc 0.5131293402777778\n",
            "epoch 6 batch id 289 loss 1.6275138854980469 train acc 0.5134623702422145\n",
            "epoch 6 batch id 290 loss 1.8201292753219604 train acc 0.5135775862068965\n",
            "epoch 6 batch id 291 loss 1.9935529232025146 train acc 0.5135309278350515\n",
            "epoch 6 batch id 292 loss 1.8898632526397705 train acc 0.513591609589041\n",
            "epoch 6 batch id 293 loss 2.160818099975586 train acc 0.5134918941979523\n",
            "epoch 6 batch id 294 loss 1.6275769472122192 train acc 0.5137117346938775\n",
            "epoch 6 batch id 295 loss 1.7649452686309814 train acc 0.5139830508474577\n",
            "epoch 6 batch id 296 loss 1.6935685873031616 train acc 0.5141997466216216\n",
            "epoch 6 batch id 297 loss 1.994480848312378 train acc 0.5140467171717171\n",
            "epoch 6 batch id 298 loss 1.658748984336853 train acc 0.514419043624161\n",
            "epoch 6 batch id 299 loss 1.9727271795272827 train acc 0.5144230769230769\n",
            "epoch 6 batch id 300 loss 1.8247816562652588 train acc 0.5143229166666666\n",
            "epoch 6 batch id 301 loss 2.0219404697418213 train acc 0.5141196013289037\n",
            "epoch 6 batch id 302 loss 1.8396565914154053 train acc 0.5140211092715232\n",
            "epoch 6 batch id 303 loss 1.562190055847168 train acc 0.5142326732673267\n",
            "epoch 6 batch id 304 loss 1.8331620693206787 train acc 0.5143400493421053\n",
            "epoch 6 batch id 305 loss 1.8891302347183228 train acc 0.5142418032786885\n",
            "epoch 6 batch id 306 loss 1.6760575771331787 train acc 0.5146037581699346\n",
            "epoch 6 batch id 307 loss 1.4928770065307617 train acc 0.5147597719869706\n",
            "epoch 6 batch id 308 loss 1.6455273628234863 train acc 0.5149655032467533\n",
            "epoch 6 batch id 309 loss 1.6744639873504639 train acc 0.5152204692556634\n",
            "epoch 6 batch id 310 loss 2.085732936859131 train acc 0.5152217741935484\n",
            "epoch 6 batch id 311 loss 1.9781482219696045 train acc 0.5151728295819936\n",
            "epoch 6 batch id 312 loss 1.8468434810638428 train acc 0.5152744391025641\n",
            "epoch 6 batch id 313 loss 1.5349485874176025 train acc 0.5154253194888179\n",
            "epoch 6 batch id 314 loss 1.5889935493469238 train acc 0.5158738057324841\n",
            "epoch 6 batch id 315 loss 2.062528133392334 train acc 0.5157242063492063\n",
            "epoch 6 batch id 316 loss 2.1418235301971436 train acc 0.5154272151898734\n",
            "epoch 6 batch id 317 loss 1.7693397998809814 train acc 0.5155264195583596\n",
            "epoch 6 batch id 318 loss 1.7367669343948364 train acc 0.5156741352201258\n",
            "epoch 6 batch id 319 loss 1.7613567113876343 train acc 0.5159188871473355\n",
            "epoch 6 batch id 320 loss 1.9271490573883057 train acc 0.51591796875\n",
            "epoch 6 batch id 321 loss 1.8178640604019165 train acc 0.5158197040498442\n",
            "epoch 6 batch id 322 loss 1.8387082815170288 train acc 0.516110248447205\n",
            "epoch 6 batch id 323 loss 1.862689733505249 train acc 0.5162054953560371\n",
            "epoch 6 batch id 324 loss 2.09458589553833 train acc 0.5162037037037037\n",
            "epoch 6 batch id 325 loss 1.7648770809173584 train acc 0.5163461538461539\n",
            "epoch 6 batch id 326 loss 1.7827296257019043 train acc 0.5162960122699386\n",
            "epoch 6 batch id 327 loss 1.9139267206192017 train acc 0.5161983944954128\n",
            "epoch 6 batch id 328 loss 1.4951494932174683 train acc 0.5163871951219512\n",
            "epoch 6 batch id 329 loss 1.671631097793579 train acc 0.5167648176291794\n",
            "epoch 6 batch id 330 loss 1.9488533735275269 train acc 0.5167613636363636\n",
            "epoch 6 batch id 331 loss 1.4729225635528564 train acc 0.5171355740181269\n",
            "epoch 6 batch id 332 loss 1.7066066265106201 train acc 0.5172722138554217\n",
            "epoch 6 batch id 333 loss 1.8281657695770264 train acc 0.5173611111111112\n",
            "epoch 6 batch id 334 loss 2.0861752033233643 train acc 0.5171220059880239\n",
            "epoch 6 batch id 335 loss 1.5915167331695557 train acc 0.5172574626865671\n",
            "epoch 6 batch id 336 loss 1.7711888551712036 train acc 0.5175316220238095\n",
            "epoch 6 batch id 337 loss 1.7555664777755737 train acc 0.5175259643916914\n",
            "epoch 6 batch id 338 loss 1.8643672466278076 train acc 0.5177514792899408\n",
            "epoch 6 batch id 339 loss 1.6879956722259521 train acc 0.5179756637168141\n",
            "epoch 6 batch id 340 loss 1.5808918476104736 train acc 0.5181066176470588\n",
            "epoch 6 batch id 341 loss 2.1929211616516113 train acc 0.5176869501466276\n",
            "epoch 6 batch id 342 loss 1.9236232042312622 train acc 0.5178636695906432\n",
            "epoch 6 batch id 343 loss 1.916357159614563 train acc 0.5177204810495627\n",
            "epoch 6 batch id 344 loss 1.5480023622512817 train acc 0.5178506540697675\n",
            "epoch 6 batch id 345 loss 2.0418860912323 train acc 0.5175271739130435\n",
            "epoch 6 batch id 346 loss 2.0852789878845215 train acc 0.5172507225433526\n",
            "epoch 6 batch id 347 loss 1.6535146236419678 train acc 0.517471181556196\n",
            "epoch 6 batch id 348 loss 2.1930549144744873 train acc 0.5172413793103449\n",
            "epoch 6 batch id 349 loss 2.0294690132141113 train acc 0.517102435530086\n",
            "epoch 6 batch id 350 loss 1.7034090757369995 train acc 0.5172767857142857\n",
            "epoch 6 batch id 351 loss 1.6700422763824463 train acc 0.5174946581196581\n",
            "epoch 6 batch id 352 loss 2.445286750793457 train acc 0.5170010653409091\n",
            "epoch 6 batch id 353 loss 1.6272587776184082 train acc 0.5173070113314447\n",
            "epoch 6 batch id 354 loss 1.9155001640319824 train acc 0.5173022598870056\n",
            "epoch 6 batch id 355 loss 1.6909624338150024 train acc 0.5175616197183098\n",
            "epoch 6 batch id 356 loss 1.6674408912658691 train acc 0.5177756320224719\n",
            "epoch 6 batch id 357 loss 1.993251085281372 train acc 0.5176820728291317\n",
            "epoch 6 batch id 358 loss 1.6152966022491455 train acc 0.5177199720670391\n",
            "epoch 6 batch id 359 loss 1.8450617790222168 train acc 0.5177576601671309\n",
            "epoch 6 batch id 360 loss 1.816108226776123 train acc 0.5179253472222223\n",
            "epoch 6 batch id 361 loss 1.9038136005401611 train acc 0.5179189750692521\n",
            "epoch 6 batch id 362 loss 1.903481364250183 train acc 0.5179989640883977\n",
            "epoch 6 batch id 363 loss 1.8529325723648071 train acc 0.5179063360881543\n",
            "epoch 6 batch id 364 loss 1.5851341485977173 train acc 0.5179429945054945\n",
            "epoch 6 batch id 365 loss 2.125215768814087 train acc 0.517722602739726\n",
            "epoch 6 batch id 366 loss 1.9601672887802124 train acc 0.517973019125683\n",
            "epoch 6 batch id 367 loss 1.5548843145370483 train acc 0.5182220708446866\n",
            "epoch 6 batch id 368 loss 1.7964917421340942 train acc 0.518172554347826\n",
            "epoch 6 batch id 369 loss 1.3564859628677368 train acc 0.518504403794038\n",
            "epoch 6 batch id 370 loss 1.719231367111206 train acc 0.518581081081081\n",
            "epoch 6 batch id 371 loss 1.5907009840011597 train acc 0.518741576819407\n",
            "epoch 6 batch id 372 loss 1.6416678428649902 train acc 0.5189432123655914\n",
            "epoch 6 batch id 373 loss 2.220456123352051 train acc 0.5188086461126006\n",
            "epoch 6 batch id 374 loss 1.6664155721664429 train acc 0.5190508021390374\n",
            "epoch 6 batch id 375 loss 2.064293622970581 train acc 0.5188333333333334\n",
            "epoch 6 batch id 376 loss 1.5121678113937378 train acc 0.5189494680851063\n",
            "epoch 6 batch id 377 loss 1.7698971033096313 train acc 0.5190649867374005\n",
            "epoch 6 batch id 378 loss 1.648288369178772 train acc 0.5193039021164021\n",
            "epoch 6 batch id 379 loss 1.7859104871749878 train acc 0.5193766490765171\n",
            "epoch 6 batch id 380 loss 1.8089758157730103 train acc 0.5193667763157894\n",
            "epoch 6 batch id 381 loss 1.470317006111145 train acc 0.5195209973753281\n",
            "epoch 6 batch id 382 loss 1.5193469524383545 train acc 0.5197153141361257\n",
            "epoch 6 batch id 383 loss 1.5510612726211548 train acc 0.519949412532637\n",
            "epoch 6 batch id 384 loss 2.0867698192596436 train acc 0.5198567708333334\n",
            "epoch 6 batch id 385 loss 1.768407940864563 train acc 0.5200892857142857\n",
            "epoch 6 batch id 386 loss 1.4863709211349487 train acc 0.5202396373056994\n",
            "epoch 6 batch id 387 loss 1.63252592086792 train acc 0.5203892118863049\n",
            "epoch 6 batch id 388 loss 1.7134438753128052 train acc 0.5204172036082474\n",
            "epoch 6 batch id 389 loss 2.1978633403778076 train acc 0.5202442159383034\n",
            "epoch 6 batch id 390 loss 2.010504961013794 train acc 0.5201121794871795\n",
            "epoch 6 batch id 391 loss 1.842294454574585 train acc 0.5201406649616368\n",
            "epoch 6 batch id 392 loss 1.4861730337142944 train acc 0.5202885841836735\n",
            "epoch 6 batch id 393 loss 1.8941267728805542 train acc 0.520316475826972\n",
            "epoch 6 batch id 394 loss 1.901368260383606 train acc 0.5202649111675127\n",
            "epoch 6 batch id 395 loss 1.5990424156188965 train acc 0.5204113924050633\n",
            "epoch 6 batch id 396 loss 1.5435545444488525 train acc 0.5206755050505051\n",
            "epoch 6 batch id 397 loss 1.8298629522323608 train acc 0.5207021410579346\n",
            "epoch 6 batch id 398 loss 1.4775668382644653 train acc 0.5209641959798995\n",
            "epoch 6 batch id 399 loss 1.8004509210586548 train acc 0.5211857769423559\n",
            "epoch 6 batch id 400 loss 1.7127662897109985 train acc 0.5212890625\n",
            "epoch 6 batch id 401 loss 1.4323582649230957 train acc 0.5215866583541147\n",
            "epoch 6 batch id 402 loss 1.9147875308990479 train acc 0.521610696517413\n",
            "epoch 6 batch id 403 loss 1.7615547180175781 train acc 0.5216733870967742\n",
            "epoch 6 batch id 404 loss 1.7406812906265259 train acc 0.5219291460396039\n",
            "epoch 6 batch id 405 loss 1.8370881080627441 train acc 0.5219521604938272\n",
            "epoch 6 batch id 406 loss 1.8465080261230469 train acc 0.5217826354679803\n",
            "epoch 6 batch id 407 loss 1.5862854719161987 train acc 0.5218826781326781\n",
            "epoch 6 batch id 408 loss 1.3471362590789795 train acc 0.522250306372549\n",
            "epoch 6 batch id 409 loss 1.4426801204681396 train acc 0.5225015281173594\n",
            "epoch 6 batch id 410 loss 1.60836923122406 train acc 0.5226371951219512\n",
            "epoch 6 batch id 411 loss 1.4765745401382446 train acc 0.5228862530413625\n",
            "epoch 6 batch id 412 loss 1.9295778274536133 train acc 0.5229065533980582\n",
            "epoch 6 batch id 413 loss 1.7408713102340698 train acc 0.5228889225181598\n",
            "epoch 6 batch id 414 loss 1.8200209140777588 train acc 0.5230978260869565\n",
            "epoch 6 batch id 415 loss 1.5136842727661133 train acc 0.5233810240963855\n",
            "epoch 6 batch id 416 loss 1.5597869157791138 train acc 0.5235877403846154\n",
            "epoch 6 batch id 417 loss 2.1053755283355713 train acc 0.5236061151079137\n",
            "epoch 6 batch id 418 loss 2.0439419746398926 train acc 0.5235496411483254\n",
            "epoch 6 batch id 419 loss 1.9469152688980103 train acc 0.5236053102625299\n",
            "epoch 6 batch id 420 loss 1.6371384859085083 train acc 0.5236607142857143\n",
            "epoch 6 batch id 421 loss 2.044431447982788 train acc 0.5236787410926366\n",
            "epoch 6 batch id 422 loss 1.6997002363204956 train acc 0.5236226303317536\n",
            "epoch 6 batch id 423 loss 1.8013514280319214 train acc 0.5236776004728132\n",
            "epoch 6 batch id 424 loss 1.9814560413360596 train acc 0.5235849056603774\n",
            "epoch 6 batch id 425 loss 1.8459322452545166 train acc 0.5235661764705882\n",
            "epoch 6 batch id 426 loss 2.05745530128479 train acc 0.5234375\n",
            "epoch 6 batch id 427 loss 1.620789647102356 train acc 0.5236387587822015\n",
            "epoch 6 batch id 428 loss 1.786637544631958 train acc 0.5236930490654206\n",
            "epoch 6 batch id 429 loss 1.7180020809173584 train acc 0.5237835081585082\n",
            "epoch 6 batch id 430 loss 1.8419666290283203 train acc 0.5237645348837209\n",
            "epoch 6 batch id 431 loss 1.9559924602508545 train acc 0.5237093967517401\n",
            "epoch 6 batch id 432 loss 1.5914394855499268 train acc 0.5237991898148148\n",
            "epoch 6 batch id 433 loss 1.861794114112854 train acc 0.523780311778291\n",
            "epoch 6 batch id 434 loss 1.8220328092575073 train acc 0.5239415322580645\n",
            "epoch 6 batch id 435 loss 1.9625349044799805 train acc 0.5239583333333333\n",
            "epoch 6 batch id 436 loss 1.8381565809249878 train acc 0.5239750573394495\n",
            "epoch 6 batch id 437 loss 1.9383817911148071 train acc 0.5238129290617849\n",
            "epoch 6 batch id 438 loss 1.6510263681411743 train acc 0.5239369292237442\n",
            "epoch 6 batch id 439 loss 2.403510093688965 train acc 0.5235976651480638\n",
            "epoch 6 batch id 440 loss 1.978761076927185 train acc 0.5236150568181818\n",
            "epoch 6 batch id 441 loss 1.934394121170044 train acc 0.5234552154195011\n",
            "epoch 6 batch id 442 loss 1.9112545251846313 train acc 0.5232607466063348\n",
            "epoch 6 batch id 443 loss 1.9480175971984863 train acc 0.5231024266365688\n",
            "epoch 6 batch id 444 loss 1.7359809875488281 train acc 0.5231911599099099\n",
            "epoch 6 batch id 445 loss 1.8389755487442017 train acc 0.5232443820224719\n",
            "epoch 6 batch id 446 loss 1.6319096088409424 train acc 0.5231572309417041\n",
            "epoch 6 batch id 447 loss 1.8628309965133667 train acc 0.5232452460850112\n",
            "epoch 6 batch id 448 loss 1.6562325954437256 train acc 0.5234026227678571\n",
            "epoch 6 batch id 449 loss 1.535345196723938 train acc 0.5234548997772829\n",
            "epoch 6 batch id 450 loss 1.6820939779281616 train acc 0.5235416666666667\n",
            "epoch 6 batch id 451 loss 1.7994012832641602 train acc 0.523454822616408\n",
            "epoch 6 batch id 452 loss 1.4642332792282104 train acc 0.5236794800884956\n",
            "epoch 6 batch id 453 loss 2.1313652992248535 train acc 0.5234547461368654\n",
            "epoch 6 batch id 454 loss 1.5397958755493164 train acc 0.5233686674008811\n",
            "epoch 6 batch id 455 loss 1.585312008857727 train acc 0.5235576923076923\n",
            "epoch 6 batch id 456 loss 1.3443714380264282 train acc 0.5238829495614035\n",
            "epoch 6 batch id 457 loss 1.5868732929229736 train acc 0.5241042122538293\n",
            "epoch 6 batch id 458 loss 1.7107679843902588 train acc 0.5241539301310044\n",
            "epoch 6 batch id 459 loss 1.940062403678894 train acc 0.5239651416122004\n",
            "epoch 6 batch id 460 loss 1.8336100578308105 train acc 0.5240828804347826\n",
            "epoch 6 batch id 461 loss 1.3230018615722656 train acc 0.524267895878525\n",
            "epoch 6 batch id 462 loss 1.7931541204452515 train acc 0.5242830086580087\n",
            "epoch 6 batch id 463 loss 1.835736870765686 train acc 0.5241968142548596\n",
            "epoch 6 batch id 464 loss 1.757851481437683 train acc 0.5241446659482759\n",
            "epoch 6 batch id 465 loss 1.454821228981018 train acc 0.5244959677419355\n",
            "epoch 6 batch id 466 loss 1.6870031356811523 train acc 0.5245104613733905\n",
            "epoch 6 batch id 467 loss 1.5671236515045166 train acc 0.5246921841541756\n",
            "epoch 6 batch id 468 loss 1.806606650352478 train acc 0.5247729700854701\n",
            "epoch 6 batch id 469 loss 2.0047852993011475 train acc 0.5247201492537313\n",
            "epoch 6 batch id 470 loss 1.9482256174087524 train acc 0.5247672872340425\n",
            "epoch 6 batch id 471 loss 1.730546236038208 train acc 0.5248142250530785\n",
            "epoch 6 batch id 472 loss 1.4372423887252808 train acc 0.5249933792372882\n",
            "epoch 6 batch id 473 loss 1.4889013767242432 train acc 0.5251387420718816\n",
            "epoch 6 batch id 474 loss 2.0241153240203857 train acc 0.5250527426160337\n",
            "epoch 6 batch id 475 loss 1.9576574563980103 train acc 0.5251644736842105\n",
            "epoch 6 batch id 476 loss 1.5749292373657227 train acc 0.5253085609243697\n",
            "epoch 6 batch id 477 loss 1.828494906425476 train acc 0.5253865303983228\n",
            "epoch 6 batch id 478 loss 1.5292495489120483 train acc 0.5254968619246861\n",
            "epoch 6 batch id 479 loss 1.8232417106628418 train acc 0.5254762526096033\n",
            "epoch 6 batch id 480 loss 1.6605530977249146 train acc 0.5254557291666667\n",
            "epoch 6 batch id 481 loss 1.3621790409088135 train acc 0.5257276507276507\n",
            "epoch 6 batch id 482 loss 1.629534125328064 train acc 0.5259336099585062\n",
            "epoch 6 batch id 483 loss 1.8313542604446411 train acc 0.5259446169772257\n",
            "epoch 6 batch id 484 loss 1.8368903398513794 train acc 0.5259555785123967\n",
            "epoch 6 batch id 485 loss 2.0536651611328125 train acc 0.5258376288659794\n",
            "epoch 6 batch id 486 loss 1.657349705696106 train acc 0.5260416666666666\n",
            "epoch 6 batch id 487 loss 1.7385469675064087 train acc 0.5260523613963038\n",
            "epoch 6 batch id 488 loss 1.6572291851043701 train acc 0.526063012295082\n",
            "epoch 6 batch id 489 loss 1.6661549806594849 train acc 0.5261694785276073\n",
            "epoch 6 batch id 490 loss 1.8220056295394897 train acc 0.5262117346938775\n",
            "epoch 6 batch id 491 loss 1.2673728466033936 train acc 0.5265084012219959\n",
            "epoch 6 batch id 492 loss 1.9027068614959717 train acc 0.5265180386178862\n",
            "epoch 6 batch id 493 loss 1.825308918952942 train acc 0.5265276369168357\n",
            "epoch 6 batch id 494 loss 1.7066125869750977 train acc 0.5265371963562753\n",
            "epoch 6 batch id 495 loss 1.6953321695327759 train acc 0.5266414141414142\n",
            "epoch 6 batch id 496 loss 1.5585912466049194 train acc 0.5267137096774194\n",
            "epoch 6 batch id 497 loss 1.808205246925354 train acc 0.5267542756539235\n",
            "epoch 6 batch id 498 loss 1.557953119277954 train acc 0.5267946787148594\n",
            "epoch 6 batch id 499 loss 1.8726047277450562 train acc 0.5268349198396793\n",
            "epoch 6 batch id 500 loss 1.9356532096862793 train acc 0.5268125\n",
            "epoch 6 batch id 501 loss 1.9664274454116821 train acc 0.5267589820359282\n",
            "epoch 6 batch id 502 loss 1.7220759391784668 train acc 0.5268924302788844\n",
            "epoch 6 batch id 503 loss 1.6273102760314941 train acc 0.5268079025844931\n",
            "epoch 6 batch id 504 loss 2.0482559204101562 train acc 0.5267547123015873\n",
            "epoch 6 batch id 505 loss 1.7124767303466797 train acc 0.5267945544554455\n",
            "epoch 6 batch id 506 loss 1.686543583869934 train acc 0.5268651185770751\n",
            "epoch 6 batch id 507 loss 1.9982259273529053 train acc 0.5268121301775148\n",
            "epoch 6 batch id 508 loss 1.4500994682312012 train acc 0.5270361712598425\n",
            "epoch 6 batch id 509 loss 1.8898903131484985 train acc 0.5269523575638507\n",
            "epoch 6 batch id 510 loss 1.501573085784912 train acc 0.5272058823529412\n",
            "epoch 6 batch id 511 loss 1.8057997226715088 train acc 0.5271992358587271\n",
            "epoch 6 train acc 0.5271992358587271\n",
            "epoch 6 test acc 0.3877766927083333\n",
            "epoch 7 batch id 1 loss 1.602690577507019 train acc 0.5625\n",
            "epoch 7 batch id 2 loss 1.7286527156829834 train acc 0.5390625\n",
            "epoch 7 batch id 3 loss 1.7947419881820679 train acc 0.5572916666666666\n",
            "epoch 7 batch id 4 loss 1.634351372718811 train acc 0.578125\n",
            "epoch 7 batch id 5 loss 1.6738685369491577 train acc 0.575\n",
            "epoch 7 batch id 6 loss 1.7197465896606445 train acc 0.5833333333333334\n",
            "epoch 7 batch id 7 loss 1.6043362617492676 train acc 0.5892857142857143\n",
            "epoch 7 batch id 8 loss 1.9503026008605957 train acc 0.568359375\n",
            "epoch 7 batch id 9 loss 1.3970435857772827 train acc 0.5815972222222222\n",
            "epoch 7 batch id 10 loss 1.5840022563934326 train acc 0.5921875\n",
            "epoch 7 batch id 11 loss 1.6550538539886475 train acc 0.5923295454545454\n",
            "epoch 7 batch id 12 loss 1.4667507410049438 train acc 0.5950520833333334\n",
            "epoch 7 batch id 13 loss 1.6665079593658447 train acc 0.5949519230769231\n",
            "epoch 7 batch id 14 loss 1.8216484785079956 train acc 0.59375\n",
            "epoch 7 batch id 15 loss 1.5789790153503418 train acc 0.5916666666666667\n",
            "epoch 7 batch id 16 loss 1.9098272323608398 train acc 0.5869140625\n",
            "epoch 7 batch id 17 loss 1.612772822380066 train acc 0.5882352941176471\n",
            "epoch 7 batch id 18 loss 1.367045521736145 train acc 0.5894097222222222\n",
            "epoch 7 batch id 19 loss 1.9289917945861816 train acc 0.5855263157894737\n",
            "epoch 7 batch id 20 loss 1.8854848146438599 train acc 0.57890625\n",
            "epoch 7 batch id 21 loss 1.431046485900879 train acc 0.5803571428571429\n",
            "epoch 7 batch id 22 loss 1.4967855215072632 train acc 0.5816761363636364\n",
            "epoch 7 batch id 23 loss 1.512740135192871 train acc 0.5815217391304348\n",
            "epoch 7 batch id 24 loss 1.9250521659851074 train acc 0.5807291666666666\n",
            "epoch 7 batch id 25 loss 1.9045429229736328 train acc 0.579375\n",
            "epoch 7 batch id 26 loss 1.8683521747589111 train acc 0.5775240384615384\n",
            "epoch 7 batch id 27 loss 1.4080356359481812 train acc 0.5827546296296297\n",
            "epoch 7 batch id 28 loss 1.9435383081436157 train acc 0.5786830357142857\n",
            "epoch 7 batch id 29 loss 1.5572919845581055 train acc 0.578125\n",
            "epoch 7 batch id 30 loss 1.4287993907928467 train acc 0.5802083333333333\n",
            "epoch 7 batch id 31 loss 2.0948877334594727 train acc 0.5751008064516129\n",
            "epoch 7 batch id 32 loss 1.4747060537338257 train acc 0.57763671875\n",
            "epoch 7 batch id 33 loss 1.8222788572311401 train acc 0.5748106060606061\n",
            "epoch 7 batch id 34 loss 1.7511751651763916 train acc 0.5735294117647058\n",
            "epoch 7 batch id 35 loss 1.8030930757522583 train acc 0.5745535714285714\n",
            "epoch 7 batch id 36 loss 1.6309752464294434 train acc 0.57421875\n",
            "epoch 7 batch id 37 loss 1.5866010189056396 train acc 0.573902027027027\n",
            "epoch 7 batch id 38 loss 1.7022799253463745 train acc 0.5723684210526315\n",
            "epoch 7 batch id 39 loss 1.5356509685516357 train acc 0.5737179487179487\n",
            "epoch 7 batch id 40 loss 1.4061660766601562 train acc 0.5765625\n",
            "epoch 7 batch id 41 loss 1.853874921798706 train acc 0.5754573170731707\n",
            "epoch 7 batch id 42 loss 1.7996578216552734 train acc 0.5736607142857143\n",
            "epoch 7 batch id 43 loss 1.7918766736984253 train acc 0.5704941860465116\n",
            "epoch 7 batch id 44 loss 1.7367136478424072 train acc 0.5685369318181818\n",
            "epoch 7 batch id 45 loss 1.5300747156143188 train acc 0.5697916666666667\n",
            "epoch 7 batch id 46 loss 1.7898485660552979 train acc 0.5672554347826086\n",
            "epoch 7 batch id 47 loss 1.5007059574127197 train acc 0.5674867021276596\n",
            "epoch 7 batch id 48 loss 1.8953478336334229 train acc 0.5654296875\n",
            "epoch 7 batch id 49 loss 1.4540514945983887 train acc 0.5656887755102041\n",
            "epoch 7 batch id 50 loss 1.1058682203292847 train acc 0.5690625\n",
            "epoch 7 batch id 51 loss 1.6203492879867554 train acc 0.5689338235294118\n",
            "epoch 7 batch id 52 loss 1.875606894493103 train acc 0.5685096153846154\n",
            "epoch 7 batch id 53 loss 1.7622140645980835 train acc 0.5678066037735849\n",
            "epoch 7 batch id 54 loss 1.520465612411499 train acc 0.5691550925925926\n",
            "epoch 7 batch id 55 loss 1.861961007118225 train acc 0.5678977272727272\n",
            "epoch 7 batch id 56 loss 1.2831264734268188 train acc 0.5691964285714286\n",
            "epoch 7 batch id 57 loss 1.5765750408172607 train acc 0.569078947368421\n",
            "epoch 7 batch id 58 loss 1.3892638683319092 train acc 0.5703125\n",
            "epoch 7 batch id 59 loss 1.669446587562561 train acc 0.5709745762711864\n",
            "epoch 7 batch id 60 loss 1.8720322847366333 train acc 0.5703125\n",
            "epoch 7 batch id 61 loss 1.6475732326507568 train acc 0.5706967213114754\n",
            "epoch 7 batch id 62 loss 1.716176152229309 train acc 0.5705645161290323\n",
            "epoch 7 batch id 63 loss 1.669208288192749 train acc 0.5704365079365079\n",
            "epoch 7 batch id 64 loss 1.5447710752487183 train acc 0.57080078125\n",
            "epoch 7 batch id 65 loss 1.9435455799102783 train acc 0.5699519230769231\n",
            "epoch 7 batch id 66 loss 1.2253684997558594 train acc 0.5717329545454546\n",
            "epoch 7 batch id 67 loss 2.0117874145507812 train acc 0.570429104477612\n",
            "epoch 7 batch id 68 loss 1.5909605026245117 train acc 0.5705422794117647\n",
            "epoch 7 batch id 69 loss 1.720295786857605 train acc 0.5690670289855072\n",
            "epoch 7 batch id 70 loss 1.8271580934524536 train acc 0.5676339285714286\n",
            "epoch 7 batch id 71 loss 1.7475265264511108 train acc 0.5682218309859155\n",
            "epoch 7 batch id 72 loss 1.879580020904541 train acc 0.5685763888888888\n",
            "epoch 7 batch id 73 loss 1.8149081468582153 train acc 0.5680650684931506\n",
            "epoch 7 batch id 74 loss 1.7564690113067627 train acc 0.5682010135135135\n",
            "epoch 7 batch id 75 loss 1.8106119632720947 train acc 0.5675\n",
            "epoch 7 batch id 76 loss 1.3460863828659058 train acc 0.5686677631578947\n",
            "epoch 7 batch id 77 loss 1.6746666431427002 train acc 0.567573051948052\n",
            "epoch 7 batch id 78 loss 1.5601727962493896 train acc 0.5677083333333334\n",
            "epoch 7 batch id 79 loss 1.6501989364624023 train acc 0.567246835443038\n",
            "epoch 7 batch id 80 loss 1.5430656671524048 train acc 0.567578125\n",
            "epoch 7 batch id 81 loss 2.0872838497161865 train acc 0.5671296296296297\n",
            "epoch 7 batch id 82 loss 1.552382230758667 train acc 0.5676448170731707\n",
            "epoch 7 batch id 83 loss 1.753688097000122 train acc 0.567394578313253\n",
            "epoch 7 batch id 84 loss 1.3216831684112549 train acc 0.5684523809523809\n",
            "epoch 7 batch id 85 loss 1.592382788658142 train acc 0.56875\n",
            "epoch 7 batch id 86 loss 1.685889482498169 train acc 0.5686773255813954\n",
            "epoch 7 batch id 87 loss 1.6442451477050781 train acc 0.5689655172413793\n",
            "epoch 7 batch id 88 loss 1.7720094919204712 train acc 0.5696022727272727\n",
            "epoch 7 batch id 89 loss 1.9217792749404907 train acc 0.5691713483146067\n",
            "epoch 7 batch id 90 loss 2.0272483825683594 train acc 0.56875\n",
            "epoch 7 batch id 91 loss 1.5913578271865845 train acc 0.5690247252747253\n",
            "epoch 7 batch id 92 loss 1.8980504274368286 train acc 0.5684442934782609\n",
            "epoch 7 batch id 93 loss 1.2425347566604614 train acc 0.5695564516129032\n",
            "epoch 7 batch id 94 loss 1.4409830570220947 train acc 0.5701462765957447\n",
            "epoch 7 batch id 95 loss 1.4659227132797241 train acc 0.5708881578947368\n",
            "epoch 7 batch id 96 loss 1.8973846435546875 train acc 0.5711263020833334\n",
            "epoch 7 batch id 97 loss 1.854370355606079 train acc 0.5708762886597938\n",
            "epoch 7 batch id 98 loss 1.3812388181686401 train acc 0.5712691326530612\n",
            "epoch 7 batch id 99 loss 1.5863670110702515 train acc 0.5716540404040404\n",
            "epoch 7 batch id 100 loss 1.718796968460083 train acc 0.57140625\n",
            "epoch 7 batch id 101 loss 1.5322771072387695 train acc 0.5720915841584159\n",
            "epoch 7 batch id 102 loss 1.5134162902832031 train acc 0.5729166666666666\n",
            "epoch 7 batch id 103 loss 1.783537745475769 train acc 0.5726638349514563\n",
            "epoch 7 batch id 104 loss 1.9292585849761963 train acc 0.5721153846153846\n",
            "epoch 7 batch id 105 loss 1.6054407358169556 train acc 0.5721726190476191\n",
            "epoch 7 batch id 106 loss 1.398718237876892 train acc 0.5731132075471698\n",
            "epoch 7 batch id 107 loss 1.865778923034668 train acc 0.5733060747663551\n",
            "epoch 7 batch id 108 loss 1.5591459274291992 train acc 0.5736400462962963\n",
            "epoch 7 batch id 109 loss 1.4889247417449951 train acc 0.5736811926605505\n",
            "epoch 7 batch id 110 loss 1.426657795906067 train acc 0.5741477272727272\n",
            "epoch 7 batch id 111 loss 1.7591506242752075 train acc 0.5743243243243243\n",
            "epoch 7 batch id 112 loss 1.381094217300415 train acc 0.5747767857142857\n",
            "epoch 7 batch id 113 loss 1.6430904865264893 train acc 0.5752212389380531\n",
            "epoch 7 batch id 114 loss 1.4817349910736084 train acc 0.5763432017543859\n",
            "epoch 7 batch id 115 loss 1.664815902709961 train acc 0.5766304347826087\n",
            "epoch 7 batch id 116 loss 1.9173330068588257 train acc 0.5758351293103449\n",
            "epoch 7 batch id 117 loss 1.2937744855880737 train acc 0.5769230769230769\n",
            "epoch 7 batch id 118 loss 1.165473461151123 train acc 0.5779925847457628\n",
            "epoch 7 batch id 119 loss 1.556267261505127 train acc 0.5782563025210085\n",
            "epoch 7 batch id 120 loss 1.6541045904159546 train acc 0.578125\n",
            "epoch 7 batch id 121 loss 1.5063533782958984 train acc 0.57838326446281\n",
            "epoch 7 batch id 122 loss 1.7342170476913452 train acc 0.5779969262295082\n",
            "epoch 7 batch id 123 loss 1.391384243965149 train acc 0.5783790650406504\n",
            "epoch 7 batch id 124 loss 1.7947825193405151 train acc 0.5779989919354839\n",
            "epoch 7 batch id 125 loss 1.395307183265686 train acc 0.57825\n",
            "epoch 7 batch id 126 loss 1.418629765510559 train acc 0.5787450396825397\n",
            "epoch 7 batch id 127 loss 1.6010301113128662 train acc 0.578986220472441\n",
            "epoch 7 batch id 128 loss 1.825442910194397 train acc 0.57861328125\n",
            "epoch 7 batch id 129 loss 1.377225637435913 train acc 0.5792151162790697\n",
            "epoch 7 batch id 130 loss 1.5940653085708618 train acc 0.5792067307692308\n",
            "epoch 7 batch id 131 loss 1.2577967643737793 train acc 0.579675572519084\n",
            "epoch 7 batch id 132 loss 1.9217805862426758 train acc 0.5787168560606061\n",
            "epoch 7 batch id 133 loss 1.3878226280212402 train acc 0.5791823308270677\n",
            "epoch 7 batch id 134 loss 1.6262712478637695 train acc 0.5790578358208955\n",
            "epoch 7 batch id 135 loss 1.4902191162109375 train acc 0.5793981481481482\n",
            "epoch 7 batch id 136 loss 1.471652865409851 train acc 0.5799632352941176\n",
            "epoch 7 batch id 137 loss 1.968627691268921 train acc 0.5791514598540146\n",
            "epoch 7 batch id 138 loss 1.628786563873291 train acc 0.5793704710144928\n",
            "epoch 7 batch id 139 loss 1.5488499402999878 train acc 0.5794739208633094\n",
            "epoch 7 batch id 140 loss 1.8183636665344238 train acc 0.5786830357142857\n",
            "epoch 7 batch id 141 loss 2.024919271469116 train acc 0.5779033687943262\n",
            "epoch 7 batch id 142 loss 1.718631386756897 train acc 0.5776848591549296\n",
            "epoch 7 batch id 143 loss 1.4659169912338257 train acc 0.5779064685314685\n",
            "epoch 7 batch id 144 loss 1.5503132343292236 train acc 0.5783420138888888\n",
            "epoch 7 batch id 145 loss 1.3184956312179565 train acc 0.578771551724138\n",
            "epoch 7 batch id 146 loss 1.5451804399490356 train acc 0.5789811643835616\n",
            "epoch 7 batch id 147 loss 1.3883521556854248 train acc 0.5792942176870748\n",
            "epoch 7 batch id 148 loss 1.7335000038146973 train acc 0.5788640202702703\n",
            "epoch 7 batch id 149 loss 1.6650052070617676 train acc 0.5785444630872483\n",
            "epoch 7 batch id 150 loss 1.7165048122406006 train acc 0.5783333333333334\n",
            "epoch 7 batch id 151 loss 1.6335489749908447 train acc 0.578125\n",
            "epoch 7 batch id 152 loss 1.429382085800171 train acc 0.5785361842105263\n",
            "epoch 7 batch id 153 loss 1.610094428062439 train acc 0.5783292483660131\n",
            "epoch 7 batch id 154 loss 2.04823637008667 train acc 0.578023538961039\n",
            "epoch 7 batch id 155 loss 1.4134294986724854 train acc 0.5783266129032258\n",
            "epoch 7 batch id 156 loss 1.1882388591766357 train acc 0.5794270833333334\n",
            "epoch 7 batch id 157 loss 1.6182833909988403 train acc 0.5795183121019108\n",
            "epoch 7 batch id 158 loss 1.6738985776901245 train acc 0.5799050632911392\n",
            "epoch 7 batch id 159 loss 1.3908412456512451 train acc 0.5804834905660378\n",
            "epoch 7 batch id 160 loss 1.5383878946304321 train acc 0.58017578125\n",
            "epoch 7 batch id 161 loss 1.764977216720581 train acc 0.5795807453416149\n",
            "epoch 7 batch id 162 loss 1.3843343257904053 train acc 0.5796682098765432\n",
            "epoch 7 batch id 163 loss 1.4946577548980713 train acc 0.5794670245398773\n",
            "epoch 7 batch id 164 loss 1.1712087392807007 train acc 0.5800304878048781\n",
            "epoch 7 batch id 165 loss 1.4858465194702148 train acc 0.5800189393939394\n",
            "epoch 7 batch id 166 loss 1.691455602645874 train acc 0.5799134036144579\n",
            "epoch 7 batch id 167 loss 1.8465420007705688 train acc 0.5798091317365269\n",
            "epoch 7 batch id 168 loss 1.5037204027175903 train acc 0.5799851190476191\n",
            "epoch 7 batch id 169 loss 1.4074150323867798 train acc 0.5803439349112426\n",
            "epoch 7 batch id 170 loss 1.3424491882324219 train acc 0.5806985294117647\n",
            "epoch 7 batch id 171 loss 1.7074594497680664 train acc 0.5806834795321637\n",
            "epoch 7 batch id 172 loss 1.5060029029846191 train acc 0.5813953488372093\n",
            "epoch 7 batch id 173 loss 1.6066131591796875 train acc 0.5812861271676301\n",
            "epoch 7 batch id 174 loss 1.5676629543304443 train acc 0.5816271551724138\n",
            "epoch 7 batch id 175 loss 1.3654109239578247 train acc 0.5822321428571429\n",
            "epoch 7 batch id 176 loss 1.751793622970581 train acc 0.5822088068181818\n",
            "epoch 7 batch id 177 loss 1.6133953332901 train acc 0.5823622881355932\n",
            "epoch 7 batch id 178 loss 1.4247840642929077 train acc 0.5824262640449438\n",
            "epoch 7 batch id 179 loss 1.5244430303573608 train acc 0.5827513966480447\n",
            "epoch 7 batch id 180 loss 2.0484983921051025 train acc 0.58203125\n",
            "epoch 7 batch id 181 loss 1.520640254020691 train acc 0.5821823204419889\n",
            "epoch 7 batch id 182 loss 1.4226391315460205 train acc 0.5826751373626373\n",
            "epoch 7 batch id 183 loss 1.292350172996521 train acc 0.5830771857923497\n",
            "epoch 7 batch id 184 loss 1.426127552986145 train acc 0.5831351902173914\n",
            "epoch 7 batch id 185 loss 1.5859061479568481 train acc 0.5835304054054054\n",
            "epoch 7 batch id 186 loss 1.4534075260162354 train acc 0.5838373655913979\n",
            "epoch 7 batch id 187 loss 1.8079400062561035 train acc 0.5833054812834224\n",
            "epoch 7 batch id 188 loss 1.7903236150741577 train acc 0.5831948138297872\n",
            "epoch 7 batch id 189 loss 1.5245673656463623 train acc 0.5834160052910053\n",
            "epoch 7 batch id 190 loss 1.6571173667907715 train acc 0.5831414473684211\n",
            "epoch 7 batch id 191 loss 1.513730525970459 train acc 0.5831969895287958\n",
            "epoch 7 batch id 192 loss 1.8120375871658325 train acc 0.5830078125\n",
            "epoch 7 batch id 193 loss 2.070774793624878 train acc 0.5827396373056994\n",
            "epoch 7 batch id 194 loss 1.2964800596237183 train acc 0.5833601804123711\n",
            "epoch 7 batch id 195 loss 1.7568373680114746 train acc 0.5832532051282051\n",
            "epoch 7 batch id 196 loss 1.2175753116607666 train acc 0.583625637755102\n",
            "epoch 7 batch id 197 loss 1.822045087814331 train acc 0.5832804568527918\n",
            "epoch 7 batch id 198 loss 1.7570871114730835 train acc 0.5834911616161617\n",
            "epoch 7 batch id 199 loss 1.8243744373321533 train acc 0.5832286432160804\n",
            "epoch 7 batch id 200 loss 1.1653562784194946 train acc 0.583984375\n",
            "epoch 7 batch id 201 loss 1.6391021013259888 train acc 0.584032960199005\n",
            "epoch 7 batch id 202 loss 1.84540855884552 train acc 0.5837716584158416\n",
            "epoch 7 batch id 203 loss 1.5936270952224731 train acc 0.5835129310344828\n",
            "epoch 7 batch id 204 loss 1.7007566690444946 train acc 0.5836397058823529\n",
            "epoch 7 batch id 205 loss 1.6220873594284058 train acc 0.583765243902439\n",
            "epoch 7 batch id 206 loss 1.7778228521347046 train acc 0.5835861650485437\n",
            "epoch 7 batch id 207 loss 1.603649616241455 train acc 0.5836352657004831\n",
            "epoch 7 batch id 208 loss 1.5053378343582153 train acc 0.5840594951923077\n",
            "epoch 7 batch id 209 loss 1.9675507545471191 train acc 0.5838815789473685\n",
            "epoch 7 batch id 210 loss 1.4787462949752808 train acc 0.5835565476190476\n",
            "epoch 7 batch id 211 loss 1.4531632661819458 train acc 0.583752962085308\n",
            "epoch 7 batch id 212 loss 1.3829023838043213 train acc 0.5837264150943396\n",
            "epoch 7 batch id 213 loss 1.776532530784607 train acc 0.5835534037558685\n",
            "epoch 7 batch id 214 loss 1.795857310295105 train acc 0.5833820093457944\n",
            "epoch 7 batch id 215 loss 1.5798170566558838 train acc 0.5835029069767442\n",
            "epoch 7 batch id 216 loss 1.2712124586105347 train acc 0.583984375\n",
            "epoch 7 batch id 217 loss 1.710249423980713 train acc 0.5838133640552995\n",
            "epoch 7 batch id 218 loss 1.8553996086120605 train acc 0.5835005733944955\n",
            "epoch 7 batch id 219 loss 1.51392662525177 train acc 0.5836187214611872\n",
            "epoch 7 batch id 220 loss 1.4546324014663696 train acc 0.5838068181818182\n",
            "epoch 7 batch id 221 loss 1.8936898708343506 train acc 0.5834983031674208\n",
            "epoch 7 batch id 222 loss 1.9336895942687988 train acc 0.5831221846846847\n",
            "epoch 7 batch id 223 loss 1.2518727779388428 train acc 0.5833099775784754\n",
            "epoch 7 batch id 224 loss 1.2957029342651367 train acc 0.5837053571428571\n",
            "epoch 7 batch id 225 loss 1.6157128810882568 train acc 0.5835416666666666\n",
            "epoch 7 batch id 226 loss 1.6316578388214111 train acc 0.5835176991150443\n",
            "epoch 7 batch id 227 loss 1.4478042125701904 train acc 0.5837004405286343\n",
            "epoch 7 batch id 228 loss 1.4968912601470947 train acc 0.5836074561403509\n",
            "epoch 7 batch id 229 loss 1.3640238046646118 train acc 0.5837199781659389\n",
            "epoch 7 batch id 230 loss 1.5352997779846191 train acc 0.5837635869565218\n",
            "epoch 7 batch id 231 loss 1.6003801822662354 train acc 0.5838744588744589\n",
            "epoch 7 batch id 232 loss 1.6457231044769287 train acc 0.5837149784482759\n",
            "epoch 7 batch id 233 loss 1.4931331872940063 train acc 0.5837580472103004\n",
            "epoch 7 batch id 234 loss 1.7853602170944214 train acc 0.5835336538461539\n",
            "epoch 7 batch id 235 loss 1.3065232038497925 train acc 0.5835106382978723\n",
            "epoch 7 batch id 236 loss 1.2841198444366455 train acc 0.5838188559322034\n",
            "epoch 7 batch id 237 loss 1.3589626550674438 train acc 0.5840585443037974\n",
            "epoch 7 batch id 238 loss 1.446414589881897 train acc 0.5842305672268907\n",
            "epoch 7 batch id 239 loss 1.3678210973739624 train acc 0.5845319037656904\n",
            "epoch 7 batch id 240 loss 1.2506097555160522 train acc 0.584765625\n",
            "epoch 7 batch id 241 loss 1.9612375497817993 train acc 0.5845435684647303\n",
            "epoch 7 batch id 242 loss 1.62981379032135 train acc 0.5845170454545454\n",
            "epoch 7 batch id 243 loss 1.336795687675476 train acc 0.5846836419753086\n",
            "epoch 7 batch id 244 loss 1.3595222234725952 train acc 0.5848488729508197\n",
            "epoch 7 batch id 245 loss 1.8554496765136719 train acc 0.5846301020408163\n",
            "epoch 7 batch id 246 loss 1.4630752801895142 train acc 0.584984756097561\n",
            "epoch 7 batch id 247 loss 1.6644172668457031 train acc 0.5850835020242915\n",
            "epoch 7 batch id 248 loss 1.75301992893219 train acc 0.584992439516129\n",
            "epoch 7 batch id 249 loss 2.0603039264678955 train acc 0.5848393574297188\n",
            "epoch 7 batch id 250 loss 1.5135961771011353 train acc 0.58475\n",
            "epoch 7 batch id 251 loss 1.7171776294708252 train acc 0.5847858565737052\n",
            "epoch 7 batch id 252 loss 1.802571415901184 train acc 0.5848834325396826\n",
            "epoch 7 batch id 253 loss 1.3607722520828247 train acc 0.5852272727272727\n",
            "epoch 7 batch id 254 loss 1.6424939632415771 train acc 0.585076279527559\n",
            "epoch 7 batch id 255 loss 1.3403105735778809 train acc 0.5856004901960784\n",
            "epoch 7 batch id 256 loss 1.4948214292526245 train acc 0.585693359375\n",
            "epoch 7 batch id 257 loss 1.4552528858184814 train acc 0.5855423151750972\n",
            "epoch 7 batch id 258 loss 1.2912417650222778 train acc 0.5858769379844961\n",
            "epoch 7 batch id 259 loss 1.5763295888900757 train acc 0.5859073359073359\n",
            "epoch 7 batch id 260 loss 1.5444467067718506 train acc 0.5859975961538462\n",
            "epoch 7 batch id 261 loss 1.5012953281402588 train acc 0.5862068965517241\n",
            "epoch 7 batch id 262 loss 1.7288575172424316 train acc 0.5864742366412213\n",
            "epoch 7 batch id 263 loss 1.647752046585083 train acc 0.5863236692015209\n",
            "epoch 7 batch id 264 loss 1.4099255800247192 train acc 0.5867660984848485\n",
            "epoch 7 batch id 265 loss 1.5339144468307495 train acc 0.5867334905660377\n",
            "epoch 7 batch id 266 loss 1.453433632850647 train acc 0.5868186090225563\n",
            "epoch 7 batch id 267 loss 1.3777095079421997 train acc 0.5867860486891385\n",
            "epoch 7 batch id 268 loss 1.2267420291900635 train acc 0.5869869402985075\n",
            "epoch 7 batch id 269 loss 1.8141690492630005 train acc 0.5866635687732342\n",
            "epoch 7 batch id 270 loss 1.6322249174118042 train acc 0.586574074074074\n",
            "epoch 7 batch id 271 loss 1.538827896118164 train acc 0.5866582103321033\n",
            "epoch 7 batch id 272 loss 1.5794970989227295 train acc 0.5866268382352942\n",
            "epoch 7 batch id 273 loss 1.4385360479354858 train acc 0.5868246336996337\n",
            "epoch 7 batch id 274 loss 1.6437842845916748 train acc 0.5869069343065694\n",
            "epoch 7 batch id 275 loss 1.3871489763259888 train acc 0.5871022727272728\n",
            "epoch 7 batch id 276 loss 1.7771027088165283 train acc 0.5867300724637681\n",
            "epoch 7 batch id 277 loss 1.6873856782913208 train acc 0.5868682310469314\n",
            "epoch 7 batch id 278 loss 1.1123298406600952 train acc 0.5873988309352518\n",
            "epoch 7 batch id 279 loss 1.561468482017517 train acc 0.5875336021505376\n",
            "epoch 7 batch id 280 loss 1.7919634580612183 train acc 0.5873883928571428\n",
            "epoch 7 batch id 281 loss 1.674432396888733 train acc 0.5874666370106761\n",
            "epoch 7 batch id 282 loss 1.4594436883926392 train acc 0.58771054964539\n",
            "epoch 7 batch id 283 loss 1.613039493560791 train acc 0.5877318904593639\n",
            "epoch 7 batch id 284 loss 1.6932610273361206 train acc 0.5877530809859155\n",
            "epoch 7 batch id 285 loss 1.4231973886489868 train acc 0.5878837719298246\n",
            "epoch 7 batch id 286 loss 1.2698936462402344 train acc 0.5882867132867133\n",
            "epoch 7 batch id 287 loss 1.5609921216964722 train acc 0.5883601916376306\n",
            "epoch 7 batch id 288 loss 1.5147478580474854 train acc 0.5884874131944444\n",
            "epoch 7 batch id 289 loss 1.6185563802719116 train acc 0.5883434256055363\n",
            "epoch 7 batch id 290 loss 1.4223803281784058 train acc 0.5883081896551724\n",
            "epoch 7 batch id 291 loss 1.7662190198898315 train acc 0.5881121134020618\n",
            "epoch 7 batch id 292 loss 1.7265626192092896 train acc 0.5881314212328768\n",
            "epoch 7 batch id 293 loss 1.567665696144104 train acc 0.5881505972696246\n",
            "epoch 7 batch id 294 loss 1.6272988319396973 train acc 0.5882227891156463\n",
            "epoch 7 batch id 295 loss 1.8287992477416992 train acc 0.5880826271186441\n",
            "epoch 7 batch id 296 loss 1.1373323202133179 train acc 0.5884712837837838\n",
            "epoch 7 batch id 297 loss 1.7017050981521606 train acc 0.5884364478114478\n",
            "epoch 7 batch id 298 loss 1.316677212715149 train acc 0.5884018456375839\n",
            "epoch 7 batch id 299 loss 1.5039503574371338 train acc 0.5884197324414716\n",
            "epoch 7 batch id 300 loss 1.7820020914077759 train acc 0.5884895833333333\n",
            "epoch 7 batch id 301 loss 1.4068512916564941 train acc 0.5887147009966778\n",
            "epoch 7 batch id 302 loss 1.8245525360107422 train acc 0.5884209437086093\n",
            "epoch 7 batch id 303 loss 1.543392300605774 train acc 0.5883869636963697\n",
            "epoch 7 batch id 304 loss 1.489570140838623 train acc 0.5886615953947368\n",
            "epoch 7 batch id 305 loss 1.6117359399795532 train acc 0.5884733606557377\n",
            "epoch 7 batch id 306 loss 0.9970411658287048 train acc 0.5891544117647058\n",
            "epoch 7 batch id 307 loss 1.374513864517212 train acc 0.5892711726384365\n",
            "epoch 7 batch id 308 loss 1.523328185081482 train acc 0.5892857142857143\n",
            "epoch 7 batch id 309 loss 1.3226271867752075 train acc 0.589502427184466\n",
            "epoch 7 batch id 310 loss 1.545985221862793 train acc 0.5897177419354839\n",
            "epoch 7 batch id 311 loss 1.0236363410949707 train acc 0.5902331189710611\n",
            "epoch 7 batch id 312 loss 1.304091453552246 train acc 0.5905448717948718\n",
            "epoch 7 batch id 313 loss 1.6704349517822266 train acc 0.5906549520766773\n",
            "epoch 7 batch id 314 loss 1.9536982774734497 train acc 0.5903662420382165\n",
            "epoch 7 batch id 315 loss 1.7042107582092285 train acc 0.5904761904761905\n",
            "epoch 7 batch id 316 loss 1.7224671840667725 train acc 0.5904865506329114\n",
            "epoch 7 batch id 317 loss 1.3863651752471924 train acc 0.5905954258675079\n",
            "epoch 7 batch id 318 loss 1.9650126695632935 train acc 0.590310534591195\n",
            "epoch 7 batch id 319 loss 1.5989210605621338 train acc 0.5902723354231975\n",
            "epoch 7 batch id 320 loss 1.686284065246582 train acc 0.590234375\n",
            "epoch 7 batch id 321 loss 1.3658677339553833 train acc 0.5902453271028038\n",
            "epoch 7 batch id 322 loss 1.6175724267959595 train acc 0.5903532608695652\n",
            "epoch 7 batch id 323 loss 1.4127914905548096 train acc 0.5906056501547987\n",
            "epoch 7 batch id 324 loss 1.3900543451309204 train acc 0.5906635802469136\n",
            "epoch 7 batch id 325 loss 1.8194762468338013 train acc 0.5903365384615384\n",
            "epoch 7 batch id 326 loss 1.3162035942077637 train acc 0.5904907975460123\n",
            "epoch 7 batch id 327 loss 1.6698181629180908 train acc 0.5905485474006116\n",
            "epoch 7 batch id 328 loss 1.6267367601394653 train acc 0.5904153963414634\n",
            "epoch 7 batch id 329 loss 1.6546176671981812 train acc 0.5903780395136778\n",
            "epoch 7 batch id 330 loss 1.5679904222488403 train acc 0.5904356060606061\n",
            "epoch 7 batch id 331 loss 1.4101934432983398 train acc 0.5905400302114804\n",
            "epoch 7 batch id 332 loss 1.5499906539916992 train acc 0.5903614457831325\n",
            "epoch 7 batch id 333 loss 1.4055324792861938 train acc 0.5904654654654654\n",
            "epoch 7 batch id 334 loss 1.7408963441848755 train acc 0.5904752994011976\n",
            "epoch 7 batch id 335 loss 1.2342802286148071 train acc 0.5908582089552239\n",
            "epoch 7 batch id 336 loss 1.8047887086868286 train acc 0.5907273065476191\n",
            "epoch 7 batch id 337 loss 1.643351674079895 train acc 0.5906899109792285\n",
            "epoch 7 batch id 338 loss 1.6594423055648804 train acc 0.5906527366863905\n",
            "epoch 7 batch id 339 loss 1.6803171634674072 train acc 0.5905696902654868\n",
            "epoch 7 batch id 340 loss 1.4894872903823853 train acc 0.5905330882352942\n",
            "epoch 7 batch id 341 loss 1.40780770778656 train acc 0.5907716275659824\n",
            "epoch 7 batch id 342 loss 1.2676210403442383 train acc 0.5910087719298246\n",
            "epoch 7 batch id 343 loss 1.372670292854309 train acc 0.5912445335276968\n",
            "epoch 7 batch id 344 loss 1.4039207696914673 train acc 0.5911609738372093\n",
            "epoch 7 batch id 345 loss 1.5789241790771484 train acc 0.5912590579710145\n",
            "epoch 7 batch id 346 loss 1.885079264640808 train acc 0.591221098265896\n",
            "epoch 7 batch id 347 loss 1.4196722507476807 train acc 0.5913184438040345\n",
            "epoch 7 batch id 348 loss 1.918034553527832 train acc 0.5910560344827587\n",
            "epoch 7 batch id 349 loss 1.7570960521697998 train acc 0.5907951289398281\n",
            "epoch 7 batch id 350 loss 1.6189569234848022 train acc 0.5906696428571429\n",
            "epoch 7 batch id 351 loss 1.6206247806549072 train acc 0.5907229344729344\n",
            "epoch 7 batch id 352 loss 1.3419550657272339 train acc 0.5909534801136364\n",
            "epoch 7 batch id 353 loss 1.6957738399505615 train acc 0.5910056657223796\n",
            "epoch 7 batch id 354 loss 1.5739034414291382 train acc 0.5910575564971752\n",
            "epoch 7 batch id 355 loss 1.505959153175354 train acc 0.5911531690140845\n",
            "epoch 7 batch id 356 loss 1.5159111022949219 train acc 0.5912043539325843\n",
            "epoch 7 batch id 357 loss 1.6224721670150757 train acc 0.5912552521008403\n",
            "epoch 7 batch id 358 loss 1.6625779867172241 train acc 0.5913495111731844\n",
            "epoch 7 batch id 359 loss 1.5863314867019653 train acc 0.591399721448468\n",
            "epoch 7 batch id 360 loss 1.5192744731903076 train acc 0.5914496527777777\n",
            "epoch 7 batch id 361 loss 1.3819491863250732 train acc 0.5915425900277008\n",
            "epoch 7 batch id 362 loss 1.535949945449829 train acc 0.5916350138121547\n",
            "epoch 7 batch id 363 loss 1.7450815439224243 train acc 0.5915547520661157\n",
            "epoch 7 batch id 364 loss 1.5302815437316895 train acc 0.5915178571428571\n",
            "epoch 7 batch id 365 loss 1.5277817249298096 train acc 0.5915239726027397\n",
            "epoch 7 batch id 366 loss 1.6031132936477661 train acc 0.5916581284153005\n",
            "epoch 7 batch id 367 loss 1.4373608827590942 train acc 0.5918767029972752\n",
            "epoch 7 batch id 368 loss 1.5429039001464844 train acc 0.591796875\n",
            "epoch 7 batch id 369 loss 1.5366578102111816 train acc 0.5918445121951219\n",
            "epoch 7 batch id 370 loss 1.6031248569488525 train acc 0.5918074324324324\n",
            "epoch 7 batch id 371 loss 1.4757030010223389 train acc 0.5917284366576819\n",
            "epoch 7 batch id 372 loss 1.405009388923645 train acc 0.591817876344086\n",
            "epoch 7 batch id 373 loss 1.5933762788772583 train acc 0.5918649463806971\n",
            "epoch 7 batch id 374 loss 1.3938579559326172 train acc 0.5919117647058824\n",
            "epoch 7 batch id 375 loss 1.409089207649231 train acc 0.592\n",
            "epoch 7 batch id 376 loss 1.3194987773895264 train acc 0.5923371010638298\n",
            "epoch 7 batch id 377 loss 1.7991153001785278 train acc 0.5923822944297082\n",
            "epoch 7 batch id 378 loss 1.7144659757614136 train acc 0.5922619047619048\n",
            "epoch 7 batch id 379 loss 1.2527931928634644 train acc 0.5924307387862797\n",
            "epoch 7 batch id 380 loss 1.7485334873199463 train acc 0.5923108552631579\n",
            "epoch 7 batch id 381 loss 1.6301571130752563 train acc 0.5921916010498688\n",
            "epoch 7 batch id 382 loss 1.2866415977478027 train acc 0.592154777486911\n",
            "epoch 7 batch id 383 loss 1.2927030324935913 train acc 0.5922813315926893\n",
            "epoch 7 batch id 384 loss 2.004772186279297 train acc 0.5918782552083334\n",
            "epoch 7 batch id 385 loss 1.4482030868530273 train acc 0.5918425324675325\n",
            "epoch 7 batch id 386 loss 1.4440557956695557 train acc 0.5919284326424871\n",
            "epoch 7 batch id 387 loss 1.3850560188293457 train acc 0.5918927648578811\n",
            "epoch 7 batch id 388 loss 1.493703842163086 train acc 0.5921794458762887\n",
            "epoch 7 batch id 389 loss 1.8383032083511353 train acc 0.5921031491002571\n",
            "epoch 7 batch id 390 loss 1.5382344722747803 train acc 0.592227564102564\n",
            "epoch 7 batch id 391 loss 1.5230766534805298 train acc 0.5921115728900256\n",
            "epoch 7 batch id 392 loss 1.5724308490753174 train acc 0.5922751913265306\n",
            "epoch 7 batch id 393 loss 1.671417236328125 train acc 0.5922391857506362\n",
            "epoch 7 batch id 394 loss 1.5026065111160278 train acc 0.5923223350253807\n",
            "epoch 7 batch id 395 loss 1.6363368034362793 train acc 0.592246835443038\n",
            "epoch 7 batch id 396 loss 1.2380831241607666 train acc 0.5924479166666666\n",
            "epoch 7 batch id 397 loss 1.8567757606506348 train acc 0.5925692695214105\n",
            "epoch 7 batch id 398 loss 1.4544044733047485 train acc 0.5926114949748744\n",
            "epoch 7 batch id 399 loss 1.5741997957229614 train acc 0.5926535087719298\n",
            "epoch 7 batch id 400 loss 1.6352704763412476 train acc 0.5925390625\n",
            "epoch 7 batch id 401 loss 1.8176920413970947 train acc 0.59223036159601\n",
            "epoch 7 batch id 402 loss 1.3676508665084839 train acc 0.5925450870646766\n",
            "epoch 7 batch id 403 loss 1.6565507650375366 train acc 0.5925480769230769\n",
            "epoch 7 batch id 404 loss 1.4016844034194946 train acc 0.5924737004950495\n",
            "epoch 7 batch id 405 loss 2.1405463218688965 train acc 0.5921682098765432\n",
            "epoch 7 batch id 406 loss 1.8166111707687378 train acc 0.591864224137931\n",
            "epoch 7 batch id 407 loss 1.3548873662948608 train acc 0.5920224201474201\n",
            "epoch 7 batch id 408 loss 1.6256352663040161 train acc 0.5921032475490197\n",
            "epoch 7 batch id 409 loss 1.5052212476730347 train acc 0.5921454767726161\n",
            "epoch 7 batch id 410 loss 1.6454204320907593 train acc 0.5920350609756098\n",
            "epoch 7 batch id 411 loss 1.3129169940948486 train acc 0.592191301703163\n",
            "epoch 7 batch id 412 loss 1.346827745437622 train acc 0.592308859223301\n",
            "epoch 7 batch id 413 loss 1.577330231666565 train acc 0.592350181598063\n",
            "epoch 7 batch id 414 loss 1.4673364162445068 train acc 0.592542270531401\n",
            "epoch 7 batch id 415 loss 1.3723753690719604 train acc 0.5926204819277109\n",
            "epoch 7 batch id 416 loss 1.7792421579360962 train acc 0.5923978365384616\n",
            "epoch 7 batch id 417 loss 1.2432613372802734 train acc 0.5926258992805755\n",
            "epoch 7 batch id 418 loss 1.5480492115020752 train acc 0.5927033492822966\n",
            "epoch 7 batch id 419 loss 1.1229451894760132 train acc 0.5930414677804295\n",
            "epoch 7 batch id 420 loss 1.455971598625183 train acc 0.5931919642857143\n",
            "epoch 7 batch id 421 loss 1.4446293115615845 train acc 0.5932675178147269\n",
            "epoch 7 batch id 422 loss 1.8798637390136719 train acc 0.5930835308056872\n",
            "epoch 7 batch id 423 loss 1.1707555055618286 train acc 0.5932697990543735\n",
            "epoch 7 batch id 424 loss 1.6603832244873047 train acc 0.5932340801886793\n",
            "epoch 7 batch id 425 loss 1.5063945055007935 train acc 0.5932720588235294\n",
            "epoch 7 batch id 426 loss 1.2794126272201538 train acc 0.5934932511737089\n",
            "epoch 7 batch id 427 loss 1.3316404819488525 train acc 0.59375\n",
            "epoch 7 batch id 428 loss 1.1672515869140625 train acc 0.5939690420560748\n",
            "epoch 7 batch id 429 loss 1.2681041955947876 train acc 0.5941142191142191\n",
            "epoch 7 batch id 430 loss 1.2534284591674805 train acc 0.5942587209302326\n",
            "epoch 7 batch id 431 loss 1.385068416595459 train acc 0.5944388051044084\n",
            "epoch 7 batch id 432 loss 1.792399525642395 train acc 0.5943648726851852\n",
            "epoch 7 batch id 433 loss 1.5592163801193237 train acc 0.5943273672055427\n",
            "epoch 7 batch id 434 loss 1.5729073286056519 train acc 0.5942540322580645\n",
            "epoch 7 batch id 435 loss 1.7602570056915283 train acc 0.5943247126436781\n",
            "epoch 7 batch id 436 loss 1.3317091464996338 train acc 0.5942517201834863\n",
            "epoch 7 batch id 437 loss 1.371586799621582 train acc 0.5943935926773455\n",
            "epoch 7 batch id 438 loss 1.0489383935928345 train acc 0.5946775114155252\n",
            "epoch 7 batch id 439 loss 1.4118341207504272 train acc 0.5948177676537585\n",
            "epoch 7 batch id 440 loss 1.4566465616226196 train acc 0.5947088068181818\n",
            "epoch 7 batch id 441 loss 1.465699315071106 train acc 0.5947774943310657\n",
            "epoch 7 batch id 442 loss 1.4675862789154053 train acc 0.594810520361991\n",
            "epoch 7 batch id 443 loss 1.2435773611068726 train acc 0.59494920993228\n",
            "epoch 7 batch id 444 loss 1.6457966566085815 train acc 0.5951224662162162\n",
            "epoch 7 batch id 445 loss 1.852266788482666 train acc 0.5951544943820225\n",
            "epoch 7 batch id 446 loss 1.3379080295562744 train acc 0.5954316143497758\n",
            "epoch 7 batch id 447 loss 1.6079548597335815 train acc 0.5954278523489933\n",
            "epoch 7 batch id 448 loss 1.649293303489685 train acc 0.5953194754464286\n",
            "epoch 7 batch id 449 loss 1.4421192407608032 train acc 0.5952811804008908\n",
            "epoch 7 batch id 450 loss 1.5546177625656128 train acc 0.5953125\n",
            "epoch 7 batch id 451 loss 1.2371867895126343 train acc 0.5954129711751663\n",
            "epoch 7 batch id 452 loss 1.622657060623169 train acc 0.5953401548672567\n",
            "epoch 7 batch id 453 loss 1.37175452709198 train acc 0.5954056291390728\n",
            "epoch 7 batch id 454 loss 1.5573630332946777 train acc 0.5953331497797357\n",
            "epoch 7 batch id 455 loss 1.6493388414382935 train acc 0.595364010989011\n",
            "epoch 7 batch id 456 loss 1.3987486362457275 train acc 0.5954632675438597\n",
            "epoch 7 batch id 457 loss 1.1703977584838867 train acc 0.5957330415754923\n",
            "epoch 7 batch id 458 loss 1.424590826034546 train acc 0.595762827510917\n",
            "epoch 7 batch id 459 loss 1.2556227445602417 train acc 0.5956903594771242\n",
            "epoch 7 batch id 460 loss 1.5454152822494507 train acc 0.5957201086956522\n",
            "epoch 7 batch id 461 loss 1.1594960689544678 train acc 0.5959530911062907\n",
            "epoch 7 batch id 462 loss 1.6742286682128906 train acc 0.5959821428571429\n",
            "epoch 7 batch id 463 loss 1.573384404182434 train acc 0.5959773218142549\n",
            "epoch 7 batch id 464 loss 1.2480076551437378 train acc 0.5960735452586207\n",
            "epoch 7 batch id 465 loss 1.6699939966201782 train acc 0.5961021505376344\n",
            "epoch 7 batch id 466 loss 1.5243291854858398 train acc 0.5961641630901288\n",
            "epoch 7 batch id 467 loss 1.6404815912246704 train acc 0.596058618843683\n",
            "epoch 7 batch id 468 loss 1.6247750520706177 train acc 0.5961204594017094\n",
            "epoch 7 batch id 469 loss 1.4793438911437988 train acc 0.5961820362473348\n",
            "epoch 7 batch id 470 loss 1.4350861310958862 train acc 0.5962765957446808\n",
            "epoch 7 batch id 471 loss 1.422440528869629 train acc 0.5965034501061571\n",
            "epoch 7 batch id 472 loss 1.6829084157943726 train acc 0.5964976165254238\n",
            "epoch 7 batch id 473 loss 1.7508857250213623 train acc 0.5963927061310782\n",
            "epoch 7 batch id 474 loss 1.2281250953674316 train acc 0.5964200949367089\n",
            "epoch 7 batch id 475 loss 1.4778488874435425 train acc 0.5964473684210526\n",
            "epoch 7 batch id 476 loss 1.3593566417694092 train acc 0.5964417016806722\n",
            "epoch 7 batch id 477 loss 1.5701425075531006 train acc 0.5964688155136268\n",
            "epoch 7 batch id 478 loss 1.3639286756515503 train acc 0.5965611924686193\n",
            "epoch 7 batch id 479 loss 1.5247095823287964 train acc 0.5966205636743215\n",
            "epoch 7 batch id 480 loss 1.589718222618103 train acc 0.5967122395833333\n",
            "epoch 7 batch id 481 loss 1.6767698526382446 train acc 0.5967385654885655\n",
            "epoch 7 batch id 482 loss 1.048185110092163 train acc 0.5969268672199171\n",
            "epoch 7 batch id 483 loss 1.3402177095413208 train acc 0.5970173395445134\n",
            "epoch 7 batch id 484 loss 1.4113582372665405 train acc 0.596978305785124\n",
            "epoch 7 batch id 485 loss 1.2619619369506836 train acc 0.5970682989690722\n",
            "epoch 7 batch id 486 loss 1.8011157512664795 train acc 0.5969650205761317\n",
            "epoch 7 batch id 487 loss 1.635786533355713 train acc 0.5970225872689938\n",
            "epoch 7 batch id 488 loss 1.6575064659118652 train acc 0.597015881147541\n",
            "epoch 7 batch id 489 loss 1.4655897617340088 train acc 0.597073108384458\n",
            "epoch 7 batch id 490 loss 1.19402277469635 train acc 0.5972576530612245\n",
            "epoch 7 batch id 491 loss 1.3498722314834595 train acc 0.5974414460285132\n",
            "epoch 7 batch id 492 loss 1.411745309829712 train acc 0.5974339430894309\n",
            "epoch 7 batch id 493 loss 1.5603909492492676 train acc 0.5974581643002028\n",
            "epoch 7 batch id 494 loss 1.2494730949401855 train acc 0.5975455465587044\n",
            "epoch 7 batch id 495 loss 1.6047983169555664 train acc 0.5974431818181818\n",
            "epoch 7 batch id 496 loss 1.5124026536941528 train acc 0.5974987399193549\n",
            "epoch 7 batch id 497 loss 1.4812595844268799 train acc 0.5974911971830986\n",
            "epoch 7 batch id 498 loss 1.3875093460083008 train acc 0.5975778112449799\n",
            "epoch 7 batch id 499 loss 1.112168312072754 train acc 0.5977893286573146\n",
            "epoch 7 batch id 500 loss 1.2522540092468262 train acc 0.59796875\n",
            "epoch 7 batch id 501 loss 1.4096994400024414 train acc 0.5978979540918163\n",
            "epoch 7 batch id 502 loss 1.6022295951843262 train acc 0.5978896912350598\n",
            "epoch 7 batch id 503 loss 1.2165565490722656 train acc 0.5980057157057654\n",
            "epoch 7 batch id 504 loss 1.5314332246780396 train acc 0.5979042658730159\n",
            "epoch 7 batch id 505 loss 1.2288165092468262 train acc 0.5980507425742574\n",
            "epoch 7 batch id 506 loss 1.7411693334579468 train acc 0.5978878458498024\n",
            "epoch 7 batch id 507 loss 1.2399715185165405 train acc 0.5980645956607495\n",
            "epoch 7 batch id 508 loss 1.3812532424926758 train acc 0.598148375984252\n",
            "epoch 7 batch id 509 loss 1.2052534818649292 train acc 0.5982932220039293\n",
            "epoch 7 batch id 510 loss 1.5643173456192017 train acc 0.5982843137254902\n",
            "epoch 7 batch id 511 loss 1.3914140462875366 train acc 0.5982628211101791\n",
            "epoch 7 train acc 0.5982628211101791\n",
            "epoch 7 test acc 0.3869222005208333\n",
            "epoch 8 batch id 1 loss 1.352868914604187 train acc 0.625\n",
            "epoch 8 batch id 2 loss 1.2214815616607666 train acc 0.65625\n",
            "epoch 8 batch id 3 loss 1.6088846921920776 train acc 0.609375\n",
            "epoch 8 batch id 4 loss 1.2818048000335693 train acc 0.61328125\n",
            "epoch 8 batch id 5 loss 1.560147762298584 train acc 0.609375\n",
            "epoch 8 batch id 6 loss 1.6919307708740234 train acc 0.6067708333333334\n",
            "epoch 8 batch id 7 loss 1.4303089380264282 train acc 0.6138392857142857\n",
            "epoch 8 batch id 8 loss 1.499185562133789 train acc 0.615234375\n",
            "epoch 8 batch id 9 loss 1.1869035959243774 train acc 0.6302083333333334\n",
            "epoch 8 batch id 10 loss 1.4194443225860596 train acc 0.625\n",
            "epoch 8 batch id 11 loss 1.3368852138519287 train acc 0.6221590909090909\n",
            "epoch 8 batch id 12 loss 1.3063828945159912 train acc 0.6263020833333334\n",
            "epoch 8 batch id 13 loss 1.191717267036438 train acc 0.6286057692307693\n",
            "epoch 8 batch id 14 loss 1.205085277557373 train acc 0.6339285714285714\n",
            "epoch 8 batch id 15 loss 1.539579153060913 train acc 0.6354166666666666\n",
            "epoch 8 batch id 16 loss 1.2656251192092896 train acc 0.6396484375\n",
            "epoch 8 batch id 17 loss 1.846937656402588 train acc 0.6341911764705882\n",
            "epoch 8 batch id 18 loss 1.9497525691986084 train acc 0.6284722222222222\n",
            "epoch 8 batch id 19 loss 1.4418479204177856 train acc 0.6282894736842105\n",
            "epoch 8 batch id 20 loss 1.5687977075576782 train acc 0.62578125\n",
            "epoch 8 batch id 21 loss 1.170156717300415 train acc 0.6294642857142857\n",
            "epoch 8 batch id 22 loss 1.3834936618804932 train acc 0.6299715909090909\n",
            "epoch 8 batch id 23 loss 1.1576499938964844 train acc 0.6338315217391305\n",
            "epoch 8 batch id 24 loss 1.2400776147842407 train acc 0.63671875\n",
            "epoch 8 batch id 25 loss 1.195082426071167 train acc 0.6375\n",
            "epoch 8 batch id 26 loss 1.326365351676941 train acc 0.6358173076923077\n",
            "epoch 8 batch id 27 loss 1.5763299465179443 train acc 0.6359953703703703\n",
            "epoch 8 batch id 28 loss 1.372261643409729 train acc 0.6361607142857143\n",
            "epoch 8 batch id 29 loss 1.5110381841659546 train acc 0.6341594827586207\n",
            "epoch 8 batch id 30 loss 1.620148777961731 train acc 0.6302083333333334\n",
            "epoch 8 batch id 31 loss 1.3987782001495361 train acc 0.6290322580645161\n",
            "epoch 8 batch id 32 loss 2.035004138946533 train acc 0.62744140625\n",
            "epoch 8 batch id 33 loss 1.3205382823944092 train acc 0.6302083333333334\n",
            "epoch 8 batch id 34 loss 1.5045403242111206 train acc 0.6291360294117647\n",
            "epoch 8 batch id 35 loss 1.4539722204208374 train acc 0.6290178571428572\n",
            "epoch 8 batch id 36 loss 1.4575389623641968 train acc 0.62890625\n",
            "epoch 8 batch id 37 loss 1.419865608215332 train acc 0.6283783783783784\n",
            "epoch 8 batch id 38 loss 1.4454668760299683 train acc 0.6274671052631579\n",
            "epoch 8 batch id 39 loss 1.50505530834198 train acc 0.6278044871794872\n",
            "epoch 8 batch id 40 loss 1.5412746667861938 train acc 0.627734375\n",
            "epoch 8 batch id 41 loss 1.4007471799850464 train acc 0.6291920731707317\n",
            "epoch 8 batch id 42 loss 1.3010542392730713 train acc 0.6294642857142857\n",
            "epoch 8 batch id 43 loss 1.4596567153930664 train acc 0.6304505813953488\n",
            "epoch 8 batch id 44 loss 1.383062481880188 train acc 0.6299715909090909\n",
            "epoch 8 batch id 45 loss 1.4936416149139404 train acc 0.6288194444444445\n",
            "epoch 8 batch id 46 loss 1.148244857788086 train acc 0.6311141304347826\n",
            "epoch 8 batch id 47 loss 1.505890130996704 train acc 0.6299867021276596\n",
            "epoch 8 batch id 48 loss 1.43654203414917 train acc 0.6282552083333334\n",
            "epoch 8 batch id 49 loss 1.7519959211349487 train acc 0.6253188775510204\n",
            "epoch 8 batch id 50 loss 1.1885051727294922 train acc 0.6275\n",
            "epoch 8 batch id 51 loss 1.3930307626724243 train acc 0.6280637254901961\n",
            "epoch 8 batch id 52 loss 1.59514319896698 train acc 0.6277043269230769\n",
            "epoch 8 batch id 53 loss 1.24378502368927 train acc 0.6276533018867925\n",
            "epoch 8 batch id 54 loss 1.8380376100540161 train acc 0.6264467592592593\n",
            "epoch 8 batch id 55 loss 1.431392788887024 train acc 0.6264204545454546\n",
            "epoch 8 batch id 56 loss 1.3413233757019043 train acc 0.6261160714285714\n",
            "epoch 8 batch id 57 loss 1.448097825050354 train acc 0.6260964912280702\n",
            "epoch 8 batch id 58 loss 1.5456178188323975 train acc 0.6260775862068966\n",
            "epoch 8 batch id 59 loss 1.272209882736206 train acc 0.6273834745762712\n",
            "epoch 8 batch id 60 loss 1.5492398738861084 train acc 0.6263020833333334\n",
            "epoch 8 batch id 61 loss 1.3831406831741333 train acc 0.6267930327868853\n",
            "epoch 8 batch id 62 loss 1.423651099205017 train acc 0.6265120967741935\n",
            "epoch 8 batch id 63 loss 1.2197072505950928 train acc 0.6274801587301587\n",
            "epoch 8 batch id 64 loss 1.7117267847061157 train acc 0.626708984375\n",
            "epoch 8 batch id 65 loss 1.317825436592102 train acc 0.628125\n",
            "epoch 8 batch id 66 loss 1.5780428647994995 train acc 0.6278409090909091\n",
            "epoch 8 batch id 67 loss 1.5410504341125488 train acc 0.6275652985074627\n",
            "epoch 8 batch id 68 loss 1.1263630390167236 train acc 0.62890625\n",
            "epoch 8 batch id 69 loss 1.1409718990325928 train acc 0.6297554347826086\n",
            "epoch 8 batch id 70 loss 1.5140118598937988 train acc 0.6287946428571428\n",
            "epoch 8 batch id 71 loss 1.0878795385360718 train acc 0.6296214788732394\n",
            "epoch 8 batch id 72 loss 1.7990416288375854 train acc 0.6286892361111112\n",
            "epoch 8 batch id 73 loss 1.6722100973129272 train acc 0.6279965753424658\n",
            "epoch 8 batch id 74 loss 1.4360042810440063 train acc 0.629222972972973\n",
            "epoch 8 batch id 75 loss 1.3382070064544678 train acc 0.6291666666666667\n",
            "epoch 8 batch id 76 loss 1.5928056240081787 train acc 0.6280838815789473\n",
            "epoch 8 batch id 77 loss 1.3052924871444702 train acc 0.6286525974025974\n",
            "epoch 8 batch id 78 loss 1.1242197751998901 train acc 0.6294070512820513\n",
            "epoch 8 batch id 79 loss 1.3430657386779785 train acc 0.6301424050632911\n",
            "epoch 8 batch id 80 loss 1.0842419862747192 train acc 0.63203125\n",
            "epoch 8 batch id 81 loss 1.322571039199829 train acc 0.6319444444444444\n",
            "epoch 8 batch id 82 loss 1.509861707687378 train acc 0.6328125\n",
            "epoch 8 batch id 83 loss 1.1990103721618652 train acc 0.6338478915662651\n",
            "epoch 8 batch id 84 loss 1.8043650388717651 train acc 0.6331845238095238\n",
            "epoch 8 batch id 85 loss 1.262202501296997 train acc 0.6338235294117647\n",
            "epoch 8 batch id 86 loss 1.6272575855255127 train acc 0.6335392441860465\n",
            "epoch 8 batch id 87 loss 1.0250200033187866 train acc 0.6350574712643678\n",
            "epoch 8 batch id 88 loss 1.4196314811706543 train acc 0.6345880681818182\n",
            "epoch 8 batch id 89 loss 1.6289116144180298 train acc 0.6337780898876404\n",
            "epoch 8 batch id 90 loss 1.5148860216140747 train acc 0.6342013888888889\n",
            "epoch 8 batch id 91 loss 1.4370254278182983 train acc 0.6334134615384616\n",
            "epoch 8 batch id 92 loss 1.044434666633606 train acc 0.6348505434782609\n",
            "epoch 8 batch id 93 loss 1.4299174547195435 train acc 0.6350806451612904\n",
            "epoch 8 batch id 94 loss 1.3654391765594482 train acc 0.6356382978723404\n",
            "epoch 8 batch id 95 loss 1.2451273202896118 train acc 0.6365131578947368\n",
            "epoch 8 batch id 96 loss 1.4251160621643066 train acc 0.6365559895833334\n",
            "epoch 8 batch id 97 loss 1.2147269248962402 train acc 0.6375644329896907\n",
            "epoch 8 batch id 98 loss 1.1937044858932495 train acc 0.6383928571428571\n",
            "epoch 8 batch id 99 loss 1.3844810724258423 train acc 0.6382575757575758\n",
            "epoch 8 batch id 100 loss 1.3032896518707275 train acc 0.638125\n",
            "epoch 8 batch id 101 loss 1.3806536197662354 train acc 0.6376856435643564\n",
            "epoch 8 batch id 102 loss 1.7102643251419067 train acc 0.6367953431372549\n",
            "epoch 8 batch id 103 loss 1.2295269966125488 train acc 0.6372876213592233\n",
            "epoch 8 batch id 104 loss 1.3383326530456543 train acc 0.6371694711538461\n",
            "epoch 8 batch id 105 loss 1.8039178848266602 train acc 0.6363095238095238\n",
            "epoch 8 batch id 106 loss 1.306527853012085 train acc 0.6366450471698113\n",
            "epoch 8 batch id 107 loss 1.639822006225586 train acc 0.6368282710280374\n",
            "epoch 8 batch id 108 loss 1.1359108686447144 train acc 0.6374421296296297\n",
            "epoch 8 batch id 109 loss 1.5257787704467773 train acc 0.6374713302752294\n",
            "epoch 8 batch id 110 loss 1.1562620401382446 train acc 0.6376420454545455\n",
            "epoch 8 batch id 111 loss 1.3641453981399536 train acc 0.6380912162162162\n",
            "epoch 8 batch id 112 loss 1.1631380319595337 train acc 0.638671875\n",
            "epoch 8 batch id 113 loss 1.2591525316238403 train acc 0.6388274336283186\n",
            "epoch 8 batch id 114 loss 1.4534432888031006 train acc 0.6387061403508771\n",
            "epoch 8 batch id 115 loss 1.1661957502365112 train acc 0.6384510869565218\n",
            "epoch 8 batch id 116 loss 1.387675404548645 train acc 0.6388739224137931\n",
            "epoch 8 batch id 117 loss 1.2117414474487305 train acc 0.6394230769230769\n",
            "epoch 8 batch id 118 loss 1.0271261930465698 train acc 0.6402277542372882\n",
            "epoch 8 batch id 119 loss 0.9882605671882629 train acc 0.6410189075630253\n",
            "epoch 8 batch id 120 loss 1.3279963731765747 train acc 0.6412760416666666\n",
            "epoch 8 batch id 121 loss 1.1315146684646606 train acc 0.6419163223140496\n",
            "epoch 8 batch id 122 loss 1.0277272462844849 train acc 0.6424180327868853\n",
            "epoch 8 batch id 123 loss 1.2065964937210083 train acc 0.6425304878048781\n",
            "epoch 8 batch id 124 loss 1.3689086437225342 train acc 0.6425151209677419\n",
            "epoch 8 batch id 125 loss 1.8318418264389038 train acc 0.641625\n",
            "epoch 8 batch id 126 loss 1.2403764724731445 train acc 0.6419890873015873\n",
            "epoch 8 batch id 127 loss 1.1084524393081665 train acc 0.6423474409448819\n",
            "epoch 8 batch id 128 loss 1.457116723060608 train acc 0.6424560546875\n",
            "epoch 8 batch id 129 loss 1.1699985265731812 train acc 0.6426841085271318\n",
            "epoch 8 batch id 130 loss 1.7039246559143066 train acc 0.6424278846153846\n",
            "epoch 8 batch id 131 loss 1.1702373027801514 train acc 0.6427719465648855\n",
            "epoch 8 batch id 132 loss 1.4344478845596313 train acc 0.6427556818181818\n",
            "epoch 8 batch id 133 loss 1.4079654216766357 train acc 0.6420347744360902\n",
            "epoch 8 batch id 134 loss 1.2507487535476685 train acc 0.6427238805970149\n",
            "epoch 8 batch id 135 loss 1.3977676630020142 train acc 0.6425925925925926\n",
            "epoch 8 batch id 136 loss 1.636373519897461 train acc 0.6421185661764706\n",
            "epoch 8 batch id 137 loss 1.402424931526184 train acc 0.6418795620437956\n",
            "epoch 8 batch id 138 loss 1.0810292959213257 train acc 0.642776268115942\n",
            "epoch 8 batch id 139 loss 1.619003415107727 train acc 0.642873201438849\n",
            "epoch 8 batch id 140 loss 1.2988519668579102 train acc 0.6428571428571429\n",
            "epoch 8 batch id 141 loss 1.2903167009353638 train acc 0.6428413120567376\n",
            "epoch 8 batch id 142 loss 1.3061654567718506 train acc 0.6433758802816901\n",
            "epoch 8 batch id 143 loss 1.3105473518371582 train acc 0.6432473776223776\n",
            "epoch 8 batch id 144 loss 1.1493892669677734 train acc 0.6434461805555556\n",
            "epoch 8 batch id 145 loss 1.0823309421539307 train acc 0.64375\n",
            "epoch 8 batch id 146 loss 1.5076254606246948 train acc 0.6436215753424658\n",
            "epoch 8 batch id 147 loss 1.3735058307647705 train acc 0.6437074829931972\n",
            "epoch 8 batch id 148 loss 1.5432180166244507 train acc 0.6432643581081081\n",
            "epoch 8 batch id 149 loss 1.4882789850234985 train acc 0.6430369127516778\n",
            "epoch 8 batch id 150 loss 1.4307544231414795 train acc 0.6435416666666667\n",
            "epoch 8 batch id 151 loss 1.0753684043884277 train acc 0.6439362582781457\n",
            "epoch 8 batch id 152 loss 0.8859472274780273 train acc 0.64453125\n",
            "epoch 8 batch id 153 loss 1.26003897190094 train acc 0.6446078431372549\n",
            "epoch 8 batch id 154 loss 1.6059765815734863 train acc 0.6440746753246753\n",
            "epoch 8 batch id 155 loss 1.5200587511062622 train acc 0.6438508064516129\n",
            "epoch 8 batch id 156 loss 1.4805811643600464 train acc 0.6438301282051282\n",
            "epoch 8 batch id 157 loss 1.5967376232147217 train acc 0.6437101910828026\n",
            "epoch 8 batch id 158 loss 1.2712955474853516 train acc 0.6435917721518988\n",
            "epoch 8 batch id 159 loss 1.2414515018463135 train acc 0.6439661949685535\n",
            "epoch 8 batch id 160 loss 1.0536900758743286 train acc 0.64462890625\n",
            "epoch 8 batch id 161 loss 1.1744192838668823 train acc 0.6453804347826086\n",
            "epoch 8 batch id 162 loss 1.3071255683898926 train acc 0.6457368827160493\n",
            "epoch 8 batch id 163 loss 1.3565282821655273 train acc 0.6458972392638037\n",
            "epoch 8 batch id 164 loss 1.1484801769256592 train acc 0.6462461890243902\n",
            "epoch 8 batch id 165 loss 1.0526220798492432 train acc 0.6472537878787878\n",
            "epoch 8 batch id 166 loss 0.9928354620933533 train acc 0.6479668674698795\n",
            "epoch 8 batch id 167 loss 1.4104838371276855 train acc 0.6476422155688623\n",
            "epoch 8 batch id 168 loss 1.604459524154663 train acc 0.6472284226190477\n",
            "epoch 8 batch id 169 loss 1.3365716934204102 train acc 0.6473742603550295\n",
            "epoch 8 batch id 170 loss 1.5101889371871948 train acc 0.6467830882352941\n",
            "epoch 8 batch id 171 loss 1.4290828704833984 train acc 0.6468384502923976\n",
            "epoch 8 batch id 172 loss 1.2867982387542725 train acc 0.6466206395348837\n",
            "epoch 8 batch id 173 loss 1.2876207828521729 train acc 0.6464956647398844\n",
            "epoch 8 batch id 174 loss 1.3784459829330444 train acc 0.6464619252873564\n",
            "epoch 8 batch id 175 loss 1.4722824096679688 train acc 0.6465178571428571\n",
            "epoch 8 batch id 176 loss 1.286656379699707 train acc 0.6463955965909091\n",
            "epoch 8 batch id 177 loss 1.0919345617294312 train acc 0.6468926553672316\n",
            "epoch 8 batch id 178 loss 1.646179437637329 train acc 0.6466818820224719\n",
            "epoch 8 batch id 179 loss 1.6599689722061157 train acc 0.6456878491620112\n",
            "epoch 8 batch id 180 loss 1.0907953977584839 train acc 0.6461805555555555\n",
            "epoch 8 batch id 181 loss 1.2837785482406616 train acc 0.6463225138121547\n",
            "epoch 8 batch id 182 loss 1.003373146057129 train acc 0.6466346153846154\n",
            "epoch 8 batch id 183 loss 1.4571171998977661 train acc 0.6461748633879781\n",
            "epoch 8 batch id 184 loss 1.6099299192428589 train acc 0.6459748641304348\n",
            "epoch 8 batch id 185 loss 1.5151727199554443 train acc 0.6455236486486486\n",
            "epoch 8 batch id 186 loss 1.2350225448608398 train acc 0.6457493279569892\n",
            "epoch 8 batch id 187 loss 1.3469655513763428 train acc 0.6458054812834224\n",
            "epoch 8 batch id 188 loss 1.1637095212936401 train acc 0.6461934840425532\n",
            "epoch 8 batch id 189 loss 1.6533596515655518 train acc 0.6456679894179894\n",
            "epoch 8 batch id 190 loss 1.397924542427063 train acc 0.6453947368421052\n",
            "epoch 8 batch id 191 loss 1.4683781862258911 train acc 0.6452879581151832\n",
            "epoch 8 batch id 192 loss 1.442417860031128 train acc 0.64501953125\n",
            "epoch 8 batch id 193 loss 1.3466204404830933 train acc 0.6449967616580311\n",
            "epoch 8 batch id 194 loss 1.2831579446792603 train acc 0.6453769329896907\n",
            "epoch 8 batch id 195 loss 1.125226378440857 train acc 0.6455929487179487\n",
            "epoch 8 batch id 196 loss 1.1674975156784058 train acc 0.6458067602040817\n",
            "epoch 8 batch id 197 loss 1.3069076538085938 train acc 0.6457804568527918\n",
            "epoch 8 batch id 198 loss 1.164531946182251 train acc 0.6455965909090909\n",
            "epoch 8 batch id 199 loss 1.4966877698898315 train acc 0.6457286432160804\n",
            "epoch 8 batch id 200 loss 1.114264965057373 train acc 0.646171875\n",
            "epoch 8 batch id 201 loss 1.2634605169296265 train acc 0.6460665422885572\n",
            "epoch 8 batch id 202 loss 1.3047090768814087 train acc 0.6461169554455446\n",
            "epoch 8 batch id 203 loss 1.059777855873108 train acc 0.6467056650246306\n",
            "epoch 8 batch id 204 loss 1.41898512840271 train acc 0.6469056372549019\n",
            "epoch 8 batch id 205 loss 1.4108613729476929 train acc 0.6469512195121951\n",
            "epoch 8 batch id 206 loss 1.0678322315216064 train acc 0.646996359223301\n",
            "epoch 8 batch id 207 loss 1.4563145637512207 train acc 0.6468146135265701\n",
            "epoch 8 batch id 208 loss 1.2011113166809082 train acc 0.6472355769230769\n",
            "epoch 8 batch id 209 loss 1.3093359470367432 train acc 0.647203947368421\n",
            "epoch 8 batch id 210 loss 1.17096745967865 train acc 0.6475446428571429\n",
            "epoch 8 batch id 211 loss 1.35349440574646 train acc 0.6476599526066351\n",
            "epoch 8 batch id 212 loss 1.6017874479293823 train acc 0.6476267688679245\n",
            "epoch 8 batch id 213 loss 1.2784960269927979 train acc 0.6478139671361502\n",
            "epoch 8 batch id 214 loss 1.1445850133895874 train acc 0.6479994158878505\n",
            "epoch 8 batch id 215 loss 1.3397488594055176 train acc 0.6479651162790697\n",
            "epoch 8 batch id 216 loss 1.4271165132522583 train acc 0.6480758101851852\n",
            "epoch 8 batch id 217 loss 1.1021649837493896 train acc 0.6484735023041475\n",
            "epoch 8 batch id 218 loss 1.298928141593933 train acc 0.6485808486238532\n",
            "epoch 8 batch id 219 loss 1.3672934770584106 train acc 0.6485445205479452\n",
            "epoch 8 batch id 220 loss 1.2965911626815796 train acc 0.6485085227272728\n",
            "epoch 8 batch id 221 loss 1.5613054037094116 train acc 0.6480486425339367\n",
            "epoch 8 batch id 222 loss 1.3396941423416138 train acc 0.6479448198198198\n",
            "epoch 8 batch id 223 loss 1.2337846755981445 train acc 0.6479119955156951\n",
            "epoch 8 batch id 224 loss 1.3700724840164185 train acc 0.6478794642857143\n",
            "epoch 8 batch id 225 loss 0.9881274104118347 train acc 0.6484722222222222\n",
            "epoch 8 batch id 226 loss 1.453037142753601 train acc 0.6485757743362832\n",
            "epoch 8 batch id 227 loss 1.26059091091156 train acc 0.6485407488986784\n",
            "epoch 8 batch id 228 loss 1.1821844577789307 train acc 0.6487801535087719\n",
            "epoch 8 batch id 229 loss 1.3168002367019653 train acc 0.6486763100436681\n",
            "epoch 8 batch id 230 loss 1.3026654720306396 train acc 0.6488451086956522\n",
            "epoch 8 batch id 231 loss 1.2684639692306519 train acc 0.6491477272727273\n",
            "epoch 8 batch id 232 loss 1.5083101987838745 train acc 0.6489762931034483\n",
            "epoch 8 batch id 233 loss 1.3880908489227295 train acc 0.6489404506437768\n",
            "epoch 8 batch id 234 loss 1.137105107307434 train acc 0.6491720085470085\n",
            "epoch 8 batch id 235 loss 1.0890936851501465 train acc 0.6492686170212766\n",
            "epoch 8 batch id 236 loss 1.2563196420669556 train acc 0.6492981991525424\n",
            "epoch 8 batch id 237 loss 1.2391843795776367 train acc 0.6492616033755274\n",
            "epoch 8 batch id 238 loss 1.2162210941314697 train acc 0.6492909663865546\n",
            "epoch 8 batch id 239 loss 0.9918369650840759 train acc 0.649581589958159\n",
            "epoch 8 batch id 240 loss 1.196887731552124 train acc 0.6498046875\n",
            "epoch 8 batch id 241 loss 1.3172643184661865 train acc 0.6496369294605809\n",
            "epoch 8 batch id 242 loss 1.2849234342575073 train acc 0.6496642561983471\n",
            "epoch 8 batch id 243 loss 1.2769150733947754 train acc 0.6499485596707819\n",
            "epoch 8 batch id 244 loss 1.377131700515747 train acc 0.6499743852459017\n",
            "epoch 8 batch id 245 loss 1.2215197086334229 train acc 0.6500637755102041\n",
            "epoch 8 batch id 246 loss 1.0829768180847168 train acc 0.6504065040650406\n",
            "epoch 8 batch id 247 loss 1.4848273992538452 train acc 0.6501138663967612\n",
            "epoch 8 batch id 248 loss 1.1927112340927124 train acc 0.6502646169354839\n",
            "epoch 8 batch id 249 loss 1.7356146574020386 train acc 0.6501631526104418\n",
            "epoch 8 batch id 250 loss 1.5614995956420898 train acc 0.65025\n",
            "epoch 8 batch id 251 loss 1.3325053453445435 train acc 0.6500871513944223\n",
            "epoch 8 batch id 252 loss 1.2963985204696655 train acc 0.6499255952380952\n",
            "epoch 8 batch id 253 loss 1.2618205547332764 train acc 0.6500123517786561\n",
            "epoch 8 batch id 254 loss 1.3136537075042725 train acc 0.6502214566929134\n",
            "epoch 8 batch id 255 loss 1.207528829574585 train acc 0.6503676470588236\n",
            "epoch 8 batch id 256 loss 1.0821243524551392 train acc 0.65081787109375\n",
            "epoch 8 batch id 257 loss 1.2281852960586548 train acc 0.6510821984435797\n",
            "epoch 8 batch id 258 loss 1.0999878644943237 train acc 0.651344476744186\n",
            "epoch 8 batch id 259 loss 1.0572364330291748 train acc 0.6518460424710425\n",
            "epoch 8 batch id 260 loss 1.374744176864624 train acc 0.6516225961538461\n",
            "epoch 8 batch id 261 loss 1.4030179977416992 train acc 0.6515205938697318\n",
            "epoch 8 batch id 262 loss 1.1320018768310547 train acc 0.6517771946564885\n",
            "epoch 8 batch id 263 loss 1.1757919788360596 train acc 0.6516753802281369\n",
            "epoch 8 batch id 264 loss 1.0263010263442993 train acc 0.6522253787878788\n",
            "epoch 8 batch id 265 loss 1.639062762260437 train acc 0.6517099056603773\n",
            "epoch 8 batch id 266 loss 1.1006289720535278 train acc 0.6517269736842105\n",
            "epoch 8 batch id 267 loss 1.0304754972457886 train acc 0.6520950374531835\n",
            "epoch 8 batch id 268 loss 1.2601808309555054 train acc 0.652227145522388\n",
            "epoch 8 batch id 269 loss 1.4012376070022583 train acc 0.6521840148698885\n",
            "epoch 8 batch id 270 loss 1.0021685361862183 train acc 0.6526041666666667\n",
            "epoch 8 batch id 271 loss 1.0557861328125 train acc 0.6529059040590406\n",
            "epoch 8 batch id 272 loss 1.180442214012146 train acc 0.6530330882352942\n",
            "epoch 8 batch id 273 loss 1.0661838054656982 train acc 0.6531593406593407\n",
            "epoch 8 batch id 274 loss 1.3334941864013672 train acc 0.6531135948905109\n",
            "epoch 8 batch id 275 loss 1.1561672687530518 train acc 0.6534090909090909\n",
            "epoch 8 batch id 276 loss 1.167846441268921 train acc 0.6535892210144928\n",
            "epoch 8 batch id 277 loss 1.0498722791671753 train acc 0.6538808664259927\n",
            "epoch 8 batch id 278 loss 1.5927224159240723 train acc 0.653720773381295\n",
            "epoch 8 batch id 279 loss 1.0608874559402466 train acc 0.6540658602150538\n",
            "epoch 8 batch id 280 loss 1.790229320526123 train acc 0.6537946428571428\n",
            "epoch 8 batch id 281 loss 1.426336407661438 train acc 0.6536365658362989\n",
            "epoch 8 batch id 282 loss 1.1416493654251099 train acc 0.653978280141844\n",
            "epoch 8 batch id 283 loss 1.6003897190093994 train acc 0.6537102473498233\n",
            "epoch 8 batch id 284 loss 1.6825109720230103 train acc 0.6535541373239436\n",
            "epoch 8 batch id 285 loss 1.3833110332489014 train acc 0.6533991228070175\n",
            "epoch 8 batch id 286 loss 1.1650745868682861 train acc 0.6535729895104895\n",
            "epoch 8 batch id 287 loss 1.3234823942184448 train acc 0.6535278745644599\n",
            "epoch 8 batch id 288 loss 0.8694901466369629 train acc 0.6538628472222222\n",
            "epoch 8 batch id 289 loss 1.1834684610366821 train acc 0.6539251730103807\n",
            "epoch 8 batch id 290 loss 0.9339608550071716 train acc 0.6543103448275862\n",
            "epoch 8 batch id 291 loss 1.2885661125183105 train acc 0.6543707044673539\n",
            "epoch 8 batch id 292 loss 1.2189042568206787 train acc 0.654377140410959\n",
            "epoch 8 batch id 293 loss 1.7864829301834106 train acc 0.654063566552901\n",
            "epoch 8 batch id 294 loss 1.180095911026001 train acc 0.6543367346938775\n",
            "epoch 8 batch id 295 loss 1.2233725786209106 train acc 0.6543432203389831\n",
            "epoch 8 batch id 296 loss 1.162092924118042 train acc 0.6545080236486487\n",
            "epoch 8 batch id 297 loss 1.1649965047836304 train acc 0.6544612794612794\n",
            "epoch 8 batch id 298 loss 1.2563718557357788 train acc 0.6545721476510067\n",
            "epoch 8 batch id 299 loss 1.2868000268936157 train acc 0.6544209866220736\n",
            "epoch 8 batch id 300 loss 0.9133606553077698 train acc 0.6546875\n",
            "epoch 8 batch id 301 loss 1.0523865222930908 train acc 0.6548484219269103\n",
            "epoch 8 batch id 302 loss 1.292069435119629 train acc 0.6549048013245033\n",
            "epoch 8 batch id 303 loss 1.2327371835708618 train acc 0.6550123762376238\n",
            "epoch 8 batch id 304 loss 1.124392032623291 train acc 0.6552220394736842\n",
            "epoch 8 batch id 305 loss 1.2611262798309326 train acc 0.6552766393442623\n",
            "epoch 8 batch id 306 loss 1.1996867656707764 train acc 0.6555351307189542\n",
            "epoch 8 batch id 307 loss 1.0740821361541748 train acc 0.6557919381107492\n",
            "epoch 8 batch id 308 loss 1.1158721446990967 train acc 0.656047077922078\n",
            "epoch 8 batch id 309 loss 1.4078058004379272 train acc 0.6560477346278317\n",
            "epoch 8 batch id 310 loss 1.203830361366272 train acc 0.6561491935483871\n",
            "epoch 8 batch id 311 loss 1.1666496992111206 train acc 0.6564007234726688\n",
            "epoch 8 batch id 312 loss 1.646704912185669 train acc 0.6560997596153846\n",
            "epoch 8 batch id 313 loss 1.0385725498199463 train acc 0.6562999201277955\n",
            "epoch 8 batch id 314 loss 1.4004257917404175 train acc 0.65625\n",
            "epoch 8 batch id 315 loss 1.3192086219787598 train acc 0.6563492063492063\n",
            "epoch 8 batch id 316 loss 1.287286639213562 train acc 0.6562994462025317\n",
            "epoch 8 batch id 317 loss 0.9498326778411865 train acc 0.6564471608832808\n",
            "epoch 8 batch id 318 loss 0.8673000335693359 train acc 0.6567413522012578\n",
            "epoch 8 batch id 319 loss 1.2289972305297852 train acc 0.6568377742946708\n",
            "epoch 8 batch id 320 loss 1.4469135999679565 train acc 0.6564453125\n",
            "epoch 8 batch id 321 loss 1.511817216873169 train acc 0.6562013239875389\n",
            "epoch 8 batch id 322 loss 1.3565504550933838 train acc 0.6561044254658385\n",
            "epoch 8 batch id 323 loss 1.0331220626831055 train acc 0.6563951238390093\n",
            "epoch 8 batch id 324 loss 1.2422008514404297 train acc 0.6565393518518519\n",
            "epoch 8 batch id 325 loss 1.2712243795394897 train acc 0.6563461538461538\n",
            "epoch 8 batch id 326 loss 1.4058701992034912 train acc 0.656441717791411\n",
            "epoch 8 batch id 327 loss 1.3258100748062134 train acc 0.65625\n",
            "epoch 8 batch id 328 loss 1.2624952793121338 train acc 0.6564881859756098\n",
            "epoch 8 batch id 329 loss 1.3859727382659912 train acc 0.6567249240121581\n",
            "epoch 8 batch id 330 loss 1.3634164333343506 train acc 0.6566287878787879\n",
            "epoch 8 batch id 331 loss 1.2875237464904785 train acc 0.6567220543806647\n",
            "epoch 8 batch id 332 loss 1.5368423461914062 train acc 0.6564853162650602\n",
            "epoch 8 batch id 333 loss 1.3225862979888916 train acc 0.6565315315315315\n",
            "epoch 8 batch id 334 loss 1.2189197540283203 train acc 0.6564839071856288\n",
            "epoch 8 batch id 335 loss 1.0587812662124634 train acc 0.6569029850746269\n",
            "epoch 8 batch id 336 loss 1.091855764389038 train acc 0.6570870535714286\n",
            "epoch 8 batch id 337 loss 1.2212213277816772 train acc 0.6570382047477745\n",
            "epoch 8 batch id 338 loss 1.4084686040878296 train acc 0.6570358727810651\n",
            "epoch 8 batch id 339 loss 1.7593729496002197 train acc 0.6566648230088495\n",
            "epoch 8 batch id 340 loss 1.4459242820739746 train acc 0.6564797794117647\n",
            "epoch 8 batch id 341 loss 1.2277430295944214 train acc 0.656708211143695\n",
            "epoch 8 batch id 342 loss 0.7374801635742188 train acc 0.6571637426900585\n",
            "epoch 8 batch id 343 loss 1.3218777179718018 train acc 0.6572521865889213\n",
            "epoch 8 batch id 344 loss 1.254041075706482 train acc 0.6573401162790697\n",
            "epoch 8 batch id 345 loss 1.2905117273330688 train acc 0.6573822463768116\n",
            "epoch 8 batch id 346 loss 1.4950904846191406 train acc 0.657198338150289\n",
            "epoch 8 batch id 347 loss 1.0910348892211914 train acc 0.6574657780979827\n",
            "epoch 8 batch id 348 loss 1.23098623752594 train acc 0.6575520833333334\n",
            "epoch 8 batch id 349 loss 1.2466078996658325 train acc 0.6574140401146131\n",
            "epoch 8 batch id 350 loss 1.1283739805221558 train acc 0.6574553571428572\n",
            "epoch 8 batch id 351 loss 0.9103052616119385 train acc 0.6578080484330484\n",
            "epoch 8 batch id 352 loss 1.0215762853622437 train acc 0.6580255681818182\n",
            "epoch 8 batch id 353 loss 1.215038537979126 train acc 0.6579320113314447\n",
            "epoch 8 batch id 354 loss 0.9430637955665588 train acc 0.6581920903954802\n",
            "epoch 8 batch id 355 loss 1.1054496765136719 train acc 0.6584947183098592\n",
            "epoch 8 batch id 356 loss 1.4039041996002197 train acc 0.6584006320224719\n",
            "epoch 8 batch id 357 loss 1.5185127258300781 train acc 0.6582633053221288\n",
            "epoch 8 batch id 358 loss 1.4001537561416626 train acc 0.6583449720670391\n",
            "epoch 8 batch id 359 loss 1.2800570726394653 train acc 0.6583826601671309\n",
            "epoch 8 batch id 360 loss 1.36208176612854 train acc 0.6584201388888888\n",
            "epoch 8 batch id 361 loss 0.7505601048469543 train acc 0.6587603878116344\n",
            "epoch 8 batch id 362 loss 0.8935020565986633 train acc 0.6591419198895028\n",
            "epoch 8 batch id 363 loss 0.9661481380462646 train acc 0.6594352617079889\n",
            "epoch 8 batch id 364 loss 1.256757140159607 train acc 0.6593835851648352\n",
            "epoch 8 batch id 365 loss 1.4225621223449707 train acc 0.6592893835616438\n",
            "epoch 8 batch id 366 loss 1.4938783645629883 train acc 0.659238387978142\n",
            "epoch 8 batch id 367 loss 1.1761150360107422 train acc 0.6594431198910081\n",
            "epoch 8 batch id 368 loss 1.4327247142791748 train acc 0.6593070652173914\n",
            "epoch 8 batch id 369 loss 1.2720409631729126 train acc 0.6592564363143631\n",
            "epoch 8 batch id 370 loss 1.1367121934890747 train acc 0.6593327702702703\n",
            "epoch 8 batch id 371 loss 1.3497081995010376 train acc 0.6594508086253369\n",
            "epoch 8 batch id 372 loss 0.9225231409072876 train acc 0.6598622311827957\n",
            "epoch 8 batch id 373 loss 1.2447896003723145 train acc 0.6600201072386059\n",
            "epoch 8 batch id 374 loss 1.9667530059814453 train acc 0.6598011363636364\n",
            "epoch 8 batch id 375 loss 1.3163623809814453 train acc 0.6599166666666667\n",
            "epoch 8 batch id 376 loss 1.1609503030776978 train acc 0.6599484707446809\n",
            "epoch 8 batch id 377 loss 0.8984325528144836 train acc 0.6601458885941645\n",
            "epoch 8 batch id 378 loss 1.19782555103302 train acc 0.66005291005291\n",
            "epoch 8 batch id 379 loss 1.0314358472824097 train acc 0.660207783641161\n",
            "epoch 8 batch id 380 loss 1.0491724014282227 train acc 0.6604440789473685\n",
            "epoch 8 batch id 381 loss 1.1115577220916748 train acc 0.6605561023622047\n",
            "epoch 8 batch id 382 loss 1.3623862266540527 train acc 0.6603812172774869\n",
            "epoch 8 batch id 383 loss 1.1334538459777832 train acc 0.6602888381201044\n",
            "epoch 8 batch id 384 loss 1.0137585401535034 train acc 0.6603190104166666\n",
            "epoch 8 batch id 385 loss 1.4180734157562256 train acc 0.6602678571428572\n",
            "epoch 8 batch id 386 loss 1.168482780456543 train acc 0.6602979274611399\n",
            "epoch 8 batch id 387 loss 1.277421474456787 train acc 0.6602874677002584\n",
            "epoch 8 batch id 388 loss 1.1333705186843872 train acc 0.6603978737113402\n",
            "epoch 8 batch id 389 loss 1.12383234500885 train acc 0.6605880462724936\n",
            "epoch 8 batch id 390 loss 1.2903836965560913 train acc 0.6606169871794871\n",
            "epoch 8 batch id 391 loss 1.246003270149231 train acc 0.6607257033248082\n",
            "epoch 8 batch id 392 loss 1.0617849826812744 train acc 0.6610331632653061\n",
            "epoch 8 batch id 393 loss 1.3613611459732056 train acc 0.6609017175572519\n",
            "epoch 8 batch id 394 loss 1.3903427124023438 train acc 0.6609692258883249\n",
            "epoch 8 batch id 395 loss 1.4203633069992065 train acc 0.6610363924050633\n",
            "epoch 8 batch id 396 loss 1.0764800310134888 train acc 0.6612215909090909\n",
            "epoch 8 batch id 397 loss 0.8340247273445129 train acc 0.6614452141057935\n",
            "epoch 8 batch id 398 loss 0.896807074546814 train acc 0.6617462311557789\n",
            "epoch 8 batch id 399 loss 1.1430888175964355 train acc 0.6618107769423559\n",
            "epoch 8 batch id 400 loss 1.1412450075149536 train acc 0.661875\n",
            "epoch 8 batch id 401 loss 1.2785078287124634 train acc 0.6618220074812967\n",
            "epoch 8 batch id 402 loss 0.8687605261802673 train acc 0.662157960199005\n",
            "epoch 8 batch id 403 loss 1.151106357574463 train acc 0.6624147022332506\n",
            "epoch 8 batch id 404 loss 1.2546210289001465 train acc 0.6624381188118812\n",
            "epoch 8 batch id 405 loss 1.095731258392334 train acc 0.6626929012345679\n",
            "epoch 8 batch id 406 loss 0.9815000295639038 train acc 0.6629079433497537\n",
            "epoch 8 batch id 407 loss 1.1904064416885376 train acc 0.6632371007371007\n",
            "epoch 8 batch id 408 loss 0.9380028247833252 train acc 0.6634880514705882\n",
            "epoch 8 batch id 409 loss 1.221818447113037 train acc 0.6635085574572127\n",
            "epoch 8 batch id 410 loss 1.0606478452682495 train acc 0.6635670731707317\n",
            "epoch 8 batch id 411 loss 1.1655174493789673 train acc 0.6635872871046229\n",
            "epoch 8 batch id 412 loss 1.305740237236023 train acc 0.663721177184466\n",
            "epoch 8 batch id 413 loss 1.121390461921692 train acc 0.6636274213075061\n",
            "epoch 8 batch id 414 loss 1.5188908576965332 train acc 0.6634963768115942\n",
            "epoch 8 batch id 415 loss 1.214133381843567 train acc 0.6635918674698795\n",
            "epoch 8 batch id 416 loss 0.9920905828475952 train acc 0.6637620192307693\n",
            "epoch 8 batch id 417 loss 1.5544915199279785 train acc 0.663744004796163\n",
            "epoch 8 batch id 418 loss 1.0826067924499512 train acc 0.6638755980861244\n",
            "epoch 8 batch id 419 loss 1.1792380809783936 train acc 0.6640065632458234\n",
            "epoch 8 batch id 420 loss 1.3314006328582764 train acc 0.6639136904761904\n",
            "epoch 8 batch id 421 loss 1.3277205228805542 train acc 0.6639326009501187\n",
            "epoch 8 batch id 422 loss 1.2601712942123413 train acc 0.6639884478672986\n",
            "epoch 8 batch id 423 loss 1.4559870958328247 train acc 0.6640440307328606\n",
            "epoch 8 batch id 424 loss 1.39536452293396 train acc 0.6640625\n",
            "epoch 8 batch id 425 loss 1.3335185050964355 train acc 0.6640808823529412\n",
            "epoch 8 batch id 426 loss 0.8908578753471375 train acc 0.6644292840375586\n",
            "epoch 8 batch id 427 loss 1.5593070983886719 train acc 0.6643369437939111\n",
            "epoch 8 batch id 428 loss 1.2149919271469116 train acc 0.6643910630841121\n",
            "epoch 8 batch id 429 loss 1.0950350761413574 train acc 0.6645906177156177\n",
            "epoch 8 batch id 430 loss 1.439806580543518 train acc 0.6643895348837209\n",
            "epoch 8 batch id 431 loss 0.9489652514457703 train acc 0.6644794083526682\n",
            "epoch 8 batch id 432 loss 1.095881700515747 train acc 0.6646773726851852\n",
            "epoch 8 batch id 433 loss 1.220671534538269 train acc 0.6648022517321016\n",
            "epoch 8 batch id 434 loss 1.286219835281372 train acc 0.6647825460829493\n",
            "epoch 8 batch id 435 loss 0.6357935667037964 train acc 0.6651939655172414\n",
            "epoch 8 batch id 436 loss 1.1534119844436646 train acc 0.6653526376146789\n",
            "epoch 8 batch id 437 loss 0.94273841381073 train acc 0.6656536041189931\n",
            "epoch 8 batch id 438 loss 1.0522712469100952 train acc 0.6658818493150684\n",
            "epoch 8 batch id 439 loss 1.3783962726593018 train acc 0.6658243166287016\n",
            "epoch 8 batch id 440 loss 1.2134406566619873 train acc 0.6657670454545455\n",
            "epoch 8 batch id 441 loss 1.1399167776107788 train acc 0.6658871882086168\n",
            "epoch 8 batch id 442 loss 1.132157325744629 train acc 0.6659360859728507\n",
            "epoch 8 batch id 443 loss 1.0209037065505981 train acc 0.6660200338600452\n",
            "epoch 8 batch id 444 loss 1.2662593126296997 train acc 0.666138795045045\n",
            "epoch 8 batch id 445 loss 1.3265918493270874 train acc 0.6661516853932584\n",
            "epoch 8 batch id 446 loss 1.21095609664917 train acc 0.6662696188340808\n",
            "epoch 8 batch id 447 loss 1.3063089847564697 train acc 0.6661423378076062\n",
            "epoch 8 batch id 448 loss 1.372463345527649 train acc 0.666015625\n",
            "epoch 8 batch id 449 loss 1.168849229812622 train acc 0.6660982739420935\n",
            "epoch 8 batch id 450 loss 1.5757590532302856 train acc 0.6660416666666666\n",
            "epoch 8 batch id 451 loss 1.2977293729782104 train acc 0.6659160199556541\n",
            "epoch 8 batch id 452 loss 0.8863915801048279 train acc 0.6660674778761062\n",
            "epoch 8 batch id 453 loss 1.1230164766311646 train acc 0.6662527593818984\n",
            "epoch 8 batch id 454 loss 0.960131049156189 train acc 0.6663339757709251\n",
            "epoch 8 batch id 455 loss 0.992884635925293 train acc 0.6666208791208791\n",
            "epoch 8 batch id 456 loss 0.7336636781692505 train acc 0.6668379934210527\n",
            "epoch 8 batch id 457 loss 1.0070604085922241 train acc 0.6669173960612691\n",
            "epoch 8 batch id 458 loss 1.1896913051605225 train acc 0.6669282205240175\n",
            "epoch 8 batch id 459 loss 1.3831629753112793 train acc 0.6668368736383442\n",
            "epoch 8 batch id 460 loss 1.051622748374939 train acc 0.6670176630434783\n",
            "epoch 8 batch id 461 loss 0.8913958668708801 train acc 0.6674010303687635\n",
            "epoch 8 batch id 462 loss 0.915299654006958 train acc 0.667478354978355\n",
            "epoch 8 batch id 463 loss 1.1634687185287476 train acc 0.6675553455723542\n",
            "epoch 8 batch id 464 loss 1.3317368030548096 train acc 0.6675646551724138\n",
            "epoch 8 batch id 465 loss 0.8496465682983398 train acc 0.6676747311827957\n",
            "epoch 8 batch id 466 loss 0.9519466757774353 train acc 0.667817864806867\n",
            "epoch 8 batch id 467 loss 1.1163955926895142 train acc 0.6678600107066381\n",
            "epoch 8 batch id 468 loss 0.8575282096862793 train acc 0.6681690705128205\n",
            "epoch 8 batch id 469 loss 1.0892080068588257 train acc 0.6682436034115139\n",
            "epoch 8 batch id 470 loss 0.9708513021469116 train acc 0.6684175531914893\n",
            "epoch 8 batch id 471 loss 1.207786202430725 train acc 0.6684248938428875\n",
            "epoch 8 batch id 472 loss 1.1539735794067383 train acc 0.6684653072033898\n",
            "epoch 8 batch id 473 loss 1.3029417991638184 train acc 0.6684725158562368\n",
            "epoch 8 batch id 474 loss 0.9676980972290039 train acc 0.6686115506329114\n",
            "epoch 8 batch id 475 loss 1.0785287618637085 train acc 0.6685855263157895\n",
            "epoch 8 batch id 476 loss 1.212649941444397 train acc 0.6687237394957983\n",
            "epoch 8 batch id 477 loss 1.074345588684082 train acc 0.6688613731656184\n",
            "epoch 8 batch id 478 loss 1.2273801565170288 train acc 0.6688676778242678\n",
            "epoch 8 batch id 479 loss 1.4842934608459473 train acc 0.6687434759916493\n",
            "epoch 8 batch id 480 loss 1.110769271850586 train acc 0.6687825520833334\n",
            "epoch 8 batch id 481 loss 0.9773948192596436 train acc 0.6689514033264033\n",
            "epoch 8 batch id 482 loss 1.5376092195510864 train acc 0.6688926348547718\n",
            "epoch 8 batch id 483 loss 0.8558220863342285 train acc 0.6691576086956522\n",
            "epoch 8 batch id 484 loss 0.8957778811454773 train acc 0.6694214876033058\n",
            "epoch 8 batch id 485 loss 1.4767907857894897 train acc 0.6692332474226804\n",
            "epoch 8 batch id 486 loss 1.0815504789352417 train acc 0.6694637345679012\n",
            "epoch 8 batch id 487 loss 1.101102590560913 train acc 0.6695649383983573\n",
            "epoch 8 batch id 488 loss 1.1820019483566284 train acc 0.6695376536885246\n",
            "epoch 8 batch id 489 loss 0.9319385886192322 train acc 0.6697341513292433\n",
            "epoch 8 batch id 490 loss 1.2500078678131104 train acc 0.6696747448979592\n",
            "epoch 8 batch id 491 loss 1.1250437498092651 train acc 0.6697428716904277\n",
            "epoch 8 batch id 492 loss 1.054002046585083 train acc 0.6699059959349594\n",
            "epoch 8 batch id 493 loss 1.0920647382736206 train acc 0.6699416835699797\n",
            "epoch 8 batch id 494 loss 1.4036651849746704 train acc 0.6698507085020243\n",
            "epoch 8 batch id 495 loss 1.3538477420806885 train acc 0.6699179292929293\n",
            "epoch 8 batch id 496 loss 1.505183219909668 train acc 0.6697958669354839\n",
            "epoch 8 batch id 497 loss 1.1144105195999146 train acc 0.6698943661971831\n",
            "epoch 8 batch id 498 loss 1.116507887840271 train acc 0.6700552208835341\n",
            "epoch 8 batch id 499 loss 1.178992509841919 train acc 0.6700901803607214\n",
            "epoch 8 batch id 500 loss 1.322853684425354 train acc 0.67009375\n",
            "epoch 8 batch id 501 loss 0.9948021769523621 train acc 0.6701908682634731\n",
            "epoch 8 batch id 502 loss 1.213411808013916 train acc 0.6702253486055777\n",
            "epoch 8 batch id 503 loss 1.4521963596343994 train acc 0.6700422465208747\n",
            "epoch 8 batch id 504 loss 1.0235962867736816 train acc 0.6700458829365079\n",
            "epoch 8 batch id 505 loss 1.3687041997909546 train acc 0.6699876237623762\n",
            "epoch 8 batch id 506 loss 1.060839295387268 train acc 0.670114871541502\n",
            "epoch 8 batch id 507 loss 1.1737562417984009 train acc 0.6702107988165681\n",
            "epoch 8 batch id 508 loss 0.9484601020812988 train acc 0.6704908956692913\n",
            "epoch 8 batch id 509 loss 1.4606837034225464 train acc 0.6704629174852652\n",
            "epoch 8 batch id 510 loss 0.9325047731399536 train acc 0.6706801470588235\n",
            "epoch 8 batch id 511 loss 1.1416491270065308 train acc 0.6706722928897587\n",
            "epoch 8 train acc 0.6706722928897587\n",
            "epoch 8 test acc 0.3992106119791667\n",
            "epoch 9 batch id 1 loss 1.7395883798599243 train acc 0.59375\n",
            "epoch 9 batch id 2 loss 1.2627633810043335 train acc 0.65625\n",
            "epoch 9 batch id 3 loss 1.2900365591049194 train acc 0.6458333333333334\n",
            "epoch 9 batch id 4 loss 1.166062831878662 train acc 0.66015625\n",
            "epoch 9 batch id 5 loss 1.1078323125839233 train acc 0.66875\n",
            "epoch 9 batch id 6 loss 1.3023384809494019 train acc 0.6744791666666666\n",
            "epoch 9 batch id 7 loss 1.1897015571594238 train acc 0.6830357142857143\n",
            "epoch 9 batch id 8 loss 1.2816859483718872 train acc 0.67578125\n",
            "epoch 9 batch id 9 loss 1.138710856437683 train acc 0.6805555555555556\n",
            "epoch 9 batch id 10 loss 1.468701720237732 train acc 0.675\n",
            "epoch 9 batch id 11 loss 1.3545567989349365 train acc 0.6661931818181818\n",
            "epoch 9 batch id 12 loss 1.1757123470306396 train acc 0.6705729166666666\n",
            "epoch 9 batch id 13 loss 1.3509056568145752 train acc 0.6670673076923077\n",
            "epoch 9 batch id 14 loss 1.2497694492340088 train acc 0.6729910714285714\n",
            "epoch 9 batch id 15 loss 1.1611045598983765 train acc 0.6729166666666667\n",
            "epoch 9 batch id 16 loss 0.8972642421722412 train acc 0.6796875\n",
            "epoch 9 batch id 17 loss 1.182759404182434 train acc 0.6810661764705882\n",
            "epoch 9 batch id 18 loss 1.1124796867370605 train acc 0.6814236111111112\n",
            "epoch 9 batch id 19 loss 1.1732531785964966 train acc 0.6817434210526315\n",
            "epoch 9 batch id 20 loss 1.213246464729309 train acc 0.68046875\n",
            "epoch 9 batch id 21 loss 0.9768515229225159 train acc 0.6830357142857143\n",
            "epoch 9 batch id 22 loss 0.9731693863868713 train acc 0.6825284090909091\n",
            "epoch 9 batch id 23 loss 1.0440961122512817 train acc 0.6827445652173914\n",
            "epoch 9 batch id 24 loss 1.15809965133667 train acc 0.6822916666666666\n",
            "epoch 9 batch id 25 loss 1.3213419914245605 train acc 0.681875\n",
            "epoch 9 batch id 26 loss 0.9646022915840149 train acc 0.6856971153846154\n",
            "epoch 9 batch id 27 loss 1.087451696395874 train acc 0.6886574074074074\n",
            "epoch 9 batch id 28 loss 1.0680075883865356 train acc 0.6908482142857143\n",
            "epoch 9 batch id 29 loss 1.02059805393219 train acc 0.6901939655172413\n",
            "epoch 9 batch id 30 loss 1.5021079778671265 train acc 0.6869791666666667\n",
            "epoch 9 batch id 31 loss 0.989410936832428 train acc 0.6895161290322581\n",
            "epoch 9 batch id 32 loss 1.23868727684021 train acc 0.689453125\n",
            "epoch 9 batch id 33 loss 1.080569863319397 train acc 0.693655303030303\n",
            "epoch 9 batch id 34 loss 1.272286057472229 train acc 0.6930147058823529\n",
            "epoch 9 batch id 35 loss 1.0355010032653809 train acc 0.6941964285714286\n",
            "epoch 9 batch id 36 loss 1.4302527904510498 train acc 0.6918402777777778\n",
            "epoch 9 batch id 37 loss 1.349052906036377 train acc 0.6896114864864865\n",
            "epoch 9 batch id 38 loss 0.9956330060958862 train acc 0.6907894736842105\n",
            "epoch 9 batch id 39 loss 1.2044864892959595 train acc 0.6911057692307693\n",
            "epoch 9 batch id 40 loss 0.8315671682357788 train acc 0.694140625\n",
            "epoch 9 batch id 41 loss 1.068302869796753 train acc 0.6947408536585366\n",
            "epoch 9 batch id 42 loss 0.6933979988098145 train acc 0.6979166666666666\n",
            "epoch 9 batch id 43 loss 0.8146243095397949 train acc 0.700218023255814\n",
            "epoch 9 batch id 44 loss 1.2447853088378906 train acc 0.69921875\n",
            "epoch 9 batch id 45 loss 0.8666886687278748 train acc 0.7006944444444444\n",
            "epoch 9 batch id 46 loss 1.270707368850708 train acc 0.6993885869565217\n",
            "epoch 9 batch id 47 loss 0.8178824186325073 train acc 0.7011303191489362\n",
            "epoch 9 batch id 48 loss 1.0013149976730347 train acc 0.701171875\n",
            "epoch 9 batch id 49 loss 0.6231712102890015 train acc 0.7040816326530612\n",
            "epoch 9 batch id 50 loss 1.324798583984375 train acc 0.703125\n",
            "epoch 9 batch id 51 loss 0.6550264954566956 train acc 0.7055759803921569\n",
            "epoch 9 batch id 52 loss 0.9044740200042725 train acc 0.70703125\n",
            "epoch 9 batch id 53 loss 1.163407325744629 train acc 0.707252358490566\n",
            "epoch 9 batch id 54 loss 1.3402743339538574 train acc 0.7065972222222222\n",
            "epoch 9 batch id 55 loss 1.3717113733291626 train acc 0.7048295454545455\n",
            "epoch 9 batch id 56 loss 0.9376371502876282 train acc 0.705078125\n",
            "epoch 9 batch id 57 loss 0.7812877297401428 train acc 0.7072368421052632\n",
            "epoch 9 batch id 58 loss 1.3935697078704834 train acc 0.7060883620689655\n",
            "epoch 9 batch id 59 loss 0.9806478023529053 train acc 0.7060381355932204\n",
            "epoch 9 batch id 60 loss 1.2898211479187012 train acc 0.7041666666666667\n",
            "epoch 9 batch id 61 loss 0.9434880614280701 train acc 0.7051741803278688\n",
            "epoch 9 batch id 62 loss 0.8400496244430542 train acc 0.7056451612903226\n",
            "epoch 9 batch id 63 loss 1.074953317642212 train acc 0.7061011904761905\n",
            "epoch 9 batch id 64 loss 1.0526608228683472 train acc 0.706787109375\n",
            "epoch 9 batch id 65 loss 0.8034456968307495 train acc 0.7079326923076923\n",
            "epoch 9 batch id 66 loss 1.0984379053115845 train acc 0.7080965909090909\n",
            "epoch 9 batch id 67 loss 1.0006173849105835 train acc 0.7094216417910447\n",
            "epoch 9 batch id 68 loss 0.9893981218338013 train acc 0.7097886029411765\n",
            "epoch 9 batch id 69 loss 1.1454709768295288 train acc 0.7085597826086957\n",
            "epoch 9 batch id 70 loss 1.0181101560592651 train acc 0.7087053571428571\n",
            "epoch 9 batch id 71 loss 1.4768067598342896 train acc 0.7066461267605634\n",
            "epoch 9 batch id 72 loss 0.9972389936447144 train acc 0.7076822916666666\n",
            "epoch 9 batch id 73 loss 0.997051477432251 train acc 0.7074058219178082\n",
            "epoch 9 batch id 74 loss 1.314211130142212 train acc 0.706714527027027\n",
            "epoch 9 batch id 75 loss 1.0177534818649292 train acc 0.7075\n",
            "epoch 9 batch id 76 loss 0.7859143018722534 train acc 0.7080592105263158\n",
            "epoch 9 batch id 77 loss 1.4158719778060913 train acc 0.7073863636363636\n",
            "epoch 9 batch id 78 loss 1.0813121795654297 train acc 0.7083333333333334\n",
            "epoch 9 batch id 79 loss 1.2932538986206055 train acc 0.707871835443038\n",
            "epoch 9 batch id 80 loss 1.154598355293274 train acc 0.7083984375\n",
            "epoch 9 batch id 81 loss 1.1491551399230957 train acc 0.7085262345679012\n",
            "epoch 9 batch id 82 loss 1.0583752393722534 train acc 0.7090320121951219\n",
            "epoch 9 batch id 83 loss 1.147007703781128 train acc 0.7095256024096386\n",
            "epoch 9 batch id 84 loss 1.4847006797790527 train acc 0.7083333333333334\n",
            "epoch 9 batch id 85 loss 1.29669189453125 train acc 0.7082720588235294\n",
            "epoch 9 batch id 86 loss 1.0675281286239624 train acc 0.7076671511627907\n",
            "epoch 9 batch id 87 loss 1.1179732084274292 train acc 0.7074353448275862\n",
            "epoch 9 batch id 88 loss 1.1376975774765015 train acc 0.7068536931818182\n",
            "epoch 9 batch id 89 loss 1.2066783905029297 train acc 0.7071629213483146\n",
            "epoch 9 batch id 90 loss 1.137253761291504 train acc 0.7071180555555555\n",
            "epoch 9 batch id 91 loss 1.3163948059082031 train acc 0.7067307692307693\n",
            "epoch 9 batch id 92 loss 1.1023290157318115 train acc 0.7063519021739131\n",
            "epoch 9 batch id 93 loss 1.0778100490570068 train acc 0.7063172043010753\n",
            "epoch 9 batch id 94 loss 0.98736572265625 train acc 0.7059507978723404\n",
            "epoch 9 batch id 95 loss 1.1364612579345703 train acc 0.7057565789473684\n",
            "epoch 9 batch id 96 loss 1.1485016345977783 train acc 0.70556640625\n",
            "epoch 9 batch id 97 loss 1.0991113185882568 train acc 0.7058634020618557\n",
            "epoch 9 batch id 98 loss 1.2724275588989258 train acc 0.704719387755102\n",
            "epoch 9 batch id 99 loss 1.4521509408950806 train acc 0.7039141414141414\n",
            "epoch 9 batch id 100 loss 1.183221459388733 train acc 0.70359375\n",
            "epoch 9 batch id 101 loss 1.0730054378509521 train acc 0.7038985148514851\n",
            "epoch 9 batch id 102 loss 1.2872556447982788 train acc 0.703125\n",
            "epoch 9 batch id 103 loss 1.0460530519485474 train acc 0.7037317961165048\n",
            "epoch 9 batch id 104 loss 1.2001209259033203 train acc 0.7034254807692307\n",
            "epoch 9 batch id 105 loss 1.1878713369369507 train acc 0.7038690476190477\n",
            "epoch 9 batch id 106 loss 1.0595365762710571 train acc 0.7038620283018868\n",
            "epoch 9 batch id 107 loss 1.2821778059005737 train acc 0.7034170560747663\n",
            "epoch 9 batch id 108 loss 1.0469344854354858 train acc 0.7041377314814815\n",
            "epoch 9 batch id 109 loss 1.037632942199707 train acc 0.7042717889908257\n",
            "epoch 9 batch id 110 loss 0.9555210471153259 train acc 0.7048295454545455\n",
            "epoch 9 batch id 111 loss 1.1649609804153442 train acc 0.7046734234234234\n",
            "epoch 9 batch id 112 loss 0.8426151275634766 train acc 0.7049386160714286\n",
            "epoch 9 batch id 113 loss 1.0562386512756348 train acc 0.7053373893805309\n",
            "epoch 9 batch id 114 loss 1.0302492380142212 train acc 0.7057291666666666\n",
            "epoch 9 batch id 115 loss 1.151127576828003 train acc 0.7048913043478261\n",
            "epoch 9 batch id 116 loss 0.971791684627533 train acc 0.705010775862069\n",
            "epoch 9 batch id 117 loss 1.100290060043335 train acc 0.7052617521367521\n",
            "epoch 9 batch id 118 loss 1.044050931930542 train acc 0.705905720338983\n",
            "epoch 9 batch id 119 loss 1.1930147409439087 train acc 0.7048319327731093\n",
            "epoch 9 batch id 120 loss 1.136305570602417 train acc 0.7048177083333333\n",
            "epoch 9 batch id 121 loss 1.0321427583694458 train acc 0.7051911157024794\n",
            "epoch 9 batch id 122 loss 0.9112086892127991 train acc 0.7054303278688525\n",
            "epoch 9 batch id 123 loss 0.9787143468856812 train acc 0.7056656504065041\n",
            "epoch 9 batch id 124 loss 1.0210803747177124 train acc 0.7062752016129032\n",
            "epoch 9 batch id 125 loss 0.8915555477142334 train acc 0.707\n",
            "epoch 9 batch id 126 loss 0.7092183232307434 train acc 0.7075892857142857\n",
            "epoch 9 batch id 127 loss 1.1353679895401 train acc 0.7070620078740157\n",
            "epoch 9 batch id 128 loss 1.0791269540786743 train acc 0.7073974609375\n",
            "epoch 9 batch id 129 loss 1.1757986545562744 train acc 0.7078488372093024\n",
            "epoch 9 batch id 130 loss 0.8571447730064392 train acc 0.7080528846153846\n",
            "epoch 9 batch id 131 loss 1.3145607709884644 train acc 0.707418893129771\n",
            "epoch 9 batch id 132 loss 1.1009900569915771 train acc 0.7071496212121212\n",
            "epoch 9 batch id 133 loss 1.227590560913086 train acc 0.7068843984962406\n",
            "epoch 9 batch id 134 loss 0.9340340495109558 train acc 0.707206156716418\n",
            "epoch 9 batch id 135 loss 0.8820582628250122 train acc 0.7074074074074074\n",
            "epoch 9 batch id 136 loss 1.2835779190063477 train acc 0.7074908088235294\n",
            "epoch 9 batch id 137 loss 1.0746204853057861 train acc 0.7075729927007299\n",
            "epoch 9 batch id 138 loss 1.2576476335525513 train acc 0.7075407608695652\n",
            "epoch 9 batch id 139 loss 0.9340539574623108 train acc 0.7077338129496403\n",
            "epoch 9 batch id 140 loss 1.3331172466278076 train acc 0.7073660714285714\n",
            "epoch 9 batch id 141 loss 1.1151721477508545 train acc 0.7076684397163121\n",
            "epoch 9 batch id 142 loss 1.0551888942718506 train acc 0.7074163732394366\n",
            "epoch 9 batch id 143 loss 1.3988710641860962 train acc 0.7070585664335665\n",
            "epoch 9 batch id 144 loss 1.0441195964813232 train acc 0.7072482638888888\n",
            "epoch 9 batch id 145 loss 1.2611421346664429 train acc 0.7070043103448276\n",
            "epoch 9 batch id 146 loss 0.9544810056686401 train acc 0.7075128424657534\n",
            "epoch 9 batch id 147 loss 1.0869829654693604 train acc 0.7073767006802721\n",
            "epoch 9 batch id 148 loss 1.0030193328857422 train acc 0.7077702702702703\n",
            "epoch 9 batch id 149 loss 1.5227882862091064 train acc 0.7078439597315436\n",
            "epoch 9 batch id 150 loss 0.9597917199134827 train acc 0.7075\n",
            "epoch 9 batch id 151 loss 1.3440827131271362 train acc 0.7072640728476821\n",
            "epoch 9 batch id 152 loss 0.7797984480857849 train acc 0.7079564144736842\n",
            "epoch 9 batch id 153 loss 1.1904232501983643 train acc 0.7078227124183006\n",
            "epoch 9 batch id 154 loss 1.148697018623352 train acc 0.708299512987013\n",
            "epoch 9 batch id 155 loss 1.1780776977539062 train acc 0.708366935483871\n",
            "epoch 9 batch id 156 loss 1.0918859243392944 train acc 0.7082331730769231\n",
            "epoch 9 batch id 157 loss 0.9033195972442627 train acc 0.7083001592356688\n",
            "epoch 9 batch id 158 loss 0.7972342371940613 train acc 0.7090585443037974\n",
            "epoch 9 batch id 159 loss 0.9685379862785339 train acc 0.7089229559748428\n",
            "epoch 9 batch id 160 loss 1.091995358467102 train acc 0.708984375\n",
            "epoch 9 batch id 161 loss 1.120607852935791 train acc 0.7091420807453416\n",
            "epoch 9 batch id 162 loss 1.0079931020736694 train acc 0.7092978395061729\n",
            "epoch 9 batch id 163 loss 1.4066163301467896 train acc 0.7090682515337423\n",
            "epoch 9 batch id 164 loss 1.1137518882751465 train acc 0.7092225609756098\n",
            "epoch 9 batch id 165 loss 0.8824511170387268 train acc 0.7097537878787878\n",
            "epoch 9 batch id 166 loss 1.0331536531448364 train acc 0.7097138554216867\n",
            "epoch 9 batch id 167 loss 0.9415259957313538 train acc 0.7099550898203593\n",
            "epoch 9 batch id 168 loss 1.5276401042938232 train acc 0.7094494047619048\n",
            "epoch 9 batch id 169 loss 1.0985957384109497 train acc 0.709319526627219\n",
            "epoch 9 batch id 170 loss 0.8721926808357239 train acc 0.7099264705882353\n",
            "epoch 9 batch id 171 loss 0.884792685508728 train acc 0.710343567251462\n",
            "epoch 9 batch id 172 loss 1.1737060546875 train acc 0.7101199127906976\n",
            "epoch 9 batch id 173 loss 1.04450261592865 train acc 0.7103504335260116\n",
            "epoch 9 batch id 174 loss 0.9940457344055176 train acc 0.7106681034482759\n",
            "epoch 9 batch id 175 loss 0.8757706880569458 train acc 0.7109821428571429\n",
            "epoch 9 batch id 176 loss 0.6360257863998413 train acc 0.7117365056818182\n",
            "epoch 9 batch id 177 loss 1.0646106004714966 train acc 0.7115112994350282\n",
            "epoch 9 batch id 178 loss 1.1540815830230713 train acc 0.7112008426966292\n",
            "epoch 9 batch id 179 loss 1.1422696113586426 train acc 0.7109811452513967\n",
            "epoch 9 batch id 180 loss 1.267129898071289 train acc 0.7104166666666667\n",
            "epoch 9 batch id 181 loss 0.972120463848114 train acc 0.7108943370165746\n",
            "epoch 9 batch id 182 loss 0.9128784537315369 train acc 0.7111092032967034\n",
            "epoch 9 batch id 183 loss 1.2136750221252441 train acc 0.710724043715847\n",
            "epoch 9 batch id 184 loss 1.084801435470581 train acc 0.7110224184782609\n",
            "epoch 9 batch id 185 loss 1.0953706502914429 train acc 0.7107263513513513\n",
            "epoch 9 batch id 186 loss 0.816277027130127 train acc 0.7111895161290323\n",
            "epoch 9 batch id 187 loss 0.6059291362762451 train acc 0.7118983957219251\n",
            "epoch 9 batch id 188 loss 0.8160857558250427 train acc 0.7125166223404256\n",
            "epoch 9 batch id 189 loss 1.1543805599212646 train acc 0.7123015873015873\n",
            "epoch 9 batch id 190 loss 1.0117486715316772 train acc 0.7126644736842105\n",
            "epoch 9 batch id 191 loss 1.243035078048706 train acc 0.7119600785340314\n",
            "epoch 9 batch id 192 loss 0.8460574150085449 train acc 0.7122395833333334\n",
            "epoch 9 batch id 193 loss 1.4227067232131958 train acc 0.711949481865285\n",
            "epoch 9 batch id 194 loss 0.8632555603981018 train acc 0.7123872422680413\n",
            "epoch 9 batch id 195 loss 1.3404974937438965 train acc 0.7124198717948718\n",
            "epoch 9 batch id 196 loss 0.6716092824935913 train acc 0.7130899234693877\n",
            "epoch 9 batch id 197 loss 1.1533993482589722 train acc 0.7128013959390863\n",
            "epoch 9 batch id 198 loss 1.160839319229126 train acc 0.7126736111111112\n",
            "epoch 9 batch id 199 loss 1.1133533716201782 train acc 0.7124685929648241\n",
            "epoch 9 batch id 200 loss 0.9907835125923157 train acc 0.71265625\n",
            "epoch 9 batch id 201 loss 0.9477618932723999 train acc 0.712764303482587\n",
            "epoch 9 batch id 202 loss 1.01143217086792 train acc 0.7128712871287128\n",
            "epoch 9 batch id 203 loss 1.0365854501724243 train acc 0.712823275862069\n",
            "epoch 9 batch id 204 loss 0.8703112602233887 train acc 0.7133118872549019\n",
            "epoch 9 batch id 205 loss 1.2259376049041748 train acc 0.7128810975609756\n",
            "epoch 9 batch id 206 loss 1.1442806720733643 train acc 0.7126820388349514\n",
            "epoch 9 batch id 207 loss 0.9577645063400269 train acc 0.7129378019323671\n",
            "epoch 9 batch id 208 loss 1.208937406539917 train acc 0.7130408653846154\n",
            "epoch 9 batch id 209 loss 0.9411442875862122 train acc 0.713441985645933\n",
            "epoch 9 batch id 210 loss 0.8615714311599731 train acc 0.7136904761904762\n",
            "epoch 9 batch id 211 loss 1.1125513315200806 train acc 0.7135663507109005\n",
            "epoch 9 batch id 212 loss 0.911604642868042 train acc 0.7138856132075472\n",
            "epoch 9 batch id 213 loss 0.8691304326057434 train acc 0.7142018779342723\n",
            "epoch 9 batch id 214 loss 1.0642249584197998 train acc 0.7141501168224299\n",
            "epoch 9 batch id 215 loss 1.030267596244812 train acc 0.7143168604651163\n",
            "epoch 9 batch id 216 loss 1.3077813386917114 train acc 0.7142650462962963\n",
            "epoch 9 batch id 217 loss 1.3298978805541992 train acc 0.7138536866359447\n",
            "epoch 9 batch id 218 loss 0.8618378639221191 train acc 0.7142345183486238\n",
            "epoch 9 batch id 219 loss 1.27470862865448 train acc 0.714041095890411\n",
            "epoch 9 batch id 220 loss 0.8103069067001343 train acc 0.7141335227272727\n",
            "epoch 9 batch id 221 loss 1.060742974281311 train acc 0.7141544117647058\n",
            "epoch 9 batch id 222 loss 1.267789363861084 train acc 0.7141047297297297\n",
            "epoch 9 batch id 223 loss 1.1463758945465088 train acc 0.7140554932735426\n",
            "epoch 9 batch id 224 loss 1.2333276271820068 train acc 0.7140066964285714\n",
            "epoch 9 batch id 225 loss 1.3251471519470215 train acc 0.7138888888888889\n",
            "epoch 9 batch id 226 loss 1.0189257860183716 train acc 0.7138412610619469\n",
            "epoch 9 batch id 227 loss 1.0561296939849854 train acc 0.7136563876651982\n",
            "epoch 9 batch id 228 loss 1.381829857826233 train acc 0.7132675438596491\n",
            "epoch 9 batch id 229 loss 1.3648765087127686 train acc 0.712745633187773\n",
            "epoch 9 batch id 230 loss 1.0915688276290894 train acc 0.7127038043478261\n",
            "epoch 9 batch id 231 loss 0.9739544987678528 train acc 0.7127299783549783\n",
            "epoch 9 batch id 232 loss 0.9923012256622314 train acc 0.7130926724137931\n",
            "epoch 9 batch id 233 loss 1.4401190280914307 train acc 0.7127145922746781\n",
            "epoch 9 batch id 234 loss 1.027138113975525 train acc 0.7127403846153846\n",
            "epoch 9 batch id 235 loss 1.2016710042953491 train acc 0.7127659574468085\n",
            "epoch 9 batch id 236 loss 0.9610826373100281 train acc 0.7128575211864406\n",
            "epoch 9 batch id 237 loss 0.9804905652999878 train acc 0.7128164556962026\n",
            "epoch 9 batch id 238 loss 1.0112342834472656 train acc 0.7128413865546218\n",
            "epoch 9 batch id 239 loss 1.1215022802352905 train acc 0.7126046025104602\n",
            "epoch 9 batch id 240 loss 1.3417341709136963 train acc 0.7125\n",
            "epoch 9 batch id 241 loss 1.0896419286727905 train acc 0.7122017634854771\n",
            "epoch 9 batch id 242 loss 0.9338849782943726 train acc 0.7122933884297521\n",
            "epoch 9 batch id 243 loss 0.936029851436615 train acc 0.7123842592592593\n",
            "epoch 9 batch id 244 loss 0.873749852180481 train acc 0.7124743852459017\n",
            "epoch 9 batch id 245 loss 1.2307450771331787 train acc 0.7119260204081632\n",
            "epoch 9 batch id 246 loss 1.3892921209335327 train acc 0.7120172764227642\n",
            "epoch 9 batch id 247 loss 1.3473995923995972 train acc 0.711918016194332\n",
            "epoch 9 batch id 248 loss 1.0536192655563354 train acc 0.711882560483871\n",
            "epoch 9 batch id 249 loss 1.1278311014175415 train acc 0.7118473895582329\n",
            "epoch 9 batch id 250 loss 1.4379223585128784 train acc 0.71175\n",
            "epoch 9 batch id 251 loss 1.064377784729004 train acc 0.7117778884462151\n",
            "epoch 9 batch id 252 loss 0.8570622205734253 train acc 0.7119915674603174\n",
            "epoch 9 batch id 253 loss 1.3173004388809204 train acc 0.7118947628458498\n",
            "epoch 9 batch id 254 loss 1.3925470113754272 train acc 0.7116141732283464\n",
            "epoch 9 batch id 255 loss 1.2136191129684448 train acc 0.7115808823529411\n",
            "epoch 9 batch id 256 loss 1.0473378896713257 train acc 0.71173095703125\n",
            "epoch 9 batch id 257 loss 0.8686075806617737 train acc 0.7116974708171206\n",
            "epoch 9 batch id 258 loss 1.542275309562683 train acc 0.7113614341085271\n",
            "epoch 9 batch id 259 loss 0.9280847311019897 train acc 0.7116312741312741\n",
            "epoch 9 batch id 260 loss 0.754071056842804 train acc 0.7118389423076923\n",
            "epoch 9 batch id 261 loss 0.8548126220703125 train acc 0.7121048850574713\n",
            "epoch 9 batch id 262 loss 1.2030693292617798 train acc 0.7115338740458015\n",
            "epoch 9 batch id 263 loss 0.8829484581947327 train acc 0.7116801330798479\n",
            "epoch 9 batch id 264 loss 1.160860300064087 train acc 0.7112926136363636\n",
            "epoch 9 batch id 265 loss 0.9422639608383179 train acc 0.7112028301886792\n",
            "epoch 9 batch id 266 loss 0.9436861872673035 train acc 0.7114661654135338\n",
            "epoch 9 batch id 267 loss 1.0305067300796509 train acc 0.7116104868913857\n",
            "epoch 9 batch id 268 loss 1.3815010786056519 train acc 0.7112290111940298\n",
            "epoch 9 batch id 269 loss 1.1178851127624512 train acc 0.7111988847583643\n",
            "epoch 9 batch id 270 loss 1.259483814239502 train acc 0.7110532407407407\n",
            "epoch 9 batch id 271 loss 1.3030811548233032 train acc 0.7109086715867159\n",
            "epoch 9 batch id 272 loss 1.1711233854293823 train acc 0.7105928308823529\n",
            "epoch 9 batch id 273 loss 0.7117255926132202 train acc 0.7108516483516484\n",
            "epoch 9 batch id 274 loss 1.052278995513916 train acc 0.7108804744525548\n",
            "epoch 9 batch id 275 loss 1.1390339136123657 train acc 0.7106818181818182\n",
            "epoch 9 batch id 276 loss 0.6641752123832703 train acc 0.7112205615942029\n",
            "epoch 9 batch id 277 loss 0.8367952704429626 train acc 0.7114733754512635\n",
            "epoch 9 batch id 278 loss 1.2065348625183105 train acc 0.7114995503597122\n",
            "epoch 9 batch id 279 loss 1.0334099531173706 train acc 0.711581541218638\n",
            "epoch 9 batch id 280 loss 1.0964865684509277 train acc 0.7116629464285714\n",
            "epoch 9 batch id 281 loss 0.86042720079422 train acc 0.7117993772241993\n",
            "epoch 9 batch id 282 loss 1.0185723304748535 train acc 0.7119902482269503\n",
            "epoch 9 batch id 283 loss 0.8312961459159851 train acc 0.7120141342756183\n",
            "epoch 9 batch id 284 loss 0.9194791316986084 train acc 0.7123129401408451\n",
            "epoch 9 batch id 285 loss 1.0949838161468506 train acc 0.712280701754386\n",
            "epoch 9 batch id 286 loss 1.1806371212005615 train acc 0.7124125874125874\n",
            "epoch 9 batch id 287 loss 1.0509659051895142 train acc 0.7124891114982579\n",
            "epoch 9 batch id 288 loss 1.1643879413604736 train acc 0.71240234375\n",
            "epoch 9 batch id 289 loss 1.0400441884994507 train acc 0.7125324394463668\n",
            "epoch 9 batch id 290 loss 0.9601642489433289 train acc 0.7128771551724138\n",
            "epoch 9 batch id 291 loss 1.1192704439163208 train acc 0.7128973367697594\n",
            "epoch 9 batch id 292 loss 0.894257128238678 train acc 0.7130244006849316\n",
            "epoch 9 batch id 293 loss 0.8160343766212463 train acc 0.7131505972696246\n",
            "epoch 9 batch id 294 loss 0.9201259016990662 train acc 0.7132759353741497\n",
            "epoch 9 batch id 295 loss 1.0324573516845703 train acc 0.7136122881355932\n",
            "epoch 9 batch id 296 loss 0.9709624648094177 train acc 0.7137880067567568\n",
            "epoch 9 batch id 297 loss 1.0809376239776611 train acc 0.7138047138047138\n",
            "epoch 9 batch id 298 loss 1.1710422039031982 train acc 0.713611577181208\n",
            "epoch 9 batch id 299 loss 0.9517447352409363 train acc 0.7136810200668896\n",
            "epoch 9 batch id 300 loss 0.7605841159820557 train acc 0.7138541666666667\n",
            "epoch 9 batch id 301 loss 0.9578884243965149 train acc 0.7138185215946844\n",
            "epoch 9 batch id 302 loss 1.185459017753601 train acc 0.7136278973509934\n",
            "epoch 9 batch id 303 loss 0.8286589980125427 train acc 0.7139542079207921\n",
            "epoch 9 batch id 304 loss 1.2205617427825928 train acc 0.7134560032894737\n",
            "epoch 9 batch id 305 loss 0.8924984931945801 train acc 0.7134733606557377\n",
            "epoch 9 batch id 306 loss 0.6648070812225342 train acc 0.713796977124183\n",
            "epoch 9 batch id 307 loss 0.9516963958740234 train acc 0.7139657980456026\n",
            "epoch 9 batch id 308 loss 0.893791675567627 train acc 0.7141335227272727\n",
            "epoch 9 batch id 309 loss 0.833977222442627 train acc 0.7144012944983819\n",
            "epoch 9 batch id 310 loss 1.180445909500122 train acc 0.7143145161290323\n",
            "epoch 9 batch id 311 loss 1.135140299797058 train acc 0.714278536977492\n",
            "epoch 9 batch id 312 loss 0.9850526452064514 train acc 0.7143429487179487\n",
            "epoch 9 batch id 313 loss 0.9497786164283752 train acc 0.7144568690095847\n",
            "epoch 9 batch id 314 loss 0.8509204387664795 train acc 0.7146198248407644\n",
            "epoch 9 batch id 315 loss 0.92228102684021 train acc 0.7146825396825397\n",
            "epoch 9 batch id 316 loss 1.4282208681106567 train acc 0.7144481803797469\n",
            "epoch 9 batch id 317 loss 0.9327605962753296 train acc 0.714560331230284\n",
            "epoch 9 batch id 318 loss 0.9053102731704712 train acc 0.7147700471698113\n",
            "epoch 9 batch id 319 loss 1.3206462860107422 train acc 0.7146355799373041\n",
            "epoch 9 batch id 320 loss 1.1413522958755493 train acc 0.714599609375\n",
            "epoch 9 batch id 321 loss 0.9647035598754883 train acc 0.7147585669781932\n",
            "epoch 9 batch id 322 loss 0.7235957384109497 train acc 0.7151591614906833\n",
            "epoch 9 batch id 323 loss 1.041280746459961 train acc 0.7151702786377709\n",
            "epoch 9 batch id 324 loss 1.0197315216064453 train acc 0.7151813271604939\n",
            "epoch 9 batch id 325 loss 1.2953323125839233 train acc 0.7150480769230769\n",
            "epoch 9 batch id 326 loss 1.1092559099197388 train acc 0.7150115030674846\n",
            "epoch 9 batch id 327 loss 0.9219492077827454 train acc 0.7151662844036697\n",
            "epoch 9 batch id 328 loss 1.0036143064498901 train acc 0.7152248475609756\n",
            "epoch 9 batch id 329 loss 1.3127084970474243 train acc 0.7149506079027356\n",
            "epoch 9 batch id 330 loss 0.7972050905227661 train acc 0.7152935606060606\n",
            "epoch 9 batch id 331 loss 0.9062897562980652 train acc 0.7154456193353474\n",
            "epoch 9 batch id 332 loss 0.8611876368522644 train acc 0.7155496987951807\n",
            "epoch 9 batch id 333 loss 1.1144957542419434 train acc 0.7155123873873874\n",
            "epoch 9 batch id 334 loss 1.1969950199127197 train acc 0.7155688622754491\n",
            "epoch 9 batch id 335 loss 0.7773712873458862 train acc 0.7158582089552239\n",
            "epoch 9 batch id 336 loss 0.7426126599311829 train acc 0.7162853422619048\n",
            "epoch 9 batch id 337 loss 0.9302688241004944 train acc 0.7164781157270029\n",
            "epoch 9 batch id 338 loss 1.2720545530319214 train acc 0.7164386094674556\n",
            "epoch 9 batch id 339 loss 1.1248446702957153 train acc 0.7164454277286135\n",
            "epoch 9 batch id 340 loss 0.7221364378929138 train acc 0.7167738970588236\n",
            "epoch 9 batch id 341 loss 1.364114761352539 train acc 0.7165505865102639\n",
            "epoch 9 batch id 342 loss 1.1328668594360352 train acc 0.7166027046783626\n",
            "epoch 9 batch id 343 loss 0.902316153049469 train acc 0.7167000728862973\n",
            "epoch 9 batch id 344 loss 0.8829165101051331 train acc 0.7167514534883721\n",
            "epoch 9 batch id 345 loss 0.860374927520752 train acc 0.7169384057971014\n",
            "epoch 9 batch id 346 loss 0.9513035416603088 train acc 0.7169436416184971\n",
            "epoch 9 batch id 347 loss 1.2044732570648193 train acc 0.7168587896253602\n",
            "epoch 9 batch id 348 loss 1.3012601137161255 train acc 0.7166397270114943\n",
            "epoch 9 batch id 349 loss 0.9361000061035156 train acc 0.7168248567335244\n",
            "epoch 9 batch id 350 loss 1.0836306810379028 train acc 0.716875\n",
            "epoch 9 batch id 351 loss 1.0085793733596802 train acc 0.7170584045584045\n",
            "epoch 9 batch id 352 loss 0.6739372611045837 train acc 0.7173739346590909\n",
            "epoch 9 batch id 353 loss 0.844666600227356 train acc 0.7174220963172805\n",
            "epoch 9 batch id 354 loss 0.8494971990585327 train acc 0.7176906779661016\n",
            "epoch 9 batch id 355 loss 1.1480228900909424 train acc 0.717649647887324\n",
            "epoch 9 batch id 356 loss 1.002872109413147 train acc 0.7176088483146067\n",
            "epoch 9 batch id 357 loss 0.899101972579956 train acc 0.7177871148459384\n",
            "epoch 9 batch id 358 loss 1.0524911880493164 train acc 0.7178334497206704\n",
            "epoch 9 batch id 359 loss 1.1153644323349 train acc 0.7177924791086351\n",
            "epoch 9 batch id 360 loss 0.8387632966041565 train acc 0.71796875\n",
            "epoch 9 batch id 361 loss 1.2941125631332397 train acc 0.7178843490304709\n",
            "epoch 9 batch id 362 loss 0.7404230833053589 train acc 0.718016229281768\n",
            "epoch 9 batch id 363 loss 0.7776318192481995 train acc 0.7179752066115702\n",
            "epoch 9 batch id 364 loss 0.6497908234596252 train acc 0.7183636675824175\n",
            "epoch 9 batch id 365 loss 1.033106803894043 train acc 0.7184931506849315\n",
            "epoch 9 batch id 366 loss 0.9467526078224182 train acc 0.7185792349726776\n",
            "epoch 9 batch id 367 loss 0.6464904546737671 train acc 0.7188777247956403\n",
            "epoch 9 batch id 368 loss 1.0303475856781006 train acc 0.7188349184782609\n",
            "epoch 9 batch id 369 loss 1.045345425605774 train acc 0.7187923441734417\n",
            "epoch 9 batch id 370 loss 1.1791657209396362 train acc 0.71875\n",
            "epoch 9 batch id 371 loss 0.9292969107627869 train acc 0.71875\n",
            "epoch 9 batch id 372 loss 1.2406481504440308 train acc 0.7188340053763441\n",
            "epoch 9 batch id 373 loss 0.8886629939079285 train acc 0.7189175603217158\n",
            "epoch 9 batch id 374 loss 1.019507646560669 train acc 0.7189171122994652\n",
            "epoch 9 batch id 375 loss 1.2577388286590576 train acc 0.7189583333333334\n",
            "epoch 9 batch id 376 loss 0.8651062846183777 train acc 0.719248670212766\n",
            "epoch 9 batch id 377 loss 1.0504788160324097 train acc 0.7192887931034483\n",
            "epoch 9 batch id 378 loss 1.2727324962615967 train acc 0.7192873677248677\n",
            "epoch 9 batch id 379 loss 0.847830593585968 train acc 0.7193684036939314\n",
            "epoch 9 batch id 380 loss 0.892096221446991 train acc 0.7193667763157895\n",
            "epoch 9 batch id 381 loss 1.0788381099700928 train acc 0.7192831364829396\n",
            "epoch 9 batch id 382 loss 1.3664445877075195 train acc 0.71907722513089\n",
            "epoch 9 batch id 383 loss 0.8629902601242065 train acc 0.7191579634464752\n",
            "epoch 9 batch id 384 loss 1.201852798461914 train acc 0.7191162109375\n",
            "epoch 9 batch id 385 loss 0.9062414765357971 train acc 0.7191964285714286\n",
            "epoch 9 batch id 386 loss 0.8049450516700745 train acc 0.719357189119171\n",
            "epoch 9 batch id 387 loss 0.9317944049835205 train acc 0.7194767441860465\n",
            "epoch 9 batch id 388 loss 0.7763496041297913 train acc 0.7197164948453608\n",
            "epoch 9 batch id 389 loss 1.0592870712280273 train acc 0.719633676092545\n",
            "epoch 9 batch id 390 loss 0.8051907420158386 train acc 0.7198717948717949\n",
            "epoch 9 batch id 391 loss 0.7103803157806396 train acc 0.7200687340153452\n",
            "epoch 9 batch id 392 loss 0.9760103821754456 train acc 0.7201450892857143\n",
            "epoch 9 batch id 393 loss 1.000518798828125 train acc 0.7201812977099237\n",
            "epoch 9 batch id 394 loss 1.287223219871521 train acc 0.7199793781725888\n",
            "epoch 9 batch id 395 loss 0.8929603099822998 train acc 0.720253164556962\n",
            "epoch 9 batch id 396 loss 0.9427448511123657 train acc 0.7201704545454546\n",
            "epoch 9 batch id 397 loss 0.9209150075912476 train acc 0.7202455919395466\n",
            "epoch 9 batch id 398 loss 1.0849517583847046 train acc 0.7201633165829145\n",
            "epoch 9 batch id 399 loss 1.2016637325286865 train acc 0.7200031328320802\n",
            "epoch 9 batch id 400 loss 1.086471676826477 train acc 0.72\n",
            "epoch 9 batch id 401 loss 0.7678077816963196 train acc 0.7202306733167082\n",
            "epoch 9 batch id 402 loss 1.0422441959381104 train acc 0.7201881218905473\n",
            "epoch 9 batch id 403 loss 0.662625253200531 train acc 0.7204171836228288\n",
            "epoch 9 batch id 404 loss 1.3038914203643799 train acc 0.7202583539603961\n",
            "epoch 9 batch id 405 loss 1.093018889427185 train acc 0.7202546296296296\n",
            "epoch 9 batch id 406 loss 1.1015362739562988 train acc 0.7202124384236454\n",
            "epoch 9 batch id 407 loss 0.9951781034469604 train acc 0.7202856265356266\n",
            "epoch 9 batch id 408 loss 0.6540039777755737 train acc 0.7204733455882353\n",
            "epoch 9 batch id 409 loss 1.0384196043014526 train acc 0.7205455378973105\n",
            "epoch 9 batch id 410 loss 0.8789498209953308 train acc 0.7205792682926829\n",
            "epoch 9 batch id 411 loss 0.7998128533363342 train acc 0.7206508515815085\n",
            "epoch 9 batch id 412 loss 0.9113717079162598 train acc 0.7207600121359223\n",
            "epoch 9 batch id 413 loss 0.9694645404815674 train acc 0.7209443099273608\n",
            "epoch 9 batch id 414 loss 1.1658947467803955 train acc 0.7208635265700483\n",
            "epoch 9 batch id 415 loss 0.9677982330322266 train acc 0.7208584337349397\n",
            "epoch 9 batch id 416 loss 1.3806936740875244 train acc 0.7208158052884616\n",
            "epoch 9 batch id 417 loss 1.0266873836517334 train acc 0.7207359112709832\n",
            "epoch 9 batch id 418 loss 1.2041454315185547 train acc 0.720619019138756\n",
            "epoch 9 batch id 419 loss 0.9721531867980957 train acc 0.7206145584725537\n",
            "epoch 9 batch id 420 loss 1.091828465461731 train acc 0.7205729166666667\n",
            "epoch 9 batch id 421 loss 1.1065441370010376 train acc 0.7205685866983373\n",
            "epoch 9 batch id 422 loss 0.9722359776496887 train acc 0.7206383293838863\n",
            "epoch 9 batch id 423 loss 1.0145074129104614 train acc 0.7206708037825059\n",
            "epoch 9 batch id 424 loss 0.8427560329437256 train acc 0.7208136792452831\n",
            "epoch 9 batch id 425 loss 1.0710636377334595 train acc 0.720735294117647\n",
            "epoch 9 batch id 426 loss 0.9909990429878235 train acc 0.7207673122065728\n",
            "epoch 9 batch id 427 loss 1.3354331254959106 train acc 0.7208723653395784\n",
            "epoch 9 batch id 428 loss 1.1681292057037354 train acc 0.7207213785046729\n",
            "epoch 9 batch id 429 loss 0.7985650897026062 train acc 0.7208988927738927\n",
            "epoch 9 batch id 430 loss 0.911324679851532 train acc 0.7210755813953489\n",
            "epoch 9 batch id 431 loss 1.2672173976898193 train acc 0.7210339327146171\n",
            "epoch 9 batch id 432 loss 0.8071323037147522 train acc 0.7211733217592593\n",
            "epoch 9 batch id 433 loss 1.4599967002868652 train acc 0.7210594688221709\n",
            "epoch 9 batch id 434 loss 0.9885432124137878 train acc 0.7211261520737328\n",
            "epoch 9 batch id 435 loss 1.1284661293029785 train acc 0.7210847701149425\n",
            "epoch 9 batch id 436 loss 1.1401921510696411 train acc 0.7209719036697247\n",
            "epoch 9 batch id 437 loss 0.7932490110397339 train acc 0.7212171052631579\n",
            "epoch 9 batch id 438 loss 0.9883701205253601 train acc 0.7212114726027398\n",
            "epoch 9 batch id 439 loss 0.9740933775901794 train acc 0.7213126423690205\n",
            "epoch 9 batch id 440 loss 0.7327073216438293 train acc 0.721484375\n",
            "epoch 9 batch id 441 loss 0.8111792206764221 train acc 0.7217616213151927\n",
            "epoch 9 batch id 442 loss 1.289894700050354 train acc 0.7216841063348416\n",
            "epoch 9 batch id 443 loss 0.9496867656707764 train acc 0.7217480248306998\n",
            "epoch 9 batch id 444 loss 0.5095935463905334 train acc 0.7221283783783784\n",
            "epoch 9 batch id 445 loss 0.9223395586013794 train acc 0.7222261235955056\n",
            "epoch 9 batch id 446 loss 1.083715796470642 train acc 0.7220781950672646\n",
            "epoch 9 batch id 447 loss 1.0005152225494385 train acc 0.7221756152125279\n",
            "epoch 9 batch id 448 loss 1.411628007888794 train acc 0.7220633370535714\n",
            "epoch 9 batch id 449 loss 0.7812327742576599 train acc 0.722125556792873\n",
            "epoch 9 batch id 450 loss 1.0785540342330933 train acc 0.7221527777777778\n",
            "epoch 9 batch id 451 loss 0.8394184708595276 train acc 0.7222491685144125\n",
            "epoch 9 batch id 452 loss 1.210142731666565 train acc 0.7222759955752213\n",
            "epoch 9 batch id 453 loss 0.8684521913528442 train acc 0.7224406732891833\n",
            "epoch 9 batch id 454 loss 1.3274459838867188 train acc 0.7221572136563876\n",
            "epoch 9 batch id 455 loss 0.9774991869926453 train acc 0.7221497252747253\n",
            "epoch 9 batch id 456 loss 0.8427532911300659 train acc 0.7223135964912281\n",
            "epoch 9 batch id 457 loss 1.065388560295105 train acc 0.7222374179431073\n",
            "epoch 9 batch id 458 loss 0.7621431350708008 train acc 0.7224003820960698\n",
            "epoch 9 batch id 459 loss 0.9659504294395447 train acc 0.7223243464052288\n",
            "epoch 9 batch id 460 loss 1.0417948961257935 train acc 0.7222486413043478\n",
            "epoch 9 batch id 461 loss 1.0001494884490967 train acc 0.72220715835141\n",
            "epoch 9 batch id 462 loss 0.8827163577079773 train acc 0.7223011363636364\n",
            "epoch 9 batch id 463 loss 1.233139991760254 train acc 0.7221584773218143\n",
            "epoch 9 batch id 464 loss 0.9373655915260315 train acc 0.7222184806034483\n",
            "epoch 9 batch id 465 loss 1.5510514974594116 train acc 0.7220766129032258\n",
            "epoch 9 batch id 466 loss 0.878271758556366 train acc 0.722136534334764\n",
            "epoch 9 batch id 467 loss 1.1090409755706787 train acc 0.7222296573875803\n",
            "epoch 9 batch id 468 loss 0.9100543856620789 train acc 0.7222556089743589\n",
            "epoch 9 batch id 469 loss 0.9440431594848633 train acc 0.7222814498933902\n",
            "epoch 9 batch id 470 loss 1.091181993484497 train acc 0.7221077127659574\n",
            "epoch 9 batch id 471 loss 0.9026038646697998 train acc 0.7220674097664543\n",
            "epoch 9 batch id 472 loss 1.01352059841156 train acc 0.7221927966101694\n",
            "epoch 9 batch id 473 loss 1.2077103853225708 train acc 0.7222846194503171\n",
            "epoch 9 batch id 474 loss 1.0060813426971436 train acc 0.7223430907172996\n",
            "epoch 9 batch id 475 loss 0.7586345672607422 train acc 0.7225\n",
            "epoch 9 batch id 476 loss 0.9806587100028992 train acc 0.7225577731092437\n",
            "epoch 9 batch id 477 loss 1.1176670789718628 train acc 0.7225170335429769\n",
            "epoch 9 batch id 478 loss 0.6977558135986328 train acc 0.7227379707112971\n",
            "epoch 9 batch id 479 loss 0.860853374004364 train acc 0.722794885177453\n",
            "epoch 9 batch id 480 loss 0.8503627181053162 train acc 0.7228841145833333\n",
            "epoch 9 batch id 481 loss 0.781904935836792 train acc 0.723135395010395\n",
            "epoch 9 batch id 482 loss 1.1285508871078491 train acc 0.7232235477178424\n",
            "epoch 9 batch id 483 loss 1.0154204368591309 train acc 0.7233113354037267\n",
            "epoch 9 batch id 484 loss 0.7630419731140137 train acc 0.7235278925619835\n",
            "epoch 9 batch id 485 loss 0.9506471753120422 train acc 0.7237113402061855\n",
            "epoch 9 batch id 486 loss 1.0449693202972412 train acc 0.7237975823045267\n",
            "epoch 9 batch id 487 loss 1.145803689956665 train acc 0.7236588809034907\n",
            "epoch 9 batch id 488 loss 0.7557274699211121 train acc 0.723936987704918\n",
            "epoch 9 batch id 489 loss 0.9534262418746948 train acc 0.7240222392638037\n",
            "epoch 9 batch id 490 loss 0.5302878022193909 train acc 0.7243303571428571\n",
            "epoch 9 batch id 491 loss 0.8971958160400391 train acc 0.724446283095723\n",
            "epoch 9 batch id 492 loss 0.9620782136917114 train acc 0.7244982215447154\n",
            "epoch 9 batch id 493 loss 0.8850398659706116 train acc 0.724676724137931\n",
            "epoch 9 batch id 494 loss 0.9076801538467407 train acc 0.7247912449392713\n",
            "epoch 9 batch id 495 loss 1.0884991884231567 train acc 0.7248106060606061\n",
            "epoch 9 batch id 496 loss 0.9560894966125488 train acc 0.7247983870967742\n",
            "epoch 9 batch id 497 loss 0.7495275735855103 train acc 0.7249119718309859\n",
            "epoch 9 batch id 498 loss 1.140241026878357 train acc 0.7248995983935743\n",
            "epoch 9 batch id 499 loss 0.9849817752838135 train acc 0.7249812124248497\n",
            "epoch 9 batch id 500 loss 0.9926310777664185 train acc 0.72496875\n",
            "epoch 9 batch id 501 loss 0.6842945218086243 train acc 0.7252058383233533\n",
            "epoch 9 batch id 502 loss 1.0650280714035034 train acc 0.7253174800796812\n",
            "epoch 9 batch id 503 loss 1.15977942943573 train acc 0.7252733598409543\n",
            "epoch 9 batch id 504 loss 1.0143471956253052 train acc 0.7252604166666666\n",
            "epoch 9 batch id 505 loss 0.8270018100738525 train acc 0.7254022277227723\n",
            "epoch 9 batch id 506 loss 0.8347837328910828 train acc 0.7254508399209486\n",
            "epoch 9 batch id 507 loss 0.8030386567115784 train acc 0.7255300788954635\n",
            "epoch 9 batch id 508 loss 0.9673009514808655 train acc 0.7254859744094488\n",
            "epoch 9 batch id 509 loss 1.134218454360962 train acc 0.7255341355599214\n",
            "epoch 9 batch id 510 loss 0.9300875663757324 train acc 0.7256740196078432\n",
            "epoch 9 batch id 511 loss 0.8741023540496826 train acc 0.72568279594943\n",
            "epoch 9 train acc 0.72568279594943\n",
            "epoch 9 test acc 0.3892008463541667\n",
            "epoch 10 batch id 1 loss 0.822809636592865 train acc 0.703125\n",
            "epoch 10 batch id 2 loss 0.54273921251297 train acc 0.78125\n",
            "epoch 10 batch id 3 loss 1.1540409326553345 train acc 0.75\n",
            "epoch 10 batch id 4 loss 0.9447025656700134 train acc 0.75\n",
            "epoch 10 batch id 5 loss 0.8854560256004333 train acc 0.74375\n",
            "epoch 10 batch id 6 loss 1.2316954135894775 train acc 0.7161458333333334\n",
            "epoch 10 batch id 7 loss 0.8107884526252747 train acc 0.7276785714285714\n",
            "epoch 10 batch id 8 loss 0.6890435218811035 train acc 0.734375\n",
            "epoch 10 batch id 9 loss 0.9183794856071472 train acc 0.7413194444444444\n",
            "epoch 10 batch id 10 loss 0.8277853727340698 train acc 0.74375\n",
            "epoch 10 batch id 11 loss 1.0735793113708496 train acc 0.7414772727272727\n",
            "epoch 10 batch id 12 loss 0.8654980659484863 train acc 0.7434895833333334\n",
            "epoch 10 batch id 13 loss 1.08030104637146 train acc 0.7415865384615384\n",
            "epoch 10 batch id 14 loss 0.6763792037963867 train acc 0.7477678571428571\n",
            "epoch 10 batch id 15 loss 1.1732558012008667 train acc 0.746875\n",
            "epoch 10 batch id 16 loss 1.003204107284546 train acc 0.744140625\n",
            "epoch 10 batch id 17 loss 0.6734013557434082 train acc 0.7509191176470589\n",
            "epoch 10 batch id 18 loss 0.7306687235832214 train acc 0.7526041666666666\n",
            "epoch 10 batch id 19 loss 0.9029819965362549 train acc 0.7557565789473685\n",
            "epoch 10 batch id 20 loss 0.7912580370903015 train acc 0.75625\n",
            "epoch 10 batch id 21 loss 0.807780385017395 train acc 0.7552083333333334\n",
            "epoch 10 batch id 22 loss 0.8287304043769836 train acc 0.7549715909090909\n",
            "epoch 10 batch id 23 loss 1.027116060256958 train acc 0.7533967391304348\n",
            "epoch 10 batch id 24 loss 1.1469051837921143 train acc 0.75390625\n",
            "epoch 10 batch id 25 loss 0.803314745426178 train acc 0.755\n",
            "epoch 10 batch id 26 loss 1.2633519172668457 train acc 0.7506009615384616\n",
            "epoch 10 batch id 27 loss 0.77388995885849 train acc 0.7505787037037037\n",
            "epoch 10 batch id 28 loss 0.7468453645706177 train acc 0.7533482142857143\n",
            "epoch 10 batch id 29 loss 0.9041661024093628 train acc 0.7532327586206896\n",
            "epoch 10 batch id 30 loss 0.8793086409568787 train acc 0.7546875\n",
            "epoch 10 batch id 31 loss 0.5423542261123657 train acc 0.7575604838709677\n",
            "epoch 10 batch id 32 loss 1.1149704456329346 train acc 0.7568359375\n",
            "epoch 10 batch id 33 loss 1.1981908082962036 train acc 0.7556818181818182\n",
            "epoch 10 batch id 34 loss 1.0312445163726807 train acc 0.7564338235294118\n",
            "epoch 10 batch id 35 loss 1.1427903175354004 train acc 0.7540178571428572\n",
            "epoch 10 batch id 36 loss 0.924964964389801 train acc 0.7547743055555556\n",
            "epoch 10 batch id 37 loss 1.0382592678070068 train acc 0.7546452702702703\n",
            "epoch 10 batch id 38 loss 1.1348217725753784 train acc 0.7532894736842105\n",
            "epoch 10 batch id 39 loss 0.9046685695648193 train acc 0.7516025641025641\n",
            "epoch 10 batch id 40 loss 0.8489012718200684 train acc 0.7515625\n",
            "epoch 10 batch id 41 loss 0.7418943643569946 train acc 0.7515243902439024\n",
            "epoch 10 batch id 42 loss 0.8058456182479858 train acc 0.7533482142857143\n",
            "epoch 10 batch id 43 loss 1.1020944118499756 train acc 0.7521802325581395\n",
            "epoch 10 batch id 44 loss 0.7894579768180847 train acc 0.75390625\n",
            "epoch 10 batch id 45 loss 0.6956517696380615 train acc 0.7555555555555555\n",
            "epoch 10 batch id 46 loss 0.936739444732666 train acc 0.7554347826086957\n",
            "epoch 10 batch id 47 loss 0.8326908349990845 train acc 0.7553191489361702\n",
            "epoch 10 batch id 48 loss 0.8719040155410767 train acc 0.7568359375\n",
            "epoch 10 batch id 49 loss 0.7996413707733154 train acc 0.7576530612244898\n",
            "epoch 10 batch id 50 loss 1.0840142965316772 train acc 0.7571875\n",
            "epoch 10 batch id 51 loss 0.8342912197113037 train acc 0.7576593137254902\n",
            "epoch 10 batch id 52 loss 0.9947026371955872 train acc 0.7572115384615384\n",
            "epoch 10 batch id 53 loss 0.906958818435669 train acc 0.7576650943396226\n",
            "epoch 10 batch id 54 loss 0.6896578669548035 train acc 0.7586805555555556\n",
            "epoch 10 batch id 55 loss 1.1242341995239258 train acc 0.7573863636363637\n",
            "epoch 10 batch id 56 loss 1.2043169736862183 train acc 0.7572544642857143\n",
            "epoch 10 batch id 57 loss 0.9752361178398132 train acc 0.7574013157894737\n",
            "epoch 10 batch id 58 loss 0.7144711017608643 train acc 0.7586206896551724\n",
            "epoch 10 batch id 59 loss 0.6752466559410095 train acc 0.760593220338983\n",
            "epoch 10 batch id 60 loss 0.8336610794067383 train acc 0.76015625\n",
            "epoch 10 batch id 61 loss 1.0489799976348877 train acc 0.7602459016393442\n",
            "epoch 10 batch id 62 loss 0.9819121956825256 train acc 0.7605846774193549\n",
            "epoch 10 batch id 63 loss 0.9873247146606445 train acc 0.7594246031746031\n",
            "epoch 10 batch id 64 loss 1.1202311515808105 train acc 0.758544921875\n",
            "epoch 10 batch id 65 loss 1.0538487434387207 train acc 0.7579326923076923\n",
            "epoch 10 batch id 66 loss 0.9467989802360535 train acc 0.7578125\n",
            "epoch 10 batch id 67 loss 0.9437429308891296 train acc 0.757695895522388\n",
            "epoch 10 batch id 68 loss 0.8639344573020935 train acc 0.7580422794117647\n",
            "epoch 10 batch id 69 loss 0.9261279106140137 train acc 0.7576992753623188\n",
            "epoch 10 batch id 70 loss 0.8905107975006104 train acc 0.7582589285714286\n",
            "epoch 10 batch id 71 loss 0.9044271111488342 train acc 0.7585827464788732\n",
            "epoch 10 batch id 72 loss 1.0120975971221924 train acc 0.7591145833333334\n",
            "epoch 10 batch id 73 loss 0.9926071763038635 train acc 0.7589897260273972\n",
            "epoch 10 batch id 74 loss 0.8542405962944031 train acc 0.7590793918918919\n",
            "epoch 10 batch id 75 loss 0.8019704222679138 train acc 0.76\n",
            "epoch 10 batch id 76 loss 1.2399901151657104 train acc 0.759046052631579\n",
            "epoch 10 batch id 77 loss 0.8987734317779541 train acc 0.7591314935064936\n",
            "epoch 10 batch id 78 loss 1.0179619789123535 train acc 0.7592147435897436\n",
            "epoch 10 batch id 79 loss 1.1724717617034912 train acc 0.7589003164556962\n",
            "epoch 10 batch id 80 loss 0.6440330147743225 train acc 0.759375\n",
            "epoch 10 batch id 81 loss 1.0069730281829834 train acc 0.7600308641975309\n",
            "epoch 10 batch id 82 loss 0.8046738505363464 train acc 0.7593368902439024\n",
            "epoch 10 batch id 83 loss 1.114009141921997 train acc 0.7584713855421686\n",
            "epoch 10 batch id 84 loss 1.1719635725021362 train acc 0.7574404761904762\n",
            "epoch 10 batch id 85 loss 0.8808500170707703 train acc 0.7579044117647059\n",
            "epoch 10 batch id 86 loss 1.0186618566513062 train acc 0.7585392441860465\n",
            "epoch 10 batch id 87 loss 0.5698654651641846 train acc 0.7595186781609196\n",
            "epoch 10 batch id 88 loss 1.1800363063812256 train acc 0.7581676136363636\n",
            "epoch 10 batch id 89 loss 1.063035011291504 train acc 0.7575491573033708\n",
            "epoch 10 batch id 90 loss 0.8860681056976318 train acc 0.7571180555555556\n",
            "epoch 10 batch id 91 loss 1.1385520696640015 train acc 0.7570398351648352\n",
            "epoch 10 batch id 92 loss 0.9107668399810791 train acc 0.7566236413043478\n",
            "epoch 10 batch id 93 loss 1.0465221405029297 train acc 0.7563844086021505\n",
            "epoch 10 batch id 94 loss 1.434438943862915 train acc 0.7551529255319149\n",
            "epoch 10 batch id 95 loss 0.883033275604248 train acc 0.7554276315789473\n",
            "epoch 10 batch id 96 loss 0.884361207485199 train acc 0.7556966145833334\n",
            "epoch 10 batch id 97 loss 0.9482520222663879 train acc 0.7557989690721649\n",
            "epoch 10 batch id 98 loss 0.7786085605621338 train acc 0.7563775510204082\n",
            "epoch 10 batch id 99 loss 0.8650761842727661 train acc 0.7563131313131313\n",
            "epoch 10 batch id 100 loss 0.9362892508506775 train acc 0.756875\n",
            "epoch 10 batch id 101 loss 0.9709195494651794 train acc 0.7568069306930693\n",
            "epoch 10 batch id 102 loss 0.8205405473709106 train acc 0.7571997549019608\n",
            "epoch 10 batch id 103 loss 0.5867521166801453 train acc 0.7578883495145631\n",
            "epoch 10 batch id 104 loss 0.7519776821136475 train acc 0.7587139423076923\n",
            "epoch 10 batch id 105 loss 0.9350758790969849 train acc 0.7587797619047619\n",
            "epoch 10 batch id 106 loss 1.2837845087051392 train acc 0.7579599056603774\n",
            "epoch 10 batch id 107 loss 0.9808441400527954 train acc 0.7577394859813084\n",
            "epoch 10 batch id 108 loss 0.9478017091751099 train acc 0.7575231481481481\n",
            "epoch 10 batch id 109 loss 0.9873883724212646 train acc 0.7573107798165137\n",
            "epoch 10 batch id 110 loss 0.9735419750213623 train acc 0.7571022727272727\n",
            "epoch 10 batch id 111 loss 1.0243840217590332 train acc 0.7571790540540541\n",
            "epoch 10 batch id 112 loss 0.9255953431129456 train acc 0.7569754464285714\n",
            "epoch 10 batch id 113 loss 0.947365403175354 train acc 0.7573285398230089\n",
            "epoch 10 batch id 114 loss 0.8710414171218872 train acc 0.7576754385964912\n",
            "epoch 10 batch id 115 loss 0.8142749071121216 train acc 0.7573369565217392\n",
            "epoch 10 batch id 116 loss 0.9720852375030518 train acc 0.7566002155172413\n",
            "epoch 10 batch id 117 loss 0.9187524914741516 train acc 0.7561431623931624\n",
            "epoch 10 batch id 118 loss 0.6558359265327454 train acc 0.7566207627118644\n",
            "epoch 10 batch id 119 loss 0.8401753902435303 train acc 0.7566964285714286\n",
            "epoch 10 batch id 120 loss 0.8010254502296448 train acc 0.7567708333333333\n",
            "epoch 10 batch id 121 loss 0.6107822060585022 train acc 0.7577479338842975\n",
            "epoch 10 batch id 122 loss 0.8971932530403137 train acc 0.7579405737704918\n",
            "epoch 10 batch id 123 loss 0.898118793964386 train acc 0.7582571138211383\n",
            "epoch 10 batch id 124 loss 0.7970260977745056 train acc 0.7585685483870968\n",
            "epoch 10 batch id 125 loss 0.7731587886810303 train acc 0.75875\n",
            "epoch 10 batch id 126 loss 0.7380415797233582 train acc 0.7594246031746031\n",
            "epoch 10 batch id 127 loss 1.0173327922821045 train acc 0.7594734251968503\n",
            "epoch 10 batch id 128 loss 0.8082255721092224 train acc 0.759765625\n",
            "epoch 10 batch id 129 loss 0.9260507225990295 train acc 0.7601744186046512\n",
            "epoch 10 batch id 130 loss 0.7356938123703003 train acc 0.760576923076923\n",
            "epoch 10 batch id 131 loss 0.6549572348594666 train acc 0.7608540076335878\n",
            "epoch 10 batch id 132 loss 0.9545172452926636 train acc 0.7610085227272727\n",
            "epoch 10 batch id 133 loss 0.6011426448822021 train acc 0.7615131578947368\n",
            "epoch 10 batch id 134 loss 0.8126779794692993 train acc 0.7613106343283582\n",
            "epoch 10 batch id 135 loss 0.7777620553970337 train acc 0.7613425925925926\n",
            "epoch 10 batch id 136 loss 0.9294618964195251 train acc 0.7607996323529411\n",
            "epoch 10 batch id 137 loss 1.0610848665237427 train acc 0.760036496350365\n",
            "epoch 10 batch id 138 loss 1.3080836534500122 train acc 0.7595108695652174\n",
            "epoch 10 batch id 139 loss 1.1402469873428345 train acc 0.7589928057553957\n",
            "epoch 10 batch id 140 loss 0.7015511393547058 train acc 0.7589285714285714\n",
            "epoch 10 batch id 141 loss 0.7248773574829102 train acc 0.759197695035461\n",
            "epoch 10 batch id 142 loss 0.7414391040802002 train acc 0.7596830985915493\n",
            "epoch 10 batch id 143 loss 0.6829416751861572 train acc 0.7599431818181818\n",
            "epoch 10 batch id 144 loss 1.1639697551727295 train acc 0.7592230902777778\n",
            "epoch 10 batch id 145 loss 0.860154390335083 train acc 0.759698275862069\n",
            "epoch 10 batch id 146 loss 0.6223703622817993 train acc 0.760380993150685\n",
            "epoch 10 batch id 147 loss 0.6729522943496704 train acc 0.7609481292517006\n",
            "epoch 10 batch id 148 loss 0.9620240330696106 train acc 0.7608741554054054\n",
            "epoch 10 batch id 149 loss 0.8875494003295898 train acc 0.7613255033557047\n",
            "epoch 10 batch id 150 loss 0.9080848097801208 train acc 0.7611458333333333\n",
            "epoch 10 batch id 151 loss 0.7552936673164368 train acc 0.7611754966887417\n",
            "epoch 10 batch id 152 loss 0.7908403277397156 train acc 0.7612047697368421\n",
            "epoch 10 batch id 153 loss 0.6914398670196533 train acc 0.7615400326797386\n",
            "epoch 10 batch id 154 loss 1.1169233322143555 train acc 0.7613636363636364\n",
            "epoch 10 batch id 155 loss 0.8767167329788208 train acc 0.7615927419354839\n",
            "epoch 10 batch id 156 loss 1.0382747650146484 train acc 0.7616185897435898\n",
            "epoch 10 batch id 157 loss 1.159877061843872 train acc 0.7615445859872612\n",
            "epoch 10 batch id 158 loss 0.8112657070159912 train acc 0.7617681962025317\n",
            "epoch 10 batch id 159 loss 0.5794882774353027 train acc 0.7622838050314465\n",
            "epoch 10 batch id 160 loss 0.5223661661148071 train acc 0.762890625\n",
            "epoch 10 batch id 161 loss 0.9572133421897888 train acc 0.7630046583850931\n",
            "epoch 10 batch id 162 loss 0.9799374341964722 train acc 0.7629243827160493\n",
            "epoch 10 batch id 163 loss 0.8903688788414001 train acc 0.7623657975460123\n",
            "epoch 10 batch id 164 loss 0.708001434803009 train acc 0.762766768292683\n",
            "epoch 10 batch id 165 loss 0.8605045676231384 train acc 0.7630681818181818\n",
            "epoch 10 batch id 166 loss 0.7319695949554443 train acc 0.7632718373493976\n",
            "epoch 10 batch id 167 loss 1.193520426750183 train acc 0.7630052395209581\n",
            "epoch 10 batch id 168 loss 0.9275155663490295 train acc 0.7631138392857143\n",
            "epoch 10 batch id 169 loss 1.1601213216781616 train acc 0.7629437869822485\n",
            "epoch 10 batch id 170 loss 0.8641588687896729 train acc 0.7628676470588235\n",
            "epoch 10 batch id 171 loss 0.8620532155036926 train acc 0.7627010233918129\n",
            "epoch 10 batch id 172 loss 0.8889555335044861 train acc 0.7626271802325582\n",
            "epoch 10 batch id 173 loss 0.8112812042236328 train acc 0.7626445086705202\n",
            "epoch 10 batch id 174 loss 0.9608939290046692 train acc 0.7625718390804598\n",
            "epoch 10 batch id 175 loss 0.8009130358695984 train acc 0.7629464285714286\n",
            "epoch 10 batch id 176 loss 0.8482206463813782 train acc 0.7627840909090909\n",
            "epoch 10 batch id 177 loss 0.6380384564399719 train acc 0.7631532485875706\n",
            "epoch 10 batch id 178 loss 1.253798007965088 train acc 0.7628160112359551\n",
            "epoch 10 batch id 179 loss 1.1535024642944336 train acc 0.7623079608938548\n",
            "epoch 10 batch id 180 loss 1.057198166847229 train acc 0.7620659722222223\n",
            "epoch 10 batch id 181 loss 0.7745921611785889 train acc 0.762085635359116\n",
            "epoch 10 batch id 182 loss 1.0398911237716675 train acc 0.7615899725274725\n",
            "epoch 10 batch id 183 loss 1.0608569383621216 train acc 0.761441256830601\n",
            "epoch 10 batch id 184 loss 0.7080134153366089 train acc 0.7618036684782609\n",
            "epoch 10 batch id 185 loss 0.9412927627563477 train acc 0.7617398648648649\n",
            "epoch 10 batch id 186 loss 0.9274241924285889 train acc 0.7615927419354839\n",
            "epoch 10 batch id 187 loss 0.9172163009643555 train acc 0.7611129679144385\n",
            "epoch 10 batch id 188 loss 1.2469009160995483 train acc 0.7608876329787234\n",
            "epoch 10 batch id 189 loss 0.7760698199272156 train acc 0.7609126984126984\n",
            "epoch 10 batch id 190 loss 0.8547756671905518 train acc 0.7609375\n",
            "epoch 10 batch id 191 loss 0.6147821545600891 train acc 0.7615346858638743\n",
            "epoch 10 batch id 192 loss 0.9121978282928467 train acc 0.7613932291666666\n",
            "epoch 10 batch id 193 loss 1.0559130907058716 train acc 0.7614961139896373\n",
            "epoch 10 batch id 194 loss 1.0255155563354492 train acc 0.7614368556701031\n",
            "epoch 10 batch id 195 loss 0.7108302712440491 train acc 0.7616987179487179\n",
            "epoch 10 batch id 196 loss 1.130079746246338 train acc 0.7615593112244898\n",
            "epoch 10 batch id 197 loss 0.8596728444099426 train acc 0.761738578680203\n",
            "epoch 10 batch id 198 loss 0.8317698836326599 train acc 0.7618371212121212\n",
            "epoch 10 batch id 199 loss 0.9825006723403931 train acc 0.7616206030150754\n",
            "epoch 10 batch id 200 loss 0.8261789083480835 train acc 0.76171875\n",
            "epoch 10 batch id 201 loss 0.7577540278434753 train acc 0.761893656716418\n",
            "epoch 10 batch id 202 loss 0.8919786214828491 train acc 0.7622215346534653\n",
            "epoch 10 batch id 203 loss 0.8590726256370544 train acc 0.7623152709359606\n",
            "epoch 10 batch id 204 loss 0.846569299697876 train acc 0.762484681372549\n",
            "epoch 10 batch id 205 loss 0.822510302066803 train acc 0.7625\n",
            "epoch 10 batch id 206 loss 0.8320286870002747 train acc 0.7625151699029126\n",
            "epoch 10 batch id 207 loss 1.0714884996414185 train acc 0.7626056763285024\n",
            "epoch 10 batch id 208 loss 1.0708879232406616 train acc 0.7620943509615384\n",
            "epoch 10 batch id 209 loss 0.7609596252441406 train acc 0.7621112440191388\n",
            "epoch 10 batch id 210 loss 1.0550346374511719 train acc 0.7617559523809524\n",
            "epoch 10 batch id 211 loss 1.0358742475509644 train acc 0.761774289099526\n",
            "epoch 10 batch id 212 loss 0.8563768863677979 train acc 0.7620135613207547\n",
            "epoch 10 batch id 213 loss 0.8508427143096924 train acc 0.7618838028169014\n",
            "epoch 10 batch id 214 loss 1.1346361637115479 train acc 0.7616092289719626\n",
            "epoch 10 batch id 215 loss 0.8328779935836792 train acc 0.7615552325581395\n",
            "epoch 10 batch id 216 loss 0.6926958560943604 train acc 0.76171875\n",
            "epoch 10 batch id 217 loss 0.8055832386016846 train acc 0.7616647465437788\n",
            "epoch 10 batch id 218 loss 0.44216328859329224 train acc 0.7622563073394495\n",
            "epoch 10 batch id 219 loss 0.9005515575408936 train acc 0.7622716894977168\n",
            "epoch 10 batch id 220 loss 0.9121494889259338 train acc 0.7621448863636363\n",
            "epoch 10 batch id 221 loss 1.1994305849075317 train acc 0.7616657239819005\n",
            "epoch 10 batch id 222 loss 0.9494561553001404 train acc 0.7616131756756757\n",
            "epoch 10 batch id 223 loss 0.6565431952476501 train acc 0.7620515695067265\n",
            "epoch 10 batch id 224 loss 1.2773185968399048 train acc 0.7619977678571429\n",
            "epoch 10 batch id 225 loss 1.2232718467712402 train acc 0.7617361111111111\n",
            "epoch 10 batch id 226 loss 1.0363080501556396 train acc 0.761545907079646\n",
            "epoch 10 batch id 227 loss 1.002557396888733 train acc 0.7615638766519823\n",
            "epoch 10 batch id 228 loss 0.8511859178543091 train acc 0.7618558114035088\n",
            "epoch 10 batch id 229 loss 0.8146418929100037 train acc 0.76180403930131\n",
            "epoch 10 batch id 230 loss 0.6550247073173523 train acc 0.7620244565217391\n",
            "epoch 10 batch id 231 loss 0.7104526162147522 train acc 0.7623782467532467\n",
            "epoch 10 batch id 232 loss 0.8073521852493286 train acc 0.7626616379310345\n",
            "epoch 10 batch id 233 loss 0.9893031120300293 train acc 0.7626743562231759\n",
            "epoch 10 batch id 234 loss 0.5844957232475281 train acc 0.7630208333333334\n",
            "epoch 10 batch id 235 loss 0.9858283996582031 train acc 0.7627659574468085\n",
            "epoch 10 batch id 236 loss 0.7762882709503174 train acc 0.7629766949152542\n",
            "epoch 10 batch id 237 loss 0.9024327397346497 train acc 0.7631197257383966\n",
            "epoch 10 batch id 238 loss 0.8520382642745972 train acc 0.7633272058823529\n",
            "epoch 10 batch id 239 loss 0.7008827924728394 train acc 0.763532949790795\n",
            "epoch 10 batch id 240 loss 0.786611020565033 train acc 0.7636067708333333\n",
            "epoch 10 batch id 241 loss 0.7466579675674438 train acc 0.7638744813278008\n",
            "epoch 10 batch id 242 loss 1.1604734659194946 train acc 0.7636234504132231\n",
            "epoch 10 batch id 243 loss 0.9918361306190491 train acc 0.7634387860082305\n",
            "epoch 10 batch id 244 loss 0.8036726713180542 train acc 0.7633837090163934\n",
            "epoch 10 batch id 245 loss 0.9403704404830933 train acc 0.763329081632653\n",
            "epoch 10 batch id 246 loss 0.8555616736412048 train acc 0.7632748983739838\n",
            "epoch 10 batch id 247 loss 1.1068536043167114 train acc 0.7630946356275303\n",
            "epoch 10 batch id 248 loss 0.6149603128433228 train acc 0.7636088709677419\n",
            "epoch 10 batch id 249 loss 1.0531452894210815 train acc 0.7637424698795181\n",
            "epoch 10 batch id 250 loss 0.920421838760376 train acc 0.763625\n",
            "epoch 10 batch id 251 loss 1.0261644124984741 train acc 0.7635084661354582\n",
            "epoch 10 batch id 252 loss 0.8098142147064209 train acc 0.763640873015873\n",
            "epoch 10 batch id 253 loss 0.8317425847053528 train acc 0.7637104743083004\n",
            "epoch 10 batch id 254 loss 0.6205739974975586 train acc 0.7638410433070866\n",
            "epoch 10 batch id 255 loss 1.339011311531067 train acc 0.7635416666666667\n",
            "epoch 10 batch id 256 loss 0.7982159852981567 train acc 0.76361083984375\n",
            "epoch 10 batch id 257 loss 0.8603491187095642 train acc 0.7636794747081712\n",
            "epoch 10 batch id 258 loss 0.7367042303085327 train acc 0.7639292635658915\n",
            "epoch 10 batch id 259 loss 0.7153536677360535 train acc 0.7640564671814671\n",
            "epoch 10 batch id 260 loss 0.54167240858078 train acc 0.7644230769230769\n",
            "epoch 10 batch id 261 loss 1.0445729494094849 train acc 0.764367816091954\n",
            "epoch 10 batch id 262 loss 0.8875179290771484 train acc 0.7644322519083969\n",
            "epoch 10 batch id 263 loss 0.7134961485862732 train acc 0.7646744296577946\n",
            "epoch 10 batch id 264 loss 0.9472389221191406 train acc 0.7647964015151515\n",
            "epoch 10 batch id 265 loss 1.014320969581604 train acc 0.7645047169811321\n",
            "epoch 10 batch id 266 loss 0.8552168607711792 train acc 0.7643327067669173\n",
            "epoch 10 batch id 267 loss 0.8443702459335327 train acc 0.7643375468164794\n",
            "epoch 10 batch id 268 loss 0.6505168676376343 train acc 0.7646338619402985\n",
            "epoch 10 batch id 269 loss 0.9976593255996704 train acc 0.7645794609665427\n",
            "epoch 10 batch id 270 loss 0.9059633612632751 train acc 0.7646412037037037\n",
            "epoch 10 batch id 271 loss 0.7685129642486572 train acc 0.7648178044280443\n",
            "epoch 10 batch id 272 loss 0.9025025367736816 train acc 0.7647633272058824\n",
            "epoch 10 batch id 273 loss 0.9244567155838013 train acc 0.7647664835164835\n",
            "epoch 10 batch id 274 loss 0.9959221482276917 train acc 0.7644844890510949\n",
            "epoch 10 batch id 275 loss 0.7111096382141113 train acc 0.7646022727272728\n",
            "epoch 10 batch id 276 loss 0.8688327670097351 train acc 0.7646059782608695\n",
            "epoch 10 batch id 277 loss 0.8521159887313843 train acc 0.7648352888086642\n",
            "epoch 10 batch id 278 loss 0.8179769515991211 train acc 0.7649505395683454\n",
            "epoch 10 batch id 279 loss 1.1279728412628174 train acc 0.7646729390681004\n",
            "epoch 10 batch id 280 loss 0.7978399395942688 train acc 0.7647879464285714\n",
            "epoch 10 batch id 281 loss 0.6837747693061829 train acc 0.7650133451957295\n",
            "epoch 10 batch id 282 loss 0.9501073360443115 train acc 0.7649601063829787\n",
            "epoch 10 batch id 283 loss 1.2194818258285522 train acc 0.764631183745583\n",
            "epoch 10 batch id 284 loss 0.6035981774330139 train acc 0.764799735915493\n",
            "epoch 10 batch id 285 loss 0.9666407704353333 train acc 0.7648574561403508\n",
            "epoch 10 batch id 286 loss 1.0200982093811035 train acc 0.7646416083916084\n",
            "epoch 10 batch id 287 loss 1.0178419351577759 train acc 0.764536149825784\n",
            "epoch 10 batch id 288 loss 0.8146910071372986 train acc 0.7646484375\n",
            "epoch 10 batch id 289 loss 1.0716745853424072 train acc 0.7645436851211073\n",
            "epoch 10 batch id 290 loss 0.9278301000595093 train acc 0.7644935344827586\n",
            "epoch 10 batch id 291 loss 1.0438772439956665 train acc 0.7643363402061856\n",
            "epoch 10 batch id 292 loss 0.770138144493103 train acc 0.7645012842465754\n",
            "epoch 10 batch id 293 loss 0.7293246984481812 train acc 0.7647717576791809\n",
            "epoch 10 batch id 294 loss 0.7503179907798767 train acc 0.7648809523809523\n",
            "epoch 10 batch id 295 loss 0.7849986553192139 train acc 0.7649364406779661\n",
            "epoch 10 batch id 296 loss 1.2372562885284424 train acc 0.764622043918919\n",
            "epoch 10 batch id 297 loss 0.9682152271270752 train acc 0.7645728114478114\n",
            "epoch 10 batch id 298 loss 0.870956301689148 train acc 0.7647336409395973\n",
            "epoch 10 batch id 299 loss 1.0129448175430298 train acc 0.7645798494983278\n",
            "epoch 10 batch id 300 loss 0.9053441286087036 train acc 0.7643229166666666\n",
            "epoch 10 batch id 301 loss 0.8116820454597473 train acc 0.7643791528239202\n",
            "epoch 10 batch id 302 loss 0.9729639291763306 train acc 0.7642798013245033\n",
            "epoch 10 batch id 303 loss 0.4384200870990753 train acc 0.7647483498349835\n",
            "epoch 10 batch id 304 loss 1.0604435205459595 train acc 0.7645456414473685\n",
            "epoch 10 batch id 305 loss 0.8694449663162231 train acc 0.7647540983606558\n",
            "epoch 10 batch id 306 loss 0.720622718334198 train acc 0.7648080065359477\n",
            "epoch 10 batch id 307 loss 1.0333386659622192 train acc 0.764810667752443\n",
            "epoch 10 batch id 308 loss 1.016133189201355 train acc 0.764458198051948\n",
            "epoch 10 batch id 309 loss 0.8561376333236694 train acc 0.7644114077669902\n",
            "epoch 10 batch id 310 loss 0.7867668867111206 train acc 0.7644657258064517\n",
            "epoch 10 batch id 311 loss 0.7698495388031006 train acc 0.7646201768488746\n",
            "epoch 10 batch id 312 loss 0.7160167098045349 train acc 0.7649238782051282\n",
            "epoch 10 batch id 313 loss 0.8170138597488403 train acc 0.7650758785942492\n",
            "epoch 10 batch id 314 loss 0.480695903301239 train acc 0.7654259554140127\n",
            "epoch 10 batch id 315 loss 1.0253033638000488 train acc 0.7655753968253968\n",
            "epoch 10 batch id 316 loss 1.343328595161438 train acc 0.7655261075949367\n",
            "epoch 10 batch id 317 loss 0.7035022377967834 train acc 0.7658221608832808\n",
            "epoch 10 batch id 318 loss 1.1408532857894897 train acc 0.7656741352201258\n",
            "epoch 10 batch id 319 loss 0.5819228291511536 train acc 0.7660168495297806\n",
            "epoch 10 batch id 320 loss 0.7375761866569519 train acc 0.765966796875\n",
            "epoch 10 batch id 321 loss 0.8518640398979187 train acc 0.7660630841121495\n",
            "epoch 10 batch id 322 loss 0.7921356558799744 train acc 0.7663043478260869\n",
            "epoch 10 batch id 323 loss 0.5869821906089783 train acc 0.7665924922600619\n",
            "epoch 10 batch id 324 loss 0.5344728231430054 train acc 0.7670235339506173\n",
            "epoch 10 batch id 325 loss 0.869411826133728 train acc 0.7669230769230769\n",
            "epoch 10 batch id 326 loss 1.0627979040145874 train acc 0.7666794478527608\n",
            "epoch 10 batch id 327 loss 0.8973405957221985 train acc 0.7666762232415902\n",
            "epoch 10 batch id 328 loss 0.9060759544372559 train acc 0.7668159298780488\n",
            "epoch 10 batch id 329 loss 0.7855646014213562 train acc 0.7668598024316109\n",
            "epoch 10 batch id 330 loss 0.9221773743629456 train acc 0.766903409090909\n",
            "epoch 10 batch id 331 loss 0.6813660264015198 train acc 0.7669939577039275\n",
            "epoch 10 batch id 332 loss 0.7828025221824646 train acc 0.7671310240963856\n",
            "epoch 10 batch id 333 loss 1.0031064748764038 train acc 0.7670326576576577\n",
            "epoch 10 batch id 334 loss 0.9561612010002136 train acc 0.7668880988023952\n",
            "epoch 10 batch id 335 loss 0.8434885740280151 train acc 0.767070895522388\n",
            "epoch 10 batch id 336 loss 0.7044139504432678 train acc 0.7671130952380952\n",
            "epoch 10 batch id 337 loss 0.6923427581787109 train acc 0.7672014094955489\n",
            "epoch 10 batch id 338 loss 0.8508475422859192 train acc 0.7671042899408284\n",
            "epoch 10 batch id 339 loss 0.9765422940254211 train acc 0.7670077433628318\n",
            "epoch 10 batch id 340 loss 0.8723114132881165 train acc 0.7670036764705882\n",
            "epoch 10 batch id 341 loss 0.509747326374054 train acc 0.7673203812316716\n",
            "epoch 10 batch id 342 loss 0.7269183993339539 train acc 0.7675895467836257\n",
            "epoch 10 batch id 343 loss 1.1498117446899414 train acc 0.7674016034985423\n",
            "epoch 10 batch id 344 loss 0.606987476348877 train acc 0.7676689680232558\n",
            "epoch 10 batch id 345 loss 0.8333999514579773 train acc 0.7677083333333333\n",
            "epoch 10 batch id 346 loss 0.6350885033607483 train acc 0.7678829479768786\n",
            "epoch 10 batch id 347 loss 0.8712416887283325 train acc 0.7679664985590778\n",
            "epoch 10 batch id 348 loss 0.8636016249656677 train acc 0.7678699712643678\n",
            "epoch 10 batch id 349 loss 0.9084456562995911 train acc 0.7678635386819485\n",
            "epoch 10 batch id 350 loss 0.8429417014122009 train acc 0.7679017857142857\n",
            "epoch 10 batch id 351 loss 0.8921968936920166 train acc 0.7678952991452992\n",
            "epoch 10 batch id 352 loss 0.6667042970657349 train acc 0.7680220170454546\n",
            "epoch 10 batch id 353 loss 1.1643873453140259 train acc 0.7678824362606232\n",
            "epoch 10 batch id 354 loss 0.7123483419418335 train acc 0.7678760593220338\n",
            "epoch 10 batch id 355 loss 0.8770313858985901 train acc 0.7678697183098592\n",
            "epoch 10 batch id 356 loss 0.874668300151825 train acc 0.7678195224719101\n",
            "epoch 10 batch id 357 loss 1.2067869901657104 train acc 0.7674632352941176\n",
            "epoch 10 batch id 358 loss 1.1658743619918823 train acc 0.7673708100558659\n",
            "epoch 10 batch id 359 loss 1.0746629238128662 train acc 0.7671483286908078\n",
            "epoch 10 batch id 360 loss 0.7522163391113281 train acc 0.7672743055555555\n",
            "epoch 10 batch id 361 loss 0.6521365642547607 train acc 0.7674428670360111\n",
            "epoch 10 batch id 362 loss 0.7494387030601501 train acc 0.7675673342541437\n",
            "epoch 10 batch id 363 loss 1.0014081001281738 train acc 0.7675189393939394\n",
            "epoch 10 batch id 364 loss 0.8198560476303101 train acc 0.7674708104395604\n",
            "epoch 10 batch id 365 loss 0.767203688621521 train acc 0.7675941780821918\n",
            "epoch 10 batch id 366 loss 0.7719489932060242 train acc 0.7675887978142076\n",
            "epoch 10 batch id 367 loss 0.625882089138031 train acc 0.7676685967302452\n",
            "epoch 10 batch id 368 loss 0.8109964728355408 train acc 0.7677055027173914\n",
            "epoch 10 batch id 369 loss 0.8216547966003418 train acc 0.7677422086720868\n",
            "epoch 10 batch id 370 loss 0.5844201445579529 train acc 0.7679898648648649\n",
            "epoch 10 batch id 371 loss 0.8426030874252319 train acc 0.7679413746630728\n",
            "epoch 10 batch id 372 loss 0.7174134850502014 train acc 0.7681451612903226\n",
            "epoch 10 batch id 373 loss 0.7156296372413635 train acc 0.7682221849865952\n",
            "epoch 10 batch id 374 loss 0.7848968505859375 train acc 0.7682987967914439\n",
            "epoch 10 batch id 375 loss 0.867572546005249 train acc 0.768375\n",
            "epoch 10 batch id 376 loss 0.7872092723846436 train acc 0.7684507978723404\n",
            "epoch 10 batch id 377 loss 0.958260178565979 train acc 0.7683604111405835\n",
            "epoch 10 batch id 378 loss 0.6849861145019531 train acc 0.7685598544973545\n",
            "epoch 10 batch id 379 loss 0.7444747686386108 train acc 0.7686345646437994\n",
            "epoch 10 batch id 380 loss 0.761622965335846 train acc 0.7687911184210526\n",
            "epoch 10 batch id 381 loss 0.9275981783866882 train acc 0.7687417979002624\n",
            "epoch 10 batch id 382 loss 0.822591245174408 train acc 0.7686109293193717\n",
            "epoch 10 batch id 383 loss 0.9778391718864441 train acc 0.7685623368146214\n",
            "epoch 10 batch id 384 loss 1.0624648332595825 train acc 0.7684326171875\n",
            "epoch 10 batch id 385 loss 0.4937078058719635 train acc 0.7687094155844156\n",
            "epoch 10 batch id 386 loss 0.8562544584274292 train acc 0.7687014248704663\n",
            "epoch 10 batch id 387 loss 0.8938536643981934 train acc 0.7687338501291989\n",
            "epoch 10 batch id 388 loss 0.8344905376434326 train acc 0.7687258376288659\n",
            "epoch 10 batch id 389 loss 0.7313804030418396 train acc 0.7687580334190232\n",
            "epoch 10 batch id 390 loss 0.9278095960617065 train acc 0.76875\n",
            "epoch 10 batch id 391 loss 0.9470849633216858 train acc 0.7687420076726342\n",
            "epoch 10 batch id 392 loss 0.8619846701622009 train acc 0.7686941964285714\n",
            "epoch 10 batch id 393 loss 0.9615005254745483 train acc 0.7685671119592875\n",
            "epoch 10 batch id 394 loss 0.6059380769729614 train acc 0.7687975888324873\n",
            "epoch 10 batch id 395 loss 0.6989234685897827 train acc 0.7687895569620253\n",
            "epoch 10 batch id 396 loss 0.8318791389465332 train acc 0.7688210227272727\n",
            "epoch 10 batch id 397 loss 0.7824913263320923 train acc 0.7688523299748111\n",
            "epoch 10 batch id 398 loss 0.7909542918205261 train acc 0.7689619974874372\n",
            "epoch 10 batch id 399 loss 0.6720044016838074 train acc 0.7690711152882206\n",
            "epoch 10 batch id 400 loss 0.850771427154541 train acc 0.7690625\n",
            "epoch 10 batch id 401 loss 1.2779903411865234 train acc 0.7688201371571073\n",
            "epoch 10 batch id 402 loss 0.7839412093162537 train acc 0.7689287935323383\n",
            "epoch 10 batch id 403 loss 0.5870354771614075 train acc 0.7691532258064516\n",
            "epoch 10 batch id 404 loss 0.7424530386924744 train acc 0.769221844059406\n",
            "epoch 10 batch id 405 loss 0.6209381818771362 train acc 0.769483024691358\n",
            "epoch 10 batch id 406 loss 0.5319540500640869 train acc 0.7697044334975369\n",
            "epoch 10 batch id 407 loss 1.2140909433364868 train acc 0.7695408476658476\n",
            "epoch 10 batch id 408 loss 1.0366246700286865 train acc 0.7695695465686274\n",
            "epoch 10 batch id 409 loss 0.8926437497138977 train acc 0.7695216992665037\n",
            "epoch 10 batch id 410 loss 0.752397894859314 train acc 0.7695884146341463\n",
            "epoch 10 batch id 411 loss 0.7304569482803345 train acc 0.7697308394160584\n",
            "epoch 10 batch id 412 loss 0.7329301238059998 train acc 0.7698346480582524\n",
            "epoch 10 batch id 413 loss 0.7178481817245483 train acc 0.7699757869249395\n",
            "epoch 10 batch id 414 loss 0.9001342058181763 train acc 0.769927536231884\n",
            "epoch 10 batch id 415 loss 1.092201828956604 train acc 0.7698042168674699\n",
            "epoch 10 batch id 416 loss 1.048530101776123 train acc 0.7696063701923077\n",
            "epoch 10 batch id 417 loss 0.8464728593826294 train acc 0.7695593525179856\n",
            "epoch 10 batch id 418 loss 0.8638638257980347 train acc 0.769363038277512\n",
            "epoch 10 batch id 419 loss 0.8880931735038757 train acc 0.7692795346062052\n",
            "epoch 10 batch id 420 loss 0.7569401860237122 train acc 0.7693824404761904\n",
            "epoch 10 batch id 421 loss 0.9265395998954773 train acc 0.7692621733966746\n",
            "epoch 10 batch id 422 loss 0.7221182584762573 train acc 0.7694386848341233\n",
            "epoch 10 batch id 423 loss 0.9873668551445007 train acc 0.7693927304964538\n",
            "epoch 10 batch id 424 loss 0.7300828695297241 train acc 0.7694943985849056\n",
            "epoch 10 batch id 425 loss 0.7672886252403259 train acc 0.7695220588235294\n",
            "epoch 10 batch id 426 loss 0.5855264067649841 train acc 0.7697329812206573\n",
            "epoch 10 batch id 427 loss 0.4299757778644562 train acc 0.7699429156908665\n",
            "epoch 10 batch id 428 loss 0.6381955742835999 train acc 0.7701883761682243\n",
            "epoch 10 batch id 429 loss 0.960766077041626 train acc 0.7701777389277389\n",
            "epoch 10 batch id 430 loss 1.100634217262268 train acc 0.7701308139534884\n",
            "epoch 10 batch id 431 loss 0.7339569926261902 train acc 0.7703016241299304\n",
            "epoch 10 batch id 432 loss 0.6987929344177246 train acc 0.7702907986111112\n",
            "epoch 10 batch id 433 loss 0.6017712950706482 train acc 0.7704243648960739\n",
            "epoch 10 batch id 434 loss 0.5826377868652344 train acc 0.7706293202764977\n",
            "epoch 10 batch id 435 loss 0.4027736783027649 train acc 0.7707974137931034\n",
            "epoch 10 batch id 436 loss 0.9905233383178711 train acc 0.7707855504587156\n",
            "epoch 10 batch id 437 loss 0.9119880199432373 train acc 0.7708094965675057\n",
            "epoch 10 batch id 438 loss 0.8880015015602112 train acc 0.770869006849315\n",
            "epoch 10 batch id 439 loss 1.0493441820144653 train acc 0.770750284738041\n",
            "epoch 10 batch id 440 loss 0.9747677445411682 train acc 0.770809659090909\n",
            "epoch 10 batch id 441 loss 0.8689758777618408 train acc 0.7707624716553289\n",
            "epoch 10 batch id 442 loss 0.7679850459098816 train acc 0.7707861990950227\n",
            "epoch 10 batch id 443 loss 0.8522982001304626 train acc 0.7708450902934537\n",
            "epoch 10 batch id 444 loss 0.8516330718994141 train acc 0.7708685247747747\n",
            "epoch 10 batch id 445 loss 0.6811785101890564 train acc 0.770997191011236\n",
            "epoch 10 batch id 446 loss 0.8578680157661438 train acc 0.7710552130044843\n",
            "epoch 10 batch id 447 loss 0.6508928537368774 train acc 0.7712527964205816\n",
            "epoch 10 batch id 448 loss 0.7782730460166931 train acc 0.771484375\n",
            "epoch 10 batch id 449 loss 0.5008553266525269 train acc 0.7717149220489977\n",
            "epoch 10 batch id 450 loss 0.5829627513885498 train acc 0.7718055555555555\n",
            "epoch 10 batch id 451 loss 0.6832305788993835 train acc 0.7720690133037694\n",
            "epoch 10 batch id 452 loss 0.7932915091514587 train acc 0.7722275995575221\n",
            "epoch 10 batch id 453 loss 0.7523325681686401 train acc 0.7723854856512141\n",
            "epoch 10 batch id 454 loss 0.7212898135185242 train acc 0.7725082599118943\n",
            "epoch 10 batch id 455 loss 0.977199137210846 train acc 0.7725961538461539\n",
            "epoch 10 batch id 456 loss 0.5922199487686157 train acc 0.7728207236842105\n",
            "epoch 10 batch id 457 loss 0.8445483446121216 train acc 0.7728391684901532\n",
            "epoch 10 batch id 458 loss 1.0235978364944458 train acc 0.7728234170305677\n",
            "epoch 10 batch id 459 loss 0.6746334433555603 train acc 0.7729098583877996\n",
            "epoch 10 batch id 460 loss 0.7270371913909912 train acc 0.7729279891304348\n",
            "epoch 10 batch id 461 loss 0.7228742837905884 train acc 0.7731155097613883\n",
            "epoch 10 batch id 462 loss 0.7454246282577515 train acc 0.7732007575757576\n",
            "epoch 10 batch id 463 loss 1.1373213529586792 train acc 0.7729481641468683\n",
            "epoch 10 batch id 464 loss 0.8854426741600037 train acc 0.7729660560344828\n",
            "epoch 10 batch id 465 loss 0.5309698581695557 train acc 0.773252688172043\n",
            "epoch 10 batch id 466 loss 0.8459535837173462 train acc 0.7733033798283262\n",
            "epoch 10 batch id 467 loss 0.916556715965271 train acc 0.7732534796573876\n",
            "epoch 10 batch id 468 loss 0.9409565329551697 train acc 0.7732037927350427\n",
            "epoch 10 batch id 469 loss 0.5470935702323914 train acc 0.7732209488272921\n",
            "epoch 10 batch id 470 loss 0.8630539178848267 train acc 0.7732047872340425\n",
            "epoch 10 batch id 471 loss 0.8934680223464966 train acc 0.7730891719745223\n",
            "epoch 10 batch id 472 loss 0.7463163733482361 train acc 0.7731395656779662\n",
            "epoch 10 batch id 473 loss 0.8604276776313782 train acc 0.7731236786469344\n",
            "epoch 10 batch id 474 loss 0.9985524415969849 train acc 0.773074894514768\n",
            "epoch 10 batch id 475 loss 0.5223639011383057 train acc 0.7732565789473684\n",
            "epoch 10 batch id 476 loss 0.7996363639831543 train acc 0.7733061974789915\n",
            "epoch 10 batch id 477 loss 0.6800850629806519 train acc 0.7734538784067087\n",
            "epoch 10 batch id 478 loss 0.8082775473594666 train acc 0.7734375\n",
            "epoch 10 batch id 479 loss 0.7485126852989197 train acc 0.7735516701461378\n",
            "epoch 10 batch id 480 loss 0.8571152091026306 train acc 0.7736328125\n",
            "epoch 10 batch id 481 loss 0.6716763973236084 train acc 0.7737785862785863\n",
            "epoch 10 batch id 482 loss 0.6763357520103455 train acc 0.7738913381742739\n",
            "epoch 10 batch id 483 loss 0.6567834615707397 train acc 0.7740359730848861\n",
            "epoch 10 batch id 484 loss 0.9666880965232849 train acc 0.7740508780991735\n",
            "epoch 10 batch id 485 loss 1.2074888944625854 train acc 0.773840206185567\n",
            "epoch 10 batch id 486 loss 0.5480297207832336 train acc 0.774048353909465\n",
            "epoch 10 batch id 487 loss 0.6919947862625122 train acc 0.7741273100616016\n",
            "epoch 10 batch id 488 loss 0.6920298933982849 train acc 0.7741419057377049\n",
            "epoch 10 batch id 489 loss 0.6937813758850098 train acc 0.7742523006134969\n",
            "epoch 10 batch id 490 loss 0.6296788454055786 train acc 0.7743622448979591\n",
            "epoch 10 batch id 491 loss 0.829824686050415 train acc 0.7744399185336049\n",
            "epoch 10 batch id 492 loss 0.6032921075820923 train acc 0.7745490345528455\n",
            "epoch 10 batch id 493 loss 0.9183467030525208 train acc 0.7744992393509128\n",
            "epoch 10 batch id 494 loss 0.5284895896911621 train acc 0.7747659412955465\n",
            "epoch 10 batch id 495 loss 0.7145940661430359 train acc 0.774715909090909\n",
            "epoch 10 batch id 496 loss 0.7949960827827454 train acc 0.7746660786290323\n",
            "epoch 10 batch id 497 loss 0.602141797542572 train acc 0.7748050804828974\n",
            "epoch 10 batch id 498 loss 1.069439172744751 train acc 0.7746925200803213\n",
            "epoch 10 batch id 499 loss 0.5172149538993835 train acc 0.7747995991983968\n",
            "epoch 10 batch id 500 loss 0.5723936557769775 train acc 0.7749375\n",
            "epoch 10 batch id 501 loss 0.7426924705505371 train acc 0.7749812874251497\n",
            "epoch 10 batch id 502 loss 0.6727120876312256 train acc 0.7749937749003984\n",
            "epoch 10 batch id 503 loss 0.9221534132957458 train acc 0.7749751491053678\n",
            "epoch 10 batch id 504 loss 0.7235656380653381 train acc 0.7750496031746031\n",
            "epoch 10 batch id 505 loss 0.5117952227592468 train acc 0.7752165841584159\n",
            "epoch 10 batch id 506 loss 1.0329729318618774 train acc 0.775197628458498\n",
            "epoch 10 batch id 507 loss 0.5330917239189148 train acc 0.7754252958579881\n",
            "epoch 10 batch id 508 loss 0.7376381158828735 train acc 0.7754060039370079\n",
            "epoch 10 batch id 509 loss 0.5066375732421875 train acc 0.775601669941061\n",
            "epoch 10 batch id 510 loss 0.5321841239929199 train acc 0.7757965686274509\n",
            "epoch 10 batch id 511 loss 0.6912482976913452 train acc 0.7758004457490759\n",
            "epoch 10 train acc 0.7758004457490759\n",
            "epoch 10 test acc 0.3958333333333333\n",
            "epoch 11 batch id 1 loss 0.6788752675056458 train acc 0.796875\n",
            "epoch 11 batch id 2 loss 0.7732998132705688 train acc 0.78125\n",
            "epoch 11 batch id 3 loss 0.8855340480804443 train acc 0.765625\n",
            "epoch 11 batch id 4 loss 1.0242102146148682 train acc 0.75390625\n",
            "epoch 11 batch id 5 loss 0.8481590151786804 train acc 0.76875\n",
            "epoch 11 batch id 6 loss 0.8456281423568726 train acc 0.7604166666666666\n",
            "epoch 11 batch id 7 loss 0.784703254699707 train acc 0.7589285714285714\n",
            "epoch 11 batch id 8 loss 0.7754241824150085 train acc 0.76171875\n",
            "epoch 11 batch id 9 loss 0.816412091255188 train acc 0.7621527777777778\n",
            "epoch 11 batch id 10 loss 1.0394985675811768 train acc 0.7578125\n",
            "epoch 11 batch id 11 loss 0.601097822189331 train acc 0.7684659090909091\n",
            "epoch 11 batch id 12 loss 0.5696114897727966 train acc 0.7760416666666666\n",
            "epoch 11 batch id 13 loss 0.4669252932071686 train acc 0.7872596153846154\n",
            "epoch 11 batch id 14 loss 0.7133138179779053 train acc 0.7924107142857143\n",
            "epoch 11 batch id 15 loss 0.7076665163040161 train acc 0.79375\n",
            "epoch 11 batch id 16 loss 0.9361273050308228 train acc 0.7919921875\n",
            "epoch 11 batch id 17 loss 0.7117093205451965 train acc 0.7886029411764706\n",
            "epoch 11 batch id 18 loss 0.7263544201850891 train acc 0.7881944444444444\n",
            "epoch 11 batch id 19 loss 0.7335563898086548 train acc 0.787828947368421\n",
            "epoch 11 batch id 20 loss 0.8510517477989197 train acc 0.7875\n",
            "epoch 11 batch id 21 loss 0.7113122940063477 train acc 0.7879464285714286\n",
            "epoch 11 batch id 22 loss 1.2009018659591675 train acc 0.7833806818181818\n",
            "epoch 11 batch id 23 loss 0.9503454566001892 train acc 0.7839673913043478\n",
            "epoch 11 batch id 24 loss 0.7217565774917603 train acc 0.7864583333333334\n",
            "epoch 11 batch id 25 loss 0.7878619432449341 train acc 0.7875\n",
            "epoch 11 batch id 26 loss 0.7686994075775146 train acc 0.7890625\n",
            "epoch 11 batch id 27 loss 0.7618141174316406 train acc 0.7905092592592593\n",
            "epoch 11 batch id 28 loss 1.0427192449569702 train acc 0.7879464285714286\n",
            "epoch 11 batch id 29 loss 0.904181957244873 train acc 0.787176724137931\n",
            "epoch 11 batch id 30 loss 1.0785231590270996 train acc 0.784375\n",
            "epoch 11 batch id 31 loss 0.6950638890266418 train acc 0.7857862903225806\n",
            "epoch 11 batch id 32 loss 0.7467653751373291 train acc 0.78564453125\n",
            "epoch 11 batch id 33 loss 1.0669537782669067 train acc 0.7859848484848485\n",
            "epoch 11 batch id 34 loss 0.6889997124671936 train acc 0.7867647058823529\n",
            "epoch 11 batch id 35 loss 1.0428476333618164 train acc 0.7857142857142857\n",
            "epoch 11 batch id 36 loss 0.6551871299743652 train acc 0.7860243055555556\n",
            "epoch 11 batch id 37 loss 0.6241990923881531 train acc 0.7867398648648649\n",
            "epoch 11 batch id 38 loss 0.9584971070289612 train acc 0.7865953947368421\n",
            "epoch 11 batch id 39 loss 1.0914390087127686 train acc 0.7852564102564102\n",
            "epoch 11 batch id 40 loss 0.6173394322395325 train acc 0.787109375\n",
            "epoch 11 batch id 41 loss 0.7746075391769409 train acc 0.7854420731707317\n",
            "epoch 11 batch id 42 loss 0.6339206099510193 train acc 0.7857142857142857\n",
            "epoch 11 batch id 43 loss 0.7259906530380249 train acc 0.7856104651162791\n",
            "epoch 11 batch id 44 loss 0.7236990928649902 train acc 0.7865767045454546\n",
            "epoch 11 batch id 45 loss 0.581609308719635 train acc 0.7875\n",
            "epoch 11 batch id 46 loss 0.8086373209953308 train acc 0.7883831521739131\n",
            "epoch 11 batch id 47 loss 0.939158022403717 train acc 0.7875664893617021\n",
            "epoch 11 batch id 48 loss 0.630569338798523 train acc 0.7890625\n",
            "epoch 11 batch id 49 loss 0.9889240860939026 train acc 0.7882653061224489\n",
            "epoch 11 batch id 50 loss 0.9821972846984863 train acc 0.7871875\n",
            "epoch 11 batch id 51 loss 0.6570942997932434 train acc 0.7876838235294118\n",
            "epoch 11 batch id 52 loss 1.2210545539855957 train acc 0.7854567307692307\n",
            "epoch 11 batch id 53 loss 0.6916625499725342 train acc 0.7856721698113207\n",
            "epoch 11 batch id 54 loss 0.7520297765731812 train acc 0.7870370370370371\n",
            "epoch 11 batch id 55 loss 0.7470475435256958 train acc 0.7869318181818182\n",
            "epoch 11 batch id 56 loss 0.5984562635421753 train acc 0.7879464285714286\n",
            "epoch 11 batch id 57 loss 0.7004125714302063 train acc 0.7872807017543859\n",
            "epoch 11 batch id 58 loss 0.9931057691574097 train acc 0.7860991379310345\n",
            "epoch 11 batch id 59 loss 0.9355882406234741 train acc 0.7865466101694916\n",
            "epoch 11 batch id 60 loss 0.8029133677482605 train acc 0.7869791666666667\n",
            "epoch 11 batch id 61 loss 0.6546927094459534 train acc 0.7879098360655737\n",
            "epoch 11 batch id 62 loss 0.5345093607902527 train acc 0.7890625\n",
            "epoch 11 batch id 63 loss 0.62330162525177 train acc 0.7901785714285714\n",
            "epoch 11 batch id 64 loss 0.5690581202507019 train acc 0.790771484375\n",
            "epoch 11 batch id 65 loss 0.8568187952041626 train acc 0.790625\n",
            "epoch 11 batch id 66 loss 0.5355436205863953 train acc 0.7914299242424242\n",
            "epoch 11 batch id 67 loss 0.589557945728302 train acc 0.7926772388059702\n",
            "epoch 11 batch id 68 loss 0.7307314872741699 train acc 0.7934283088235294\n",
            "epoch 11 batch id 69 loss 0.7743833661079407 train acc 0.7932518115942029\n",
            "epoch 11 batch id 70 loss 1.0491915941238403 train acc 0.7928571428571428\n",
            "epoch 11 batch id 71 loss 0.6922881007194519 train acc 0.7931338028169014\n",
            "epoch 11 batch id 72 loss 0.8585330843925476 train acc 0.7934027777777778\n",
            "epoch 11 batch id 73 loss 0.6663283109664917 train acc 0.7940924657534246\n",
            "epoch 11 batch id 74 loss 0.9321221113204956 train acc 0.7941300675675675\n",
            "epoch 11 batch id 75 loss 0.761448860168457 train acc 0.7941666666666667\n",
            "epoch 11 batch id 76 loss 0.8740570545196533 train acc 0.7935855263157895\n",
            "epoch 11 batch id 77 loss 0.5623482465744019 train acc 0.7940340909090909\n",
            "epoch 11 batch id 78 loss 0.9865797758102417 train acc 0.7932692307692307\n",
            "epoch 11 batch id 79 loss 0.5984883904457092 train acc 0.7937104430379747\n",
            "epoch 11 batch id 80 loss 1.0999871492385864 train acc 0.7921875\n",
            "epoch 11 batch id 81 loss 0.7995920181274414 train acc 0.7924382716049383\n",
            "epoch 11 batch id 82 loss 0.71065753698349 train acc 0.7923018292682927\n",
            "epoch 11 batch id 83 loss 0.8158586621284485 train acc 0.7917921686746988\n",
            "epoch 11 batch id 84 loss 0.5505980849266052 train acc 0.7924107142857143\n",
            "epoch 11 batch id 85 loss 0.6106078624725342 train acc 0.7926470588235294\n",
            "epoch 11 batch id 86 loss 0.8280535340309143 train acc 0.7926962209302325\n",
            "epoch 11 batch id 87 loss 0.8491089344024658 train acc 0.7931034482758621\n",
            "epoch 11 batch id 88 loss 0.7956057786941528 train acc 0.7936789772727273\n",
            "epoch 11 batch id 89 loss 0.6719818115234375 train acc 0.7940660112359551\n",
            "epoch 11 batch id 90 loss 0.6201547384262085 train acc 0.7942708333333334\n",
            "epoch 11 batch id 91 loss 0.937340259552002 train acc 0.7936126373626373\n",
            "epoch 11 batch id 92 loss 0.8525501489639282 train acc 0.7933084239130435\n",
            "epoch 11 batch id 93 loss 0.8836159706115723 train acc 0.7933467741935484\n",
            "epoch 11 batch id 94 loss 0.9832318425178528 train acc 0.793218085106383\n",
            "epoch 11 batch id 95 loss 0.4822941720485687 train acc 0.7939144736842105\n",
            "epoch 11 batch id 96 loss 0.6737010478973389 train acc 0.7939453125\n",
            "epoch 11 batch id 97 loss 0.696846604347229 train acc 0.7942976804123711\n",
            "epoch 11 batch id 98 loss 0.6882428526878357 train acc 0.7943239795918368\n",
            "epoch 11 batch id 99 loss 0.8456643223762512 train acc 0.7940340909090909\n",
            "epoch 11 batch id 100 loss 0.5337389707565308 train acc 0.79453125\n",
            "epoch 11 batch id 101 loss 0.8486176133155823 train acc 0.7940903465346535\n",
            "epoch 11 batch id 102 loss 0.8962041139602661 train acc 0.7942708333333334\n",
            "epoch 11 batch id 103 loss 0.6255307197570801 train acc 0.794751213592233\n",
            "epoch 11 batch id 104 loss 0.799102246761322 train acc 0.7947716346153846\n",
            "epoch 11 batch id 105 loss 0.7700045108795166 train acc 0.7956845238095238\n",
            "epoch 11 batch id 106 loss 0.556692898273468 train acc 0.7962853773584906\n",
            "epoch 11 batch id 107 loss 0.8927417397499084 train acc 0.795998831775701\n",
            "epoch 11 batch id 108 loss 0.4212760031223297 train acc 0.7967303240740741\n",
            "epoch 11 batch id 109 loss 0.6585325002670288 train acc 0.796875\n",
            "epoch 11 batch id 110 loss 0.9246378540992737 train acc 0.7967329545454546\n",
            "epoch 11 batch id 111 loss 0.7279647588729858 train acc 0.7965934684684685\n",
            "epoch 11 batch id 112 loss 1.0744739770889282 train acc 0.7957589285714286\n",
            "epoch 11 batch id 113 loss 0.9229205846786499 train acc 0.7954922566371682\n",
            "epoch 11 batch id 114 loss 0.8206670880317688 train acc 0.7955043859649122\n",
            "epoch 11 batch id 115 loss 0.800432026386261 train acc 0.7951086956521739\n",
            "epoch 11 batch id 116 loss 0.6885631084442139 train acc 0.7951239224137931\n",
            "epoch 11 batch id 117 loss 0.6625216603279114 train acc 0.7951388888888888\n",
            "epoch 11 batch id 118 loss 0.7556122541427612 train acc 0.7954184322033898\n",
            "epoch 11 batch id 119 loss 0.8842973113059998 train acc 0.7954306722689075\n",
            "epoch 11 batch id 120 loss 0.8384484648704529 train acc 0.7951822916666667\n",
            "epoch 11 batch id 121 loss 0.8990206718444824 train acc 0.7951962809917356\n",
            "epoch 11 batch id 122 loss 0.7754666805267334 train acc 0.7950819672131147\n",
            "epoch 11 batch id 123 loss 0.6756337881088257 train acc 0.7953506097560976\n",
            "epoch 11 batch id 124 loss 0.69092857837677 train acc 0.795866935483871\n",
            "epoch 11 batch id 125 loss 1.1457674503326416 train acc 0.79525\n",
            "epoch 11 batch id 126 loss 0.860304594039917 train acc 0.7951388888888888\n",
            "epoch 11 batch id 127 loss 0.7079587578773499 train acc 0.7950295275590551\n",
            "epoch 11 batch id 128 loss 0.7604878544807434 train acc 0.7952880859375\n",
            "epoch 11 batch id 129 loss 0.3951578140258789 train acc 0.7962693798449613\n",
            "epoch 11 batch id 130 loss 0.7840280532836914 train acc 0.7963942307692308\n",
            "epoch 11 batch id 131 loss 1.009581446647644 train acc 0.7954437022900763\n",
            "epoch 11 batch id 132 loss 0.8401942253112793 train acc 0.7948626893939394\n",
            "epoch 11 batch id 133 loss 0.9336891770362854 train acc 0.7945253759398496\n",
            "epoch 11 batch id 134 loss 0.8304505944252014 train acc 0.7945429104477612\n",
            "epoch 11 batch id 135 loss 0.6081734299659729 train acc 0.7949074074074074\n",
            "epoch 11 batch id 136 loss 0.6517366766929626 train acc 0.7951516544117647\n",
            "epoch 11 batch id 137 loss 0.7189847230911255 train acc 0.7956204379562044\n",
            "epoch 11 batch id 138 loss 0.4867555797100067 train acc 0.7960824275362319\n",
            "epoch 11 batch id 139 loss 0.8656104803085327 train acc 0.7963129496402878\n",
            "epoch 11 batch id 140 loss 0.9543887376785278 train acc 0.7958705357142857\n",
            "epoch 11 batch id 141 loss 0.9291957020759583 train acc 0.7955452127659575\n",
            "epoch 11 batch id 142 loss 0.7307125926017761 train acc 0.795774647887324\n",
            "epoch 11 batch id 143 loss 0.5047101974487305 train acc 0.7962194055944056\n",
            "epoch 11 batch id 144 loss 0.6520218253135681 train acc 0.7965494791666666\n",
            "epoch 11 batch id 145 loss 0.5107234716415405 train acc 0.7970905172413794\n",
            "epoch 11 batch id 146 loss 0.7465771436691284 train acc 0.797410102739726\n",
            "epoch 11 batch id 147 loss 0.6957021355628967 train acc 0.7973001700680272\n",
            "epoch 11 batch id 148 loss 0.6838326454162598 train acc 0.7974028716216216\n",
            "epoch 11 batch id 149 loss 0.5973899364471436 train acc 0.7976090604026845\n",
            "epoch 11 batch id 150 loss 0.9083027243614197 train acc 0.7971875\n",
            "epoch 11 batch id 151 loss 0.7604759931564331 train acc 0.7972889072847682\n",
            "epoch 11 batch id 152 loss 0.7642043232917786 train acc 0.7971833881578947\n",
            "epoch 11 batch id 153 loss 0.5987793803215027 train acc 0.7977941176470589\n",
            "epoch 11 batch id 154 loss 0.5956734418869019 train acc 0.7977881493506493\n",
            "epoch 11 batch id 155 loss 0.5885045528411865 train acc 0.7979838709677419\n",
            "epoch 11 batch id 156 loss 0.9474603533744812 train acc 0.7977764423076923\n",
            "epoch 11 batch id 157 loss 0.7100428938865662 train acc 0.79796974522293\n",
            "epoch 11 batch id 158 loss 0.860185980796814 train acc 0.7978639240506329\n",
            "epoch 11 batch id 159 loss 0.6349561214447021 train acc 0.7979559748427673\n",
            "epoch 11 batch id 160 loss 0.680806040763855 train acc 0.7978515625\n",
            "epoch 11 batch id 161 loss 0.6287103891372681 train acc 0.7980395962732919\n",
            "epoch 11 batch id 162 loss 0.5308613181114197 train acc 0.7985146604938271\n",
            "epoch 11 batch id 163 loss 0.640383780002594 train acc 0.7989838957055214\n",
            "epoch 11 batch id 164 loss 0.6444206833839417 train acc 0.7988757621951219\n",
            "epoch 11 batch id 165 loss 0.8965311646461487 train acc 0.7987689393939394\n",
            "epoch 11 batch id 166 loss 0.5636035799980164 train acc 0.7993222891566265\n",
            "epoch 11 batch id 167 loss 0.6401129364967346 train acc 0.7994947604790419\n",
            "epoch 11 batch id 168 loss 0.8167783617973328 train acc 0.7992931547619048\n",
            "epoch 11 batch id 169 loss 0.6463080048561096 train acc 0.7995562130177515\n",
            "epoch 11 batch id 170 loss 0.7655577063560486 train acc 0.7996323529411765\n",
            "epoch 11 batch id 171 loss 0.539372444152832 train acc 0.8001644736842105\n",
            "epoch 11 batch id 172 loss 0.4572334289550781 train acc 0.80078125\n",
            "epoch 11 batch id 173 loss 0.42652660608291626 train acc 0.8013005780346821\n",
            "epoch 11 batch id 174 loss 0.4799478352069855 train acc 0.8015445402298851\n",
            "epoch 11 batch id 175 loss 0.9457855820655823 train acc 0.8009821428571429\n",
            "epoch 11 batch id 176 loss 0.5416622757911682 train acc 0.8014026988636364\n",
            "epoch 11 batch id 177 loss 0.6704099774360657 train acc 0.8013771186440678\n",
            "epoch 11 batch id 178 loss 0.7892414927482605 train acc 0.8013518258426966\n",
            "epoch 11 batch id 179 loss 0.875268816947937 train acc 0.8011522346368715\n",
            "epoch 11 batch id 180 loss 0.436445027589798 train acc 0.8013888888888889\n",
            "epoch 11 batch id 181 loss 0.5919954180717468 train acc 0.801450276243094\n",
            "epoch 11 batch id 182 loss 0.6160618662834167 train acc 0.801510989010989\n",
            "epoch 11 batch id 183 loss 0.6027511954307556 train acc 0.8017418032786885\n",
            "epoch 11 batch id 184 loss 0.5684529542922974 train acc 0.8018851902173914\n",
            "epoch 11 batch id 185 loss 0.6366685628890991 train acc 0.8021114864864864\n",
            "epoch 11 batch id 186 loss 0.6915496587753296 train acc 0.8021673387096774\n",
            "epoch 11 batch id 187 loss 0.6639746427536011 train acc 0.8023061497326203\n",
            "epoch 11 batch id 188 loss 0.8382518291473389 train acc 0.8022772606382979\n",
            "epoch 11 batch id 189 loss 0.6794480681419373 train acc 0.8020833333333334\n",
            "epoch 11 batch id 190 loss 0.6596750020980835 train acc 0.8023026315789473\n",
            "epoch 11 batch id 191 loss 0.9132696986198425 train acc 0.8023560209424084\n",
            "epoch 11 batch id 192 loss 1.049562931060791 train acc 0.8020833333333334\n",
            "epoch 11 batch id 193 loss 0.9259055256843567 train acc 0.8018944300518135\n",
            "epoch 11 batch id 194 loss 0.7104748487472534 train acc 0.8021101804123711\n",
            "epoch 11 batch id 195 loss 0.8563276529312134 train acc 0.8017628205128206\n",
            "epoch 11 batch id 196 loss 0.8535757660865784 train acc 0.8018176020408163\n",
            "epoch 11 batch id 197 loss 0.4600403606891632 train acc 0.8021097715736041\n",
            "epoch 11 batch id 198 loss 0.528719961643219 train acc 0.8022411616161617\n",
            "epoch 11 batch id 199 loss 0.5322953462600708 train acc 0.8022927135678392\n",
            "epoch 11 batch id 200 loss 0.6955065131187439 train acc 0.802578125\n",
            "epoch 11 batch id 201 loss 0.6451944708824158 train acc 0.8023942786069652\n",
            "epoch 11 batch id 202 loss 0.5792665481567383 train acc 0.8028310643564357\n",
            "epoch 11 batch id 203 loss 0.7042292952537537 train acc 0.8027247536945813\n",
            "epoch 11 batch id 204 loss 0.8585020899772644 train acc 0.8024662990196079\n",
            "epoch 11 batch id 205 loss 0.7500612735748291 train acc 0.802439024390244\n",
            "epoch 11 batch id 206 loss 0.6160541772842407 train acc 0.8024120145631068\n",
            "epoch 11 batch id 207 loss 0.6034881472587585 train acc 0.802536231884058\n",
            "epoch 11 batch id 208 loss 0.6659021973609924 train acc 0.802734375\n",
            "epoch 11 batch id 209 loss 0.7159327864646912 train acc 0.8028558612440191\n",
            "epoch 11 batch id 210 loss 0.8002800941467285 train acc 0.8029017857142857\n",
            "epoch 11 batch id 211 loss 1.0878468751907349 train acc 0.8025770142180095\n",
            "epoch 11 batch id 212 loss 1.0605171918869019 train acc 0.8023290094339622\n",
            "epoch 11 batch id 213 loss 0.5214413404464722 train acc 0.8023767605633803\n",
            "epoch 11 batch id 214 loss 0.6949781179428101 train acc 0.8023510514018691\n",
            "epoch 11 batch id 215 loss 1.0195667743682861 train acc 0.8021802325581395\n",
            "epoch 11 batch id 216 loss 0.5038770437240601 train acc 0.8025173611111112\n",
            "epoch 11 batch id 217 loss 0.7982591986656189 train acc 0.8022753456221198\n",
            "epoch 11 batch id 218 loss 0.572742760181427 train acc 0.8024655963302753\n",
            "epoch 11 batch id 219 loss 0.6082394123077393 train acc 0.8027254566210046\n",
            "epoch 11 batch id 220 loss 0.5149879455566406 train acc 0.8028409090909091\n",
            "epoch 11 batch id 221 loss 0.6832124590873718 train acc 0.8030260180995475\n",
            "epoch 11 batch id 222 loss 0.6387694478034973 train acc 0.8032094594594594\n",
            "epoch 11 batch id 223 loss 0.9143767952919006 train acc 0.8030409192825112\n",
            "epoch 11 batch id 224 loss 0.5285306572914124 train acc 0.80322265625\n",
            "epoch 11 batch id 225 loss 0.5691884756088257 train acc 0.8035416666666667\n",
            "epoch 11 batch id 226 loss 0.5234434604644775 train acc 0.8038578539823009\n",
            "epoch 11 batch id 227 loss 0.7656167149543762 train acc 0.8038270925110133\n",
            "epoch 11 batch id 228 loss 0.526159405708313 train acc 0.8040707236842105\n",
            "epoch 11 batch id 229 loss 0.5770784020423889 train acc 0.8043122270742358\n",
            "epoch 11 batch id 230 loss 0.8937559127807617 train acc 0.8040760869565218\n",
            "epoch 11 batch id 231 loss 0.5580835938453674 train acc 0.8041801948051948\n",
            "epoch 11 batch id 232 loss 0.5657634735107422 train acc 0.8043507543103449\n",
            "epoch 11 batch id 233 loss 0.7337557673454285 train acc 0.804318669527897\n",
            "epoch 11 batch id 234 loss 0.7495947480201721 train acc 0.8042200854700855\n",
            "epoch 11 batch id 235 loss 0.4866568148136139 train acc 0.8045877659574469\n",
            "epoch 11 batch id 236 loss 0.6757211685180664 train acc 0.8046212923728814\n",
            "epoch 11 batch id 237 loss 0.5493313074111938 train acc 0.8048523206751055\n",
            "epoch 11 batch id 238 loss 0.6406128406524658 train acc 0.8048188025210085\n",
            "epoch 11 batch id 239 loss 0.7179756164550781 train acc 0.8049816945606695\n",
            "epoch 11 batch id 240 loss 0.42027631402015686 train acc 0.8054036458333333\n",
            "epoch 11 batch id 241 loss 0.8450726866722107 train acc 0.8053682572614108\n",
            "epoch 11 batch id 242 loss 0.9045554399490356 train acc 0.8054622933884298\n",
            "epoch 11 batch id 243 loss 0.8274504542350769 train acc 0.8053626543209876\n",
            "epoch 11 batch id 244 loss 0.5240304470062256 train acc 0.8055840163934426\n",
            "epoch 11 batch id 245 loss 0.7369611263275146 train acc 0.8056760204081632\n",
            "epoch 11 batch id 246 loss 0.8475959300994873 train acc 0.8055767276422764\n",
            "epoch 11 batch id 247 loss 0.5720016360282898 train acc 0.805668016194332\n",
            "epoch 11 batch id 248 loss 0.9864962697029114 train acc 0.805632560483871\n",
            "epoch 11 batch id 249 loss 0.8025357127189636 train acc 0.8055973895582329\n",
            "epoch 11 batch id 250 loss 0.7789838910102844 train acc 0.805375\n",
            "epoch 11 batch id 251 loss 0.96378493309021 train acc 0.8052166334661355\n",
            "epoch 11 batch id 252 loss 0.6159377098083496 train acc 0.8054315476190477\n",
            "epoch 11 batch id 253 loss 0.638593852519989 train acc 0.8055830039525692\n",
            "epoch 11 batch id 254 loss 0.6757158041000366 train acc 0.8057332677165354\n",
            "epoch 11 batch id 255 loss 0.5794623494148254 train acc 0.8058210784313725\n",
            "epoch 11 batch id 256 loss 0.583283007144928 train acc 0.80615234375\n",
            "epoch 11 batch id 257 loss 0.6854280829429626 train acc 0.8062986381322957\n",
            "epoch 11 batch id 258 loss 0.5470598340034485 train acc 0.8063226744186046\n",
            "epoch 11 batch id 259 loss 0.6590300798416138 train acc 0.8061655405405406\n",
            "epoch 11 batch id 260 loss 0.8190361261367798 train acc 0.8061899038461539\n",
            "epoch 11 batch id 261 loss 0.9222960472106934 train acc 0.8059746168582376\n",
            "epoch 11 batch id 262 loss 0.6850126385688782 train acc 0.8060591603053435\n",
            "epoch 11 batch id 263 loss 0.6759970784187317 train acc 0.8060242395437263\n",
            "epoch 11 batch id 264 loss 0.8588147163391113 train acc 0.8061671401515151\n",
            "epoch 11 batch id 265 loss 0.930484414100647 train acc 0.8061910377358491\n",
            "epoch 11 batch id 266 loss 0.6640933752059937 train acc 0.8062147556390977\n",
            "epoch 11 batch id 267 loss 0.801600456237793 train acc 0.806121254681648\n",
            "epoch 11 batch id 268 loss 0.752200186252594 train acc 0.8060867537313433\n",
            "epoch 11 batch id 269 loss 0.8240361213684082 train acc 0.8059944237918215\n",
            "epoch 11 batch id 270 loss 0.7688857913017273 train acc 0.8057291666666667\n",
            "epoch 11 batch id 271 loss 0.6109116077423096 train acc 0.8058118081180812\n",
            "epoch 11 batch id 272 loss 0.5820978283882141 train acc 0.8060087316176471\n",
            "epoch 11 batch id 273 loss 0.7273510098457336 train acc 0.8059752747252747\n",
            "epoch 11 batch id 274 loss 0.4503748118877411 train acc 0.8063982664233577\n",
            "epoch 11 batch id 275 loss 0.8841344714164734 train acc 0.8063068181818182\n",
            "epoch 11 batch id 276 loss 0.6889753341674805 train acc 0.8061028079710145\n",
            "epoch 11 batch id 277 loss 0.9755266308784485 train acc 0.8061259025270758\n",
            "epoch 11 batch id 278 loss 0.720480740070343 train acc 0.8058678057553957\n",
            "epoch 11 batch id 279 loss 0.6469405889511108 train acc 0.8059475806451613\n",
            "epoch 11 batch id 280 loss 0.530463695526123 train acc 0.8061941964285714\n",
            "epoch 11 batch id 281 loss 0.8572704792022705 train acc 0.8062166370106761\n",
            "epoch 11 batch id 282 loss 0.8323503732681274 train acc 0.8061281028368794\n",
            "epoch 11 batch id 283 loss 0.5986889600753784 train acc 0.8060401943462897\n",
            "epoch 11 batch id 284 loss 0.9093754291534424 train acc 0.8061729753521126\n",
            "epoch 11 batch id 285 loss 0.7217153310775757 train acc 0.8060855263157894\n",
            "epoch 11 batch id 286 loss 0.533431887626648 train acc 0.806326486013986\n",
            "epoch 11 batch id 287 loss 0.5293899178504944 train acc 0.8064024390243902\n",
            "epoch 11 batch id 288 loss 0.6057281494140625 train acc 0.8064778645833334\n",
            "epoch 11 batch id 289 loss 0.8379672765731812 train acc 0.8063365051903114\n",
            "epoch 11 batch id 290 loss 0.7892186045646667 train acc 0.8063577586206897\n",
            "epoch 11 batch id 291 loss 0.48744723200798035 train acc 0.8065936426116839\n",
            "epoch 11 batch id 292 loss 0.5324421525001526 train acc 0.8066673801369864\n",
            "epoch 11 batch id 293 loss 0.6466051340103149 train acc 0.8066339590443686\n",
            "epoch 11 batch id 294 loss 0.680942177772522 train acc 0.8068664965986394\n",
            "epoch 11 batch id 295 loss 0.5989928245544434 train acc 0.8069385593220338\n",
            "epoch 11 batch id 296 loss 0.7503246665000916 train acc 0.8067989864864865\n",
            "epoch 11 batch id 297 loss 0.6875726580619812 train acc 0.8068707912457912\n",
            "epoch 11 batch id 298 loss 0.7698695659637451 train acc 0.8067848154362416\n",
            "epoch 11 batch id 299 loss 0.6153910756111145 train acc 0.8068561872909699\n",
            "epoch 11 batch id 300 loss 0.597266435623169 train acc 0.8069791666666667\n",
            "epoch 11 batch id 301 loss 0.550250232219696 train acc 0.8071532392026578\n",
            "epoch 11 batch id 302 loss 0.6574277281761169 train acc 0.8072744205298014\n",
            "epoch 11 batch id 303 loss 0.6823725700378418 train acc 0.8071885313531353\n",
            "epoch 11 batch id 304 loss 0.7527377605438232 train acc 0.8072574013157895\n",
            "epoch 11 batch id 305 loss 0.7450752854347229 train acc 0.8072745901639344\n",
            "epoch 11 batch id 306 loss 0.5181493163108826 train acc 0.8074959150326797\n",
            "epoch 11 batch id 307 loss 0.6611812114715576 train acc 0.807461319218241\n",
            "epoch 11 batch id 308 loss 0.7425976395606995 train acc 0.807426948051948\n",
            "epoch 11 batch id 309 loss 0.5648117065429688 train acc 0.807595064724919\n",
            "epoch 11 batch id 310 loss 0.6576933860778809 train acc 0.8075604838709678\n",
            "epoch 11 batch id 311 loss 0.5900173187255859 train acc 0.8075763665594855\n",
            "epoch 11 batch id 312 loss 0.5815996527671814 train acc 0.807792467948718\n",
            "epoch 11 batch id 313 loss 0.8195294737815857 train acc 0.807757587859425\n",
            "epoch 11 batch id 314 loss 0.8000524640083313 train acc 0.8077229299363057\n",
            "epoch 11 batch id 315 loss 0.6277486085891724 train acc 0.807936507936508\n",
            "epoch 11 batch id 316 loss 0.6310025453567505 train acc 0.8079509493670886\n",
            "epoch 11 batch id 317 loss 0.6943395733833313 train acc 0.8079652996845426\n",
            "epoch 11 batch id 318 loss 0.7754472494125366 train acc 0.8079304245283019\n",
            "epoch 11 batch id 319 loss 0.5099615454673767 train acc 0.8081896551724138\n",
            "epoch 11 batch id 320 loss 0.5827230215072632 train acc 0.808203125\n",
            "epoch 11 batch id 321 loss 0.5811660289764404 train acc 0.8082651869158879\n",
            "epoch 11 batch id 322 loss 0.6138830780982971 train acc 0.8083268633540373\n",
            "epoch 11 batch id 323 loss 0.6098126173019409 train acc 0.8083397832817337\n",
            "epoch 11 batch id 324 loss 0.8127192258834839 train acc 0.8083526234567902\n",
            "epoch 11 batch id 325 loss 0.6061036586761475 train acc 0.8086057692307692\n",
            "epoch 11 batch id 326 loss 0.6918048858642578 train acc 0.8085697852760736\n",
            "epoch 11 batch id 327 loss 0.5448837876319885 train acc 0.8087251529051988\n",
            "epoch 11 batch id 328 loss 0.5869879722595215 train acc 0.8086890243902439\n",
            "epoch 11 batch id 329 loss 0.7586939930915833 train acc 0.8087006079027356\n",
            "epoch 11 batch id 330 loss 0.7356163263320923 train acc 0.8087594696969697\n",
            "epoch 11 batch id 331 loss 0.6756003499031067 train acc 0.8087235649546828\n",
            "epoch 11 batch id 332 loss 0.5464040040969849 train acc 0.8089231927710844\n",
            "epoch 11 batch id 333 loss 0.48273080587387085 train acc 0.8091685435435435\n",
            "epoch 11 batch id 334 loss 0.4402204751968384 train acc 0.8093656437125748\n",
            "epoch 11 batch id 335 loss 0.506007969379425 train acc 0.8094682835820896\n",
            "epoch 11 batch id 336 loss 0.4886862337589264 train acc 0.8096633184523809\n",
            "epoch 11 batch id 337 loss 0.5931105613708496 train acc 0.8097644658753709\n",
            "epoch 11 batch id 338 loss 0.4905114769935608 train acc 0.8099574704142012\n",
            "epoch 11 batch id 339 loss 0.7945900559425354 train acc 0.8101032448377581\n",
            "epoch 11 batch id 340 loss 0.7185062766075134 train acc 0.8098805147058824\n",
            "epoch 11 batch id 341 loss 0.5673512816429138 train acc 0.8099340175953079\n",
            "epoch 11 batch id 342 loss 0.7971348166465759 train acc 0.8099872076023392\n",
            "epoch 11 batch id 343 loss 0.6682472229003906 train acc 0.8099034256559767\n",
            "epoch 11 batch id 344 loss 0.45716285705566406 train acc 0.8100926598837209\n",
            "epoch 11 batch id 345 loss 0.5334200263023376 train acc 0.8102807971014493\n",
            "epoch 11 batch id 346 loss 0.8466153144836426 train acc 0.8101968930635838\n",
            "epoch 11 batch id 347 loss 0.7013123631477356 train acc 0.8102485590778098\n",
            "epoch 11 batch id 348 loss 0.645827054977417 train acc 0.8102101293103449\n",
            "epoch 11 batch id 349 loss 0.5875669717788696 train acc 0.8103510028653295\n",
            "epoch 11 batch id 350 loss 0.5644114017486572 train acc 0.8104910714285715\n",
            "epoch 11 batch id 351 loss 0.60148024559021 train acc 0.8104967948717948\n",
            "epoch 11 batch id 352 loss 0.4854835271835327 train acc 0.8105912642045454\n",
            "epoch 11 batch id 353 loss 1.0171946287155151 train acc 0.8102868271954674\n",
            "epoch 11 batch id 354 loss 0.6847732067108154 train acc 0.8103813559322034\n",
            "epoch 11 batch id 355 loss 0.682004988193512 train acc 0.8103433098591549\n",
            "epoch 11 batch id 356 loss 0.9581734538078308 train acc 0.8102176966292135\n",
            "epoch 11 batch id 357 loss 0.790824830532074 train acc 0.8101803221288515\n",
            "epoch 11 batch id 358 loss 0.5250311493873596 train acc 0.8103613826815642\n",
            "epoch 11 batch id 359 loss 0.6006056070327759 train acc 0.8104108635097493\n",
            "epoch 11 batch id 360 loss 0.5922438502311707 train acc 0.8104166666666667\n",
            "epoch 11 batch id 361 loss 0.6837764978408813 train acc 0.8103358725761773\n",
            "epoch 11 batch id 362 loss 0.6561322808265686 train acc 0.8102555248618785\n",
            "epoch 11 batch id 363 loss 0.6459177136421204 train acc 0.8104769283746557\n",
            "epoch 11 batch id 364 loss 0.75369793176651 train acc 0.8106541895604396\n",
            "epoch 11 batch id 365 loss 1.168155550956726 train acc 0.8103167808219178\n",
            "epoch 11 batch id 366 loss 0.5129119157791138 train acc 0.8104935109289617\n",
            "epoch 11 batch id 367 loss 0.7268503308296204 train acc 0.8102861035422343\n",
            "epoch 11 batch id 368 loss 0.7207279801368713 train acc 0.8102072010869565\n",
            "epoch 11 batch id 369 loss 0.7897400259971619 train acc 0.8101287262872628\n",
            "epoch 11 batch id 370 loss 0.5980042815208435 train acc 0.810304054054054\n",
            "epoch 11 batch id 371 loss 0.8994117379188538 train acc 0.8101415094339622\n",
            "epoch 11 batch id 372 loss 0.5713057518005371 train acc 0.8103998655913979\n",
            "epoch 11 batch id 373 loss 0.627018928527832 train acc 0.8104054959785523\n",
            "epoch 11 batch id 374 loss 0.6975263953208923 train acc 0.8105364304812834\n",
            "epoch 11 batch id 375 loss 0.4986099302768707 train acc 0.81075\n",
            "epoch 11 batch id 376 loss 0.785098135471344 train acc 0.810796210106383\n",
            "epoch 11 batch id 377 loss 0.653863787651062 train acc 0.8107592838196287\n",
            "epoch 11 batch id 378 loss 0.4225972294807434 train acc 0.8109705687830688\n",
            "epoch 11 batch id 379 loss 0.42474842071533203 train acc 0.8111395118733509\n",
            "epoch 11 batch id 380 loss 0.8834905624389648 train acc 0.8108963815789474\n",
            "epoch 11 batch id 381 loss 0.753837525844574 train acc 0.8108595800524935\n",
            "epoch 11 batch id 382 loss 0.6653133630752563 train acc 0.8108229712041884\n",
            "epoch 11 batch id 383 loss 0.7995617389678955 train acc 0.8107049608355091\n",
            "epoch 11 batch id 384 loss 0.8962758183479309 train acc 0.8106282552083334\n",
            "epoch 11 batch id 385 loss 0.35633859038352966 train acc 0.810836038961039\n",
            "epoch 11 batch id 386 loss 0.7383592128753662 train acc 0.8106784326424871\n",
            "epoch 11 batch id 387 loss 0.7230170369148254 train acc 0.8106831395348837\n",
            "epoch 11 batch id 388 loss 0.3578846752643585 train acc 0.8109697164948454\n",
            "epoch 11 batch id 389 loss 1.2097407579421997 train acc 0.8105719794344473\n",
            "epoch 11 batch id 390 loss 0.4495881199836731 train acc 0.8106169871794872\n",
            "epoch 11 batch id 391 loss 0.5532838106155396 train acc 0.8107816496163683\n",
            "epoch 11 batch id 392 loss 0.6557546854019165 train acc 0.810905612244898\n",
            "epoch 11 batch id 393 loss 0.47351911664009094 train acc 0.8110289440203562\n",
            "epoch 11 batch id 394 loss 0.5766324400901794 train acc 0.8111516497461929\n",
            "epoch 11 batch id 395 loss 0.7621381878852844 train acc 0.8112341772151899\n",
            "epoch 11 batch id 396 loss 0.8951137661933899 train acc 0.8112373737373737\n",
            "epoch 11 batch id 397 loss 0.8399758338928223 train acc 0.8109650503778337\n",
            "epoch 11 batch id 398 loss 0.8599399924278259 train acc 0.8108511306532663\n",
            "epoch 11 batch id 399 loss 1.008560299873352 train acc 0.8107769423558897\n",
            "epoch 11 batch id 400 loss 0.7890652418136597 train acc 0.810703125\n",
            "epoch 11 batch id 401 loss 0.6062544584274292 train acc 0.8105517456359103\n",
            "epoch 11 batch id 402 loss 0.5602579712867737 train acc 0.8106343283582089\n",
            "epoch 11 batch id 403 loss 0.5472157597541809 train acc 0.8107552729528535\n",
            "epoch 11 batch id 404 loss 0.7720797061920166 train acc 0.8106048886138614\n",
            "epoch 11 batch id 405 loss 0.5678185820579529 train acc 0.8108410493827161\n",
            "epoch 11 batch id 406 loss 0.7997121214866638 train acc 0.8106527093596059\n",
            "epoch 11 batch id 407 loss 0.5693725943565369 train acc 0.8107340294840295\n",
            "epoch 11 batch id 408 loss 0.805749237537384 train acc 0.8107383578431373\n",
            "epoch 11 batch id 409 loss 0.7539302110671997 train acc 0.8106280562347188\n",
            "epoch 11 batch id 410 loss 0.4451151192188263 train acc 0.8107850609756098\n",
            "epoch 11 batch id 411 loss 0.5163156390190125 train acc 0.8109032846715328\n",
            "epoch 11 batch id 412 loss 1.0409399271011353 train acc 0.8106796116504854\n",
            "epoch 11 batch id 413 loss 0.5938882827758789 train acc 0.8107218523002422\n",
            "epoch 11 batch id 414 loss 0.650996744632721 train acc 0.8107261473429952\n",
            "epoch 11 batch id 415 loss 0.9408525228500366 train acc 0.8105798192771084\n",
            "epoch 11 batch id 416 loss 0.6729725003242493 train acc 0.8106971153846154\n",
            "epoch 11 batch id 417 loss 0.4896247982978821 train acc 0.810888788968825\n",
            "epoch 11 batch id 418 loss 0.6457347273826599 train acc 0.8108178827751196\n",
            "epoch 11 batch id 419 loss 0.9198850989341736 train acc 0.8107473150357996\n",
            "epoch 11 batch id 420 loss 0.5513430833816528 train acc 0.8108258928571429\n",
            "epoch 11 batch id 421 loss 0.7057504057884216 train acc 0.8107556413301663\n",
            "epoch 11 batch id 422 loss 0.5291800498962402 train acc 0.8109078791469194\n",
            "epoch 11 batch id 423 loss 0.6915178298950195 train acc 0.8108747044917257\n",
            "epoch 11 batch id 424 loss 0.9021589159965515 train acc 0.8106574292452831\n",
            "epoch 11 batch id 425 loss 0.49144914746284485 train acc 0.8108823529411765\n",
            "epoch 11 batch id 426 loss 0.7359727621078491 train acc 0.8109961854460094\n",
            "epoch 11 batch id 427 loss 0.4725472033023834 train acc 0.8111460772833724\n",
            "epoch 11 batch id 428 loss 0.7021087408065796 train acc 0.8111492406542056\n",
            "epoch 11 batch id 429 loss 0.4791595935821533 train acc 0.8112252331002331\n",
            "epoch 11 batch id 430 loss 0.42897307872772217 train acc 0.8114825581395348\n",
            "epoch 11 batch id 431 loss 0.7411592602729797 train acc 0.8115574245939675\n",
            "epoch 11 batch id 432 loss 0.5608367919921875 train acc 0.8117404513888888\n",
            "epoch 11 batch id 433 loss 0.6395615935325623 train acc 0.8118504618937644\n",
            "epoch 11 batch id 434 loss 0.48657989501953125 train acc 0.8119959677419355\n",
            "epoch 11 batch id 435 loss 0.8040400743484497 train acc 0.8119971264367816\n",
            "epoch 11 batch id 436 loss 0.9697483777999878 train acc 0.8118907683486238\n",
            "epoch 11 batch id 437 loss 0.5288317799568176 train acc 0.8120351830663616\n",
            "epoch 11 batch id 438 loss 0.4348263740539551 train acc 0.8122502853881278\n",
            "epoch 11 batch id 439 loss 0.5741469860076904 train acc 0.8123220387243736\n",
            "epoch 11 batch id 440 loss 0.8698095083236694 train acc 0.8123224431818182\n",
            "epoch 11 batch id 441 loss 0.8052284121513367 train acc 0.8122874149659864\n",
            "epoch 11 batch id 442 loss 0.924989640712738 train acc 0.8121818438914027\n",
            "epoch 11 batch id 443 loss 1.2666815519332886 train acc 0.8119356659142212\n",
            "epoch 11 batch id 444 loss 0.6591357588768005 train acc 0.8118665540540541\n",
            "epoch 11 batch id 445 loss 0.7287898063659668 train acc 0.8119030898876405\n",
            "epoch 11 batch id 446 loss 0.48031970858573914 train acc 0.812044562780269\n",
            "epoch 11 batch id 447 loss 0.737175464630127 train acc 0.8119756711409396\n",
            "epoch 11 batch id 448 loss 0.5227288007736206 train acc 0.8120465959821429\n",
            "epoch 11 batch id 449 loss 0.8159029483795166 train acc 0.8120128062360802\n",
            "epoch 11 batch id 450 loss 0.49887317419052124 train acc 0.8120833333333334\n",
            "epoch 11 batch id 451 loss 0.7349056005477905 train acc 0.8120496119733924\n",
            "epoch 11 batch id 452 loss 0.6752196550369263 train acc 0.811981471238938\n",
            "epoch 11 batch id 453 loss 0.5543197989463806 train acc 0.8120860927152318\n",
            "epoch 11 batch id 454 loss 0.42884233593940735 train acc 0.8122590859030837\n",
            "epoch 11 batch id 455 loss 0.6492494940757751 train acc 0.8122596153846153\n",
            "epoch 11 batch id 456 loss 0.6543895602226257 train acc 0.8122944078947368\n",
            "epoch 11 batch id 457 loss 0.5450313091278076 train acc 0.812363238512035\n",
            "epoch 11 batch id 458 loss 0.8359276652336121 train acc 0.8123635371179039\n",
            "epoch 11 batch id 459 loss 0.4894665777683258 train acc 0.812568082788671\n",
            "epoch 11 batch id 460 loss 0.6493565440177917 train acc 0.8125339673913043\n",
            "epoch 11 batch id 461 loss 0.39068514108657837 train acc 0.8127711496746204\n",
            "epoch 11 batch id 462 loss 1.086592197418213 train acc 0.812601461038961\n",
            "epoch 11 batch id 463 loss 0.6420159935951233 train acc 0.8127362311015118\n",
            "epoch 11 batch id 464 loss 0.7093181014060974 train acc 0.8127357219827587\n",
            "epoch 11 batch id 465 loss 0.5976876616477966 train acc 0.8128360215053764\n",
            "epoch 11 batch id 466 loss 0.4947580099105835 train acc 0.8130029506437768\n",
            "epoch 11 batch id 467 loss 0.348768413066864 train acc 0.813169164882227\n",
            "epoch 11 batch id 468 loss 0.7004343867301941 train acc 0.8131677350427351\n",
            "epoch 11 batch id 469 loss 0.665034830570221 train acc 0.8130330490405118\n",
            "epoch 11 batch id 470 loss 0.3894461989402771 train acc 0.8133311170212766\n",
            "epoch 11 batch id 471 loss 0.790949821472168 train acc 0.8132961783439491\n",
            "epoch 11 batch id 472 loss 0.7463328242301941 train acc 0.813228283898305\n",
            "epoch 11 batch id 473 loss 0.6834684610366821 train acc 0.813193710359408\n",
            "epoch 11 batch id 474 loss 0.721980631351471 train acc 0.813192246835443\n",
            "epoch 11 batch id 475 loss 0.6045655012130737 train acc 0.8132894736842106\n",
            "epoch 11 batch id 476 loss 0.6387853622436523 train acc 0.8132878151260504\n",
            "epoch 11 batch id 477 loss 0.3976093530654907 train acc 0.8134171907756813\n",
            "epoch 11 batch id 478 loss 0.5222007632255554 train acc 0.8135133368200836\n",
            "epoch 11 batch id 479 loss 0.699810802936554 train acc 0.8135438413361169\n",
            "epoch 11 batch id 480 loss 0.7984009981155396 train acc 0.8134765625\n",
            "epoch 11 batch id 481 loss 0.4296504855155945 train acc 0.8136694386694386\n",
            "epoch 11 batch id 482 loss 1.0401582717895508 train acc 0.813472510373444\n",
            "epoch 11 batch id 483 loss 0.5921258330345154 train acc 0.8135675465838509\n",
            "epoch 11 batch id 484 loss 0.7488434910774231 train acc 0.8136299070247934\n",
            "epoch 11 batch id 485 loss 0.39607489109039307 train acc 0.8137564432989691\n",
            "epoch 11 batch id 486 loss 0.7840418815612793 train acc 0.81372170781893\n",
            "epoch 11 batch id 487 loss 0.6714837551116943 train acc 0.8138796201232033\n",
            "epoch 11 batch id 488 loss 1.0748192071914673 train acc 0.8136526639344263\n",
            "epoch 11 batch id 489 loss 1.0949137210845947 train acc 0.8134266359918201\n",
            "epoch 11 batch id 490 loss 0.5336822867393494 train acc 0.8134885204081632\n",
            "epoch 11 batch id 491 loss 0.44817084074020386 train acc 0.8136774439918534\n",
            "epoch 11 batch id 492 loss 0.5857324600219727 train acc 0.813770325203252\n",
            "epoch 11 batch id 493 loss 0.6053130030632019 train acc 0.8137994421906694\n",
            "epoch 11 batch id 494 loss 0.8317180871963501 train acc 0.8137968117408907\n",
            "epoch 11 batch id 495 loss 0.6960463523864746 train acc 0.8138573232323232\n",
            "epoch 11 batch id 496 loss 0.6533180475234985 train acc 0.8139175907258065\n",
            "epoch 11 batch id 497 loss 0.7732714414596558 train acc 0.813851861167002\n",
            "epoch 11 batch id 498 loss 0.5489718914031982 train acc 0.8138805220883534\n",
            "epoch 11 batch id 499 loss 0.5356735587120056 train acc 0.8139403807615231\n",
            "epoch 11 batch id 500 loss 0.8231432437896729 train acc 0.81384375\n",
            "epoch 11 batch id 501 loss 0.5831141471862793 train acc 0.8139034431137725\n",
            "epoch 11 batch id 502 loss 0.5399602055549622 train acc 0.8140251494023905\n",
            "epoch 11 batch id 503 loss 0.3399517834186554 train acc 0.8142084990059643\n",
            "epoch 11 batch id 504 loss 0.5963056087493896 train acc 0.8142671130952381\n",
            "epoch 11 batch id 505 loss 0.5788815021514893 train acc 0.8143254950495049\n",
            "epoch 11 batch id 506 loss 0.5148383975028992 train acc 0.8143836462450593\n",
            "epoch 11 batch id 507 loss 0.6574865579605103 train acc 0.8144415680473372\n",
            "epoch 11 batch id 508 loss 0.4768032431602478 train acc 0.8145607775590551\n",
            "epoch 11 batch id 509 loss 0.44887232780456543 train acc 0.8146488212180747\n",
            "epoch 11 batch id 510 loss 0.7475910782814026 train acc 0.8146752450980392\n",
            "epoch 11 batch id 511 loss 0.7863794565200806 train acc 0.8146962266641816\n",
            "epoch 11 train acc 0.8146962266641816\n",
            "epoch 11 test acc 0.39892578125\n",
            "epoch 12 batch id 1 loss 0.915931224822998 train acc 0.78125\n",
            "epoch 12 batch id 2 loss 0.7572221159934998 train acc 0.8046875\n",
            "epoch 12 batch id 3 loss 0.7050318717956543 train acc 0.8020833333333334\n",
            "epoch 12 batch id 4 loss 0.3668655455112457 train acc 0.83203125\n",
            "epoch 12 batch id 5 loss 0.7915471792221069 train acc 0.8125\n",
            "epoch 12 batch id 6 loss 0.5052443742752075 train acc 0.8229166666666666\n",
            "epoch 12 batch id 7 loss 0.43652960658073425 train acc 0.8303571428571429\n",
            "epoch 12 batch id 8 loss 0.6693495512008667 train acc 0.826171875\n",
            "epoch 12 batch id 9 loss 0.5165153741836548 train acc 0.8350694444444444\n",
            "epoch 12 batch id 10 loss 0.4642515778541565 train acc 0.840625\n",
            "epoch 12 batch id 11 loss 0.6465367674827576 train acc 0.84375\n",
            "epoch 12 batch id 12 loss 0.8205610513687134 train acc 0.83984375\n",
            "epoch 12 batch id 13 loss 0.5163981318473816 train acc 0.8365384615384616\n",
            "epoch 12 batch id 14 loss 0.7652320861816406 train acc 0.8348214285714286\n",
            "epoch 12 batch id 15 loss 0.5101317167282104 train acc 0.8364583333333333\n",
            "epoch 12 batch id 16 loss 0.7357197999954224 train acc 0.8349609375\n",
            "epoch 12 batch id 17 loss 0.8659468293190002 train acc 0.8299632352941176\n",
            "epoch 12 batch id 18 loss 0.6447189450263977 train acc 0.8307291666666666\n",
            "epoch 12 batch id 19 loss 0.5969335436820984 train acc 0.8305921052631579\n",
            "epoch 12 batch id 20 loss 0.344753623008728 train acc 0.83515625\n",
            "epoch 12 batch id 21 loss 0.5048164129257202 train acc 0.8355654761904762\n",
            "epoch 12 batch id 22 loss 0.4708661437034607 train acc 0.8352272727272727\n",
            "epoch 12 batch id 23 loss 0.6802963614463806 train acc 0.8349184782608695\n",
            "epoch 12 batch id 24 loss 0.5265409350395203 train acc 0.8359375\n",
            "epoch 12 batch id 25 loss 0.7944925427436829 train acc 0.835625\n",
            "epoch 12 batch id 26 loss 0.7484577894210815 train acc 0.8371394230769231\n",
            "epoch 12 batch id 27 loss 0.35149216651916504 train acc 0.8391203703703703\n",
            "epoch 12 batch id 28 loss 0.5756324529647827 train acc 0.8409598214285714\n",
            "epoch 12 batch id 29 loss 0.4791093170642853 train acc 0.8432112068965517\n",
            "epoch 12 batch id 30 loss 0.6960045099258423 train acc 0.8432291666666667\n",
            "epoch 12 batch id 31 loss 0.8782895803451538 train acc 0.8417338709677419\n",
            "epoch 12 batch id 32 loss 0.6179205179214478 train acc 0.8427734375\n",
            "epoch 12 batch id 33 loss 0.48282289505004883 train acc 0.8432765151515151\n",
            "epoch 12 batch id 34 loss 0.6461969614028931 train acc 0.8432904411764706\n",
            "epoch 12 batch id 35 loss 0.5736114382743835 train acc 0.8424107142857142\n",
            "epoch 12 batch id 36 loss 0.47761979699134827 train acc 0.84375\n",
            "epoch 12 batch id 37 loss 0.5760176777839661 train acc 0.8445945945945946\n",
            "epoch 12 batch id 38 loss 0.4781702160835266 train acc 0.84375\n",
            "epoch 12 batch id 39 loss 0.4377382695674896 train acc 0.8457532051282052\n",
            "epoch 12 batch id 40 loss 0.5670934319496155 train acc 0.84609375\n",
            "epoch 12 batch id 41 loss 0.5214128494262695 train acc 0.8467987804878049\n",
            "epoch 12 batch id 42 loss 0.9225534796714783 train acc 0.8448660714285714\n",
            "epoch 12 batch id 43 loss 0.7465736865997314 train acc 0.8441133720930233\n",
            "epoch 12 batch id 44 loss 0.8171901106834412 train acc 0.8433948863636364\n",
            "epoch 12 batch id 45 loss 0.42481815814971924 train acc 0.8444444444444444\n",
            "epoch 12 batch id 46 loss 0.6735473871231079 train acc 0.8440896739130435\n",
            "epoch 12 batch id 47 loss 0.734900176525116 train acc 0.8430851063829787\n",
            "epoch 12 batch id 48 loss 0.6264023780822754 train acc 0.8427734375\n",
            "epoch 12 batch id 49 loss 0.5238813757896423 train acc 0.84375\n",
            "epoch 12 batch id 50 loss 0.6521395444869995 train acc 0.8428125\n",
            "epoch 12 batch id 51 loss 0.5940377116203308 train acc 0.8425245098039216\n",
            "epoch 12 batch id 52 loss 0.5483358502388 train acc 0.8422475961538461\n",
            "epoch 12 batch id 53 loss 0.7114388346672058 train acc 0.8428655660377359\n",
            "epoch 12 batch id 54 loss 0.5874660015106201 train acc 0.8423032407407407\n",
            "epoch 12 batch id 55 loss 1.012956142425537 train acc 0.8403409090909091\n",
            "epoch 12 batch id 56 loss 0.612867534160614 train acc 0.8406808035714286\n",
            "epoch 12 batch id 57 loss 0.807817816734314 train acc 0.8390899122807017\n",
            "epoch 12 batch id 58 loss 0.7295718193054199 train acc 0.8383620689655172\n",
            "epoch 12 batch id 59 loss 0.5767039656639099 train acc 0.8389830508474576\n",
            "epoch 12 batch id 60 loss 0.5276589393615723 train acc 0.83984375\n",
            "epoch 12 batch id 61 loss 0.5582258701324463 train acc 0.8393954918032787\n",
            "epoch 12 batch id 62 loss 0.6912807822227478 train acc 0.8379536290322581\n",
            "epoch 12 batch id 63 loss 0.7328475713729858 train acc 0.8375496031746031\n",
            "epoch 12 batch id 64 loss 0.5172320604324341 train acc 0.83740234375\n",
            "epoch 12 batch id 65 loss 0.35337528586387634 train acc 0.8384615384615385\n",
            "epoch 12 batch id 66 loss 0.6616153120994568 train acc 0.8385416666666666\n",
            "epoch 12 batch id 67 loss 0.4969954490661621 train acc 0.8395522388059702\n",
            "epoch 12 batch id 68 loss 0.4739500880241394 train acc 0.8400735294117647\n",
            "epoch 12 batch id 69 loss 0.5808030366897583 train acc 0.8399003623188406\n",
            "epoch 12 batch id 70 loss 0.5974981188774109 train acc 0.8392857142857143\n",
            "epoch 12 batch id 71 loss 0.5695626139640808 train acc 0.8393485915492958\n",
            "epoch 12 batch id 72 loss 0.969308078289032 train acc 0.8391927083333334\n",
            "epoch 12 batch id 73 loss 0.6045655012130737 train acc 0.8392551369863014\n",
            "epoch 12 batch id 74 loss 0.5443233251571655 train acc 0.8397381756756757\n",
            "epoch 12 batch id 75 loss 0.544389545917511 train acc 0.8395833333333333\n",
            "epoch 12 batch id 76 loss 0.571643590927124 train acc 0.8394325657894737\n",
            "epoch 12 batch id 77 loss 0.6046832203865051 train acc 0.8390827922077922\n",
            "epoch 12 batch id 78 loss 0.8146108388900757 train acc 0.8383413461538461\n",
            "epoch 12 batch id 79 loss 0.8604335784912109 train acc 0.8378164556962026\n",
            "epoch 12 batch id 80 loss 0.39472416043281555 train acc 0.8380859375\n",
            "epoch 12 batch id 81 loss 0.43040531873703003 train acc 0.8387345679012346\n",
            "epoch 12 batch id 82 loss 0.5073476433753967 train acc 0.8393673780487805\n",
            "epoch 12 batch id 83 loss 0.6298626065254211 train acc 0.8396084337349398\n",
            "epoch 12 batch id 84 loss 0.4387994408607483 train acc 0.8396577380952381\n",
            "epoch 12 batch id 85 loss 0.38088104128837585 train acc 0.8404411764705882\n",
            "epoch 12 batch id 86 loss 0.5549448728561401 train acc 0.8406613372093024\n",
            "epoch 12 batch id 87 loss 0.5197213292121887 train acc 0.8408764367816092\n",
            "epoch 12 batch id 88 loss 0.5299042463302612 train acc 0.8414417613636364\n",
            "epoch 12 batch id 89 loss 0.6130194067955017 train acc 0.8414676966292135\n",
            "epoch 12 batch id 90 loss 0.5997551679611206 train acc 0.8411458333333334\n",
            "epoch 12 batch id 91 loss 0.5632166862487793 train acc 0.8406593406593407\n",
            "epoch 12 batch id 92 loss 0.5164363980293274 train acc 0.8400135869565217\n",
            "epoch 12 batch id 93 loss 0.6881121397018433 train acc 0.8390456989247311\n",
            "epoch 12 batch id 94 loss 0.4004291296005249 train acc 0.8397606382978723\n",
            "epoch 12 batch id 95 loss 0.47008541226387024 train acc 0.8398026315789474\n",
            "epoch 12 batch id 96 loss 0.7527635097503662 train acc 0.83935546875\n",
            "epoch 12 batch id 97 loss 0.608810305595398 train acc 0.8394007731958762\n",
            "epoch 12 batch id 98 loss 0.8013483881950378 train acc 0.8392857142857143\n",
            "epoch 12 batch id 99 loss 0.7013869285583496 train acc 0.8388573232323232\n",
            "epoch 12 batch id 100 loss 0.6990647315979004 train acc 0.8390625\n",
            "epoch 12 batch id 101 loss 0.5603258609771729 train acc 0.8389542079207921\n",
            "epoch 12 batch id 102 loss 0.5438700914382935 train acc 0.8386948529411765\n",
            "epoch 12 batch id 103 loss 0.5150073766708374 train acc 0.8390473300970874\n",
            "epoch 12 batch id 104 loss 0.32694095373153687 train acc 0.8399939903846154\n",
            "epoch 12 batch id 105 loss 0.5585387945175171 train acc 0.8400297619047619\n",
            "epoch 12 batch id 106 loss 0.5562729239463806 train acc 0.8399174528301887\n",
            "epoch 12 batch id 107 loss 0.22728832066059113 train acc 0.8411214953271028\n",
            "epoch 12 batch id 108 loss 0.6572594046592712 train acc 0.8414351851851852\n",
            "epoch 12 batch id 109 loss 0.4095340073108673 train acc 0.841743119266055\n",
            "epoch 12 batch id 110 loss 1.2804224491119385 train acc 0.8404829545454545\n",
            "epoch 12 batch id 111 loss 0.6965249180793762 train acc 0.8402308558558559\n",
            "epoch 12 batch id 112 loss 0.5956404805183411 train acc 0.8404017857142857\n",
            "epoch 12 batch id 113 loss 0.5539900660514832 train acc 0.8409845132743363\n",
            "epoch 12 batch id 114 loss 0.7265124320983887 train acc 0.8405975877192983\n",
            "epoch 12 batch id 115 loss 0.6338261365890503 train acc 0.8403532608695652\n",
            "epoch 12 batch id 116 loss 0.5940870046615601 train acc 0.8406519396551724\n",
            "epoch 12 batch id 117 loss 0.4772525131702423 train acc 0.8410790598290598\n",
            "epoch 12 batch id 118 loss 0.47812068462371826 train acc 0.8416313559322034\n",
            "epoch 12 batch id 119 loss 0.575929582118988 train acc 0.8417804621848739\n",
            "epoch 12 batch id 120 loss 0.7862127423286438 train acc 0.8419270833333333\n",
            "epoch 12 batch id 121 loss 0.4045269191265106 train acc 0.8423295454545454\n",
            "epoch 12 batch id 122 loss 0.7081209421157837 train acc 0.8420850409836066\n",
            "epoch 12 batch id 123 loss 0.4956737458705902 train acc 0.842479674796748\n",
            "epoch 12 batch id 124 loss 0.855394184589386 train acc 0.8422379032258065\n",
            "epoch 12 batch id 125 loss 0.5665509104728699 train acc 0.842125\n",
            "epoch 12 batch id 126 loss 0.44938525557518005 train acc 0.8423859126984127\n",
            "epoch 12 batch id 127 loss 0.512874186038971 train acc 0.8426427165354331\n",
            "epoch 12 batch id 128 loss 0.7141621112823486 train acc 0.8424072265625\n",
            "epoch 12 batch id 129 loss 0.6428413391113281 train acc 0.8420542635658915\n",
            "epoch 12 batch id 130 loss 0.5412095189094543 train acc 0.8421875\n",
            "epoch 12 batch id 131 loss 0.367851585149765 train acc 0.8426765267175572\n",
            "epoch 12 batch id 132 loss 0.6157030463218689 train acc 0.8426846590909091\n",
            "epoch 12 batch id 133 loss 0.55655837059021 train acc 0.8425751879699248\n",
            "epoch 12 batch id 134 loss 0.5266876816749573 train acc 0.8425839552238806\n",
            "epoch 12 batch id 135 loss 0.6924949288368225 train acc 0.8424768518518518\n",
            "epoch 12 batch id 136 loss 0.8886900544166565 train acc 0.841796875\n",
            "epoch 12 batch id 137 loss 0.6751369833946228 train acc 0.8418111313868614\n",
            "epoch 12 batch id 138 loss 0.7521800994873047 train acc 0.8414855072463768\n",
            "epoch 12 batch id 139 loss 0.6088714599609375 train acc 0.8411645683453237\n",
            "epoch 12 batch id 140 loss 0.5364573001861572 train acc 0.84140625\n",
            "epoch 12 batch id 141 loss 0.6059619188308716 train acc 0.8410904255319149\n",
            "epoch 12 batch id 142 loss 0.4023355543613434 train acc 0.8414392605633803\n",
            "epoch 12 batch id 143 loss 0.6239081621170044 train acc 0.8414554195804196\n",
            "epoch 12 batch id 144 loss 0.8143345713615417 train acc 0.8409288194444444\n",
            "epoch 12 batch id 145 loss 0.7389928102493286 train acc 0.840948275862069\n",
            "epoch 12 batch id 146 loss 0.6883142590522766 train acc 0.8408604452054794\n",
            "epoch 12 batch id 147 loss 0.37268853187561035 train acc 0.84109268707483\n",
            "epoch 12 batch id 148 loss 0.5735113024711609 train acc 0.8411106418918919\n",
            "epoch 12 batch id 149 loss 0.5820990800857544 train acc 0.8408137583892618\n",
            "epoch 12 batch id 150 loss 0.7496570348739624 train acc 0.840625\n",
            "epoch 12 batch id 151 loss 0.6505765914916992 train acc 0.8405422185430463\n",
            "epoch 12 batch id 152 loss 0.5084824562072754 train acc 0.8407689144736842\n",
            "epoch 12 batch id 153 loss 0.5669090151786804 train acc 0.840890522875817\n",
            "epoch 12 batch id 154 loss 0.5675588250160217 train acc 0.841010551948052\n",
            "epoch 12 batch id 155 loss 0.45697444677352905 train acc 0.8413306451612903\n",
            "epoch 12 batch id 156 loss 0.5777977705001831 train acc 0.8413461538461539\n",
            "epoch 12 batch id 157 loss 0.6150374412536621 train acc 0.8414609872611465\n",
            "epoch 12 batch id 158 loss 0.9016032218933105 train acc 0.840684335443038\n",
            "epoch 12 batch id 159 loss 0.5974769592285156 train acc 0.8407036163522013\n",
            "epoch 12 batch id 160 loss 0.4919867515563965 train acc 0.84091796875\n",
            "epoch 12 batch id 161 loss 0.7155959606170654 train acc 0.8407414596273292\n",
            "epoch 12 batch id 162 loss 0.5524588227272034 train acc 0.8409529320987654\n",
            "epoch 12 batch id 163 loss 0.7020320296287537 train acc 0.8409700920245399\n",
            "epoch 12 batch id 164 loss 0.6462156772613525 train acc 0.8403201219512195\n",
            "epoch 12 batch id 165 loss 0.632477879524231 train acc 0.8404356060606061\n",
            "epoch 12 batch id 166 loss 0.4610527753829956 train acc 0.8406438253012049\n",
            "epoch 12 batch id 167 loss 0.5564759969711304 train acc 0.8403817365269461\n",
            "epoch 12 batch id 168 loss 0.652944803237915 train acc 0.8404017857142857\n",
            "epoch 12 batch id 169 loss 0.8346974849700928 train acc 0.8401442307692307\n",
            "epoch 12 batch id 170 loss 0.41018179059028625 train acc 0.8405330882352942\n",
            "epoch 12 batch id 171 loss 0.5758736729621887 train acc 0.840734649122807\n",
            "epoch 12 batch id 172 loss 0.7032904028892517 train acc 0.8404796511627907\n",
            "epoch 12 batch id 173 loss 0.47898149490356445 train acc 0.840679190751445\n",
            "epoch 12 batch id 174 loss 1.1416972875595093 train acc 0.8397988505747126\n",
            "epoch 12 batch id 175 loss 0.4496391713619232 train acc 0.8398214285714286\n",
            "epoch 12 batch id 176 loss 0.40378209948539734 train acc 0.8401100852272727\n",
            "epoch 12 batch id 177 loss 0.4373714029788971 train acc 0.8403072033898306\n",
            "epoch 12 batch id 178 loss 0.5566385984420776 train acc 0.840063202247191\n",
            "epoch 12 batch id 179 loss 0.5017910003662109 train acc 0.8403456703910615\n",
            "epoch 12 batch id 180 loss 0.6210551261901855 train acc 0.8405381944444444\n",
            "epoch 12 batch id 181 loss 0.4252844452857971 train acc 0.8408149171270718\n",
            "epoch 12 batch id 182 loss 0.7424241900444031 train acc 0.840573489010989\n",
            "epoch 12 batch id 183 loss 0.3657302260398865 train acc 0.8408469945355191\n",
            "epoch 12 batch id 184 loss 0.4953393340110779 train acc 0.8409476902173914\n",
            "epoch 12 batch id 185 loss 0.6359916925430298 train acc 0.840793918918919\n",
            "epoch 12 batch id 186 loss 0.5351255536079407 train acc 0.8409778225806451\n",
            "epoch 12 batch id 187 loss 0.47530922293663025 train acc 0.8410762032085561\n",
            "epoch 12 batch id 188 loss 0.7728410363197327 train acc 0.8408410904255319\n",
            "epoch 12 batch id 189 loss 0.5311556458473206 train acc 0.8407738095238095\n",
            "epoch 12 batch id 190 loss 0.40139156579971313 train acc 0.8408717105263158\n",
            "epoch 12 batch id 191 loss 0.4190639853477478 train acc 0.8411321989528796\n",
            "epoch 12 batch id 192 loss 0.4449108839035034 train acc 0.8411458333333334\n",
            "epoch 12 batch id 193 loss 0.608744204044342 train acc 0.8409974093264249\n",
            "epoch 12 batch id 194 loss 0.4477331340312958 train acc 0.8413337628865979\n",
            "epoch 12 batch id 195 loss 0.3835802674293518 train acc 0.8417467948717948\n",
            "epoch 12 batch id 196 loss 0.6554549336433411 train acc 0.8416772959183674\n",
            "epoch 12 batch id 197 loss 0.5799522399902344 train acc 0.8416878172588832\n",
            "epoch 12 batch id 198 loss 0.4677605926990509 train acc 0.8416982323232324\n",
            "epoch 12 batch id 199 loss 0.6581751704216003 train acc 0.8415515075376885\n",
            "epoch 12 batch id 200 loss 0.5904666781425476 train acc 0.84171875\n",
            "epoch 12 batch id 201 loss 0.43111345171928406 train acc 0.8418843283582089\n",
            "epoch 12 batch id 202 loss 0.5262346267700195 train acc 0.8420482673267327\n",
            "epoch 12 batch id 203 loss 0.4768666923046112 train acc 0.8419796798029556\n",
            "epoch 12 batch id 204 loss 0.602173924446106 train acc 0.8420649509803921\n",
            "epoch 12 batch id 205 loss 0.33555832505226135 train acc 0.8421493902439025\n",
            "epoch 12 batch id 206 loss 0.5434329509735107 train acc 0.8420813106796117\n",
            "epoch 12 batch id 207 loss 0.5307394862174988 train acc 0.8419384057971014\n",
            "epoch 12 batch id 208 loss 0.6226765513420105 train acc 0.8420973557692307\n",
            "epoch 12 batch id 209 loss 0.6326336860656738 train acc 0.8420305023923444\n",
            "epoch 12 batch id 210 loss 0.6932085752487183 train acc 0.8419642857142857\n",
            "epoch 12 batch id 211 loss 0.7622681260108948 train acc 0.8419727488151659\n",
            "epoch 12 batch id 212 loss 0.5184965133666992 train acc 0.8421285377358491\n",
            "epoch 12 batch id 213 loss 0.722015917301178 train acc 0.84206279342723\n",
            "epoch 12 batch id 214 loss 0.5020208954811096 train acc 0.8422167056074766\n",
            "epoch 12 batch id 215 loss 0.6487957239151001 train acc 0.842296511627907\n",
            "epoch 12 batch id 216 loss 0.5153564214706421 train acc 0.8423755787037037\n",
            "epoch 12 batch id 217 loss 0.3964345455169678 train acc 0.8425979262672811\n",
            "epoch 12 batch id 218 loss 0.4096348285675049 train acc 0.8428899082568807\n",
            "epoch 12 batch id 219 loss 0.6218399405479431 train acc 0.8431078767123288\n",
            "epoch 12 batch id 220 loss 0.41638895869255066 train acc 0.8433238636363637\n",
            "epoch 12 batch id 221 loss 0.6345080137252808 train acc 0.8433964932126696\n",
            "epoch 12 batch id 222 loss 0.5128480195999146 train acc 0.8435388513513513\n",
            "epoch 12 batch id 223 loss 0.4396536648273468 train acc 0.843609865470852\n",
            "epoch 12 batch id 224 loss 0.6394566893577576 train acc 0.8431919642857143\n",
            "epoch 12 batch id 225 loss 0.7225884199142456 train acc 0.843125\n",
            "epoch 12 batch id 226 loss 0.72789067029953 train acc 0.8429894911504425\n",
            "epoch 12 batch id 227 loss 0.7437801957130432 train acc 0.842579845814978\n",
            "epoch 12 batch id 228 loss 0.5927406549453735 train acc 0.8423108552631579\n",
            "epoch 12 batch id 229 loss 0.6480477452278137 train acc 0.8421806768558951\n",
            "epoch 12 batch id 230 loss 0.7844544649124146 train acc 0.8420516304347826\n",
            "epoch 12 batch id 231 loss 0.5510035753250122 train acc 0.8420589826839827\n",
            "epoch 12 batch id 232 loss 0.49139276146888733 train acc 0.8421336206896551\n",
            "epoch 12 batch id 233 loss 0.4945359528064728 train acc 0.8420734978540773\n",
            "epoch 12 batch id 234 loss 0.40911605954170227 train acc 0.8422809829059829\n",
            "epoch 12 batch id 235 loss 0.5666376948356628 train acc 0.8421542553191489\n",
            "epoch 12 batch id 236 loss 0.5763012170791626 train acc 0.8420286016949152\n",
            "epoch 12 batch id 237 loss 0.5996119379997253 train acc 0.8420358649789029\n",
            "epoch 12 batch id 238 loss 0.5411014556884766 train acc 0.8419117647058824\n",
            "epoch 12 batch id 239 loss 0.6654207110404968 train acc 0.8418540794979079\n",
            "epoch 12 batch id 240 loss 0.8889063596725464 train acc 0.8413411458333333\n",
            "epoch 12 batch id 241 loss 0.27820155024528503 train acc 0.8417401452282157\n",
            "epoch 12 batch id 242 loss 0.5137410759925842 train acc 0.8418130165289256\n",
            "epoch 12 batch id 243 loss 0.47213873267173767 train acc 0.8417566872427984\n",
            "epoch 12 batch id 244 loss 0.8411564826965332 train acc 0.8413165983606558\n",
            "epoch 12 batch id 245 loss 0.4203896224498749 train acc 0.8416454081632653\n",
            "epoch 12 batch id 246 loss 0.6114044785499573 train acc 0.8417174796747967\n",
            "epoch 12 batch id 247 loss 0.43171751499176025 train acc 0.8417257085020243\n",
            "epoch 12 batch id 248 loss 0.7897095084190369 train acc 0.8416708669354839\n",
            "epoch 12 batch id 249 loss 0.657723069190979 train acc 0.8415537148594378\n",
            "epoch 12 batch id 250 loss 0.6365782022476196 train acc 0.841375\n",
            "epoch 12 batch id 251 loss 0.6201500296592712 train acc 0.8415712151394422\n",
            "epoch 12 batch id 252 loss 0.3621699810028076 train acc 0.841827876984127\n",
            "epoch 12 batch id 253 loss 0.5992708802223206 train acc 0.8417119565217391\n",
            "epoch 12 batch id 254 loss 0.7544809579849243 train acc 0.8415969488188977\n",
            "epoch 12 batch id 255 loss 0.40839916467666626 train acc 0.8417892156862745\n",
            "epoch 12 batch id 256 loss 0.46129855513572693 train acc 0.84173583984375\n",
            "epoch 12 batch id 257 loss 0.6477471590042114 train acc 0.8416220817120622\n",
            "epoch 12 batch id 258 loss 0.44105884432792664 train acc 0.841812015503876\n",
            "epoch 12 batch id 259 loss 0.6501201391220093 train acc 0.8418798262548263\n",
            "epoch 12 batch id 260 loss 0.673399031162262 train acc 0.8418870192307693\n",
            "epoch 12 batch id 261 loss 0.6626492142677307 train acc 0.84165469348659\n",
            "epoch 12 batch id 262 loss 0.6723423600196838 train acc 0.8415434160305344\n",
            "epoch 12 batch id 263 loss 0.4912034571170807 train acc 0.8415518060836502\n",
            "epoch 12 batch id 264 loss 0.5190283060073853 train acc 0.8416193181818182\n",
            "epoch 12 batch id 265 loss 0.656145453453064 train acc 0.841627358490566\n",
            "epoch 12 batch id 266 loss 0.6434988975524902 train acc 0.8415765977443609\n",
            "epoch 12 batch id 267 loss 0.6012781858444214 train acc 0.8415262172284644\n",
            "epoch 12 batch id 268 loss 0.4015464782714844 train acc 0.8417677238805971\n",
            "epoch 12 batch id 269 loss 0.6200485825538635 train acc 0.841775092936803\n",
            "epoch 12 batch id 270 loss 0.3796222507953644 train acc 0.8418981481481481\n",
            "epoch 12 batch id 271 loss 0.4597814381122589 train acc 0.8419626383763837\n",
            "epoch 12 batch id 272 loss 0.847852885723114 train acc 0.8416819852941176\n",
            "epoch 12 batch id 273 loss 0.6172627210617065 train acc 0.8417467948717948\n",
            "epoch 12 batch id 274 loss 0.6707999110221863 train acc 0.8415830291970803\n",
            "epoch 12 batch id 275 loss 0.4312739074230194 train acc 0.8418181818181818\n",
            "epoch 12 batch id 276 loss 0.4893472492694855 train acc 0.841995018115942\n",
            "epoch 12 batch id 277 loss 0.41642138361930847 train acc 0.8422269855595668\n",
            "epoch 12 batch id 278 loss 0.71915602684021 train acc 0.8422324640287769\n",
            "epoch 12 batch id 279 loss 0.44236433506011963 train acc 0.8422939068100358\n",
            "epoch 12 batch id 280 loss 0.4300607144832611 train acc 0.8426339285714286\n",
            "epoch 12 batch id 281 loss 1.0000593662261963 train acc 0.8425266903914591\n",
            "epoch 12 batch id 282 loss 0.7242391109466553 train acc 0.8423093971631206\n",
            "epoch 12 batch id 283 loss 0.5919556021690369 train acc 0.8423696996466431\n",
            "epoch 12 batch id 284 loss 0.5908987522125244 train acc 0.8424295774647887\n",
            "epoch 12 batch id 285 loss 0.8506547808647156 train acc 0.8420504385964912\n",
            "epoch 12 batch id 286 loss 0.5198001861572266 train acc 0.8421656468531469\n",
            "epoch 12 batch id 287 loss 0.6136677861213684 train acc 0.8421711672473867\n",
            "epoch 12 batch id 288 loss 0.44678109884262085 train acc 0.8422309027777778\n",
            "epoch 12 batch id 289 loss 0.4895399212837219 train acc 0.8423442906574394\n",
            "epoch 12 batch id 290 loss 0.3500612676143646 train acc 0.8426185344827586\n",
            "epoch 12 batch id 291 loss 0.5318951606750488 train acc 0.8427298109965635\n",
            "epoch 12 batch id 292 loss 0.5640137791633606 train acc 0.8426262842465754\n",
            "epoch 12 batch id 293 loss 0.49906644225120544 train acc 0.8428434300341296\n",
            "epoch 12 batch id 294 loss 0.5315504670143127 train acc 0.8428465136054422\n",
            "epoch 12 batch id 295 loss 0.28596076369285583 train acc 0.8430614406779661\n",
            "epoch 12 batch id 296 loss 0.6670395135879517 train acc 0.8430109797297297\n",
            "epoch 12 batch id 297 loss 0.3605097532272339 train acc 0.8431186868686869\n",
            "epoch 12 batch id 298 loss 0.9102296829223633 train acc 0.8428586409395973\n",
            "epoch 12 batch id 299 loss 0.7030194997787476 train acc 0.842809364548495\n",
            "epoch 12 batch id 300 loss 0.6872133016586304 train acc 0.8428645833333334\n",
            "epoch 12 batch id 301 loss 0.6700588464736938 train acc 0.8428675249169435\n",
            "epoch 12 batch id 302 loss 0.619003176689148 train acc 0.8429739238410596\n",
            "epoch 12 batch id 303 loss 0.6710534691810608 train acc 0.8428733498349835\n",
            "epoch 12 batch id 304 loss 0.3871813118457794 train acc 0.8430818256578947\n",
            "epoch 12 batch id 305 loss 0.53764808177948 train acc 0.843186475409836\n",
            "epoch 12 batch id 306 loss 0.49087846279144287 train acc 0.8432393790849673\n",
            "epoch 12 batch id 307 loss 0.47010233998298645 train acc 0.8432410423452769\n",
            "epoch 12 batch id 308 loss 0.3407178521156311 train acc 0.8433441558441559\n",
            "epoch 12 batch id 309 loss 0.835040807723999 train acc 0.8429409385113269\n",
            "epoch 12 batch id 310 loss 0.5441530346870422 train acc 0.8428931451612903\n",
            "epoch 12 batch id 311 loss 0.8495413064956665 train acc 0.8426949356913184\n",
            "epoch 12 batch id 312 loss 0.5683642029762268 train acc 0.8428485576923077\n",
            "epoch 12 batch id 313 loss 0.443231463432312 train acc 0.8429512779552716\n",
            "epoch 12 batch id 314 loss 0.5149734616279602 train acc 0.8431031050955414\n",
            "epoch 12 batch id 315 loss 0.5159396529197693 train acc 0.8431051587301587\n",
            "epoch 12 batch id 316 loss 0.7080941200256348 train acc 0.8430083069620253\n",
            "epoch 12 batch id 317 loss 0.6725034713745117 train acc 0.8429120662460567\n",
            "epoch 12 batch id 318 loss 0.4997110366821289 train acc 0.843062106918239\n",
            "epoch 12 batch id 319 loss 0.6697562336921692 train acc 0.8430152821316614\n",
            "epoch 12 batch id 320 loss 0.38481906056404114 train acc 0.8431640625\n",
            "epoch 12 batch id 321 loss 0.45874980092048645 train acc 0.8432145638629284\n",
            "epoch 12 batch id 322 loss 0.4674268960952759 train acc 0.8433132763975155\n",
            "epoch 12 batch id 323 loss 0.9911202192306519 train acc 0.8430243808049536\n",
            "epoch 12 batch id 324 loss 0.700732946395874 train acc 0.8429783950617284\n",
            "epoch 12 batch id 325 loss 0.4929778277873993 train acc 0.8430769230769231\n",
            "epoch 12 batch id 326 loss 0.3912810981273651 train acc 0.8433186349693251\n",
            "epoch 12 batch id 327 loss 0.515024721622467 train acc 0.8435110856269113\n",
            "epoch 12 batch id 328 loss 0.5119460821151733 train acc 0.8435118140243902\n",
            "epoch 12 batch id 329 loss 0.5182936787605286 train acc 0.843512537993921\n",
            "epoch 12 batch id 330 loss 0.4537895917892456 train acc 0.843560606060606\n",
            "epoch 12 batch id 331 loss 0.7586944699287415 train acc 0.8433723564954683\n",
            "epoch 12 batch id 332 loss 0.48304787278175354 train acc 0.8433734939759037\n",
            "epoch 12 batch id 333 loss 0.4872240424156189 train acc 0.8434684684684685\n",
            "epoch 12 batch id 334 loss 0.7398741245269775 train acc 0.8434225299401198\n",
            "epoch 12 batch id 335 loss 0.38598671555519104 train acc 0.8434701492537313\n",
            "epoch 12 batch id 336 loss 0.5863154530525208 train acc 0.8433314732142857\n",
            "epoch 12 batch id 337 loss 0.5312585830688477 train acc 0.8434718100890207\n",
            "epoch 12 batch id 338 loss 0.5018218755722046 train acc 0.8434264053254438\n",
            "epoch 12 batch id 339 loss 0.4703093469142914 train acc 0.8436117256637168\n",
            "epoch 12 batch id 340 loss 0.7349131107330322 train acc 0.8435661764705882\n",
            "epoch 12 batch id 341 loss 0.5093780159950256 train acc 0.8437041788856305\n",
            "epoch 12 batch id 342 loss 0.5877728462219238 train acc 0.8436586257309941\n",
            "epoch 12 batch id 343 loss 0.3901209831237793 train acc 0.84375\n",
            "epoch 12 batch id 344 loss 0.5392377972602844 train acc 0.8438862645348837\n",
            "epoch 12 batch id 345 loss 0.6414381861686707 train acc 0.84375\n",
            "epoch 12 batch id 346 loss 0.4486183822154999 train acc 0.84375\n",
            "epoch 12 batch id 347 loss 0.512070894241333 train acc 0.8437049711815562\n",
            "epoch 12 batch id 348 loss 0.5538257360458374 train acc 0.84375\n",
            "epoch 12 batch id 349 loss 0.4640291929244995 train acc 0.8439290830945558\n",
            "epoch 12 batch id 350 loss 0.7753537893295288 train acc 0.8439732142857143\n",
            "epoch 12 batch id 351 loss 0.5293400287628174 train acc 0.8440616096866097\n",
            "epoch 12 batch id 352 loss 0.5773688554763794 train acc 0.8441495028409091\n",
            "epoch 12 batch id 353 loss 0.6077728271484375 train acc 0.8441483711048159\n",
            "epoch 12 batch id 354 loss 0.6668583154678345 train acc 0.8441472457627118\n",
            "epoch 12 batch id 355 loss 0.34909260272979736 train acc 0.8443661971830986\n",
            "epoch 12 batch id 356 loss 0.7504573464393616 train acc 0.8443205758426966\n",
            "epoch 12 batch id 357 loss 0.6295396089553833 train acc 0.8442314425770309\n",
            "epoch 12 batch id 358 loss 0.6441588401794434 train acc 0.8444046787709497\n",
            "epoch 12 batch id 359 loss 0.6468929648399353 train acc 0.8441852367688022\n",
            "epoch 12 batch id 360 loss 0.5352485775947571 train acc 0.8441840277777778\n",
            "epoch 12 batch id 361 loss 0.5065024495124817 train acc 0.8443126731301939\n",
            "epoch 12 batch id 362 loss 0.5287527441978455 train acc 0.8443974447513812\n",
            "epoch 12 batch id 363 loss 0.7257094383239746 train acc 0.8441804407713499\n",
            "epoch 12 batch id 364 loss 0.6326526403427124 train acc 0.8442221840659341\n",
            "epoch 12 batch id 365 loss 0.9461358785629272 train acc 0.8440068493150685\n",
            "epoch 12 batch id 366 loss 0.5360435843467712 train acc 0.8440061475409836\n",
            "epoch 12 batch id 367 loss 0.5995485186576843 train acc 0.8440480245231607\n",
            "epoch 12 batch id 368 loss 0.8277392983436584 train acc 0.8438349184782609\n",
            "epoch 12 batch id 369 loss 0.3534986078739166 train acc 0.8439617208672087\n",
            "epoch 12 batch id 370 loss 0.3655467927455902 train acc 0.8441722972972973\n",
            "epoch 12 batch id 371 loss 0.7036062479019165 train acc 0.8441711590296496\n",
            "epoch 12 batch id 372 loss 0.46416208148002625 train acc 0.8442120295698925\n",
            "epoch 12 batch id 373 loss 0.42429599165916443 train acc 0.8442107908847185\n",
            "epoch 12 batch id 374 loss 0.5654591917991638 train acc 0.844167780748663\n",
            "epoch 12 batch id 375 loss 0.35967132449150085 train acc 0.8444583333333333\n",
            "epoch 12 batch id 376 loss 0.6683967113494873 train acc 0.8444564494680851\n",
            "epoch 12 batch id 377 loss 0.5746549963951111 train acc 0.8443716843501327\n",
            "epoch 12 batch id 378 loss 0.7509238123893738 train acc 0.8442873677248677\n",
            "epoch 12 batch id 379 loss 0.6642311811447144 train acc 0.8443684036939314\n",
            "epoch 12 batch id 380 loss 0.7228173613548279 train acc 0.8443667763157895\n",
            "epoch 12 batch id 381 loss 0.6769736409187317 train acc 0.8444061679790026\n",
            "epoch 12 batch id 382 loss 0.5032604336738586 train acc 0.8444044502617801\n",
            "epoch 12 batch id 383 loss 0.6128088235855103 train acc 0.8443211488250653\n",
            "epoch 12 batch id 384 loss 0.45312467217445374 train acc 0.8445231119791666\n",
            "epoch 12 batch id 385 loss 0.6594351530075073 train acc 0.8445211038961039\n",
            "epoch 12 batch id 386 loss 0.5944718718528748 train acc 0.844559585492228\n",
            "epoch 12 batch id 387 loss 0.46351388096809387 train acc 0.8446786175710594\n",
            "epoch 12 batch id 388 loss 0.4886409640312195 train acc 0.8446762242268041\n",
            "epoch 12 batch id 389 loss 0.5205146074295044 train acc 0.8447943444730077\n",
            "epoch 12 batch id 390 loss 0.4867064952850342 train acc 0.8448717948717949\n",
            "epoch 12 batch id 391 loss 0.5883597731590271 train acc 0.8449488491048593\n",
            "epoch 12 batch id 392 loss 0.5030415058135986 train acc 0.8451052295918368\n",
            "epoch 12 batch id 393 loss 0.6623790264129639 train acc 0.8451415394402035\n",
            "epoch 12 batch id 394 loss 0.505830705165863 train acc 0.8452569796954315\n",
            "epoch 12 batch id 395 loss 0.7063608169555664 train acc 0.8451740506329114\n",
            "epoch 12 batch id 396 loss 0.4046271741390228 train acc 0.8453282828282829\n",
            "epoch 12 batch id 397 loss 0.45787057280540466 train acc 0.8454423803526449\n",
            "epoch 12 batch id 398 loss 0.5459728837013245 train acc 0.8455559045226131\n",
            "epoch 12 batch id 399 loss 0.66091388463974 train acc 0.8455122180451128\n",
            "epoch 12 batch id 400 loss 0.41805216670036316 train acc 0.845625\n",
            "epoch 12 batch id 401 loss 0.5883898138999939 train acc 0.8455813591022444\n",
            "epoch 12 batch id 402 loss 0.4584520757198334 train acc 0.845693407960199\n",
            "epoch 12 batch id 403 loss 0.39265963435173035 train acc 0.8457273573200993\n",
            "epoch 12 batch id 404 loss 0.6623765826225281 train acc 0.8456451113861386\n",
            "epoch 12 batch id 405 loss 0.5100645422935486 train acc 0.8457175925925926\n",
            "epoch 12 batch id 406 loss 0.3627844452857971 train acc 0.8458282019704434\n",
            "epoch 12 batch id 407 loss 0.3218371272087097 train acc 0.8459382678132679\n",
            "epoch 12 batch id 408 loss 0.5874171853065491 train acc 0.8457797181372549\n",
            "epoch 12 batch id 409 loss 0.5744255781173706 train acc 0.8458129584352079\n",
            "epoch 12 batch id 410 loss 0.42114758491516113 train acc 0.8459603658536585\n",
            "epoch 12 batch id 411 loss 0.6218412518501282 train acc 0.8459169708029197\n",
            "epoch 12 batch id 412 loss 0.46952319145202637 train acc 0.8459117111650486\n",
            "epoch 12 batch id 413 loss 0.580547034740448 train acc 0.8458308111380145\n",
            "epoch 12 batch id 414 loss 0.4248763918876648 train acc 0.8460144927536232\n",
            "epoch 12 batch id 415 loss 0.5167666673660278 train acc 0.8460466867469879\n",
            "epoch 12 batch id 416 loss 0.4935864508152008 train acc 0.8461162860576923\n",
            "epoch 12 batch id 417 loss 0.45587486028671265 train acc 0.8461106115107914\n",
            "epoch 12 batch id 418 loss 0.680504560470581 train acc 0.8459928229665071\n",
            "epoch 12 batch id 419 loss 0.415170818567276 train acc 0.8461739260143198\n",
            "epoch 12 batch id 420 loss 0.5746430158615112 train acc 0.8462425595238096\n",
            "epoch 12 batch id 421 loss 0.5896127223968506 train acc 0.8462366389548693\n",
            "epoch 12 batch id 422 loss 0.34765875339508057 train acc 0.8463788507109005\n",
            "epoch 12 batch id 423 loss 0.6091272830963135 train acc 0.8463726359338062\n",
            "epoch 12 batch id 424 loss 0.32024121284484863 train acc 0.8464770047169812\n",
            "epoch 12 batch id 425 loss 0.335490345954895 train acc 0.8466544117647059\n",
            "epoch 12 batch id 426 loss 0.38356563448905945 train acc 0.8467576291079812\n",
            "epoch 12 batch id 427 loss 0.7106305956840515 train acc 0.846677400468384\n",
            "epoch 12 batch id 428 loss 0.4599989950656891 train acc 0.8466340537383178\n",
            "epoch 12 batch id 429 loss 0.49673712253570557 train acc 0.846663752913753\n",
            "epoch 12 batch id 430 loss 0.5241507291793823 train acc 0.846656976744186\n",
            "epoch 12 batch id 431 loss 0.2703893780708313 train acc 0.8468677494199536\n",
            "epoch 12 batch id 432 loss 0.8349425196647644 train acc 0.8467881944444444\n",
            "epoch 12 batch id 433 loss 0.3084936738014221 train acc 0.8469616050808314\n",
            "epoch 12 batch id 434 loss 0.4596489667892456 train acc 0.8470982142857143\n",
            "epoch 12 batch id 435 loss 0.36441975831985474 train acc 0.8472701149425287\n",
            "epoch 12 batch id 436 loss 0.47404736280441284 train acc 0.8473695527522935\n",
            "epoch 12 batch id 437 loss 0.38933661580085754 train acc 0.8475042906178489\n",
            "epoch 12 batch id 438 loss 0.7224952578544617 train acc 0.8474600456621004\n",
            "epoch 12 batch id 439 loss 0.4870922565460205 train acc 0.8475227790432802\n",
            "epoch 12 batch id 440 loss 0.6657965183258057 train acc 0.8474786931818182\n",
            "epoch 12 batch id 441 loss 0.5955607295036316 train acc 0.8475056689342404\n",
            "epoch 12 batch id 442 loss 0.5290148258209229 train acc 0.8476385746606335\n",
            "epoch 12 batch id 443 loss 0.49821600317955017 train acc 0.8477356094808126\n",
            "epoch 12 batch id 444 loss 0.5663333535194397 train acc 0.8478673986486487\n",
            "epoch 12 batch id 445 loss 0.6306336522102356 train acc 0.8477879213483146\n",
            "epoch 12 batch id 446 loss 0.4315505921840668 train acc 0.8479190022421524\n",
            "epoch 12 batch id 447 loss 0.3456726372241974 train acc 0.8480494966442953\n",
            "epoch 12 batch id 448 loss 0.6166766285896301 train acc 0.8480050223214286\n",
            "epoch 12 batch id 449 loss 0.47913700342178345 train acc 0.8479955456570156\n",
            "epoch 12 batch id 450 loss 0.531230628490448 train acc 0.8480555555555556\n",
            "epoch 12 batch id 451 loss 0.6719698309898376 train acc 0.8480460088691796\n",
            "epoch 12 batch id 452 loss 0.7392416596412659 train acc 0.8479673672566371\n",
            "epoch 12 batch id 453 loss 0.4332888424396515 train acc 0.8481650110375276\n",
            "epoch 12 batch id 454 loss 0.3310542404651642 train acc 0.8483273678414097\n",
            "epoch 12 batch id 455 loss 0.38330453634262085 train acc 0.8484546703296704\n",
            "epoch 12 batch id 456 loss 0.4054585099220276 train acc 0.8485814144736842\n",
            "epoch 12 batch id 457 loss 0.7363789677619934 train acc 0.8485024617067833\n",
            "epoch 12 batch id 458 loss 0.379620760679245 train acc 0.8485944323144105\n",
            "epoch 12 batch id 459 loss 0.4206468164920807 train acc 0.8487200435729847\n",
            "epoch 12 batch id 460 loss 0.6244515776634216 train acc 0.8486752717391305\n",
            "epoch 12 batch id 461 loss 0.36162829399108887 train acc 0.8488001626898047\n",
            "epoch 12 batch id 462 loss 0.4208931028842926 train acc 0.8488906926406926\n",
            "epoch 12 batch id 463 loss 0.5618231296539307 train acc 0.8489470842332614\n",
            "epoch 12 batch id 464 loss 0.6407358050346375 train acc 0.8488685344827587\n",
            "epoch 12 batch id 465 loss 0.6880601644515991 train acc 0.8488239247311828\n",
            "epoch 12 batch id 466 loss 0.5417331457138062 train acc 0.8487795064377682\n",
            "epoch 12 batch id 467 loss 1.0359289646148682 train acc 0.8485010706638115\n",
            "epoch 12 batch id 468 loss 0.6651955842971802 train acc 0.8485243055555556\n",
            "epoch 12 batch id 469 loss 0.44992735981941223 train acc 0.8485807569296375\n",
            "epoch 12 batch id 470 loss 0.4188835918903351 train acc 0.8487034574468085\n",
            "epoch 12 batch id 471 loss 0.7013075351715088 train acc 0.8486597664543525\n",
            "epoch 12 batch id 472 loss 0.412889689207077 train acc 0.848781779661017\n",
            "epoch 12 batch id 473 loss 0.8866286873817444 train acc 0.8487381078224101\n",
            "epoch 12 batch id 474 loss 0.8690773844718933 train acc 0.8486616561181435\n",
            "epoch 12 batch id 475 loss 0.44666197896003723 train acc 0.8486513157894737\n",
            "epoch 12 batch id 476 loss 0.5189696550369263 train acc 0.8486738445378151\n",
            "epoch 12 batch id 477 loss 0.4603930413722992 train acc 0.848729035639413\n",
            "epoch 12 batch id 478 loss 0.5691465735435486 train acc 0.8486859309623431\n",
            "epoch 12 batch id 479 loss 0.5259076952934265 train acc 0.84883872651357\n",
            "epoch 12 batch id 480 loss 0.6406502723693848 train acc 0.8486979166666667\n",
            "epoch 12 batch id 481 loss 0.30345532298088074 train acc 0.8488500519750519\n",
            "epoch 12 batch id 482 loss 0.49621033668518066 train acc 0.848871887966805\n",
            "epoch 12 batch id 483 loss 0.7518388628959656 train acc 0.8488936335403726\n",
            "epoch 12 batch id 484 loss 0.506098747253418 train acc 0.8489798553719008\n",
            "epoch 12 batch id 485 loss 0.6091382503509521 train acc 0.8490335051546392\n",
            "epoch 12 batch id 486 loss 0.46897390484809875 train acc 0.8491190843621399\n",
            "epoch 12 batch id 487 loss 0.697002649307251 train acc 0.848851386036961\n",
            "epoch 12 batch id 488 loss 0.40314963459968567 train acc 0.8490010245901639\n",
            "epoch 12 batch id 489 loss 0.5691084265708923 train acc 0.8489902862985685\n",
            "epoch 12 batch id 490 loss 0.5140672922134399 train acc 0.8490114795918368\n",
            "epoch 12 batch id 491 loss 0.6946368217468262 train acc 0.8490007637474541\n",
            "epoch 12 batch id 492 loss 0.8019717931747437 train acc 0.8488948170731707\n",
            "epoch 12 batch id 493 loss 0.5673070549964905 train acc 0.8488843813387424\n",
            "epoch 12 batch id 494 loss 0.5532811284065247 train acc 0.8489056174089069\n",
            "epoch 12 batch id 495 loss 0.5656273365020752 train acc 0.8488636363636364\n",
            "epoch 12 batch id 496 loss 0.6702118515968323 train acc 0.8488218245967742\n",
            "epoch 12 batch id 497 loss 0.8003331422805786 train acc 0.8488116197183099\n",
            "epoch 12 batch id 498 loss 0.3824523389339447 train acc 0.8488328313253012\n",
            "epoch 12 batch id 499 loss 0.5114254355430603 train acc 0.8489478957915831\n",
            "epoch 12 batch id 500 loss 0.48381465673446655 train acc 0.849\n",
            "epoch 12 batch id 501 loss 0.41057080030441284 train acc 0.8490830838323353\n",
            "epoch 12 batch id 502 loss 0.24391314387321472 train acc 0.8492280876494024\n",
            "epoch 12 batch id 503 loss 0.7597998976707458 train acc 0.8492171968190855\n",
            "epoch 12 batch id 504 loss 0.5378689169883728 train acc 0.8492063492063492\n",
            "epoch 12 batch id 505 loss 0.7191812992095947 train acc 0.8491646039603961\n",
            "epoch 12 batch id 506 loss 0.7623943090438843 train acc 0.8490612648221344\n",
            "epoch 12 batch id 507 loss 0.43110740184783936 train acc 0.8491432445759369\n",
            "epoch 12 batch id 508 loss 0.5955021381378174 train acc 0.8491018700787402\n",
            "epoch 12 batch id 509 loss 0.2916751503944397 train acc 0.8492141453831041\n",
            "epoch 12 batch id 510 loss 0.49065491557121277 train acc 0.8492647058823529\n",
            "epoch 12 batch id 511 loss 0.6896188855171204 train acc 0.8492179977013636\n",
            "epoch 12 train acc 0.8492179977013636\n",
            "epoch 12 test acc 0.3971354166666667\n",
            "epoch 13 batch id 1 loss 0.32238104939460754 train acc 0.921875\n",
            "epoch 13 batch id 2 loss 0.32381296157836914 train acc 0.9140625\n",
            "epoch 13 batch id 3 loss 0.33188456296920776 train acc 0.921875\n",
            "epoch 13 batch id 4 loss 0.4384914040565491 train acc 0.90625\n",
            "epoch 13 batch id 5 loss 0.40249061584472656 train acc 0.90625\n",
            "epoch 13 batch id 6 loss 0.47222524881362915 train acc 0.90625\n",
            "epoch 13 batch id 7 loss 0.456414133310318 train acc 0.9017857142857143\n",
            "epoch 13 batch id 8 loss 0.6924933195114136 train acc 0.896484375\n",
            "epoch 13 batch id 9 loss 0.5455486178398132 train acc 0.8923611111111112\n",
            "epoch 13 batch id 10 loss 0.5500190258026123 train acc 0.884375\n",
            "epoch 13 batch id 11 loss 0.49311915040016174 train acc 0.8835227272727273\n",
            "epoch 13 batch id 12 loss 0.36164209246635437 train acc 0.8815104166666666\n",
            "epoch 13 batch id 13 loss 0.4259463846683502 train acc 0.8822115384615384\n",
            "epoch 13 batch id 14 loss 0.7532558441162109 train acc 0.8761160714285714\n",
            "epoch 13 batch id 15 loss 0.5660168528556824 train acc 0.8739583333333333\n",
            "epoch 13 batch id 16 loss 0.5725951790809631 train acc 0.8720703125\n",
            "epoch 13 batch id 17 loss 0.5426896214485168 train acc 0.8731617647058824\n",
            "epoch 13 batch id 18 loss 0.472604900598526 train acc 0.8758680555555556\n",
            "epoch 13 batch id 19 loss 0.3368835151195526 train acc 0.8774671052631579\n",
            "epoch 13 batch id 20 loss 0.5296046733856201 train acc 0.8765625\n",
            "epoch 13 batch id 21 loss 0.860676109790802 train acc 0.8727678571428571\n",
            "epoch 13 batch id 22 loss 0.48045864701271057 train acc 0.8714488636363636\n",
            "epoch 13 batch id 23 loss 0.45542797446250916 train acc 0.8729619565217391\n",
            "epoch 13 batch id 24 loss 0.896549642086029 train acc 0.869140625\n",
            "epoch 13 batch id 25 loss 0.5548164248466492 train acc 0.86875\n",
            "epoch 13 batch id 26 loss 0.5023482441902161 train acc 0.8665865384615384\n",
            "epoch 13 batch id 27 loss 0.33164075016975403 train acc 0.8692129629629629\n",
            "epoch 13 batch id 28 loss 0.8321691751480103 train acc 0.8660714285714286\n",
            "epoch 13 batch id 29 loss 0.5581087470054626 train acc 0.8642241379310345\n",
            "epoch 13 batch id 30 loss 0.44900885224342346 train acc 0.8651041666666667\n",
            "epoch 13 batch id 31 loss 0.6008914709091187 train acc 0.8629032258064516\n",
            "epoch 13 batch id 32 loss 0.5307186841964722 train acc 0.86279296875\n",
            "epoch 13 batch id 33 loss 0.42006394267082214 train acc 0.8622159090909091\n",
            "epoch 13 batch id 34 loss 0.46672260761260986 train acc 0.8625919117647058\n",
            "epoch 13 batch id 35 loss 0.8246252536773682 train acc 0.8598214285714286\n",
            "epoch 13 batch id 36 loss 0.31832772493362427 train acc 0.8615451388888888\n",
            "epoch 13 batch id 37 loss 0.5821355581283569 train acc 0.8602195945945946\n",
            "epoch 13 batch id 38 loss 0.7696181535720825 train acc 0.8597861842105263\n",
            "epoch 13 batch id 39 loss 0.6833216547966003 train acc 0.859375\n",
            "epoch 13 batch id 40 loss 0.6480928659439087 train acc 0.858984375\n",
            "epoch 13 batch id 41 loss 0.42484569549560547 train acc 0.8589939024390244\n",
            "epoch 13 batch id 42 loss 0.5838795900344849 train acc 0.8578869047619048\n",
            "epoch 13 batch id 43 loss 0.7740288972854614 train acc 0.857921511627907\n",
            "epoch 13 batch id 44 loss 0.6390700340270996 train acc 0.8575994318181818\n",
            "epoch 13 batch id 45 loss 0.6380226016044617 train acc 0.85625\n",
            "epoch 13 batch id 46 loss 0.6172001957893372 train acc 0.8556385869565217\n",
            "epoch 13 batch id 47 loss 0.37511271238327026 train acc 0.8567154255319149\n",
            "epoch 13 batch id 48 loss 0.3886473476886749 train acc 0.8580729166666666\n",
            "epoch 13 batch id 49 loss 0.46421104669570923 train acc 0.8584183673469388\n",
            "epoch 13 batch id 50 loss 0.740191638469696 train acc 0.8575\n",
            "epoch 13 batch id 51 loss 0.6958784461021423 train acc 0.8578431372549019\n",
            "epoch 13 batch id 52 loss 0.4569699764251709 train acc 0.8590745192307693\n",
            "epoch 13 batch id 53 loss 0.6181682348251343 train acc 0.859375\n",
            "epoch 13 batch id 54 loss 0.3515661060810089 train acc 0.8608217592592593\n",
            "epoch 13 batch id 55 loss 0.4611333906650543 train acc 0.8616477272727273\n",
            "epoch 13 batch id 56 loss 0.39768368005752563 train acc 0.8624441964285714\n",
            "epoch 13 batch id 57 loss 0.31534430384635925 train acc 0.8637609649122807\n",
            "epoch 13 batch id 58 loss 0.5005823969841003 train acc 0.8639547413793104\n",
            "epoch 13 batch id 59 loss 0.3610507547855377 train acc 0.8641419491525424\n",
            "epoch 13 batch id 60 loss 0.548639714717865 train acc 0.8640625\n",
            "epoch 13 batch id 61 loss 0.6453693509101868 train acc 0.8637295081967213\n",
            "epoch 13 batch id 62 loss 0.7519679069519043 train acc 0.8626512096774194\n",
            "epoch 13 batch id 63 loss 0.44998523592948914 train acc 0.8628472222222222\n",
            "epoch 13 batch id 64 loss 0.44989046454429626 train acc 0.863037109375\n",
            "epoch 13 batch id 65 loss 0.5023235082626343 train acc 0.8632211538461538\n",
            "epoch 13 batch id 66 loss 0.3781615197658539 train acc 0.8638731060606061\n",
            "epoch 13 batch id 67 loss 0.38864684104919434 train acc 0.8640391791044776\n",
            "epoch 13 batch id 68 loss 0.42816776037216187 train acc 0.8635110294117647\n",
            "epoch 13 batch id 69 loss 0.29743441939353943 train acc 0.8643568840579711\n",
            "epoch 13 batch id 70 loss 0.5257231593132019 train acc 0.8645089285714286\n",
            "epoch 13 batch id 71 loss 0.3938417434692383 train acc 0.8639964788732394\n",
            "epoch 13 batch id 72 loss 0.6940515041351318 train acc 0.8628472222222222\n",
            "epoch 13 batch id 73 loss 0.7393117547035217 train acc 0.8610873287671232\n",
            "epoch 13 batch id 74 loss 0.5168425440788269 train acc 0.8604307432432432\n",
            "epoch 13 batch id 75 loss 0.6849523782730103 train acc 0.8602083333333334\n",
            "epoch 13 batch id 76 loss 0.3360825479030609 train acc 0.8610197368421053\n",
            "epoch 13 batch id 77 loss 0.5479596853256226 train acc 0.8607954545454546\n",
            "epoch 13 batch id 78 loss 0.5674578547477722 train acc 0.860176282051282\n",
            "epoch 13 batch id 79 loss 0.48958224058151245 train acc 0.8605617088607594\n",
            "epoch 13 batch id 80 loss 0.4113849401473999 train acc 0.860546875\n",
            "epoch 13 batch id 81 loss 0.32258468866348267 train acc 0.8611111111111112\n",
            "epoch 13 batch id 82 loss 0.3097212314605713 train acc 0.8612804878048781\n",
            "epoch 13 batch id 83 loss 0.20513324439525604 train acc 0.8621987951807228\n",
            "epoch 13 batch id 84 loss 0.5852595567703247 train acc 0.8617931547619048\n",
            "epoch 13 batch id 85 loss 0.37617841362953186 train acc 0.8619485294117647\n",
            "epoch 13 batch id 86 loss 0.7580349445343018 train acc 0.8619186046511628\n",
            "epoch 13 batch id 87 loss 0.4275147020816803 train acc 0.8620689655172413\n",
            "epoch 13 batch id 88 loss 0.7557351589202881 train acc 0.861328125\n",
            "epoch 13 batch id 89 loss 0.3570241630077362 train acc 0.8621839887640449\n",
            "epoch 13 batch id 90 loss 0.4007869362831116 train acc 0.8625\n",
            "epoch 13 batch id 91 loss 0.651960551738739 train acc 0.8621222527472527\n",
            "epoch 13 batch id 92 loss 0.34660235047340393 train acc 0.8629415760869565\n",
            "epoch 13 batch id 93 loss 0.4961320459842682 train acc 0.8629032258064516\n",
            "epoch 13 batch id 94 loss 0.2924303710460663 train acc 0.863530585106383\n",
            "epoch 13 batch id 95 loss 0.5054702162742615 train acc 0.8633223684210526\n",
            "epoch 13 batch id 96 loss 0.758424699306488 train acc 0.8624674479166666\n",
            "epoch 13 batch id 97 loss 0.617947518825531 train acc 0.8617912371134021\n",
            "epoch 13 batch id 98 loss 0.646761417388916 train acc 0.8616071428571429\n",
            "epoch 13 batch id 99 loss 0.5622410178184509 train acc 0.8620580808080808\n",
            "epoch 13 batch id 100 loss 0.5685646533966064 train acc 0.86234375\n",
            "epoch 13 batch id 101 loss 0.4777303636074066 train acc 0.8626237623762376\n",
            "epoch 13 batch id 102 loss 0.6050280332565308 train acc 0.8624387254901961\n",
            "epoch 13 batch id 103 loss 0.38812440633773804 train acc 0.8630157766990292\n",
            "epoch 13 batch id 104 loss 0.5562137365341187 train acc 0.8625300480769231\n",
            "epoch 13 batch id 105 loss 0.5682210922241211 train acc 0.862202380952381\n",
            "epoch 13 batch id 106 loss 0.4471336603164673 train acc 0.8624705188679245\n",
            "epoch 13 batch id 107 loss 0.6701183915138245 train acc 0.8622955607476636\n",
            "epoch 13 batch id 108 loss 0.43607473373413086 train acc 0.8627025462962963\n",
            "epoch 13 batch id 109 loss 0.5525619387626648 train acc 0.8628153669724771\n",
            "epoch 13 batch id 110 loss 0.5410788059234619 train acc 0.8626420454545455\n",
            "epoch 13 batch id 111 loss 0.4978388547897339 train acc 0.8628941441441441\n",
            "epoch 13 batch id 112 loss 0.48645955324172974 train acc 0.8628627232142857\n",
            "epoch 13 batch id 113 loss 0.36806654930114746 train acc 0.8632466814159292\n",
            "epoch 13 batch id 114 loss 0.6441246271133423 train acc 0.8630756578947368\n",
            "epoch 13 batch id 115 loss 0.6000436544418335 train acc 0.8627717391304348\n",
            "epoch 13 batch id 116 loss 0.4671226739883423 train acc 0.8628771551724138\n",
            "epoch 13 batch id 117 loss 0.37798458337783813 train acc 0.8628472222222222\n",
            "epoch 13 batch id 118 loss 0.40162503719329834 train acc 0.8629502118644068\n",
            "epoch 13 batch id 119 loss 0.6717662811279297 train acc 0.8627888655462185\n",
            "epoch 13 batch id 120 loss 0.5217326879501343 train acc 0.862890625\n",
            "epoch 13 batch id 121 loss 0.3256405293941498 train acc 0.8633780991735537\n",
            "epoch 13 batch id 122 loss 0.4921381175518036 train acc 0.8633452868852459\n",
            "epoch 13 batch id 123 loss 0.35932132601737976 train acc 0.8634400406504065\n",
            "epoch 13 batch id 124 loss 0.5378125905990601 train acc 0.8634072580645161\n",
            "epoch 13 batch id 125 loss 0.5549795627593994 train acc 0.86325\n",
            "epoch 13 batch id 126 loss 0.4937049448490143 train acc 0.863219246031746\n",
            "epoch 13 batch id 127 loss 0.5038847923278809 train acc 0.8633120078740157\n",
            "epoch 13 batch id 128 loss 0.6687686443328857 train acc 0.8626708984375\n",
            "epoch 13 batch id 129 loss 0.6762701869010925 train acc 0.8626453488372093\n",
            "epoch 13 batch id 130 loss 0.404094934463501 train acc 0.8628605769230769\n",
            "epoch 13 batch id 131 loss 0.41394129395484924 train acc 0.8630725190839694\n",
            "epoch 13 batch id 132 loss 0.6375049948692322 train acc 0.8629261363636364\n",
            "epoch 13 batch id 133 loss 0.5739807486534119 train acc 0.8628994360902256\n",
            "epoch 13 batch id 134 loss 0.5079584717750549 train acc 0.8629897388059702\n",
            "epoch 13 batch id 135 loss 0.620365560054779 train acc 0.8629629629629629\n",
            "epoch 13 batch id 136 loss 0.632408082485199 train acc 0.8625919117647058\n",
            "epoch 13 batch id 137 loss 0.4999026358127594 train acc 0.8627965328467153\n",
            "epoch 13 batch id 138 loss 0.5762762427330017 train acc 0.8626585144927537\n",
            "epoch 13 batch id 139 loss 0.48805850744247437 train acc 0.8628597122302158\n",
            "epoch 13 batch id 140 loss 0.6569623947143555 train acc 0.8627232142857143\n",
            "epoch 13 batch id 141 loss 0.5605961680412292 train acc 0.8625886524822695\n",
            "epoch 13 batch id 142 loss 0.49773508310317993 train acc 0.8625660211267606\n",
            "epoch 13 batch id 143 loss 0.40290987491607666 train acc 0.8627622377622378\n",
            "epoch 13 batch id 144 loss 0.6189489364624023 train acc 0.8628472222222222\n",
            "epoch 13 batch id 145 loss 0.550959587097168 train acc 0.8629310344827587\n",
            "epoch 13 batch id 146 loss 0.5920654535293579 train acc 0.8629066780821918\n",
            "epoch 13 batch id 147 loss 0.6770482659339905 train acc 0.8624574829931972\n",
            "epoch 13 batch id 148 loss 0.3760358691215515 train acc 0.8628589527027027\n",
            "epoch 13 batch id 149 loss 0.4870518147945404 train acc 0.8628355704697986\n",
            "epoch 13 batch id 150 loss 0.4990234673023224 train acc 0.8626041666666666\n",
            "epoch 13 batch id 151 loss 0.8365457653999329 train acc 0.8622723509933775\n",
            "epoch 13 batch id 152 loss 0.6477978825569153 train acc 0.8621504934210527\n",
            "epoch 13 batch id 153 loss 0.4763202965259552 train acc 0.862234477124183\n",
            "epoch 13 batch id 154 loss 0.4119950830936432 train acc 0.8624188311688312\n",
            "epoch 13 batch id 155 loss 0.49673691391944885 train acc 0.8622983870967742\n",
            "epoch 13 batch id 156 loss 0.6379465460777283 train acc 0.8623798076923077\n",
            "epoch 13 batch id 157 loss 0.43796506524086 train acc 0.8622611464968153\n",
            "epoch 13 batch id 158 loss 0.6077228784561157 train acc 0.8623417721518988\n",
            "epoch 13 batch id 159 loss 0.43813836574554443 train acc 0.8625196540880503\n",
            "epoch 13 batch id 160 loss 0.4498572051525116 train acc 0.8626953125\n",
            "epoch 13 batch id 161 loss 0.4798155725002289 train acc 0.8624805900621118\n",
            "epoch 13 batch id 162 loss 0.6398501396179199 train acc 0.8623649691358025\n",
            "epoch 13 batch id 163 loss 0.3193003237247467 train acc 0.8626342024539877\n",
            "epoch 13 batch id 164 loss 0.3819584250450134 train acc 0.8627096036585366\n",
            "epoch 13 batch id 165 loss 0.40253573656082153 train acc 0.8628787878787879\n",
            "epoch 13 batch id 166 loss 0.39349374175071716 train acc 0.8630459337349398\n",
            "epoch 13 batch id 167 loss 0.4886781573295593 train acc 0.8633046407185628\n",
            "epoch 13 batch id 168 loss 0.5069633722305298 train acc 0.8633742559523809\n",
            "epoch 13 batch id 169 loss 0.42300111055374146 train acc 0.8636279585798816\n",
            "epoch 13 batch id 170 loss 0.8699250817298889 train acc 0.8632352941176471\n",
            "epoch 13 batch id 171 loss 0.616399347782135 train acc 0.8631213450292398\n",
            "epoch 13 batch id 172 loss 0.23833943903446198 train acc 0.8637354651162791\n",
            "epoch 13 batch id 173 loss 0.2994934320449829 train acc 0.8642521676300579\n",
            "epoch 13 batch id 174 loss 0.4884105622768402 train acc 0.8642241379310345\n",
            "epoch 13 batch id 175 loss 0.3253166675567627 train acc 0.8642857142857143\n",
            "epoch 13 batch id 176 loss 0.5730093121528625 train acc 0.8639026988636364\n",
            "epoch 13 batch id 177 loss 0.5229813456535339 train acc 0.863965395480226\n",
            "epoch 13 batch id 178 loss 0.5694798231124878 train acc 0.8638518258426966\n",
            "epoch 13 batch id 179 loss 0.6140980124473572 train acc 0.8638268156424581\n",
            "epoch 13 batch id 180 loss 0.5613468289375305 train acc 0.8637152777777778\n",
            "epoch 13 batch id 181 loss 0.4403989911079407 train acc 0.8637776243093923\n",
            "epoch 13 batch id 182 loss 0.6400870680809021 train acc 0.8634958791208791\n",
            "epoch 13 batch id 183 loss 0.6526690721511841 train acc 0.8633025956284153\n",
            "epoch 13 batch id 184 loss 0.5674216151237488 train acc 0.86328125\n",
            "epoch 13 batch id 185 loss 0.5964654684066772 train acc 0.8630067567567568\n",
            "epoch 13 batch id 186 loss 0.8501237630844116 train acc 0.8625672043010753\n",
            "epoch 13 batch id 187 loss 0.48600515723228455 train acc 0.8627172459893048\n",
            "epoch 13 batch id 188 loss 0.6252459287643433 train acc 0.862533244680851\n",
            "epoch 13 batch id 189 loss 0.31783539056777954 train acc 0.8625165343915344\n",
            "epoch 13 batch id 190 loss 0.6722741723060608 train acc 0.8621710526315789\n",
            "epoch 13 batch id 191 loss 0.4611109495162964 train acc 0.8621564136125655\n",
            "epoch 13 batch id 192 loss 0.3825472891330719 train acc 0.8623860677083334\n",
            "epoch 13 batch id 193 loss 0.23743443191051483 train acc 0.8626943005181347\n",
            "epoch 13 batch id 194 loss 0.502920925617218 train acc 0.8628382731958762\n",
            "epoch 13 batch id 195 loss 0.4541521668434143 train acc 0.8629807692307693\n",
            "epoch 13 batch id 196 loss 0.5507513880729675 train acc 0.8628029336734694\n",
            "epoch 13 batch id 197 loss 0.4978063106536865 train acc 0.8629441624365483\n",
            "epoch 13 batch id 198 loss 0.334618479013443 train acc 0.8631628787878788\n",
            "epoch 13 batch id 199 loss 0.5067735314369202 train acc 0.8630653266331658\n",
            "epoch 13 batch id 200 loss 0.32506707310676575 train acc 0.86328125\n",
            "epoch 13 batch id 201 loss 0.31130704283714294 train acc 0.8634950248756219\n",
            "epoch 13 batch id 202 loss 0.29440268874168396 train acc 0.8639387376237624\n",
            "epoch 13 batch id 203 loss 0.5263614654541016 train acc 0.8639162561576355\n",
            "epoch 13 batch id 204 loss 0.4688728451728821 train acc 0.8639705882352942\n",
            "epoch 13 batch id 205 loss 0.6612499952316284 train acc 0.8638719512195122\n",
            "epoch 13 batch id 206 loss 0.4864144027233124 train acc 0.8640776699029126\n",
            "epoch 13 batch id 207 loss 0.6404238343238831 train acc 0.863677536231884\n",
            "epoch 13 batch id 208 loss 0.4896470606327057 train acc 0.8638070913461539\n",
            "epoch 13 batch id 209 loss 0.444622665643692 train acc 0.8636363636363636\n",
            "epoch 13 batch id 210 loss 0.3797781467437744 train acc 0.8637648809523809\n",
            "epoch 13 batch id 211 loss 0.38170507550239563 train acc 0.8638181279620853\n",
            "epoch 13 batch id 212 loss 0.4286310076713562 train acc 0.8636497641509434\n",
            "epoch 13 batch id 213 loss 0.5006240010261536 train acc 0.863849765258216\n",
            "epoch 13 batch id 214 loss 0.42947056889533997 train acc 0.8639748831775701\n",
            "epoch 13 batch id 215 loss 0.2780289053916931 train acc 0.864171511627907\n",
            "epoch 13 batch id 216 loss 0.484203964471817 train acc 0.8642216435185185\n",
            "epoch 13 batch id 217 loss 0.5419405698776245 train acc 0.8639832949308756\n",
            "epoch 13 batch id 218 loss 0.5110297203063965 train acc 0.8638904816513762\n",
            "epoch 13 batch id 219 loss 0.6061805486679077 train acc 0.8639412100456622\n",
            "epoch 13 batch id 220 loss 0.22762109339237213 train acc 0.8641335227272727\n",
            "epoch 13 batch id 221 loss 0.4399082064628601 train acc 0.8640412895927602\n",
            "epoch 13 batch id 222 loss 0.5924689769744873 train acc 0.8638091216216216\n",
            "epoch 13 batch id 223 loss 0.5446024537086487 train acc 0.8638593049327354\n",
            "epoch 13 batch id 224 loss 0.4044398367404938 train acc 0.8639090401785714\n",
            "epoch 13 batch id 225 loss 0.5338345766067505 train acc 0.8640972222222222\n",
            "epoch 13 batch id 226 loss 0.5052081942558289 train acc 0.8641454646017699\n",
            "epoch 13 batch id 227 loss 0.31198060512542725 train acc 0.864262114537445\n",
            "epoch 13 batch id 228 loss 0.29332950711250305 train acc 0.864514802631579\n",
            "epoch 13 batch id 229 loss 0.5188124775886536 train acc 0.8644923580786026\n",
            "epoch 13 batch id 230 loss 0.47497835755348206 train acc 0.8646059782608696\n",
            "epoch 13 batch id 231 loss 0.4041071832180023 train acc 0.864448051948052\n",
            "epoch 13 batch id 232 loss 0.48606160283088684 train acc 0.8644935344827587\n",
            "epoch 13 batch id 233 loss 0.24910758435726166 train acc 0.8648739270386266\n",
            "epoch 13 batch id 234 loss 0.6033338904380798 train acc 0.8647168803418803\n",
            "epoch 13 batch id 235 loss 0.4411938488483429 train acc 0.8647606382978723\n",
            "epoch 13 batch id 236 loss 0.46736767888069153 train acc 0.8649364406779662\n",
            "epoch 13 batch id 237 loss 0.5758099555969238 train acc 0.8648470464135021\n",
            "epoch 13 batch id 238 loss 0.2723461389541626 train acc 0.8650866596638656\n",
            "epoch 13 batch id 239 loss 0.32564234733581543 train acc 0.8651935146443515\n",
            "epoch 13 batch id 240 loss 0.37882694602012634 train acc 0.8653645833333333\n",
            "epoch 13 batch id 241 loss 0.49482184648513794 train acc 0.8652748962655602\n",
            "epoch 13 batch id 242 loss 0.5949146747589111 train acc 0.8651859504132231\n",
            "epoch 13 batch id 243 loss 0.6769702434539795 train acc 0.8650334362139918\n",
            "epoch 13 batch id 244 loss 0.4605233371257782 train acc 0.8650742827868853\n",
            "epoch 13 batch id 245 loss 0.34399306774139404 train acc 0.8652423469387756\n",
            "epoch 13 batch id 246 loss 0.28944677114486694 train acc 0.8655360772357723\n",
            "epoch 13 batch id 247 loss 0.4456670582294464 train acc 0.8657009109311741\n",
            "epoch 13 batch id 248 loss 0.5904535055160522 train acc 0.8654863911290323\n",
            "epoch 13 batch id 249 loss 0.23926709592342377 train acc 0.8657128514056225\n",
            "epoch 13 batch id 250 loss 0.329988956451416 train acc 0.8659375\n",
            "epoch 13 batch id 251 loss 0.39816272258758545 train acc 0.8660981075697212\n",
            "epoch 13 batch id 252 loss 0.3240800201892853 train acc 0.8662574404761905\n",
            "epoch 13 batch id 253 loss 0.4096841812133789 train acc 0.8665390316205533\n",
            "epoch 13 batch id 254 loss 0.440829336643219 train acc 0.8666338582677166\n",
            "epoch 13 batch id 255 loss 0.21857529878616333 train acc 0.8668504901960784\n",
            "epoch 13 batch id 256 loss 0.5316241979598999 train acc 0.86669921875\n",
            "epoch 13 batch id 257 loss 0.44680511951446533 train acc 0.8666099221789884\n",
            "epoch 13 batch id 258 loss 0.5599549412727356 train acc 0.8664001937984496\n",
            "epoch 13 batch id 259 loss 0.37835410237312317 train acc 0.8666143822393823\n",
            "epoch 13 batch id 260 loss 0.4684199392795563 train acc 0.8668269230769231\n",
            "epoch 13 batch id 261 loss 0.4690621495246887 train acc 0.8667983716475096\n",
            "epoch 13 batch id 262 loss 0.5821674466133118 train acc 0.8666507633587787\n",
            "epoch 13 batch id 263 loss 0.5571202635765076 train acc 0.8668013307984791\n",
            "epoch 13 batch id 264 loss 0.31314316391944885 train acc 0.8669507575757576\n",
            "epoch 13 batch id 265 loss 0.44276726245880127 train acc 0.8669811320754717\n",
            "epoch 13 batch id 266 loss 0.6453441977500916 train acc 0.8667763157894737\n",
            "epoch 13 batch id 267 loss 0.41661810874938965 train acc 0.866748595505618\n",
            "epoch 13 batch id 268 loss 0.3489948809146881 train acc 0.8668959888059702\n",
            "epoch 13 batch id 269 loss 0.5163931846618652 train acc 0.8670422862453532\n",
            "epoch 13 batch id 270 loss 0.3614161014556885 train acc 0.8673032407407407\n",
            "epoch 13 batch id 271 loss 0.728200376033783 train acc 0.8670433579335793\n",
            "epoch 13 batch id 272 loss 0.4893049895763397 train acc 0.8670151654411765\n",
            "epoch 13 batch id 273 loss 0.5089802742004395 train acc 0.8670444139194139\n",
            "epoch 13 batch id 274 loss 0.5336174368858337 train acc 0.8671304744525548\n",
            "epoch 13 batch id 275 loss 0.45287060737609863 train acc 0.8671590909090909\n",
            "epoch 13 batch id 276 loss 0.4658093750476837 train acc 0.8671875\n",
            "epoch 13 batch id 277 loss 0.5029485821723938 train acc 0.8672157039711191\n",
            "epoch 13 batch id 278 loss 0.34371721744537354 train acc 0.8673561151079137\n",
            "epoch 13 batch id 279 loss 0.3085063695907593 train acc 0.8675515232974911\n",
            "epoch 13 batch id 280 loss 0.46001961827278137 train acc 0.8676339285714286\n",
            "epoch 13 batch id 281 loss 0.39446330070495605 train acc 0.8677713523131673\n",
            "epoch 13 batch id 282 loss 0.4900054633617401 train acc 0.8678523936170213\n",
            "epoch 13 batch id 283 loss 0.4019124209880829 train acc 0.8678224381625441\n",
            "epoch 13 batch id 284 loss 0.46529972553253174 train acc 0.8679027288732394\n",
            "epoch 13 batch id 285 loss 0.6847256422042847 train acc 0.8675438596491228\n",
            "epoch 13 batch id 286 loss 0.3520181179046631 train acc 0.8676791958041958\n",
            "epoch 13 batch id 287 loss 0.7066477537155151 train acc 0.867595818815331\n",
            "epoch 13 batch id 288 loss 0.41999080777168274 train acc 0.86767578125\n",
            "epoch 13 batch id 289 loss 0.8149590492248535 train acc 0.8674307958477508\n",
            "epoch 13 batch id 290 loss 0.3625361919403076 train acc 0.8676185344827586\n",
            "epoch 13 batch id 291 loss 0.2766067087650299 train acc 0.8678049828178694\n",
            "epoch 13 batch id 292 loss 0.9144745469093323 train acc 0.8676690924657534\n",
            "epoch 13 batch id 293 loss 0.25900402665138245 train acc 0.86785409556314\n",
            "epoch 13 batch id 294 loss 0.4688401520252228 train acc 0.8678252551020408\n",
            "epoch 13 batch id 295 loss 0.5860503315925598 train acc 0.8676377118644067\n",
            "epoch 13 batch id 296 loss 0.6158623099327087 train acc 0.8673986486486487\n",
            "epoch 13 batch id 297 loss 0.5622247457504272 train acc 0.8674242424242424\n",
            "epoch 13 batch id 298 loss 0.5494824647903442 train acc 0.8674496644295302\n",
            "epoch 13 batch id 299 loss 0.4928094744682312 train acc 0.8674226588628763\n",
            "epoch 13 batch id 300 loss 0.5373537540435791 train acc 0.8675\n",
            "epoch 13 batch id 301 loss 0.6463833451271057 train acc 0.8673691860465116\n",
            "epoch 13 batch id 302 loss 0.4934384524822235 train acc 0.8674461920529801\n",
            "epoch 13 batch id 303 loss 0.48967665433883667 train acc 0.867522689768977\n",
            "epoch 13 batch id 304 loss 0.6030052900314331 train acc 0.8674958881578947\n",
            "epoch 13 batch id 305 loss 0.5549952387809753 train acc 0.8673155737704918\n",
            "epoch 13 batch id 306 loss 0.4378011226654053 train acc 0.8674938725490197\n",
            "epoch 13 batch id 307 loss 0.5045453310012817 train acc 0.86751832247557\n",
            "epoch 13 batch id 308 loss 0.3807566165924072 train acc 0.8676948051948052\n",
            "epoch 13 batch id 309 loss 0.39577022194862366 train acc 0.8677690129449838\n",
            "epoch 13 batch id 310 loss 0.46691641211509705 train acc 0.867741935483871\n",
            "epoch 13 batch id 311 loss 0.3185606598854065 train acc 0.8680164790996785\n",
            "epoch 13 batch id 312 loss 0.5595322847366333 train acc 0.8680889423076923\n",
            "epoch 13 batch id 313 loss 0.7222398519515991 train acc 0.8679113418530351\n",
            "epoch 13 batch id 314 loss 0.34758445620536804 train acc 0.8679339171974523\n",
            "epoch 13 batch id 315 loss 0.5199187397956848 train acc 0.8679563492063492\n",
            "epoch 13 batch id 316 loss 0.21962544322013855 train acc 0.8681764240506329\n",
            "epoch 13 batch id 317 loss 0.4310794770717621 train acc 0.8680993690851735\n",
            "epoch 13 batch id 318 loss 0.3905308246612549 train acc 0.8682193396226415\n",
            "epoch 13 batch id 319 loss 0.5965834856033325 train acc 0.8682405956112853\n",
            "epoch 13 batch id 320 loss 0.639597475528717 train acc 0.86826171875\n",
            "epoch 13 batch id 321 loss 0.6723082661628723 train acc 0.8681366822429907\n",
            "epoch 13 batch id 322 loss 0.5284603834152222 train acc 0.8681094720496895\n",
            "epoch 13 batch id 323 loss 0.6531789898872375 train acc 0.8680824303405573\n",
            "epoch 13 batch id 324 loss 0.3515689969062805 train acc 0.8682002314814815\n",
            "epoch 13 batch id 325 loss 0.5943039059638977 train acc 0.8681730769230769\n",
            "epoch 13 batch id 326 loss 0.7257362008094788 train acc 0.8679064417177914\n",
            "epoch 13 batch id 327 loss 0.6111606955528259 train acc 0.8678803516819572\n",
            "epoch 13 batch id 328 loss 0.41487061977386475 train acc 0.8678544207317073\n",
            "epoch 13 batch id 329 loss 0.20591069757938385 train acc 0.8681136018237082\n",
            "epoch 13 batch id 330 loss 0.3375333547592163 train acc 0.8682291666666667\n",
            "epoch 13 batch id 331 loss 0.364254891872406 train acc 0.8683912386706949\n",
            "epoch 13 batch id 332 loss 0.3423323929309845 train acc 0.8685523343373494\n",
            "epoch 13 batch id 333 loss 0.4126942455768585 train acc 0.868384009009009\n",
            "epoch 13 batch id 334 loss 0.19936653971672058 train acc 0.8686845059880239\n",
            "epoch 13 batch id 335 loss 0.5265614986419678 train acc 0.8685167910447761\n",
            "epoch 13 batch id 336 loss 0.5278018116950989 train acc 0.8684430803571429\n",
            "epoch 13 batch id 337 loss 0.6046556830406189 train acc 0.8684625370919882\n",
            "epoch 13 batch id 338 loss 0.4478559195995331 train acc 0.868435650887574\n",
            "epoch 13 batch id 339 loss 0.46229857206344604 train acc 0.8684550147492626\n",
            "epoch 13 batch id 340 loss 0.3445495367050171 train acc 0.8685202205882353\n",
            "epoch 13 batch id 341 loss 0.6200579404830933 train acc 0.8683101173020528\n",
            "epoch 13 batch id 342 loss 0.30583515763282776 train acc 0.8683296783625731\n",
            "epoch 13 batch id 343 loss 0.6123401522636414 train acc 0.8680758017492711\n",
            "epoch 13 batch id 344 loss 0.2113836705684662 train acc 0.8682776162790697\n",
            "epoch 13 batch id 345 loss 0.4833422899246216 train acc 0.868251811594203\n",
            "epoch 13 batch id 346 loss 0.27293044328689575 train acc 0.8684067919075145\n",
            "epoch 13 batch id 347 loss 0.449230819940567 train acc 0.8683807636887608\n",
            "epoch 13 batch id 348 loss 0.4879567325115204 train acc 0.8683997844827587\n",
            "epoch 13 batch id 349 loss 0.37984970211982727 train acc 0.8685082378223495\n",
            "epoch 13 batch id 350 loss 0.2859247922897339 train acc 0.86875\n",
            "epoch 13 batch id 351 loss 0.43416979908943176 train acc 0.8687232905982906\n",
            "epoch 13 batch id 352 loss 0.39069002866744995 train acc 0.8688299005681818\n",
            "epoch 13 batch id 353 loss 0.4933586120605469 train acc 0.8688916430594901\n",
            "epoch 13 batch id 354 loss 0.2345317155122757 train acc 0.8690854519774012\n",
            "epoch 13 batch id 355 loss 0.35192590951919556 train acc 0.8691461267605634\n",
            "epoch 13 batch id 356 loss 0.5666597485542297 train acc 0.8690747893258427\n",
            "epoch 13 batch id 357 loss 0.3503354489803314 train acc 0.8691351540616247\n",
            "epoch 13 batch id 358 loss 0.43167948722839355 train acc 0.8691078910614525\n",
            "epoch 13 batch id 359 loss 0.2636767327785492 train acc 0.8692113509749304\n",
            "epoch 13 batch id 360 loss 0.43438729643821716 train acc 0.8693142361111111\n",
            "epoch 13 batch id 361 loss 0.6902040243148804 train acc 0.8693299861495845\n",
            "epoch 13 batch id 362 loss 0.41205257177352905 train acc 0.8692593232044199\n",
            "epoch 13 batch id 363 loss 0.3371864855289459 train acc 0.8693181818181818\n",
            "epoch 13 batch id 364 loss 0.39512091875076294 train acc 0.8694625686813187\n",
            "epoch 13 batch id 365 loss 0.3980196714401245 train acc 0.8694777397260274\n",
            "epoch 13 batch id 366 loss 0.3825834095478058 train acc 0.8696635928961749\n",
            "epoch 13 batch id 367 loss 0.4027237296104431 train acc 0.8697207084468664\n",
            "epoch 13 batch id 368 loss 0.6088367104530334 train acc 0.8696076766304348\n",
            "epoch 13 batch id 369 loss 0.34823739528656006 train acc 0.8697916666666666\n",
            "epoch 13 batch id 370 loss 0.3311135768890381 train acc 0.8699324324324325\n",
            "epoch 13 batch id 371 loss 0.29497161507606506 train acc 0.8701566711590296\n",
            "epoch 13 batch id 372 loss 0.2797131836414337 train acc 0.8702956989247311\n",
            "epoch 13 batch id 373 loss 0.4171315133571625 train acc 0.870350201072386\n",
            "epoch 13 batch id 374 loss 0.6199861168861389 train acc 0.8703208556149733\n",
            "epoch 13 batch id 375 loss 0.3538720905780792 train acc 0.870375\n",
            "epoch 13 batch id 376 loss 0.4166346490383148 train acc 0.8704288563829787\n",
            "epoch 13 batch id 377 loss 0.33057063817977905 train acc 0.8705238726790451\n",
            "epoch 13 batch id 378 loss 0.3958947956562042 train acc 0.8704117063492064\n",
            "epoch 13 batch id 379 loss 0.3443126678466797 train acc 0.8705062664907651\n",
            "epoch 13 batch id 380 loss 0.5247050523757935 train acc 0.8704358552631579\n",
            "epoch 13 batch id 381 loss 0.32502979040145874 train acc 0.8705708661417323\n",
            "epoch 13 batch id 382 loss 0.36630338430404663 train acc 0.870705170157068\n",
            "epoch 13 batch id 383 loss 0.300652414560318 train acc 0.870920365535248\n",
            "epoch 13 batch id 384 loss 0.39046648144721985 train acc 0.8709716796875\n",
            "epoch 13 batch id 385 loss 0.3013494312763214 train acc 0.8710227272727272\n",
            "epoch 13 batch id 386 loss 0.4859398305416107 train acc 0.8711139896373057\n",
            "epoch 13 batch id 387 loss 0.608390212059021 train acc 0.8711644056847545\n",
            "epoch 13 batch id 388 loss 0.4656130075454712 train acc 0.8711742912371134\n",
            "epoch 13 batch id 389 loss 0.7758387327194214 train acc 0.8710234575835476\n",
            "epoch 13 batch id 390 loss 0.346729040145874 train acc 0.8709935897435898\n",
            "epoch 13 batch id 391 loss 0.4328448474407196 train acc 0.8711237212276215\n",
            "epoch 13 batch id 392 loss 0.8697676062583923 train acc 0.8709343112244898\n",
            "epoch 13 batch id 393 loss 0.5520674586296082 train acc 0.8709048982188295\n",
            "epoch 13 batch id 394 loss 0.5932843089103699 train acc 0.8707566624365483\n",
            "epoch 13 batch id 395 loss 0.4453321099281311 train acc 0.8707674050632911\n",
            "epoch 13 batch id 396 loss 0.3978165090084076 train acc 0.8708175505050505\n",
            "epoch 13 batch id 397 loss 0.30324438214302063 train acc 0.870985516372796\n",
            "epoch 13 batch id 398 loss 0.27155378460884094 train acc 0.8711918969849246\n",
            "epoch 13 batch id 399 loss 0.45269855856895447 train acc 0.8712014411027569\n",
            "epoch 13 batch id 400 loss 0.42876023054122925 train acc 0.8712109375\n",
            "epoch 13 batch id 401 loss 0.6248996257781982 train acc 0.8711034912718204\n",
            "epoch 13 batch id 402 loss 0.7694761157035828 train acc 0.8709965796019901\n",
            "epoch 13 batch id 403 loss 0.3872961699962616 train acc 0.8711228287841191\n",
            "epoch 13 batch id 404 loss 0.3174203932285309 train acc 0.8712484529702971\n",
            "epoch 13 batch id 405 loss 0.42016395926475525 train acc 0.8712962962962963\n",
            "epoch 13 batch id 406 loss 0.41163042187690735 train acc 0.8713823891625616\n",
            "epoch 13 batch id 407 loss 0.3797590732574463 train acc 0.8715064496314496\n",
            "epoch 13 batch id 408 loss 0.4731420576572418 train acc 0.8715150122549019\n",
            "epoch 13 batch id 409 loss 0.5156287550926208 train acc 0.8714471271393643\n",
            "epoch 13 batch id 410 loss 0.6176025867462158 train acc 0.8713033536585366\n",
            "epoch 13 batch id 411 loss 0.36735570430755615 train acc 0.8713883819951338\n",
            "epoch 13 batch id 412 loss 0.5016794800758362 train acc 0.8713971480582524\n",
            "epoch 13 batch id 413 loss 0.3439556956291199 train acc 0.8714437046004843\n",
            "epoch 13 batch id 414 loss 0.5844128131866455 train acc 0.8712635869565217\n",
            "epoch 13 batch id 415 loss 0.5015074014663696 train acc 0.8711972891566265\n",
            "epoch 13 batch id 416 loss 0.3974626660346985 train acc 0.8712064302884616\n",
            "epoch 13 batch id 417 loss 0.21636991202831268 train acc 0.8713279376498801\n",
            "epoch 13 batch id 418 loss 0.4269374907016754 train acc 0.8714114832535885\n",
            "epoch 13 batch id 419 loss 0.17130592465400696 train acc 0.8716810859188544\n",
            "epoch 13 batch id 420 loss 0.29302218556404114 train acc 0.871875\n",
            "epoch 13 batch id 421 loss 0.46015089750289917 train acc 0.8718824228028503\n",
            "epoch 13 batch id 422 loss 0.2732313871383667 train acc 0.8720379146919431\n",
            "epoch 13 batch id 423 loss 0.39706921577453613 train acc 0.8720818557919622\n",
            "epoch 13 batch id 424 loss 0.5031367540359497 train acc 0.8720887382075472\n",
            "epoch 13 batch id 425 loss 0.277624249458313 train acc 0.8722058823529412\n",
            "epoch 13 batch id 426 loss 0.2889230251312256 train acc 0.8723224765258216\n",
            "epoch 13 batch id 427 loss 0.5101881623268127 train acc 0.8723653395784543\n",
            "epoch 13 batch id 428 loss 0.4530833959579468 train acc 0.8724080023364486\n",
            "epoch 13 batch id 429 loss 0.4511309862136841 train acc 0.8723412004662005\n",
            "epoch 13 batch id 430 loss 0.3960324823856354 train acc 0.8724200581395349\n",
            "epoch 13 batch id 431 loss 0.7546457052230835 train acc 0.8723172853828306\n",
            "epoch 13 batch id 432 loss 0.5332776308059692 train acc 0.8722149884259259\n",
            "epoch 13 batch id 433 loss 0.2968643307685852 train acc 0.8723296766743649\n",
            "epoch 13 batch id 434 loss 0.35540905594825745 train acc 0.8723358294930875\n",
            "epoch 13 batch id 435 loss 0.5081121921539307 train acc 0.8723060344827587\n",
            "epoch 13 batch id 436 loss 0.40038207173347473 train acc 0.8723480504587156\n",
            "epoch 13 batch id 437 loss 0.34701135754585266 train acc 0.8724256292906178\n",
            "epoch 13 batch id 438 loss 0.3605414032936096 train acc 0.8725385273972602\n",
            "epoch 13 batch id 439 loss 0.4105639159679413 train acc 0.8726509111617312\n",
            "epoch 13 batch id 440 loss 0.3142361342906952 train acc 0.8726917613636364\n",
            "epoch 13 batch id 441 loss 0.4905475676059723 train acc 0.8726615646258503\n",
            "epoch 13 batch id 442 loss 0.23321960866451263 train acc 0.872772907239819\n",
            "epoch 13 batch id 443 loss 0.4549541771411896 train acc 0.8728132054176072\n",
            "epoch 13 batch id 444 loss 0.35924792289733887 train acc 0.8728885135135135\n",
            "epoch 13 batch id 445 loss 0.2832156717777252 train acc 0.8729634831460674\n",
            "epoch 13 batch id 446 loss 0.4658917188644409 train acc 0.8729680493273543\n",
            "epoch 13 batch id 447 loss 0.3337450921535492 train acc 0.8730774608501118\n",
            "epoch 13 batch id 448 loss 0.3927937150001526 train acc 0.8731515066964286\n",
            "epoch 13 batch id 449 loss 0.3744668960571289 train acc 0.8732252227171492\n",
            "epoch 13 batch id 450 loss 0.2855580449104309 train acc 0.8732638888888888\n",
            "epoch 13 batch id 451 loss 0.7926645874977112 train acc 0.8731638026607539\n",
            "epoch 13 batch id 452 loss 0.29781654477119446 train acc 0.8733061393805309\n",
            "epoch 13 batch id 453 loss 0.5850538015365601 train acc 0.8731719094922737\n",
            "epoch 13 batch id 454 loss 0.4553181827068329 train acc 0.873175936123348\n",
            "epoch 13 batch id 455 loss 0.42310386896133423 train acc 0.8732486263736263\n",
            "epoch 13 batch id 456 loss 0.5305135250091553 train acc 0.8732867324561403\n",
            "epoch 13 batch id 457 loss 0.5617431998252869 train acc 0.8732562910284464\n",
            "epoch 13 batch id 458 loss 0.2831345200538635 train acc 0.8733624454148472\n",
            "epoch 13 batch id 459 loss 0.4310625195503235 train acc 0.8733319716775599\n",
            "epoch 13 batch id 460 loss 0.19575974345207214 train acc 0.8735054347826087\n",
            "epoch 13 batch id 461 loss 0.36098673939704895 train acc 0.8735086767895879\n",
            "epoch 13 batch id 462 loss 0.2314952313899994 train acc 0.8737148268398268\n",
            "epoch 13 batch id 463 loss 0.5819752812385559 train acc 0.8736501079913607\n",
            "epoch 13 batch id 464 loss 0.3186710476875305 train acc 0.8737540409482759\n",
            "epoch 13 batch id 465 loss 0.5130490064620972 train acc 0.8737231182795699\n",
            "epoch 13 batch id 466 loss 0.2985743284225464 train acc 0.8737929184549357\n",
            "epoch 13 batch id 467 loss 0.4214478135108948 train acc 0.8737955032119914\n",
            "epoch 13 batch id 468 loss 0.7141130566596985 train acc 0.8736645299145299\n",
            "epoch 13 batch id 469 loss 0.723675012588501 train acc 0.8736007462686567\n",
            "epoch 13 batch id 470 loss 0.6725273728370667 train acc 0.8736037234042553\n",
            "epoch 13 batch id 471 loss 0.3379569351673126 train acc 0.8736730360934183\n",
            "epoch 13 batch id 472 loss 0.29852139949798584 train acc 0.8737420550847458\n",
            "epoch 13 batch id 473 loss 0.6102723479270935 train acc 0.8736456131078224\n",
            "epoch 13 batch id 474 loss 0.49455344676971436 train acc 0.8736484704641351\n",
            "epoch 13 batch id 475 loss 0.24547182023525238 train acc 0.8737171052631579\n",
            "epoch 13 batch id 476 loss 0.8222116827964783 train acc 0.8736541491596639\n",
            "epoch 13 batch id 477 loss 0.40837475657463074 train acc 0.8736897274633124\n",
            "epoch 13 batch id 478 loss 0.5541366338729858 train acc 0.8737251569037657\n",
            "epoch 13 batch id 479 loss 0.39345285296440125 train acc 0.8738256784968684\n",
            "epoch 13 batch id 480 loss 0.4739599823951721 train acc 0.87392578125\n",
            "epoch 13 batch id 481 loss 0.5273525714874268 train acc 0.8738305613305614\n",
            "epoch 13 batch id 482 loss 0.35813966393470764 train acc 0.8738654045643154\n",
            "epoch 13 batch id 483 loss 0.5273266434669495 train acc 0.8737060041407867\n",
            "epoch 13 batch id 484 loss 0.3759121596813202 train acc 0.8737732438016529\n",
            "epoch 13 batch id 485 loss 0.6981483101844788 train acc 0.8736791237113402\n",
            "epoch 13 batch id 486 loss 0.601116955280304 train acc 0.8734567901234568\n",
            "epoch 13 batch id 487 loss 0.3598353862762451 train acc 0.8735241273100616\n",
            "epoch 13 batch id 488 loss 0.4733441174030304 train acc 0.8734631147540983\n",
            "epoch 13 batch id 489 loss 0.5152165293693542 train acc 0.8734662576687117\n",
            "epoch 13 batch id 490 loss 0.2745974361896515 train acc 0.8735969387755103\n",
            "epoch 13 batch id 491 loss 0.6849019527435303 train acc 0.8735679735234216\n",
            "epoch 13 batch id 492 loss 0.32651910185813904 train acc 0.8736979166666666\n",
            "epoch 13 batch id 493 loss 0.6293630003929138 train acc 0.8736371703853956\n",
            "epoch 13 batch id 494 loss 0.5520972609519958 train acc 0.8735766700404858\n",
            "epoch 13 batch id 495 loss 0.32795092463493347 train acc 0.8736742424242424\n",
            "epoch 13 batch id 496 loss 0.2829887568950653 train acc 0.8737084173387096\n",
            "epoch 13 batch id 497 loss 0.5430647730827332 train acc 0.8736795774647887\n",
            "epoch 13 batch id 498 loss 0.494501531124115 train acc 0.8736822289156626\n",
            "epoch 13 batch id 499 loss 0.31310874223709106 train acc 0.8737788076152304\n",
            "epoch 13 batch id 500 loss 0.40393638610839844 train acc 0.8738125\n",
            "epoch 13 batch id 501 loss 0.5107297897338867 train acc 0.873814870259481\n",
            "epoch 13 batch id 502 loss 0.4075879752635956 train acc 0.8738172310756972\n",
            "epoch 13 batch id 503 loss 0.46082189679145813 train acc 0.8737574552683897\n",
            "epoch 13 batch id 504 loss 0.44546595215797424 train acc 0.8737599206349206\n",
            "epoch 13 batch id 505 loss 0.4550504684448242 train acc 0.8737933168316832\n",
            "epoch 13 batch id 506 loss 0.5004115104675293 train acc 0.8738574604743083\n",
            "epoch 13 batch id 507 loss 0.29661884903907776 train acc 0.8739213510848126\n",
            "epoch 13 batch id 508 loss 0.5607097148895264 train acc 0.8738312007874016\n",
            "epoch 13 batch id 509 loss 0.2348516881465912 train acc 0.8739562868369352\n",
            "epoch 13 batch id 510 loss 0.3476155996322632 train acc 0.8740808823529411\n",
            "epoch 13 batch id 511 loss 0.5658868551254272 train acc 0.8740477355325691\n",
            "epoch 13 train acc 0.8740477355325691\n",
            "epoch 13 test acc 0.38330078125\n",
            "epoch 14 batch id 1 loss 0.4050680100917816 train acc 0.90625\n",
            "epoch 14 batch id 2 loss 0.312606543302536 train acc 0.90625\n",
            "epoch 14 batch id 3 loss 0.5882427096366882 train acc 0.8958333333333334\n",
            "epoch 14 batch id 4 loss 0.6107448935508728 train acc 0.8828125\n",
            "epoch 14 batch id 5 loss 0.2394426017999649 train acc 0.890625\n",
            "epoch 14 batch id 6 loss 0.5915542244911194 train acc 0.8854166666666666\n",
            "epoch 14 batch id 7 loss 0.40732720494270325 train acc 0.8861607142857143\n",
            "epoch 14 batch id 8 loss 0.4136933982372284 train acc 0.8828125\n",
            "epoch 14 batch id 9 loss 0.5390212535858154 train acc 0.8767361111111112\n",
            "epoch 14 batch id 10 loss 0.45527592301368713 train acc 0.878125\n",
            "epoch 14 batch id 11 loss 0.4784415662288666 train acc 0.8835227272727273\n",
            "epoch 14 batch id 12 loss 0.5670819282531738 train acc 0.8815104166666666\n",
            "epoch 14 batch id 13 loss 0.4878677725791931 train acc 0.8834134615384616\n",
            "epoch 14 batch id 14 loss 0.41404181718826294 train acc 0.8861607142857143\n",
            "epoch 14 batch id 15 loss 0.27173492312431335 train acc 0.8885416666666667\n",
            "epoch 14 batch id 16 loss 0.2803756892681122 train acc 0.8916015625\n",
            "epoch 14 batch id 17 loss 0.40584781765937805 train acc 0.8924632352941176\n",
            "epoch 14 batch id 18 loss 0.7943255305290222 train acc 0.8880208333333334\n",
            "epoch 14 batch id 19 loss 0.46112385392189026 train acc 0.8865131578947368\n",
            "epoch 14 batch id 20 loss 0.3689820468425751 train acc 0.88984375\n",
            "epoch 14 batch id 21 loss 0.3238878548145294 train acc 0.890625\n",
            "epoch 14 batch id 22 loss 0.578219473361969 train acc 0.8870738636363636\n",
            "epoch 14 batch id 23 loss 0.3056069016456604 train acc 0.8885869565217391\n",
            "epoch 14 batch id 24 loss 0.14422103762626648 train acc 0.892578125\n",
            "epoch 14 batch id 25 loss 0.4083290696144104 train acc 0.890625\n",
            "epoch 14 batch id 26 loss 0.25509920716285706 train acc 0.8930288461538461\n",
            "epoch 14 batch id 27 loss 0.5163027048110962 train acc 0.8917824074074074\n",
            "epoch 14 batch id 28 loss 0.32848137617111206 train acc 0.8917410714285714\n",
            "epoch 14 batch id 29 loss 0.39649876952171326 train acc 0.8911637931034483\n",
            "epoch 14 batch id 30 loss 0.3221178948879242 train acc 0.890625\n",
            "epoch 14 batch id 31 loss 0.4931228458881378 train acc 0.8886088709677419\n",
            "epoch 14 batch id 32 loss 0.709789514541626 train acc 0.88623046875\n",
            "epoch 14 batch id 33 loss 0.8309750556945801 train acc 0.8830492424242424\n",
            "epoch 14 batch id 34 loss 0.45501357316970825 train acc 0.8841911764705882\n",
            "epoch 14 batch id 35 loss 0.3754477798938751 train acc 0.884375\n",
            "epoch 14 batch id 36 loss 0.41215646266937256 train acc 0.8841145833333334\n",
            "epoch 14 batch id 37 loss 0.40661942958831787 train acc 0.8847128378378378\n",
            "epoch 14 batch id 38 loss 0.4791906476020813 train acc 0.8848684210526315\n",
            "epoch 14 batch id 39 loss 0.35349732637405396 train acc 0.8850160256410257\n",
            "epoch 14 batch id 40 loss 0.43110641837120056 train acc 0.884375\n",
            "epoch 14 batch id 41 loss 0.4483164846897125 train acc 0.8849085365853658\n",
            "epoch 14 batch id 42 loss 0.4571424424648285 train acc 0.8843005952380952\n",
            "epoch 14 batch id 43 loss 0.22647738456726074 train acc 0.8862645348837209\n",
            "epoch 14 batch id 44 loss 0.5075644850730896 train acc 0.8852982954545454\n",
            "epoch 14 batch id 45 loss 0.44897696375846863 train acc 0.8854166666666666\n",
            "epoch 14 batch id 46 loss 0.21518312394618988 train acc 0.8872282608695652\n",
            "epoch 14 batch id 47 loss 0.34980309009552 train acc 0.8879654255319149\n",
            "epoch 14 batch id 48 loss 0.37887731194496155 train acc 0.8876953125\n",
            "epoch 14 batch id 49 loss 0.3367321193218231 train acc 0.8877551020408163\n",
            "epoch 14 batch id 50 loss 0.322343111038208 train acc 0.888125\n",
            "epoch 14 batch id 51 loss 0.48102062940597534 train acc 0.8872549019607843\n",
            "epoch 14 batch id 52 loss 0.5180945992469788 train acc 0.88671875\n",
            "epoch 14 batch id 53 loss 0.40640172362327576 train acc 0.886497641509434\n",
            "epoch 14 batch id 54 loss 0.271275132894516 train acc 0.8871527777777778\n",
            "epoch 14 batch id 55 loss 0.5469872951507568 train acc 0.8872159090909091\n",
            "epoch 14 batch id 56 loss 0.5208593606948853 train acc 0.88671875\n",
            "epoch 14 batch id 57 loss 0.5095378160476685 train acc 0.8867872807017544\n",
            "epoch 14 batch id 58 loss 0.51542729139328 train acc 0.8868534482758621\n",
            "epoch 14 batch id 59 loss 0.344712495803833 train acc 0.8877118644067796\n",
            "epoch 14 batch id 60 loss 0.7636952996253967 train acc 0.88671875\n",
            "epoch 14 batch id 61 loss 0.4714067280292511 train acc 0.8862704918032787\n",
            "epoch 14 batch id 62 loss 0.4397961497306824 train acc 0.8860887096774194\n",
            "epoch 14 batch id 63 loss 0.4279692769050598 train acc 0.8861607142857143\n",
            "epoch 14 batch id 64 loss 0.4437001645565033 train acc 0.88525390625\n",
            "epoch 14 batch id 65 loss 0.41129419207572937 train acc 0.8853365384615385\n",
            "epoch 14 batch id 66 loss 0.40210166573524475 train acc 0.8854166666666666\n",
            "epoch 14 batch id 67 loss 0.3856108486652374 train acc 0.8857276119402985\n",
            "epoch 14 batch id 68 loss 0.2942831814289093 train acc 0.8862591911764706\n",
            "epoch 14 batch id 69 loss 0.27178141474723816 train acc 0.886322463768116\n",
            "epoch 14 batch id 70 loss 0.6861242651939392 train acc 0.8850446428571429\n",
            "epoch 14 batch id 71 loss 0.4220147728919983 train acc 0.8851232394366197\n",
            "epoch 14 batch id 72 loss 0.3982761800289154 train acc 0.8849826388888888\n",
            "epoch 14 batch id 73 loss 0.28013697266578674 train acc 0.885916095890411\n",
            "epoch 14 batch id 74 loss 0.28735458850860596 train acc 0.8866131756756757\n",
            "epoch 14 batch id 75 loss 0.38777807354927063 train acc 0.8866666666666667\n",
            "epoch 14 batch id 76 loss 0.4170718491077423 train acc 0.8863075657894737\n",
            "epoch 14 batch id 77 loss 0.36631008982658386 train acc 0.8859577922077922\n",
            "epoch 14 batch id 78 loss 0.5233275890350342 train acc 0.8846153846153846\n",
            "epoch 14 batch id 79 loss 0.474580317735672 train acc 0.8848892405063291\n",
            "epoch 14 batch id 80 loss 0.19411376118659973 train acc 0.8853515625\n",
            "epoch 14 batch id 81 loss 0.4359874129295349 train acc 0.8854166666666666\n",
            "epoch 14 batch id 82 loss 0.33220183849334717 train acc 0.8862423780487805\n",
            "epoch 14 batch id 83 loss 0.2511294484138489 train acc 0.8868599397590361\n",
            "epoch 14 batch id 84 loss 0.4623181223869324 train acc 0.8863467261904762\n",
            "epoch 14 batch id 85 loss 0.16570499539375305 train acc 0.8875\n",
            "epoch 14 batch id 86 loss 0.4514855444431305 train acc 0.8878997093023255\n",
            "epoch 14 batch id 87 loss 0.4917268455028534 train acc 0.8875718390804598\n",
            "epoch 14 batch id 88 loss 0.3213450014591217 train acc 0.8879616477272727\n",
            "epoch 14 batch id 89 loss 0.37679728865623474 train acc 0.8879915730337079\n",
            "epoch 14 batch id 90 loss 0.42654410004615784 train acc 0.8880208333333334\n",
            "epoch 14 batch id 91 loss 0.2938203513622284 train acc 0.888907967032967\n",
            "epoch 14 batch id 92 loss 0.29924720525741577 train acc 0.889266304347826\n",
            "epoch 14 batch id 93 loss 0.6923865079879761 train acc 0.8887768817204301\n",
            "epoch 14 batch id 94 loss 0.3988080322742462 train acc 0.8889627659574468\n",
            "epoch 14 batch id 95 loss 0.5568000078201294 train acc 0.8888157894736842\n",
            "epoch 14 batch id 96 loss 0.5697769522666931 train acc 0.8883463541666666\n",
            "epoch 14 batch id 97 loss 0.8176642060279846 train acc 0.8877255154639175\n",
            "epoch 14 batch id 98 loss 0.5323525071144104 train acc 0.8872767857142857\n",
            "epoch 14 batch id 99 loss 0.48221778869628906 train acc 0.8871527777777778\n",
            "epoch 14 batch id 100 loss 0.6400414109230042 train acc 0.88640625\n",
            "epoch 14 batch id 101 loss 0.31122803688049316 train acc 0.8866027227722773\n",
            "epoch 14 batch id 102 loss 0.5113205313682556 train acc 0.8867953431372549\n",
            "epoch 14 batch id 103 loss 0.4715278744697571 train acc 0.8866808252427184\n",
            "epoch 14 batch id 104 loss 0.762502908706665 train acc 0.8856670673076923\n",
            "epoch 14 batch id 105 loss 0.5653765201568604 train acc 0.8854166666666666\n",
            "epoch 14 batch id 106 loss 0.23166099190711975 train acc 0.8859080188679245\n",
            "epoch 14 batch id 107 loss 0.3794163465499878 train acc 0.8859521028037384\n",
            "epoch 14 batch id 108 loss 0.34500202536582947 train acc 0.8861400462962963\n",
            "epoch 14 batch id 109 loss 0.3213806450366974 train acc 0.8864678899082569\n",
            "epoch 14 batch id 110 loss 0.32496681809425354 train acc 0.8865056818181818\n",
            "epoch 14 batch id 111 loss 0.29814574122428894 train acc 0.8865427927927928\n",
            "epoch 14 batch id 112 loss 0.365774542093277 train acc 0.88671875\n",
            "epoch 14 batch id 113 loss 0.5452895164489746 train acc 0.886891592920354\n",
            "epoch 14 batch id 114 loss 0.5080177187919617 train acc 0.8870614035087719\n",
            "epoch 14 batch id 115 loss 0.4324883222579956 train acc 0.8869565217391304\n",
            "epoch 14 batch id 116 loss 0.6297216415405273 train acc 0.8861799568965517\n",
            "epoch 14 batch id 117 loss 0.39147210121154785 train acc 0.8864850427350427\n",
            "epoch 14 batch id 118 loss 0.5631100535392761 train acc 0.885593220338983\n",
            "epoch 14 batch id 119 loss 0.4873254597187042 train acc 0.8855042016806722\n",
            "epoch 14 batch id 120 loss 0.2181749790906906 train acc 0.8859375\n",
            "epoch 14 batch id 121 loss 0.5074657797813416 train acc 0.8855888429752066\n",
            "epoch 14 batch id 122 loss 0.7149480581283569 train acc 0.8848616803278688\n",
            "epoch 14 batch id 123 loss 0.35877999663352966 train acc 0.8847815040650406\n",
            "epoch 14 batch id 124 loss 0.3820558190345764 train acc 0.8848286290322581\n",
            "epoch 14 batch id 125 loss 0.5518827438354492 train acc 0.884375\n",
            "epoch 14 batch id 126 loss 0.43474292755126953 train acc 0.8844246031746031\n",
            "epoch 14 batch id 127 loss 0.11880744993686676 train acc 0.8850885826771654\n",
            "epoch 14 batch id 128 loss 0.3551355302333832 train acc 0.8853759765625\n",
            "epoch 14 batch id 129 loss 0.6749980449676514 train acc 0.8846899224806202\n",
            "epoch 14 batch id 130 loss 0.45292046666145325 train acc 0.8844951923076924\n",
            "epoch 14 batch id 131 loss 0.36879104375839233 train acc 0.8845419847328244\n",
            "epoch 14 batch id 132 loss 0.46338218450546265 train acc 0.8843513257575758\n",
            "epoch 14 batch id 133 loss 0.2146199345588684 train acc 0.8846334586466166\n",
            "epoch 14 batch id 134 loss 0.4004974067211151 train acc 0.8843283582089553\n",
            "epoch 14 batch id 135 loss 0.4940035045146942 train acc 0.8842592592592593\n",
            "epoch 14 batch id 136 loss 0.39413684606552124 train acc 0.8841911764705882\n",
            "epoch 14 batch id 137 loss 0.37686407566070557 train acc 0.8842381386861314\n",
            "epoch 14 batch id 138 loss 0.30326828360557556 train acc 0.8842844202898551\n",
            "epoch 14 batch id 139 loss 0.36744245886802673 train acc 0.8842176258992805\n",
            "epoch 14 batch id 140 loss 0.5050593018531799 train acc 0.8840401785714286\n",
            "epoch 14 batch id 141 loss 0.4146960377693176 train acc 0.8839760638297872\n",
            "epoch 14 batch id 142 loss 0.3527292013168335 train acc 0.8842429577464789\n",
            "epoch 14 batch id 143 loss 0.4196723699569702 train acc 0.8843968531468531\n",
            "epoch 14 batch id 144 loss 0.3911242187023163 train acc 0.8845486111111112\n",
            "epoch 14 batch id 145 loss 0.3365900218486786 train acc 0.884698275862069\n",
            "epoch 14 batch id 146 loss 0.4681190848350525 train acc 0.884845890410959\n",
            "epoch 14 batch id 147 loss 0.29937851428985596 train acc 0.8850977891156463\n",
            "epoch 14 batch id 148 loss 0.30473592877388 train acc 0.8854518581081081\n",
            "epoch 14 batch id 149 loss 0.5978458523750305 train acc 0.8851719798657718\n",
            "epoch 14 batch id 150 loss 0.26427873969078064 train acc 0.8855208333333333\n",
            "epoch 14 batch id 151 loss 0.4620899558067322 train acc 0.8852442052980133\n",
            "epoch 14 batch id 152 loss 0.5378286838531494 train acc 0.8851768092105263\n",
            "epoch 14 batch id 153 loss 0.44732794165611267 train acc 0.8851102941176471\n",
            "epoch 14 batch id 154 loss 0.47473135590553284 train acc 0.8851461038961039\n",
            "epoch 14 batch id 155 loss 0.3846126198768616 train acc 0.8855846774193549\n",
            "epoch 14 batch id 156 loss 0.387456476688385 train acc 0.885917467948718\n",
            "epoch 14 batch id 157 loss 0.5061154961585999 train acc 0.8854498407643312\n",
            "epoch 14 batch id 158 loss 0.3129582405090332 train acc 0.8855814873417721\n",
            "epoch 14 batch id 159 loss 0.4086855947971344 train acc 0.8856132075471698\n",
            "epoch 14 batch id 160 loss 0.24139367043972015 train acc 0.8859375\n",
            "epoch 14 batch id 161 loss 0.5722691416740417 train acc 0.8858695652173914\n",
            "epoch 14 batch id 162 loss 0.6836981177330017 train acc 0.8854166666666666\n",
            "epoch 14 batch id 163 loss 0.46214398741722107 train acc 0.8854486196319018\n",
            "epoch 14 batch id 164 loss 0.20474690198898315 train acc 0.8858612804878049\n",
            "epoch 14 batch id 165 loss 0.706223726272583 train acc 0.8850378787878788\n",
            "epoch 14 batch id 166 loss 0.33978942036628723 train acc 0.8852597891566265\n",
            "epoch 14 batch id 167 loss 0.436672180891037 train acc 0.8852919161676647\n",
            "epoch 14 batch id 168 loss 0.10876163095235825 train acc 0.8858816964285714\n",
            "epoch 14 batch id 169 loss 0.3981980085372925 train acc 0.886094674556213\n",
            "epoch 14 batch id 170 loss 0.19941189885139465 train acc 0.8864889705882353\n",
            "epoch 14 batch id 171 loss 0.2766731381416321 train acc 0.8868786549707602\n",
            "epoch 14 batch id 172 loss 0.18583102524280548 train acc 0.8873546511627907\n",
            "epoch 14 batch id 173 loss 0.3918055593967438 train acc 0.8871929190751445\n",
            "epoch 14 batch id 174 loss 0.5001354217529297 train acc 0.8870330459770115\n",
            "epoch 14 batch id 175 loss 0.38536036014556885 train acc 0.8872321428571428\n",
            "epoch 14 batch id 176 loss 0.4030364453792572 train acc 0.8869850852272727\n",
            "epoch 14 batch id 177 loss 0.4037759006023407 train acc 0.886917372881356\n",
            "epoch 14 batch id 178 loss 0.45994624495506287 train acc 0.886938202247191\n",
            "epoch 14 batch id 179 loss 0.1515571027994156 train acc 0.8873952513966481\n",
            "epoch 14 batch id 180 loss 0.33856403827667236 train acc 0.8876736111111111\n",
            "epoch 14 batch id 181 loss 0.38991403579711914 train acc 0.8876899171270718\n",
            "epoch 14 batch id 182 loss 0.3914329409599304 train acc 0.8878777472527473\n",
            "epoch 14 batch id 183 loss 0.3197405934333801 train acc 0.8878927595628415\n",
            "epoch 14 batch id 184 loss 0.37910905480384827 train acc 0.8881623641304348\n",
            "epoch 14 batch id 185 loss 0.6456089019775391 train acc 0.8878378378378379\n",
            "epoch 14 batch id 186 loss 0.40889880061149597 train acc 0.8877688172043011\n",
            "epoch 14 batch id 187 loss 0.6639835238456726 train acc 0.8873663101604278\n",
            "epoch 14 batch id 188 loss 0.2745244801044464 train acc 0.887466755319149\n",
            "epoch 14 batch id 189 loss 0.5361453294754028 train acc 0.8874007936507936\n",
            "epoch 14 batch id 190 loss 0.3556787967681885 train acc 0.8875822368421052\n",
            "epoch 14 batch id 191 loss 0.581466794013977 train acc 0.887434554973822\n",
            "epoch 14 batch id 192 loss 0.3859122395515442 train acc 0.8873697916666666\n",
            "epoch 14 batch id 193 loss 0.2517034113407135 train acc 0.8877104922279793\n",
            "epoch 14 batch id 194 loss 0.2425130009651184 train acc 0.8879671391752577\n",
            "epoch 14 batch id 195 loss 0.4033215045928955 train acc 0.8881410256410256\n",
            "epoch 14 batch id 196 loss 0.2863643765449524 train acc 0.8882334183673469\n",
            "epoch 14 batch id 197 loss 0.3258308470249176 train acc 0.8884835025380711\n",
            "epoch 14 batch id 198 loss 0.1951846331357956 train acc 0.8887310606060606\n",
            "epoch 14 batch id 199 loss 0.4193297326564789 train acc 0.8888190954773869\n",
            "epoch 14 batch id 200 loss 0.34356123208999634 train acc 0.888828125\n",
            "epoch 14 batch id 201 loss 0.19435030221939087 train acc 0.8889148009950248\n",
            "epoch 14 batch id 202 loss 0.33995944261550903 train acc 0.8889232673267327\n",
            "epoch 14 batch id 203 loss 0.5190253853797913 train acc 0.8884698275862069\n",
            "epoch 14 batch id 204 loss 0.1813584417104721 train acc 0.8887101715686274\n",
            "epoch 14 batch id 205 loss 0.4617650508880615 train acc 0.8885670731707317\n",
            "epoch 14 batch id 206 loss 0.3415040373802185 train acc 0.8887287621359223\n",
            "epoch 14 batch id 207 loss 0.48235830664634705 train acc 0.8886624396135265\n",
            "epoch 14 batch id 208 loss 0.28716233372688293 train acc 0.888671875\n",
            "epoch 14 batch id 209 loss 0.33439892530441284 train acc 0.888755980861244\n",
            "epoch 14 batch id 210 loss 0.2342299371957779 train acc 0.8888392857142857\n",
            "epoch 14 batch id 211 loss 0.48234620690345764 train acc 0.888699644549763\n",
            "epoch 14 batch id 212 loss 0.44626185297966003 train acc 0.8884876179245284\n",
            "epoch 14 batch id 213 loss 0.3036298453807831 train acc 0.8888644366197183\n",
            "epoch 14 batch id 214 loss 0.24408183991909027 train acc 0.8889456775700935\n",
            "epoch 14 batch id 215 loss 0.31315797567367554 train acc 0.8890988372093023\n",
            "epoch 14 batch id 216 loss 0.5292901396751404 train acc 0.8885995370370371\n",
            "epoch 14 batch id 217 loss 0.3234110176563263 train acc 0.8886808755760369\n",
            "epoch 14 batch id 218 loss 0.5401251316070557 train acc 0.8886897935779816\n",
            "epoch 14 batch id 219 loss 0.3727888762950897 train acc 0.8885559360730594\n",
            "epoch 14 batch id 220 loss 0.32650288939476013 train acc 0.8887784090909091\n",
            "epoch 14 batch id 221 loss 0.3877880573272705 train acc 0.8889988687782805\n",
            "epoch 14 batch id 222 loss 0.3666180968284607 train acc 0.8889358108108109\n",
            "epoch 14 batch id 223 loss 0.6546396017074585 train acc 0.8888032511210763\n",
            "epoch 14 batch id 224 loss 0.1953735202550888 train acc 0.88916015625\n",
            "epoch 14 batch id 225 loss 0.4937744736671448 train acc 0.8890277777777778\n",
            "epoch 14 batch id 226 loss 0.256412148475647 train acc 0.8892422566371682\n",
            "epoch 14 batch id 227 loss 0.31086498498916626 train acc 0.88931718061674\n",
            "epoch 14 batch id 228 loss 0.4157359302043915 train acc 0.8892543859649122\n",
            "epoch 14 batch id 229 loss 0.2843780219554901 train acc 0.8895332969432315\n",
            "epoch 14 batch id 230 loss 0.19926108419895172 train acc 0.889741847826087\n",
            "epoch 14 batch id 231 loss 0.5814527869224548 train acc 0.8895427489177489\n",
            "epoch 14 batch id 232 loss 0.3238367438316345 train acc 0.8897494612068966\n",
            "epoch 14 batch id 233 loss 0.21306951344013214 train acc 0.889887339055794\n",
            "epoch 14 batch id 234 loss 0.37778154015541077 train acc 0.8899572649572649\n",
            "epoch 14 batch id 235 loss 0.41620299220085144 train acc 0.8898936170212766\n",
            "epoch 14 batch id 236 loss 0.42824992537498474 train acc 0.8898305084745762\n",
            "epoch 14 batch id 237 loss 0.2903846204280853 train acc 0.8898997890295358\n",
            "epoch 14 batch id 238 loss 0.37338781356811523 train acc 0.8899684873949579\n",
            "epoch 14 batch id 239 loss 0.3304309844970703 train acc 0.890036610878661\n",
            "epoch 14 batch id 240 loss 0.4022558033466339 train acc 0.8899088541666667\n",
            "epoch 14 batch id 241 loss 0.32229921221733093 train acc 0.8900414937759336\n",
            "epoch 14 batch id 242 loss 0.33850979804992676 train acc 0.8900439049586777\n",
            "epoch 14 batch id 243 loss 0.35361579060554504 train acc 0.8901105967078189\n",
            "epoch 14 batch id 244 loss 0.5893065929412842 train acc 0.8901127049180327\n",
            "epoch 14 batch id 245 loss 0.44879916310310364 train acc 0.8900510204081633\n",
            "epoch 14 batch id 246 loss 0.3517247140407562 train acc 0.8900533536585366\n",
            "epoch 14 batch id 247 loss 0.1735536903142929 train acc 0.8902454453441295\n",
            "epoch 14 batch id 248 loss 0.22853322327136993 train acc 0.8904359879032258\n",
            "epoch 14 batch id 249 loss 0.34407705068588257 train acc 0.8904367469879518\n",
            "epoch 14 batch id 250 loss 0.3488793671131134 train acc 0.8904375\n",
            "epoch 14 batch id 251 loss 0.5807321667671204 train acc 0.8902514940239044\n",
            "epoch 14 batch id 252 loss 0.3641904294490814 train acc 0.8902529761904762\n",
            "epoch 14 batch id 253 loss 0.36896219849586487 train acc 0.8902544466403162\n",
            "epoch 14 batch id 254 loss 0.4143112897872925 train acc 0.890255905511811\n",
            "epoch 14 batch id 255 loss 0.36060136556625366 train acc 0.8901960784313725\n",
            "epoch 14 batch id 256 loss 0.6322460770606995 train acc 0.8900146484375\n",
            "epoch 14 batch id 257 loss 0.6462692022323608 train acc 0.8898954280155642\n",
            "epoch 14 batch id 258 loss 0.29433080554008484 train acc 0.8900193798449613\n",
            "epoch 14 batch id 259 loss 0.48422643542289734 train acc 0.8897200772200772\n",
            "epoch 14 batch id 260 loss 0.3721506595611572 train acc 0.88984375\n",
            "epoch 14 batch id 261 loss 0.4202556014060974 train acc 0.8899066091954023\n",
            "epoch 14 batch id 262 loss 0.46103212237358093 train acc 0.8899093511450382\n",
            "epoch 14 batch id 263 loss 0.575300931930542 train acc 0.8894961977186312\n",
            "epoch 14 batch id 264 loss 0.49597036838531494 train acc 0.8893821022727273\n",
            "epoch 14 batch id 265 loss 0.21300794184207916 train acc 0.889563679245283\n",
            "epoch 14 batch id 266 loss 0.19950973987579346 train acc 0.8897438909774437\n",
            "epoch 14 batch id 267 loss 0.43281033635139465 train acc 0.889630149812734\n",
            "epoch 14 batch id 268 loss 0.5551661252975464 train acc 0.8895755597014925\n",
            "epoch 14 batch id 269 loss 0.4379945993423462 train acc 0.8894632899628253\n",
            "epoch 14 batch id 270 loss 0.5770887732505798 train acc 0.8894097222222223\n",
            "epoch 14 batch id 271 loss 0.4345259666442871 train acc 0.8895295202952029\n",
            "epoch 14 batch id 272 loss 0.57598477602005 train acc 0.8894761029411765\n",
            "epoch 14 batch id 273 loss 0.17058295011520386 train acc 0.8897664835164835\n",
            "epoch 14 batch id 274 loss 0.25926387310028076 train acc 0.8898836678832117\n",
            "epoch 14 batch id 275 loss 0.47154808044433594 train acc 0.8896590909090909\n",
            "epoch 14 batch id 276 loss 0.22786091268062592 train acc 0.8898324275362319\n",
            "epoch 14 batch id 277 loss 0.29124438762664795 train acc 0.8898916967509025\n",
            "epoch 14 batch id 278 loss 0.4964599907398224 train acc 0.8899505395683454\n",
            "epoch 14 batch id 279 loss 0.4945727288722992 train acc 0.8899529569892473\n",
            "epoch 14 batch id 280 loss 0.4596877694129944 train acc 0.88984375\n",
            "epoch 14 batch id 281 loss 0.535310685634613 train acc 0.889790925266904\n",
            "epoch 14 batch id 282 loss 0.4368497431278229 train acc 0.8896830673758865\n",
            "epoch 14 batch id 283 loss 0.47274041175842285 train acc 0.8895759717314488\n",
            "epoch 14 batch id 284 loss 0.45324382185935974 train acc 0.8892495598591549\n",
            "epoch 14 batch id 285 loss 0.43839627504348755 train acc 0.8890899122807018\n",
            "epoch 14 batch id 286 loss 0.2843985855579376 train acc 0.8890952797202797\n",
            "epoch 14 batch id 287 loss 0.6690605878829956 train acc 0.8889372822299652\n",
            "epoch 14 batch id 288 loss 0.5445052981376648 train acc 0.8888346354166666\n",
            "epoch 14 batch id 289 loss 0.46110519766807556 train acc 0.888840830449827\n",
            "epoch 14 batch id 290 loss 0.5111333131790161 train acc 0.8888469827586207\n",
            "epoch 14 batch id 291 loss 0.2910526990890503 train acc 0.8889067869415808\n",
            "epoch 14 batch id 292 loss 0.44041842222213745 train acc 0.889019691780822\n",
            "epoch 14 batch id 293 loss 0.28851860761642456 train acc 0.8891318259385665\n",
            "epoch 14 batch id 294 loss 0.23417572677135468 train acc 0.8891369047619048\n",
            "epoch 14 batch id 295 loss 0.18854054808616638 train acc 0.8893008474576272\n",
            "epoch 14 batch id 296 loss 0.4527626037597656 train acc 0.8893581081081081\n",
            "epoch 14 batch id 297 loss 0.6650217771530151 train acc 0.8889414983164983\n",
            "epoch 14 batch id 298 loss 0.3795081079006195 train acc 0.8889995805369127\n",
            "epoch 14 batch id 299 loss 0.3235439956188202 train acc 0.8891617892976589\n",
            "epoch 14 batch id 300 loss 0.31134191155433655 train acc 0.8892708333333333\n",
            "epoch 14 batch id 301 loss 0.2804076373577118 train acc 0.8893272425249169\n",
            "epoch 14 batch id 302 loss 0.3783666491508484 train acc 0.8893832781456954\n",
            "epoch 14 batch id 303 loss 0.5884984135627747 train acc 0.8891295379537953\n",
            "epoch 14 batch id 304 loss 0.26945972442626953 train acc 0.8893400493421053\n",
            "epoch 14 batch id 305 loss 0.4301181435585022 train acc 0.8892418032786885\n",
            "epoch 14 batch id 306 loss 0.31010499596595764 train acc 0.8893995098039216\n",
            "epoch 14 batch id 307 loss 0.37966957688331604 train acc 0.8894543973941368\n",
            "epoch 14 batch id 308 loss 0.21009010076522827 train acc 0.8896103896103896\n",
            "epoch 14 batch id 309 loss 0.23164720833301544 train acc 0.8897653721682848\n",
            "epoch 14 batch id 310 loss 0.25556841492652893 train acc 0.8898689516129032\n",
            "epoch 14 batch id 311 loss 0.3144211769104004 train acc 0.890072347266881\n",
            "epoch 14 batch id 312 loss 0.4390702247619629 train acc 0.8900741185897436\n",
            "epoch 14 batch id 313 loss 0.3971233665943146 train acc 0.8902256389776357\n",
            "epoch 14 batch id 314 loss 0.2691480815410614 train acc 0.8903761942675159\n",
            "epoch 14 batch id 315 loss 0.32568803429603577 train acc 0.8905257936507937\n",
            "epoch 14 batch id 316 loss 0.272765576839447 train acc 0.890625\n",
            "epoch 14 batch id 317 loss 0.23656508326530457 train acc 0.8906742902208202\n",
            "epoch 14 batch id 318 loss 0.43274742364883423 train acc 0.8905267295597484\n",
            "epoch 14 batch id 319 loss 0.32638561725616455 train acc 0.8906739811912225\n",
            "epoch 14 batch id 320 loss 0.29510965943336487 train acc 0.8908203125\n",
            "epoch 14 batch id 321 loss 0.38275817036628723 train acc 0.8907710280373832\n",
            "epoch 14 batch id 322 loss 0.3493177592754364 train acc 0.8907705745341615\n",
            "epoch 14 batch id 323 loss 0.3900296986103058 train acc 0.8908668730650154\n",
            "epoch 14 batch id 324 loss 0.6249249577522278 train acc 0.8908661265432098\n",
            "epoch 14 batch id 325 loss 0.3384192883968353 train acc 0.8909615384615385\n",
            "epoch 14 batch id 326 loss 0.1787211149930954 train acc 0.8911522239263804\n",
            "epoch 14 batch id 327 loss 0.301299512386322 train acc 0.8913895259938838\n",
            "epoch 14 batch id 328 loss 0.3037232458591461 train acc 0.8914348323170732\n",
            "epoch 14 batch id 329 loss 0.23015809059143066 train acc 0.8915273556231003\n",
            "epoch 14 batch id 330 loss 0.20452985167503357 train acc 0.8917613636363636\n",
            "epoch 14 batch id 331 loss 0.42357656359672546 train acc 0.8917107250755287\n",
            "epoch 14 batch id 332 loss 0.39358237385749817 train acc 0.8916603915662651\n",
            "epoch 14 batch id 333 loss 0.5269215106964111 train acc 0.8916103603603603\n",
            "epoch 14 batch id 334 loss 0.34131357073783875 train acc 0.8916074101796407\n",
            "epoch 14 batch id 335 loss 0.6416213512420654 train acc 0.8914645522388059\n",
            "epoch 14 batch id 336 loss 0.3295662999153137 train acc 0.8915550595238095\n",
            "epoch 14 batch id 337 loss 0.4560609459877014 train acc 0.8914595697329377\n",
            "epoch 14 batch id 338 loss 0.6259408593177795 train acc 0.8911335059171598\n",
            "epoch 14 batch id 339 loss 0.4128863215446472 train acc 0.8909937315634219\n",
            "epoch 14 batch id 340 loss 0.4285847246646881 train acc 0.8908088235294118\n",
            "epoch 14 batch id 341 loss 0.46512681245803833 train acc 0.8908082844574781\n",
            "epoch 14 batch id 342 loss 0.41032230854034424 train acc 0.8907620614035088\n",
            "epoch 14 batch id 343 loss 0.3841918706893921 train acc 0.8907616618075802\n",
            "epoch 14 batch id 344 loss 0.40450501441955566 train acc 0.8908066860465116\n",
            "epoch 14 batch id 345 loss 0.2066408097743988 train acc 0.8909420289855072\n",
            "epoch 14 batch id 346 loss 0.2523286044597626 train acc 0.8910765895953757\n",
            "epoch 14 batch id 347 loss 0.5040298104286194 train acc 0.8908951729106628\n",
            "epoch 14 batch id 348 loss 0.2921067178249359 train acc 0.8909392959770115\n",
            "epoch 14 batch id 349 loss 0.6263961791992188 train acc 0.8908040830945558\n",
            "epoch 14 batch id 350 loss 0.3412388861179352 train acc 0.8909375\n",
            "epoch 14 batch id 351 loss 0.4586573839187622 train acc 0.8909366096866097\n",
            "epoch 14 batch id 352 loss 0.586686909198761 train acc 0.8908025568181818\n",
            "epoch 14 batch id 353 loss 0.43951597809791565 train acc 0.8908020538243626\n",
            "epoch 14 batch id 354 loss 0.2811548113822937 train acc 0.8908456920903954\n",
            "epoch 14 batch id 355 loss 0.17172624170780182 train acc 0.8910651408450704\n",
            "epoch 14 batch id 356 loss 0.40740278363227844 train acc 0.891063904494382\n",
            "epoch 14 batch id 357 loss 0.2895892858505249 train acc 0.8911939775910365\n",
            "epoch 14 batch id 358 loss 0.3224269151687622 train acc 0.891236033519553\n",
            "epoch 14 batch id 359 loss 0.4963892102241516 train acc 0.8912343314763231\n",
            "epoch 14 batch id 360 loss 0.3898799419403076 train acc 0.8912326388888889\n",
            "epoch 14 batch id 361 loss 0.32207944989204407 train acc 0.8913608033240997\n",
            "epoch 14 batch id 362 loss 0.37451279163360596 train acc 0.8914882596685083\n",
            "epoch 14 batch id 363 loss 0.31198012828826904 train acc 0.8916150137741047\n",
            "epoch 14 batch id 364 loss 0.5720289349555969 train acc 0.8916552197802198\n",
            "epoch 14 batch id 365 loss 0.4135046601295471 train acc 0.891652397260274\n",
            "epoch 14 batch id 366 loss 0.49557462334632874 train acc 0.8916922814207651\n",
            "epoch 14 batch id 367 loss 0.2909076511859894 train acc 0.8917745231607629\n",
            "epoch 14 batch id 368 loss 0.5227888822555542 train acc 0.8917289402173914\n",
            "epoch 14 batch id 369 loss 0.4168836176395416 train acc 0.8916412601626016\n",
            "epoch 14 batch id 370 loss 0.3869191110134125 train acc 0.8916807432432432\n",
            "epoch 14 batch id 371 loss 0.3894246816635132 train acc 0.891677897574124\n",
            "epoch 14 batch id 372 loss 0.2474694699048996 train acc 0.8917590725806451\n",
            "epoch 14 batch id 373 loss 0.5628337860107422 train acc 0.8917141420911529\n",
            "epoch 14 batch id 374 loss 0.4506499171257019 train acc 0.8916694518716578\n",
            "epoch 14 batch id 375 loss 0.47494590282440186 train acc 0.891625\n",
            "epoch 14 batch id 376 loss 0.6246259212493896 train acc 0.8914561170212766\n",
            "epoch 14 batch id 377 loss 0.46707963943481445 train acc 0.8913710212201591\n",
            "epoch 14 batch id 378 loss 0.4450801908969879 train acc 0.8914103835978836\n",
            "epoch 14 batch id 379 loss 0.5194452404975891 train acc 0.8914083113456465\n",
            "epoch 14 batch id 380 loss 0.31006908416748047 train acc 0.8914884868421052\n",
            "epoch 14 batch id 381 loss 0.3380754292011261 train acc 0.891486220472441\n",
            "epoch 14 batch id 382 loss 0.6093527674674988 train acc 0.8913203534031413\n",
            "epoch 14 batch id 383 loss 0.33165332674980164 train acc 0.8914409268929504\n",
            "epoch 14 batch id 384 loss 0.4198472797870636 train acc 0.8913981119791666\n",
            "epoch 14 batch id 385 loss 0.3451269268989563 train acc 0.8913961038961039\n",
            "epoch 14 batch id 386 loss 0.4035699963569641 train acc 0.8913536269430051\n",
            "epoch 14 batch id 387 loss 0.5101097226142883 train acc 0.8911902454780362\n",
            "epoch 14 batch id 388 loss 0.23697219789028168 train acc 0.8913498711340206\n",
            "epoch 14 batch id 389 loss 0.4061630666255951 train acc 0.8912275064267352\n",
            "epoch 14 batch id 390 loss 0.32947301864624023 train acc 0.8911858974358975\n",
            "epoch 14 batch id 391 loss 0.19165386259555817 train acc 0.8912643861892583\n",
            "epoch 14 batch id 392 loss 0.20603492856025696 train acc 0.8913424744897959\n",
            "epoch 14 batch id 393 loss 0.26741641759872437 train acc 0.891420165394402\n",
            "epoch 14 batch id 394 loss 0.1862066388130188 train acc 0.8915371192893401\n",
            "epoch 14 batch id 395 loss 0.2826496958732605 train acc 0.8916534810126582\n",
            "epoch 14 batch id 396 loss 0.48506632447242737 train acc 0.8916114267676768\n",
            "epoch 14 batch id 397 loss 0.4837915897369385 train acc 0.8914121536523929\n",
            "epoch 14 batch id 398 loss 0.47443100810050964 train acc 0.8913709170854272\n",
            "epoch 14 batch id 399 loss 0.2977176904678345 train acc 0.8914473684210527\n",
            "epoch 14 batch id 400 loss 0.38130682706832886 train acc 0.89140625\n",
            "epoch 14 batch id 401 loss 0.5335204601287842 train acc 0.8913653366583542\n",
            "epoch 14 batch id 402 loss 0.5078432559967041 train acc 0.8913246268656716\n",
            "epoch 14 batch id 403 loss 0.2601805329322815 train acc 0.8914004342431762\n",
            "epoch 14 batch id 404 loss 0.3567686975002289 train acc 0.8914758663366337\n",
            "epoch 14 batch id 405 loss 0.3691267967224121 train acc 0.8914737654320988\n",
            "epoch 14 batch id 406 loss 0.3872143030166626 train acc 0.8915101600985221\n",
            "epoch 14 batch id 407 loss 0.3857763111591339 train acc 0.8915079852579852\n",
            "epoch 14 batch id 408 loss 0.27207234501838684 train acc 0.8916207107843137\n",
            "epoch 14 batch id 409 loss 0.3126489222049713 train acc 0.8916564792176039\n",
            "epoch 14 batch id 410 loss 0.2936067283153534 train acc 0.8916539634146341\n",
            "epoch 14 batch id 411 loss 0.316090852022171 train acc 0.8916894768856448\n",
            "epoch 14 batch id 412 loss 0.39150139689445496 train acc 0.8916868932038835\n",
            "epoch 14 batch id 413 loss 0.36670994758605957 train acc 0.8917221549636803\n",
            "epoch 14 batch id 414 loss 0.3484104871749878 train acc 0.8917572463768116\n",
            "epoch 14 batch id 415 loss 0.5183481574058533 train acc 0.8916792168674699\n",
            "epoch 14 batch id 416 loss 0.3754797577857971 train acc 0.8918269230769231\n",
            "epoch 14 batch id 417 loss 0.3103116750717163 train acc 0.8918989808153477\n",
            "epoch 14 batch id 418 loss 0.48978710174560547 train acc 0.8918211722488039\n",
            "epoch 14 batch id 419 loss 0.3358263671398163 train acc 0.8917810262529833\n",
            "epoch 14 batch id 420 loss 0.5211504697799683 train acc 0.8917410714285714\n",
            "epoch 14 batch id 421 loss 0.19945526123046875 train acc 0.8919239904988123\n",
            "epoch 14 batch id 422 loss 0.2191949188709259 train acc 0.8921060426540285\n",
            "epoch 14 batch id 423 loss 0.42419546842575073 train acc 0.8920656028368794\n",
            "epoch 14 batch id 424 loss 0.368098646402359 train acc 0.8920990566037735\n",
            "epoch 14 batch id 425 loss 0.31696388125419617 train acc 0.8921323529411764\n",
            "epoch 14 batch id 426 loss 0.27954965829849243 train acc 0.8921654929577465\n",
            "epoch 14 batch id 427 loss 0.24638484418392181 train acc 0.892271662763466\n",
            "epoch 14 batch id 428 loss 0.23352348804473877 train acc 0.8923043224299065\n",
            "epoch 14 batch id 429 loss 0.5652210712432861 train acc 0.8921911421911422\n",
            "epoch 14 batch id 430 loss 0.16984745860099792 train acc 0.8923328488372093\n",
            "epoch 14 batch id 431 loss 0.42775386571884155 train acc 0.8922201276102089\n",
            "epoch 14 batch id 432 loss 0.364574134349823 train acc 0.8922887731481481\n",
            "epoch 14 batch id 433 loss 0.3789435029029846 train acc 0.8922488452655889\n",
            "epoch 14 batch id 434 loss 0.38481056690216064 train acc 0.8922451036866359\n",
            "epoch 14 batch id 435 loss 0.27263402938842773 train acc 0.8923132183908046\n",
            "epoch 14 batch id 436 loss 0.505317211151123 train acc 0.8922018348623854\n",
            "epoch 14 batch id 437 loss 0.4619050621986389 train acc 0.8921267162471396\n",
            "epoch 14 batch id 438 loss 0.29949429631233215 train acc 0.8920876141552512\n",
            "epoch 14 batch id 439 loss 0.38634148240089417 train acc 0.892119874715262\n",
            "epoch 14 batch id 440 loss 0.2689816653728485 train acc 0.8922230113636364\n",
            "epoch 14 batch id 441 loss 0.19104543328285217 train acc 0.8923256802721088\n",
            "epoch 14 batch id 442 loss 0.38047242164611816 train acc 0.8923571832579186\n",
            "epoch 14 batch id 443 loss 0.33375677466392517 train acc 0.8923180022573364\n",
            "epoch 14 batch id 444 loss 0.452877014875412 train acc 0.8922789977477478\n",
            "epoch 14 batch id 445 loss 0.39539971947669983 train acc 0.8922401685393259\n",
            "epoch 14 batch id 446 loss 0.424550861120224 train acc 0.8922365470852018\n",
            "epoch 14 batch id 447 loss 0.46614110469818115 train acc 0.8921979865771812\n",
            "epoch 14 batch id 448 loss 0.1913633644580841 train acc 0.892333984375\n",
            "epoch 14 batch id 449 loss 0.6898340582847595 train acc 0.8921561804008908\n",
            "epoch 14 batch id 450 loss 0.17914655804634094 train acc 0.8922916666666667\n",
            "epoch 14 batch id 451 loss 0.4500354528427124 train acc 0.8922186807095344\n",
            "epoch 14 batch id 452 loss 0.5277411341667175 train acc 0.8921460176991151\n",
            "epoch 14 batch id 453 loss 0.3704913258552551 train acc 0.8921426600441501\n",
            "epoch 14 batch id 454 loss 0.3604810833930969 train acc 0.8922081497797357\n",
            "epoch 14 batch id 455 loss 0.2892344892024994 train acc 0.892239010989011\n",
            "epoch 14 batch id 456 loss 0.42118141055107117 train acc 0.8921669407894737\n",
            "epoch 14 batch id 457 loss 0.3657057285308838 train acc 0.8921635667396062\n",
            "epoch 14 batch id 458 loss 0.2043033391237259 train acc 0.8923307860262009\n",
            "epoch 14 batch id 459 loss 0.24847683310508728 train acc 0.8923951525054467\n",
            "epoch 14 batch id 460 loss 0.40619978308677673 train acc 0.8924252717391304\n",
            "epoch 14 batch id 461 loss 0.4177873134613037 train acc 0.8925230477223427\n",
            "epoch 14 batch id 462 loss 0.4893876314163208 train acc 0.892383658008658\n",
            "epoch 14 batch id 463 loss 0.37158286571502686 train acc 0.8923461123110151\n",
            "epoch 14 batch id 464 loss 0.4859192371368408 train acc 0.8923424030172413\n",
            "epoch 14 batch id 465 loss 0.34231898188591003 train acc 0.8924059139784947\n",
            "epoch 14 batch id 466 loss 0.5536755323410034 train acc 0.8922009120171673\n",
            "epoch 14 batch id 467 loss 0.4522097408771515 train acc 0.8922309957173448\n",
            "epoch 14 batch id 468 loss 0.192788228392601 train acc 0.8923611111111112\n",
            "epoch 14 batch id 469 loss 0.3564501702785492 train acc 0.8923574093816631\n",
            "epoch 14 batch id 470 loss 0.32055747509002686 train acc 0.8923204787234043\n",
            "epoch 14 batch id 471 loss 0.2345411628484726 train acc 0.8924495753715499\n",
            "epoch 14 batch id 472 loss 0.17624619603157043 train acc 0.8925119173728814\n",
            "epoch 14 batch id 473 loss 0.17333625257015228 train acc 0.8926400634249472\n",
            "epoch 14 batch id 474 loss 0.2549772262573242 train acc 0.8927017405063291\n",
            "epoch 14 batch id 475 loss 0.36504942178726196 train acc 0.8926973684210526\n",
            "epoch 14 batch id 476 loss 0.26199695467948914 train acc 0.8928571428571429\n",
            "epoch 14 batch id 477 loss 0.6044975519180298 train acc 0.8927214360587002\n",
            "epoch 14 batch id 478 loss 0.3573870062828064 train acc 0.892717050209205\n",
            "epoch 14 batch id 479 loss 0.26598063111305237 train acc 0.8928105427974948\n",
            "epoch 14 batch id 480 loss 0.37648260593414307 train acc 0.8927083333333333\n",
            "epoch 14 batch id 481 loss 0.3991216719150543 train acc 0.8927364864864865\n",
            "epoch 14 batch id 482 loss 0.3260084390640259 train acc 0.8927645228215768\n",
            "epoch 14 batch id 483 loss 0.41213420033454895 train acc 0.8928247929606625\n",
            "epoch 14 batch id 484 loss 0.2670403718948364 train acc 0.8929816632231405\n",
            "epoch 14 batch id 485 loss 0.500476062297821 train acc 0.8929123711340207\n",
            "epoch 14 batch id 486 loss 0.3998883366584778 train acc 0.8929398148148148\n",
            "epoch 14 batch id 487 loss 0.25016191601753235 train acc 0.8930313141683778\n",
            "epoch 14 batch id 488 loss 0.2581455409526825 train acc 0.8931224385245902\n",
            "epoch 14 batch id 489 loss 0.1719067245721817 train acc 0.8933090490797546\n",
            "epoch 14 batch id 490 loss 0.3982159495353699 train acc 0.8933035714285714\n",
            "epoch 14 batch id 491 loss 0.4367631673812866 train acc 0.893393584521385\n",
            "epoch 14 batch id 492 loss 0.5800609588623047 train acc 0.8932926829268293\n",
            "epoch 14 batch id 493 loss 0.2999391257762909 train acc 0.8934140466531441\n",
            "epoch 14 batch id 494 loss 0.3285921514034271 train acc 0.8934400303643725\n",
            "epoch 14 batch id 495 loss 0.41168224811553955 train acc 0.8934027777777778\n",
            "epoch 14 batch id 496 loss 0.286362886428833 train acc 0.8934286794354839\n",
            "epoch 14 batch id 497 loss 0.31596672534942627 train acc 0.8934859154929577\n",
            "epoch 14 batch id 498 loss 0.2964845299720764 train acc 0.893542921686747\n",
            "epoch 14 batch id 499 loss 0.5498033165931702 train acc 0.8934431362725451\n",
            "epoch 14 batch id 500 loss 0.24581961333751678 train acc 0.8935\n",
            "epoch 14 batch id 501 loss 0.16529734432697296 train acc 0.8936190119760479\n",
            "epoch 14 batch id 502 loss 0.49752506613731384 train acc 0.893581922310757\n",
            "epoch 14 batch id 503 loss 0.43701428174972534 train acc 0.8935760437375746\n",
            "epoch 14 batch id 504 loss 0.13651122152805328 train acc 0.8936941964285714\n",
            "epoch 14 batch id 505 loss 0.463672012090683 train acc 0.8936571782178218\n",
            "epoch 14 batch id 506 loss 0.5084646344184875 train acc 0.893651185770751\n",
            "epoch 14 batch id 507 loss 0.27872392535209656 train acc 0.8936760355029586\n",
            "epoch 14 batch id 508 loss 0.32617977261543274 train acc 0.8936392716535433\n",
            "epoch 14 batch id 509 loss 0.367389053106308 train acc 0.893602652259332\n",
            "epoch 14 batch id 510 loss 0.4829549193382263 train acc 0.8935968137254902\n",
            "epoch 14 batch id 511 loss 0.23360812664031982 train acc 0.893649725872084\n",
            "epoch 14 train acc 0.893649725872084\n",
            "epoch 14 test acc 0.4036865234375\n",
            "epoch 15 batch id 1 loss 0.29163193702697754 train acc 0.9375\n",
            "epoch 15 batch id 2 loss 0.43061837553977966 train acc 0.90625\n",
            "epoch 15 batch id 3 loss 0.27574795484542847 train acc 0.9166666666666666\n",
            "epoch 15 batch id 4 loss 0.34601280093193054 train acc 0.91796875\n",
            "epoch 15 batch id 5 loss 0.45203977823257446 train acc 0.90625\n",
            "epoch 15 batch id 6 loss 0.32805249094963074 train acc 0.9036458333333334\n",
            "epoch 15 batch id 7 loss 0.41349586844444275 train acc 0.90625\n",
            "epoch 15 batch id 8 loss 0.33723053336143494 train acc 0.908203125\n",
            "epoch 15 batch id 9 loss 0.3217082619667053 train acc 0.90625\n",
            "epoch 15 batch id 10 loss 0.3490830957889557 train acc 0.9046875\n",
            "epoch 15 batch id 11 loss 0.2826448976993561 train acc 0.9048295454545454\n",
            "epoch 15 batch id 12 loss 0.3509000241756439 train acc 0.9036458333333334\n",
            "epoch 15 batch id 13 loss 0.1866859644651413 train acc 0.9074519230769231\n",
            "epoch 15 batch id 14 loss 0.44937628507614136 train acc 0.9073660714285714\n",
            "epoch 15 batch id 15 loss 0.3800193965435028 train acc 0.90625\n",
            "epoch 15 batch id 16 loss 0.2768591046333313 train acc 0.90625\n",
            "epoch 15 batch id 17 loss 0.40603816509246826 train acc 0.90625\n",
            "epoch 15 batch id 18 loss 0.29704752564430237 train acc 0.9045138888888888\n",
            "epoch 15 batch id 19 loss 0.3209373652935028 train acc 0.9029605263157895\n",
            "epoch 15 batch id 20 loss 0.5627956390380859 train acc 0.8984375\n",
            "epoch 15 batch id 21 loss 0.15650571882724762 train acc 0.9010416666666666\n",
            "epoch 15 batch id 22 loss 0.35481029748916626 train acc 0.9005681818181818\n",
            "epoch 15 batch id 23 loss 0.4661584794521332 train acc 0.9008152173913043\n",
            "epoch 15 batch id 24 loss 0.29074764251708984 train acc 0.9016927083333334\n",
            "epoch 15 batch id 25 loss 0.44072481989860535 train acc 0.9\n",
            "epoch 15 batch id 26 loss 0.39965370297431946 train acc 0.9002403846153846\n",
            "epoch 15 batch id 27 loss 0.42577069997787476 train acc 0.8987268518518519\n",
            "epoch 15 batch id 28 loss 0.3183906078338623 train acc 0.8995535714285714\n",
            "epoch 15 batch id 29 loss 0.20888957381248474 train acc 0.9014008620689655\n",
            "epoch 15 batch id 30 loss 0.28940099477767944 train acc 0.9020833333333333\n",
            "epoch 15 batch id 31 loss 0.3261275589466095 train acc 0.9027217741935484\n",
            "epoch 15 batch id 32 loss 0.32224422693252563 train acc 0.9033203125\n",
            "epoch 15 batch id 33 loss 0.3205345571041107 train acc 0.9038825757575758\n",
            "epoch 15 batch id 34 loss 0.38404983282089233 train acc 0.9030330882352942\n",
            "epoch 15 batch id 35 loss 0.23244743049144745 train acc 0.903125\n",
            "epoch 15 batch id 36 loss 0.32670360803604126 train acc 0.9032118055555556\n",
            "epoch 15 batch id 37 loss 0.4618532359600067 train acc 0.902027027027027\n",
            "epoch 15 batch id 38 loss 0.4097804129123688 train acc 0.9021381578947368\n",
            "epoch 15 batch id 39 loss 0.5494378209114075 train acc 0.9014423076923077\n",
            "epoch 15 batch id 40 loss 0.15192939341068268 train acc 0.903125\n",
            "epoch 15 batch id 41 loss 0.27449432015419006 train acc 0.9035823170731707\n",
            "epoch 15 batch id 42 loss 0.3762863874435425 train acc 0.9029017857142857\n",
            "epoch 15 batch id 43 loss 0.3764563500881195 train acc 0.9026162790697675\n",
            "epoch 15 batch id 44 loss 0.4172464907169342 train acc 0.90234375\n",
            "epoch 15 batch id 45 loss 0.35417455434799194 train acc 0.9020833333333333\n",
            "epoch 15 batch id 46 loss 0.7258837223052979 train acc 0.9004755434782609\n",
            "epoch 15 batch id 47 loss 0.3278513550758362 train acc 0.9005984042553191\n",
            "epoch 15 batch id 48 loss 0.31019771099090576 train acc 0.900390625\n",
            "epoch 15 batch id 49 loss 0.2770223319530487 train acc 0.9008290816326531\n",
            "epoch 15 batch id 50 loss 0.4793761372566223 train acc 0.900625\n",
            "epoch 15 batch id 51 loss 0.19760845601558685 train acc 0.9016544117647058\n",
            "epoch 15 batch id 52 loss 0.25916022062301636 train acc 0.90234375\n",
            "epoch 15 batch id 53 loss 0.17494535446166992 train acc 0.9033018867924528\n",
            "epoch 15 batch id 54 loss 0.11166311055421829 train acc 0.9050925925925926\n",
            "epoch 15 batch id 55 loss 0.48858946561813354 train acc 0.9042613636363637\n",
            "epoch 15 batch id 56 loss 0.2884697914123535 train acc 0.9045758928571429\n",
            "epoch 15 batch id 57 loss 0.5051016807556152 train acc 0.9040570175438597\n",
            "epoch 15 batch id 58 loss 0.23650267720222473 train acc 0.904364224137931\n",
            "epoch 15 batch id 59 loss 0.6004328727722168 train acc 0.9038665254237288\n",
            "epoch 15 batch id 60 loss 0.25554993748664856 train acc 0.9036458333333334\n",
            "epoch 15 batch id 61 loss 0.3762497901916504 train acc 0.9034323770491803\n",
            "epoch 15 batch id 62 loss 0.2935140132904053 train acc 0.9037298387096774\n",
            "epoch 15 batch id 63 loss 0.37486857175827026 train acc 0.9040178571428571\n",
            "epoch 15 batch id 64 loss 0.20726044476032257 train acc 0.90478515625\n",
            "epoch 15 batch id 65 loss 0.4292869567871094 train acc 0.9043269230769231\n",
            "epoch 15 batch id 66 loss 0.19771844148635864 train acc 0.9053030303030303\n",
            "epoch 15 batch id 67 loss 0.4229526221752167 train acc 0.9053171641791045\n",
            "epoch 15 batch id 68 loss 0.3324320614337921 train acc 0.9055606617647058\n",
            "epoch 15 batch id 69 loss 0.14734114706516266 train acc 0.9064764492753623\n",
            "epoch 15 batch id 70 loss 0.2670314908027649 train acc 0.9066964285714286\n",
            "epoch 15 batch id 71 loss 0.2514544427394867 train acc 0.9069102112676056\n",
            "epoch 15 batch id 72 loss 0.287074476480484 train acc 0.9073350694444444\n",
            "epoch 15 batch id 73 loss 0.2915371060371399 train acc 0.9079623287671232\n",
            "epoch 15 batch id 74 loss 0.41148582100868225 train acc 0.9083614864864865\n",
            "epoch 15 batch id 75 loss 0.38627517223358154 train acc 0.908125\n",
            "epoch 15 batch id 76 loss 0.44393056631088257 train acc 0.9081003289473685\n",
            "epoch 15 batch id 77 loss 0.21181678771972656 train acc 0.908685064935065\n",
            "epoch 15 batch id 78 loss 0.21671980619430542 train acc 0.9094551282051282\n",
            "epoch 15 batch id 79 loss 0.3408651351928711 train acc 0.9094145569620253\n",
            "epoch 15 batch id 80 loss 0.40050703287124634 train acc 0.9095703125\n",
            "epoch 15 batch id 81 loss 0.40457984805107117 train acc 0.9091435185185185\n",
            "epoch 15 batch id 82 loss 0.17105665802955627 train acc 0.9096798780487805\n",
            "epoch 15 batch id 83 loss 0.3822339177131653 train acc 0.9096385542168675\n",
            "epoch 15 batch id 84 loss 0.4481735825538635 train acc 0.9094122023809523\n",
            "epoch 15 batch id 85 loss 0.25524088740348816 train acc 0.909375\n",
            "epoch 15 batch id 86 loss 0.49459049105644226 train acc 0.9089752906976745\n",
            "epoch 15 batch id 87 loss 0.2803988456726074 train acc 0.9096623563218391\n",
            "epoch 15 batch id 88 loss 0.3924146592617035 train acc 0.9096235795454546\n",
            "epoch 15 batch id 89 loss 0.2519112229347229 train acc 0.909936797752809\n",
            "epoch 15 batch id 90 loss 0.35779571533203125 train acc 0.9100694444444445\n",
            "epoch 15 batch id 91 loss 0.4059220850467682 train acc 0.9095123626373627\n",
            "epoch 15 batch id 92 loss 0.30807989835739136 train acc 0.9094769021739131\n",
            "epoch 15 batch id 93 loss 0.3115474283695221 train acc 0.9094422043010753\n",
            "epoch 15 batch id 94 loss 0.2752728760242462 train acc 0.9095744680851063\n",
            "epoch 15 batch id 95 loss 0.4703475832939148 train acc 0.9088815789473684\n",
            "epoch 15 batch id 96 loss 0.45859140157699585 train acc 0.90869140625\n",
            "epoch 15 batch id 97 loss 0.342447966337204 train acc 0.9086662371134021\n",
            "epoch 15 batch id 98 loss 0.48964667320251465 train acc 0.9083227040816326\n",
            "epoch 15 batch id 99 loss 0.3868425488471985 train acc 0.9084595959595959\n",
            "epoch 15 batch id 100 loss 0.2764873504638672 train acc 0.90859375\n",
            "epoch 15 batch id 101 loss 0.32409048080444336 train acc 0.9090346534653465\n",
            "epoch 15 batch id 102 loss 0.35231178998947144 train acc 0.9088541666666666\n",
            "epoch 15 batch id 103 loss 0.35232993960380554 train acc 0.9089805825242718\n",
            "epoch 15 batch id 104 loss 0.3510242998600006 train acc 0.9086538461538461\n",
            "epoch 15 batch id 105 loss 0.228515163064003 train acc 0.909077380952381\n",
            "epoch 15 batch id 106 loss 0.22158841788768768 train acc 0.9094929245283019\n",
            "epoch 15 batch id 107 loss 0.37683483958244324 train acc 0.9097546728971962\n",
            "epoch 15 batch id 108 loss 0.25998225808143616 train acc 0.9100115740740741\n",
            "epoch 15 batch id 109 loss 0.4346379339694977 train acc 0.9095470183486238\n",
            "epoch 15 batch id 110 loss 0.27386391162872314 train acc 0.909375\n",
            "epoch 15 batch id 111 loss 0.17677782475948334 train acc 0.9097691441441441\n",
            "epoch 15 batch id 112 loss 0.20718179643154144 train acc 0.9102957589285714\n",
            "epoch 15 batch id 113 loss 0.3755547106266022 train acc 0.9101216814159292\n",
            "epoch 15 batch id 114 loss 0.18841944634914398 train acc 0.9106359649122807\n",
            "epoch 15 batch id 115 loss 0.14647160470485687 train acc 0.9111413043478261\n",
            "epoch 15 batch id 116 loss 0.38217103481292725 train acc 0.9105603448275862\n",
            "epoch 15 batch id 117 loss 0.33941882848739624 train acc 0.9105235042735043\n",
            "epoch 15 batch id 118 loss 0.3620983064174652 train acc 0.910884533898305\n",
            "epoch 15 batch id 119 loss 0.48507189750671387 train acc 0.9107142857142857\n",
            "epoch 15 batch id 120 loss 0.40702658891677856 train acc 0.9106770833333333\n",
            "epoch 15 batch id 121 loss 0.4666696786880493 train acc 0.9103822314049587\n",
            "epoch 15 batch id 122 loss 0.3631284236907959 train acc 0.9103483606557377\n",
            "epoch 15 batch id 123 loss 0.36546874046325684 train acc 0.9105691056910569\n",
            "epoch 15 batch id 124 loss 0.4026091396808624 train acc 0.9102822580645161\n",
            "epoch 15 batch id 125 loss 0.40028178691864014 train acc 0.91025\n",
            "epoch 15 batch id 126 loss 0.18661735951900482 train acc 0.9104662698412699\n",
            "epoch 15 batch id 127 loss 0.3432888388633728 train acc 0.9103100393700787\n",
            "epoch 15 batch id 128 loss 0.3466326594352722 train acc 0.9102783203125\n",
            "epoch 15 batch id 129 loss 0.3942497670650482 train acc 0.9101259689922481\n",
            "epoch 15 batch id 130 loss 0.6061313152313232 train acc 0.9100961538461538\n",
            "epoch 15 batch id 131 loss 0.3205433189868927 train acc 0.9099475190839694\n",
            "epoch 15 batch id 132 loss 0.260558158159256 train acc 0.91015625\n",
            "epoch 15 batch id 133 loss 0.4147058427333832 train acc 0.9097744360902256\n",
            "epoch 15 batch id 134 loss 0.40964314341545105 train acc 0.9096315298507462\n",
            "epoch 15 batch id 135 loss 0.37091997265815735 train acc 0.909375\n",
            "epoch 15 batch id 136 loss 0.4753694236278534 train acc 0.9091222426470589\n",
            "epoch 15 batch id 137 loss 0.3899930715560913 train acc 0.9089872262773723\n",
            "epoch 15 batch id 138 loss 0.25943824648857117 train acc 0.9090806159420289\n",
            "epoch 15 batch id 139 loss 0.24174687266349792 train acc 0.9095098920863309\n",
            "epoch 15 batch id 140 loss 0.3381275534629822 train acc 0.9095982142857143\n",
            "epoch 15 batch id 141 loss 0.1691117137670517 train acc 0.9100177304964538\n",
            "epoch 15 batch id 142 loss 0.4934634566307068 train acc 0.9095510563380281\n",
            "epoch 15 batch id 143 loss 0.3942233622074127 train acc 0.9093094405594405\n",
            "epoch 15 batch id 144 loss 0.3368477523326874 train acc 0.9093967013888888\n",
            "epoch 15 batch id 145 loss 0.27138400077819824 train acc 0.9095905172413793\n",
            "epoch 15 batch id 146 loss 0.18550518155097961 train acc 0.909888698630137\n",
            "epoch 15 batch id 147 loss 0.3667733073234558 train acc 0.9095450680272109\n",
            "epoch 15 batch id 148 loss 0.1815040409564972 train acc 0.9097339527027027\n",
            "epoch 15 batch id 149 loss 0.24106845259666443 train acc 0.9098154362416108\n",
            "epoch 15 batch id 150 loss 0.19951461255550385 train acc 0.9102083333333333\n",
            "epoch 15 batch id 151 loss 0.3816530406475067 train acc 0.910078642384106\n",
            "epoch 15 batch id 152 loss 0.35442087054252625 train acc 0.9100534539473685\n",
            "epoch 15 batch id 153 loss 0.24507835507392883 train acc 0.9102328431372549\n",
            "epoch 15 batch id 154 loss 0.4982042908668518 train acc 0.9101055194805194\n",
            "epoch 15 batch id 155 loss 0.3902359902858734 train acc 0.9102822580645161\n",
            "epoch 15 batch id 156 loss 0.20462378859519958 train acc 0.9105568910256411\n",
            "epoch 15 batch id 157 loss 0.3241676390171051 train acc 0.9103304140127388\n",
            "epoch 15 batch id 158 loss 0.27895477414131165 train acc 0.9103045886075949\n",
            "epoch 15 batch id 159 loss 0.17017202079296112 train acc 0.9105738993710691\n",
            "epoch 15 batch id 160 loss 0.5284332633018494 train acc 0.91005859375\n",
            "epoch 15 batch id 161 loss 0.33639687299728394 train acc 0.9101319875776398\n",
            "epoch 15 batch id 162 loss 0.4174831509590149 train acc 0.9100115740740741\n",
            "epoch 15 batch id 163 loss 0.22636640071868896 train acc 0.9100843558282209\n",
            "epoch 15 batch id 164 loss 0.4970935881137848 train acc 0.9100609756097561\n",
            "epoch 15 batch id 165 loss 0.3548651933670044 train acc 0.9099431818181818\n",
            "epoch 15 batch id 166 loss 0.36347371339797974 train acc 0.9099209337349398\n",
            "epoch 15 batch id 167 loss 0.419403076171875 train acc 0.9098053892215568\n",
            "epoch 15 batch id 168 loss 0.4650142192840576 train acc 0.9094122023809523\n",
            "epoch 15 batch id 169 loss 0.3126268684864044 train acc 0.9095784023668639\n",
            "epoch 15 batch id 170 loss 0.6043559908866882 train acc 0.9090073529411765\n",
            "epoch 15 batch id 171 loss 0.4993845820426941 train acc 0.9088998538011696\n",
            "epoch 15 batch id 172 loss 0.35967373847961426 train acc 0.9088844476744186\n",
            "epoch 15 batch id 173 loss 0.10774923861026764 train acc 0.909320809248555\n",
            "epoch 15 batch id 174 loss 0.500774085521698 train acc 0.9089439655172413\n",
            "epoch 15 batch id 175 loss 0.38579869270324707 train acc 0.9088392857142857\n",
            "epoch 15 batch id 176 loss 0.15956269204616547 train acc 0.9092684659090909\n",
            "epoch 15 batch id 177 loss 0.2733176350593567 train acc 0.9093396892655368\n",
            "epoch 15 batch id 178 loss 0.28476113080978394 train acc 0.909497893258427\n",
            "epoch 15 batch id 179 loss 0.2675085961818695 train acc 0.9096543296089385\n",
            "epoch 15 batch id 180 loss 0.3592524528503418 train acc 0.9096354166666667\n",
            "epoch 15 batch id 181 loss 0.375648558139801 train acc 0.9095303867403315\n",
            "epoch 15 batch id 182 loss 0.5649877190589905 train acc 0.9095982142857143\n",
            "epoch 15 batch id 183 loss 0.47215890884399414 train acc 0.9093237704918032\n",
            "epoch 15 batch id 184 loss 0.380948007106781 train acc 0.9090523097826086\n",
            "epoch 15 batch id 185 loss 0.4140526056289673 train acc 0.9088682432432432\n",
            "epoch 15 batch id 186 loss 0.44131457805633545 train acc 0.9088541666666666\n",
            "epoch 15 batch id 187 loss 0.3527441620826721 train acc 0.9087566844919787\n",
            "epoch 15 batch id 188 loss 0.4574126899242401 train acc 0.9086602393617021\n",
            "epoch 15 batch id 189 loss 0.4220145344734192 train acc 0.9085648148148148\n",
            "epoch 15 batch id 190 loss 0.47879719734191895 train acc 0.9083881578947368\n",
            "epoch 15 batch id 191 loss 0.38763564825057983 train acc 0.9084587696335078\n",
            "epoch 15 batch id 192 loss 0.29968133568763733 train acc 0.9085286458333334\n",
            "epoch 15 batch id 193 loss 0.24872320890426636 train acc 0.9087597150259067\n",
            "epoch 15 batch id 194 loss 0.46700918674468994 train acc 0.9087467783505154\n",
            "epoch 15 batch id 195 loss 0.1985701471567154 train acc 0.908974358974359\n",
            "epoch 15 batch id 196 loss 0.3198620676994324 train acc 0.9091198979591837\n",
            "epoch 15 batch id 197 loss 0.25698840618133545 train acc 0.9092639593908629\n",
            "epoch 15 batch id 198 loss 0.3623565435409546 train acc 0.9094065656565656\n",
            "epoch 15 batch id 199 loss 0.580926239490509 train acc 0.9091551507537688\n",
            "epoch 15 batch id 200 loss 0.33976656198501587 train acc 0.909140625\n",
            "epoch 15 batch id 201 loss 0.22743679583072662 train acc 0.9093594527363185\n",
            "epoch 15 batch id 202 loss 0.23930314183235168 train acc 0.9094214108910891\n",
            "epoch 15 batch id 203 loss 0.41346102952957153 train acc 0.9092518472906403\n",
            "epoch 15 batch id 204 loss 0.24211670458316803 train acc 0.9093137254901961\n",
            "epoch 15 batch id 205 loss 0.23608538508415222 train acc 0.909375\n",
            "epoch 15 batch id 206 loss 0.31078457832336426 train acc 0.9095115291262136\n",
            "epoch 15 batch id 207 loss 0.6259393692016602 train acc 0.9091938405797102\n",
            "epoch 15 batch id 208 loss 0.4072074890136719 train acc 0.9090294471153846\n",
            "epoch 15 batch id 209 loss 0.3827648162841797 train acc 0.9090909090909091\n",
            "epoch 15 batch id 210 loss 0.4466681480407715 train acc 0.9088541666666666\n",
            "epoch 15 batch id 211 loss 0.2657419741153717 train acc 0.9089899289099526\n",
            "epoch 15 batch id 212 loss 0.4364836812019348 train acc 0.9090507075471698\n",
            "epoch 15 batch id 213 loss 0.23117418587207794 train acc 0.909330985915493\n",
            "epoch 15 batch id 214 loss 0.5094296336174011 train acc 0.9091705607476636\n",
            "epoch 15 batch id 215 loss 0.5007525682449341 train acc 0.9088662790697675\n",
            "epoch 15 batch id 216 loss 0.08788468688726425 train acc 0.9092158564814815\n",
            "epoch 15 batch id 217 loss 0.44986066222190857 train acc 0.9092021889400922\n",
            "epoch 15 batch id 218 loss 0.3813922703266144 train acc 0.9091886467889908\n",
            "epoch 15 batch id 219 loss 0.397239625453949 train acc 0.9091752283105022\n",
            "epoch 15 batch id 220 loss 0.20752307772636414 train acc 0.9090909090909091\n",
            "epoch 15 batch id 221 loss 0.2622896134853363 train acc 0.9091487556561086\n",
            "epoch 15 batch id 222 loss 0.21219827234745026 train acc 0.909276463963964\n",
            "epoch 15 batch id 223 loss 0.265542596578598 train acc 0.9092628923766816\n",
            "epoch 15 batch id 224 loss 0.43230924010276794 train acc 0.9091796875\n",
            "epoch 15 batch id 225 loss 0.20527775585651398 train acc 0.909375\n",
            "epoch 15 batch id 226 loss 0.2781886160373688 train acc 0.9094303097345132\n",
            "epoch 15 batch id 227 loss 0.2623886466026306 train acc 0.9095539647577092\n",
            "epoch 15 batch id 228 loss 0.52731853723526 train acc 0.9094024122807017\n",
            "epoch 15 batch id 229 loss 0.25480830669403076 train acc 0.9095933406113537\n",
            "epoch 15 batch id 230 loss 0.477855384349823 train acc 0.9095108695652174\n",
            "epoch 15 batch id 231 loss 0.3971388339996338 train acc 0.9094967532467533\n",
            "epoch 15 batch id 232 loss 0.30769726634025574 train acc 0.9096174568965517\n",
            "epoch 15 batch id 233 loss 0.48349761962890625 train acc 0.9095359442060086\n",
            "epoch 15 batch id 234 loss 0.33674612641334534 train acc 0.9095219017094017\n",
            "epoch 15 batch id 235 loss 0.4110737442970276 train acc 0.9095079787234043\n",
            "epoch 15 batch id 236 loss 0.15210874378681183 train acc 0.9096265889830508\n",
            "epoch 15 batch id 237 loss 0.29106995463371277 train acc 0.9096123417721519\n",
            "epoch 15 batch id 238 loss 0.5017145276069641 train acc 0.9094669117647058\n",
            "epoch 15 batch id 239 loss 0.39796310663223267 train acc 0.9095188284518828\n",
            "epoch 15 batch id 240 loss 0.09489757567644119 train acc 0.9098307291666666\n",
            "epoch 15 batch id 241 loss 0.4568788707256317 train acc 0.9098158713692946\n",
            "epoch 15 batch id 242 loss 0.18468952178955078 train acc 0.9099302685950413\n",
            "epoch 15 batch id 243 loss 0.2967686653137207 train acc 0.910108024691358\n",
            "epoch 15 batch id 244 loss 0.4513632655143738 train acc 0.9100281762295082\n",
            "epoch 15 batch id 245 loss 0.2859572768211365 train acc 0.9100765306122449\n",
            "epoch 15 batch id 246 loss 0.5647150874137878 train acc 0.9099974593495935\n",
            "epoch 15 batch id 247 loss 0.32011058926582336 train acc 0.9100455465587044\n",
            "epoch 15 batch id 248 loss 0.2167690247297287 train acc 0.9102822580645161\n",
            "epoch 15 batch id 249 loss 0.2204148918390274 train acc 0.9102660642570282\n",
            "epoch 15 batch id 250 loss 0.3786015510559082 train acc 0.9101875\n",
            "epoch 15 batch id 251 loss 0.4699353575706482 train acc 0.9102340637450199\n",
            "epoch 15 batch id 252 loss 0.3585876524448395 train acc 0.91015625\n",
            "epoch 15 batch id 253 loss 0.26042309403419495 train acc 0.9102643280632411\n",
            "epoch 15 batch id 254 loss 0.2347794473171234 train acc 0.9103715551181102\n",
            "epoch 15 batch id 255 loss 0.3059840798377991 train acc 0.9103553921568628\n",
            "epoch 15 batch id 256 loss 0.37239310145378113 train acc 0.91033935546875\n",
            "epoch 15 batch id 257 loss 0.36634916067123413 train acc 0.9102626459143969\n",
            "epoch 15 batch id 258 loss 0.14691519737243652 train acc 0.9103682170542635\n",
            "epoch 15 batch id 259 loss 0.2078813761472702 train acc 0.9104126447876448\n",
            "epoch 15 batch id 260 loss 0.44682201743125916 train acc 0.9103365384615385\n",
            "epoch 15 batch id 261 loss 0.3123253285884857 train acc 0.9103208812260536\n",
            "epoch 15 batch id 262 loss 0.37996312975883484 train acc 0.9102457061068703\n",
            "epoch 15 batch id 263 loss 0.5375381708145142 train acc 0.9099928707224335\n",
            "epoch 15 batch id 264 loss 0.33468785881996155 train acc 0.9097419507575758\n",
            "epoch 15 batch id 265 loss 0.24225059151649475 train acc 0.9099056603773585\n",
            "epoch 15 batch id 266 loss 0.1914912462234497 train acc 0.9100681390977443\n",
            "epoch 15 batch id 267 loss 0.35291746258735657 train acc 0.9099953183520599\n",
            "epoch 15 batch id 268 loss 0.2989010810852051 train acc 0.909981343283582\n",
            "epoch 15 batch id 269 loss 0.2721824049949646 train acc 0.9101417286245354\n",
            "epoch 15 batch id 270 loss 0.25153470039367676 train acc 0.9102430555555555\n",
            "epoch 15 batch id 271 loss 0.21223239600658417 train acc 0.9104589483394834\n",
            "epoch 15 batch id 272 loss 0.2528074383735657 train acc 0.9106158088235294\n",
            "epoch 15 batch id 273 loss 0.30902600288391113 train acc 0.9106570512820513\n",
            "epoch 15 batch id 274 loss 0.44884562492370605 train acc 0.910469890510949\n",
            "epoch 15 batch id 275 loss 0.23496486246585846 train acc 0.9105681818181818\n",
            "epoch 15 batch id 276 loss 0.18488992750644684 train acc 0.9107789855072463\n",
            "epoch 15 batch id 277 loss 0.2688080966472626 train acc 0.9107626353790613\n",
            "epoch 15 batch id 278 loss 0.4962506592273712 train acc 0.9104091726618705\n",
            "epoch 15 batch id 279 loss 0.4214284420013428 train acc 0.9102262544802867\n",
            "epoch 15 batch id 280 loss 0.35484635829925537 train acc 0.9102120535714285\n",
            "epoch 15 batch id 281 loss 0.4237994849681854 train acc 0.9101423487544484\n",
            "epoch 15 batch id 282 loss 0.38901615142822266 train acc 0.9100731382978723\n",
            "epoch 15 batch id 283 loss 0.13803443312644958 train acc 0.9102804770318021\n",
            "epoch 15 batch id 284 loss 0.23909828066825867 train acc 0.9103213028169014\n",
            "epoch 15 batch id 285 loss 0.30416005849838257 train acc 0.9102521929824562\n",
            "epoch 15 batch id 286 loss 0.3610674738883972 train acc 0.9101835664335665\n",
            "epoch 15 batch id 287 loss 0.1744910329580307 train acc 0.9103331881533101\n",
            "epoch 15 batch id 288 loss 0.4474628269672394 train acc 0.9101019965277778\n",
            "epoch 15 batch id 289 loss 0.42873892188072205 train acc 0.9101967993079585\n",
            "epoch 15 batch id 290 loss 0.5010210871696472 train acc 0.9100754310344827\n",
            "epoch 15 batch id 291 loss 0.44149208068847656 train acc 0.9100085910652921\n",
            "epoch 15 batch id 292 loss 0.3588789105415344 train acc 0.9100492294520548\n",
            "epoch 15 batch id 293 loss 0.2672586441040039 train acc 0.9101962457337884\n",
            "epoch 15 batch id 294 loss 0.39020559191703796 train acc 0.9101296768707483\n",
            "epoch 15 batch id 295 loss 0.23563942313194275 train acc 0.9103813559322034\n",
            "epoch 15 batch id 296 loss 0.40851646661758423 train acc 0.9101034628378378\n",
            "epoch 15 batch id 297 loss 0.36339330673217773 train acc 0.9100904882154882\n",
            "epoch 15 batch id 298 loss 0.34383025765419006 train acc 0.910130033557047\n",
            "epoch 15 batch id 299 loss 0.20060843229293823 train acc 0.9102215719063546\n",
            "epoch 15 batch id 300 loss 0.12712252140045166 train acc 0.9104166666666667\n",
            "epoch 15 batch id 301 loss 0.20671696960926056 train acc 0.9104547342192691\n",
            "epoch 15 batch id 302 loss 0.30243074893951416 train acc 0.9104408112582781\n",
            "epoch 15 batch id 303 loss 0.17546126246452332 train acc 0.9105816831683168\n",
            "epoch 15 batch id 304 loss 0.5539990663528442 train acc 0.9104646381578947\n",
            "epoch 15 batch id 305 loss 0.6177958846092224 train acc 0.9102459016393443\n",
            "epoch 15 batch id 306 loss 0.30840644240379333 train acc 0.9102328431372549\n",
            "epoch 15 batch id 307 loss 0.42854464054107666 train acc 0.9101689739413681\n",
            "epoch 15 batch id 308 loss 0.2697478234767914 train acc 0.9102069805194806\n",
            "epoch 15 batch id 309 loss 0.23097781836986542 train acc 0.9102447411003236\n",
            "epoch 15 batch id 310 loss 0.1488591879606247 train acc 0.910383064516129\n",
            "epoch 15 batch id 311 loss 0.1593015193939209 train acc 0.9104702572347267\n",
            "epoch 15 batch id 312 loss 0.18963901698589325 train acc 0.9105068108974359\n",
            "epoch 15 batch id 313 loss 0.15827031433582306 train acc 0.9106928913738019\n",
            "epoch 15 batch id 314 loss 0.42534926533699036 train acc 0.9106289808917197\n",
            "epoch 15 batch id 315 loss 0.2312289923429489 train acc 0.9107142857142857\n",
            "epoch 15 batch id 316 loss 0.20214338600635529 train acc 0.9107990506329114\n",
            "epoch 15 batch id 317 loss 0.2181074023246765 train acc 0.9107847003154574\n",
            "epoch 15 batch id 318 loss 0.33660271763801575 train acc 0.9107704402515723\n",
            "epoch 15 batch id 319 loss 0.3393307328224182 train acc 0.9107072884012539\n",
            "epoch 15 batch id 320 loss 0.22100356221199036 train acc 0.9107421875\n",
            "epoch 15 batch id 321 loss 0.23495931923389435 train acc 0.9107768691588785\n",
            "epoch 15 batch id 322 loss 0.32330119609832764 train acc 0.9108113354037267\n",
            "epoch 15 batch id 323 loss 0.43040865659713745 train acc 0.9106037151702786\n",
            "epoch 15 batch id 324 loss 0.2812834680080414 train acc 0.9105902777777778\n",
            "epoch 15 batch id 325 loss 0.38087907433509827 train acc 0.9105288461538461\n",
            "epoch 15 batch id 326 loss 0.4218587279319763 train acc 0.9105157208588958\n",
            "epoch 15 batch id 327 loss 0.21058902144432068 train acc 0.9105504587155964\n",
            "epoch 15 batch id 328 loss 0.23182819783687592 train acc 0.9106802591463414\n",
            "epoch 15 batch id 329 loss 0.398897647857666 train acc 0.9106667933130699\n",
            "epoch 15 batch id 330 loss 0.3401299715042114 train acc 0.9106534090909091\n",
            "epoch 15 batch id 331 loss 0.22235669195652008 train acc 0.9107345166163142\n",
            "epoch 15 batch id 332 loss 0.26483049988746643 train acc 0.9107680722891566\n",
            "epoch 15 batch id 333 loss 0.24265068769454956 train acc 0.9107545045045045\n",
            "epoch 15 batch id 334 loss 0.3405459523200989 train acc 0.9106942365269461\n",
            "epoch 15 batch id 335 loss 0.3143025040626526 train acc 0.9106809701492538\n",
            "epoch 15 batch id 336 loss 0.43183788657188416 train acc 0.9105282738095238\n",
            "epoch 15 batch id 337 loss 0.36479461193084717 train acc 0.9104692136498517\n",
            "epoch 15 batch id 338 loss 0.29042717814445496 train acc 0.9104105029585798\n",
            "epoch 15 batch id 339 loss 0.3996138274669647 train acc 0.910167772861357\n",
            "epoch 15 batch id 340 loss 0.2916439175605774 train acc 0.9102022058823529\n",
            "epoch 15 batch id 341 loss 0.26383301615715027 train acc 0.9102364369501467\n",
            "epoch 15 batch id 342 loss 0.6586815118789673 train acc 0.9099963450292398\n",
            "epoch 15 batch id 343 loss 0.510879635810852 train acc 0.9099854227405247\n",
            "epoch 15 batch id 344 loss 0.539023220539093 train acc 0.9098837209302325\n",
            "epoch 15 batch id 345 loss 0.6026026606559753 train acc 0.9096920289855073\n",
            "epoch 15 batch id 346 loss 0.3746587634086609 train acc 0.9096369219653179\n",
            "epoch 15 batch id 347 loss 0.6051979660987854 train acc 0.9094920749279539\n",
            "epoch 15 batch id 348 loss 0.5989301800727844 train acc 0.9093480603448276\n",
            "epoch 15 batch id 349 loss 0.4633878171443939 train acc 0.9092944126074498\n",
            "epoch 15 batch id 350 loss 0.40827736258506775 train acc 0.9091964285714286\n",
            "epoch 15 batch id 351 loss 0.45614123344421387 train acc 0.9090990028490028\n",
            "epoch 15 batch id 352 loss 0.5064195990562439 train acc 0.9090021306818182\n",
            "epoch 15 batch id 353 loss 0.309895783662796 train acc 0.9089500708215298\n",
            "epoch 15 batch id 354 loss 0.3182729482650757 train acc 0.9089424435028248\n",
            "epoch 15 batch id 355 loss 0.2684181332588196 train acc 0.9090228873239437\n",
            "epoch 15 batch id 356 loss 0.2402511090040207 train acc 0.9089712078651685\n",
            "epoch 15 batch id 357 loss 0.3807302713394165 train acc 0.9090511204481793\n",
            "epoch 15 batch id 358 loss 0.30828648805618286 train acc 0.9091305865921788\n",
            "epoch 15 batch id 359 loss 0.2038332223892212 train acc 0.9092531337047354\n",
            "epoch 15 batch id 360 loss 0.15062308311462402 train acc 0.909375\n",
            "epoch 15 batch id 361 loss 0.22212029993534088 train acc 0.9094529085872576\n",
            "epoch 15 batch id 362 loss 0.5349901914596558 train acc 0.9094008977900553\n",
            "epoch 15 batch id 363 loss 0.4992045760154724 train acc 0.9093061294765841\n",
            "epoch 15 batch id 364 loss 0.31721609830856323 train acc 0.9092977335164835\n",
            "epoch 15 batch id 365 loss 0.24746666848659515 train acc 0.9094178082191781\n",
            "epoch 15 batch id 366 loss 0.3740563988685608 train acc 0.9094091530054644\n",
            "epoch 15 batch id 367 loss 0.3796065151691437 train acc 0.9093579700272479\n",
            "epoch 15 batch id 368 loss 0.41823747754096985 train acc 0.9093495244565217\n",
            "epoch 15 batch id 369 loss 0.3548309803009033 train acc 0.9093411246612466\n",
            "epoch 15 batch id 370 loss 0.24432697892189026 train acc 0.909375\n",
            "epoch 15 batch id 371 loss 0.3446061313152313 train acc 0.909366576819407\n",
            "epoch 15 batch id 372 loss 0.316852331161499 train acc 0.9093581989247311\n",
            "epoch 15 batch id 373 loss 0.30138105154037476 train acc 0.9092241957104558\n",
            "epoch 15 batch id 374 loss 0.38526681065559387 train acc 0.9092580213903744\n",
            "epoch 15 batch id 375 loss 0.1628943383693695 train acc 0.909375\n",
            "epoch 15 batch id 376 loss 0.3416387438774109 train acc 0.9093666888297872\n",
            "epoch 15 batch id 377 loss 0.43779897689819336 train acc 0.9093584217506632\n",
            "epoch 15 batch id 378 loss 0.247696653008461 train acc 0.9093501984126984\n",
            "epoch 15 batch id 379 loss 0.5509834289550781 train acc 0.9092595646437994\n",
            "epoch 15 batch id 380 loss 0.3343043923377991 train acc 0.9092105263157895\n",
            "epoch 15 batch id 381 loss 0.19042116403579712 train acc 0.9092847769028871\n",
            "epoch 15 batch id 382 loss 0.20395557582378387 train acc 0.909440445026178\n",
            "epoch 15 batch id 383 loss 0.23817414045333862 train acc 0.9094321148825065\n",
            "epoch 15 batch id 384 loss 0.31623759865760803 train acc 0.909423828125\n",
            "epoch 15 batch id 385 loss 0.3851427137851715 train acc 0.909375\n",
            "epoch 15 batch id 386 loss 0.1377832293510437 train acc 0.9094478626943006\n",
            "epoch 15 batch id 387 loss 0.37660717964172363 train acc 0.9093992248062015\n",
            "epoch 15 batch id 388 loss 0.4578183889389038 train acc 0.9092702963917526\n",
            "epoch 15 batch id 389 loss 0.34210851788520813 train acc 0.9093026992287918\n",
            "epoch 15 batch id 390 loss 0.28752654790878296 train acc 0.9092948717948718\n",
            "epoch 15 batch id 391 loss 0.15179342031478882 train acc 0.9094469309462916\n",
            "epoch 15 batch id 392 loss 0.4035632908344269 train acc 0.9093191964285714\n",
            "epoch 15 batch id 393 loss 0.34123364090919495 train acc 0.9092716284987278\n",
            "epoch 15 batch id 394 loss 0.3453023135662079 train acc 0.9092243020304569\n",
            "epoch 15 batch id 395 loss 0.3177797794342041 train acc 0.9092563291139241\n",
            "epoch 15 batch id 396 loss 0.2379516214132309 train acc 0.9093276515151515\n",
            "epoch 15 batch id 397 loss 0.3958956003189087 train acc 0.9092805415617129\n",
            "epoch 15 batch id 398 loss 0.4015529751777649 train acc 0.9091551507537688\n",
            "epoch 15 batch id 399 loss 0.3966785967350006 train acc 0.9090695488721805\n",
            "epoch 15 batch id 400 loss 0.23078523576259613 train acc 0.9090625\n",
            "epoch 15 batch id 401 loss 0.4918592870235443 train acc 0.9090165211970075\n",
            "epoch 15 batch id 402 loss 0.2546548843383789 train acc 0.9091262437810945\n",
            "epoch 15 batch id 403 loss 0.35620713233947754 train acc 0.909080334987593\n",
            "epoch 15 batch id 404 loss 0.38242217898368835 train acc 0.9090733292079208\n",
            "epoch 15 batch id 405 loss 0.3300634026527405 train acc 0.909104938271605\n",
            "epoch 15 batch id 406 loss 0.2546311616897583 train acc 0.9092133620689655\n",
            "epoch 15 batch id 407 loss 0.15384340286254883 train acc 0.9092828624078624\n",
            "epoch 15 batch id 408 loss 0.4243685007095337 train acc 0.9092754289215687\n",
            "epoch 15 batch id 409 loss 0.33742859959602356 train acc 0.9093062347188264\n",
            "epoch 15 batch id 410 loss 0.43427392840385437 train acc 0.9092225609756097\n",
            "epoch 15 batch id 411 loss 0.35122567415237427 train acc 0.909139294403893\n",
            "epoch 15 batch id 412 loss 0.31231066584587097 train acc 0.9090943567961165\n",
            "epoch 15 batch id 413 loss 0.5975332856178284 train acc 0.9089739709443099\n",
            "epoch 15 batch id 414 loss 0.2865563631057739 train acc 0.9090428743961353\n",
            "epoch 15 batch id 415 loss 0.42474615573883057 train acc 0.9089608433734939\n",
            "epoch 15 batch id 416 loss 0.4315037727355957 train acc 0.9089543269230769\n",
            "epoch 15 batch id 417 loss 0.27366599440574646 train acc 0.9090227817745803\n",
            "epoch 15 batch id 418 loss 0.33371904492378235 train acc 0.9090535287081339\n",
            "epoch 15 batch id 419 loss 0.40738338232040405 train acc 0.9089349642004774\n",
            "epoch 15 batch id 420 loss 0.3361513018608093 train acc 0.9089657738095238\n",
            "epoch 15 batch id 421 loss 0.33674418926239014 train acc 0.9089964370546318\n",
            "epoch 15 batch id 422 loss 0.24692878127098083 train acc 0.9090639810426541\n",
            "epoch 15 batch id 423 loss 0.3668539226055145 train acc 0.9089834515366431\n",
            "epoch 15 batch id 424 loss 0.27359849214553833 train acc 0.9090507075471698\n",
            "epoch 15 batch id 425 loss 0.2991577684879303 train acc 0.9091176470588235\n",
            "epoch 15 batch id 426 loss 0.1817103773355484 train acc 0.9091842723004695\n",
            "epoch 15 batch id 427 loss 0.2825789451599121 train acc 0.9092505854800936\n",
            "epoch 15 batch id 428 loss 0.31205514073371887 train acc 0.9093165887850467\n",
            "epoch 15 batch id 429 loss 0.19181810319423676 train acc 0.9094187062937062\n",
            "epoch 15 batch id 430 loss 0.256976842880249 train acc 0.9094476744186046\n",
            "epoch 15 batch id 431 loss 0.36127036809921265 train acc 0.9093677494199536\n",
            "epoch 15 batch id 432 loss 0.35570716857910156 train acc 0.9092881944444444\n",
            "epoch 15 batch id 433 loss 0.21579556167125702 train acc 0.9092811778290993\n",
            "epoch 15 batch id 434 loss 0.2542625665664673 train acc 0.9093101958525346\n",
            "epoch 15 batch id 435 loss 0.4310840964317322 train acc 0.9092313218390805\n",
            "epoch 15 batch id 436 loss 0.12362343817949295 train acc 0.9094036697247706\n",
            "epoch 15 batch id 437 loss 0.39458444714546204 train acc 0.9093964530892449\n",
            "epoch 15 batch id 438 loss 0.2283497452735901 train acc 0.9094962899543378\n",
            "epoch 15 batch id 439 loss 0.285809189081192 train acc 0.9094888952164009\n",
            "epoch 15 batch id 440 loss 0.328081876039505 train acc 0.9094105113636364\n",
            "epoch 15 batch id 441 loss 0.21332058310508728 train acc 0.9094387755102041\n",
            "epoch 15 batch id 442 loss 0.1516433209180832 train acc 0.909608314479638\n",
            "epoch 15 batch id 443 loss 0.15390920639038086 train acc 0.909706546275395\n",
            "epoch 15 batch id 444 loss 0.35732218623161316 train acc 0.9097339527027027\n",
            "epoch 15 batch id 445 loss 0.31599098443984985 train acc 0.9097612359550562\n",
            "epoch 15 batch id 446 loss 0.2939468026161194 train acc 0.9097883968609866\n",
            "epoch 15 batch id 447 loss 0.2936610281467438 train acc 0.9098154362416108\n",
            "epoch 15 batch id 448 loss 0.1432836800813675 train acc 0.9100167410714286\n",
            "epoch 15 batch id 449 loss 0.35821643471717834 train acc 0.9100431514476615\n",
            "epoch 15 batch id 450 loss 0.1828136444091797 train acc 0.9100694444444445\n",
            "epoch 15 batch id 451 loss 0.3654181957244873 train acc 0.9099916851441242\n",
            "epoch 15 batch id 452 loss 0.4982045888900757 train acc 0.9098451327433629\n",
            "epoch 15 batch id 453 loss 0.30633440613746643 train acc 0.9098716887417219\n",
            "epoch 15 batch id 454 loss 0.22833384573459625 train acc 0.9099325440528634\n",
            "epoch 15 batch id 455 loss 0.3053699731826782 train acc 0.9099587912087912\n",
            "epoch 15 batch id 456 loss 0.34751489758491516 train acc 0.9099506578947368\n",
            "epoch 15 batch id 457 loss 0.26117897033691406 train acc 0.9100109409190372\n",
            "epoch 15 batch id 458 loss 0.16431310772895813 train acc 0.910139192139738\n",
            "epoch 15 batch id 459 loss 0.5919378995895386 train acc 0.9100285947712419\n",
            "epoch 15 batch id 460 loss 0.32703113555908203 train acc 0.910054347826087\n",
            "epoch 15 batch id 461 loss 0.35247960686683655 train acc 0.9100460954446855\n",
            "epoch 15 batch id 462 loss 0.3581104278564453 train acc 0.9099364177489178\n",
            "epoch 15 batch id 463 loss 0.18672087788581848 train acc 0.9098947084233261\n",
            "epoch 15 batch id 464 loss 0.2895735800266266 train acc 0.9098868534482759\n",
            "epoch 15 batch id 465 loss 0.4803750514984131 train acc 0.9098454301075268\n",
            "epoch 15 batch id 466 loss 0.2738742232322693 train acc 0.9098712446351931\n",
            "epoch 15 batch id 467 loss 0.39163851737976074 train acc 0.9098634903640257\n",
            "epoch 15 batch id 468 loss 0.15472382307052612 train acc 0.9099893162393162\n",
            "epoch 15 batch id 469 loss 0.4676903486251831 train acc 0.9098480810234542\n",
            "epoch 15 batch id 470 loss 0.21233972907066345 train acc 0.909906914893617\n",
            "epoch 15 batch id 471 loss 0.3873611390590668 train acc 0.9099323248407644\n",
            "epoch 15 batch id 472 loss 0.3126812279224396 train acc 0.9099907309322034\n",
            "epoch 15 batch id 473 loss 0.3841549754142761 train acc 0.9100488900634249\n",
            "epoch 15 batch id 474 loss 0.4258922040462494 train acc 0.9099419831223629\n",
            "epoch 15 batch id 475 loss 0.2055491954088211 train acc 0.9099671052631579\n",
            "epoch 15 batch id 476 loss 0.3770190179347992 train acc 0.9099264705882353\n",
            "epoch 15 batch id 477 loss 0.4154626727104187 train acc 0.9099187631027253\n",
            "epoch 15 batch id 478 loss 0.19189020991325378 train acc 0.9099764644351465\n",
            "epoch 15 batch id 479 loss 0.2949922978878021 train acc 0.9100013048016702\n",
            "epoch 15 batch id 480 loss 0.38641056418418884 train acc 0.9099609375\n",
            "epoch 15 batch id 481 loss 0.2206365466117859 train acc 0.9099532224532224\n",
            "epoch 15 batch id 482 loss 0.21556563675403595 train acc 0.9099455394190872\n",
            "epoch 15 batch id 483 loss 0.46557503938674927 train acc 0.9099702380952381\n",
            "epoch 15 batch id 484 loss 0.12171781808137894 train acc 0.9100594008264463\n",
            "epoch 15 batch id 485 loss 0.14713072776794434 train acc 0.9101159793814433\n",
            "epoch 15 batch id 486 loss 0.43976524472236633 train acc 0.9100115740740741\n",
            "epoch 15 batch id 487 loss 0.36096253991127014 train acc 0.9099717659137577\n",
            "epoch 15 batch id 488 loss 0.1882866770029068 train acc 0.9100601946721312\n",
            "epoch 15 batch id 489 loss 0.29415640234947205 train acc 0.9100204498977505\n",
            "epoch 15 batch id 490 loss 0.2278105616569519 train acc 0.9100765306122449\n",
            "epoch 15 batch id 491 loss 0.27923762798309326 train acc 0.9101960285132383\n",
            "epoch 15 batch id 492 loss 0.33352360129356384 train acc 0.9102197662601627\n",
            "epoch 15 batch id 493 loss 0.282835990190506 train acc 0.9102117139959433\n",
            "epoch 15 batch id 494 loss 0.29502639174461365 train acc 0.9101404352226721\n",
            "epoch 15 batch id 495 loss 0.2583082616329193 train acc 0.9102272727272728\n",
            "epoch 15 batch id 496 loss 0.381198525428772 train acc 0.910187752016129\n",
            "epoch 15 batch id 497 loss 0.2033570557832718 train acc 0.9102741448692153\n",
            "epoch 15 batch id 498 loss 0.3705674707889557 train acc 0.9102346887550201\n",
            "epoch 15 batch id 499 loss 0.2382679134607315 train acc 0.9103519539078156\n",
            "epoch 15 batch id 500 loss 0.17515046894550323 train acc 0.9105\n",
            "epoch 15 batch id 501 loss 0.23725491762161255 train acc 0.9106162674650699\n",
            "epoch 15 batch id 502 loss 0.2870880663394928 train acc 0.9105764442231076\n",
            "epoch 15 batch id 503 loss 0.47729259729385376 train acc 0.9104746520874751\n",
            "epoch 15 batch id 504 loss 0.17449656128883362 train acc 0.9105592757936508\n",
            "epoch 15 batch id 505 loss 0.31597900390625 train acc 0.9105816831683168\n",
            "epoch 15 batch id 506 loss 0.1607670933008194 train acc 0.9106348814229249\n",
            "epoch 15 batch id 507 loss 0.4508551359176636 train acc 0.9105029585798816\n",
            "epoch 15 batch id 508 loss 0.21335554122924805 train acc 0.9106176181102362\n",
            "epoch 15 batch id 509 loss 0.3677442669868469 train acc 0.9105783398821218\n",
            "epoch 15 batch id 510 loss 0.3891107439994812 train acc 0.9105698529411764\n",
            "epoch 15 batch id 511 loss 0.2764938473701477 train acc 0.9105584870934675\n",
            "epoch 15 train acc 0.9105584870934675\n",
            "epoch 15 test acc 0.3944091796875\n",
            "epoch 16 batch id 1 loss 0.2554446756839752 train acc 0.921875\n",
            "epoch 16 batch id 2 loss 0.3603300154209137 train acc 0.8984375\n",
            "epoch 16 batch id 3 loss 0.40271592140197754 train acc 0.890625\n",
            "epoch 16 batch id 4 loss 0.21053831279277802 train acc 0.90234375\n",
            "epoch 16 batch id 5 loss 0.2532947361469269 train acc 0.909375\n",
            "epoch 16 batch id 6 loss 0.3286266624927521 train acc 0.9140625\n",
            "epoch 16 batch id 7 loss 0.2926654815673828 train acc 0.9129464285714286\n",
            "epoch 16 batch id 8 loss 0.254055917263031 train acc 0.912109375\n",
            "epoch 16 batch id 9 loss 0.45365840196609497 train acc 0.9097222222222222\n",
            "epoch 16 batch id 10 loss 0.3216535151004791 train acc 0.909375\n",
            "epoch 16 batch id 11 loss 0.3432954251766205 train acc 0.9119318181818182\n",
            "epoch 16 batch id 12 loss 0.3982863128185272 train acc 0.9075520833333334\n",
            "epoch 16 batch id 13 loss 0.23934024572372437 train acc 0.9110576923076923\n",
            "epoch 16 batch id 14 loss 0.4279116988182068 train acc 0.9107142857142857\n",
            "epoch 16 batch id 15 loss 0.20391426980495453 train acc 0.9135416666666667\n",
            "epoch 16 batch id 16 loss 0.36751896142959595 train acc 0.9140625\n",
            "epoch 16 batch id 17 loss 0.2755776643753052 train acc 0.9145220588235294\n",
            "epoch 16 batch id 18 loss 0.21181130409240723 train acc 0.9157986111111112\n",
            "epoch 16 batch id 19 loss 0.20287147164344788 train acc 0.9177631578947368\n",
            "epoch 16 batch id 20 loss 0.27725180983543396 train acc 0.91640625\n",
            "epoch 16 batch id 21 loss 0.2659198045730591 train acc 0.9159226190476191\n",
            "epoch 16 batch id 22 loss 0.2703743875026703 train acc 0.9169034090909091\n",
            "epoch 16 batch id 23 loss 0.3501138985157013 train acc 0.9157608695652174\n",
            "epoch 16 batch id 24 loss 0.28640031814575195 train acc 0.9153645833333334\n",
            "epoch 16 batch id 25 loss 0.2842591106891632 train acc 0.91625\n",
            "epoch 16 batch id 26 loss 0.253842830657959 train acc 0.9152644230769231\n",
            "epoch 16 batch id 27 loss 0.3374778628349304 train acc 0.9149305555555556\n",
            "epoch 16 batch id 28 loss 0.5168265104293823 train acc 0.9135044642857143\n",
            "epoch 16 batch id 29 loss 0.277992844581604 train acc 0.9143318965517241\n",
            "epoch 16 batch id 30 loss 0.3455159366130829 train acc 0.9140625\n",
            "epoch 16 batch id 31 loss 0.17665114998817444 train acc 0.9153225806451613\n",
            "epoch 16 batch id 32 loss 0.4371728003025055 train acc 0.9140625\n",
            "epoch 16 batch id 33 loss 0.34669652581214905 train acc 0.9142992424242424\n",
            "epoch 16 batch id 34 loss 0.31771039962768555 train acc 0.9140625\n",
            "epoch 16 batch id 35 loss 0.2564908266067505 train acc 0.9133928571428571\n",
            "epoch 16 batch id 36 loss 0.14913764595985413 train acc 0.9140625\n",
            "epoch 16 batch id 37 loss 0.41337114572525024 train acc 0.9134290540540541\n",
            "epoch 16 batch id 38 loss 0.5912660956382751 train acc 0.9120065789473685\n",
            "epoch 16 batch id 39 loss 0.3494323194026947 train acc 0.9118589743589743\n",
            "epoch 16 batch id 40 loss 0.4181310832500458 train acc 0.912109375\n",
            "epoch 16 batch id 41 loss 0.20419670641422272 train acc 0.913109756097561\n",
            "epoch 16 batch id 42 loss 0.3190411925315857 train acc 0.9133184523809523\n",
            "epoch 16 batch id 43 loss 0.4266887605190277 train acc 0.9124273255813954\n",
            "epoch 16 batch id 44 loss 0.24693147838115692 train acc 0.9126420454545454\n",
            "epoch 16 batch id 45 loss 0.22511178255081177 train acc 0.9128472222222223\n",
            "epoch 16 batch id 46 loss 0.21100877225399017 train acc 0.9130434782608695\n",
            "epoch 16 batch id 47 loss 0.4237876534461975 train acc 0.9115691489361702\n",
            "epoch 16 batch id 48 loss 0.5156474709510803 train acc 0.9111328125\n",
            "epoch 16 batch id 49 loss 0.21751148998737335 train acc 0.9110331632653061\n",
            "epoch 16 batch id 50 loss 0.3684558570384979 train acc 0.9115625\n",
            "epoch 16 batch id 51 loss 0.21437077224254608 train acc 0.9120710784313726\n",
            "epoch 16 batch id 52 loss 0.4774300158023834 train acc 0.9119591346153846\n",
            "epoch 16 batch id 53 loss 0.4815250039100647 train acc 0.9112617924528302\n",
            "epoch 16 batch id 54 loss 0.45394134521484375 train acc 0.9105902777777778\n",
            "epoch 16 batch id 55 loss 0.2540843188762665 train acc 0.9110795454545455\n",
            "epoch 16 batch id 56 loss 0.31400880217552185 train acc 0.9109933035714286\n",
            "epoch 16 batch id 57 loss 0.4224106967449188 train acc 0.9111842105263158\n",
            "epoch 16 batch id 58 loss 0.21409018337726593 train acc 0.9116379310344828\n",
            "epoch 16 batch id 59 loss 0.14465264976024628 train acc 0.9128707627118644\n",
            "epoch 16 batch id 60 loss 0.25248587131500244 train acc 0.91328125\n",
            "epoch 16 batch id 61 loss 0.23597413301467896 train acc 0.9136782786885246\n",
            "epoch 16 batch id 62 loss 0.140922412276268 train acc 0.9148185483870968\n",
            "epoch 16 batch id 63 loss 0.1863151490688324 train acc 0.9151785714285714\n",
            "epoch 16 batch id 64 loss 0.31975460052490234 train acc 0.9150390625\n",
            "epoch 16 batch id 65 loss 0.19226643443107605 train acc 0.915625\n",
            "epoch 16 batch id 66 loss 0.37841591238975525 train acc 0.9152462121212122\n",
            "epoch 16 batch id 67 loss 0.2731342315673828 train acc 0.9158115671641791\n",
            "epoch 16 batch id 68 loss 0.3289462924003601 train acc 0.9156709558823529\n",
            "epoch 16 batch id 69 loss 0.38447433710098267 train acc 0.9157608695652174\n",
            "epoch 16 batch id 70 loss 0.3047696352005005 train acc 0.9158482142857143\n",
            "epoch 16 batch id 71 loss 0.22694538533687592 train acc 0.9154929577464789\n",
            "epoch 16 batch id 72 loss 0.18986472487449646 train acc 0.9157986111111112\n",
            "epoch 16 batch id 73 loss 0.1956314891576767 train acc 0.9165239726027398\n",
            "epoch 16 batch id 74 loss 0.237085223197937 train acc 0.917018581081081\n",
            "epoch 16 batch id 75 loss 0.2128392904996872 train acc 0.916875\n",
            "epoch 16 batch id 76 loss 0.1580187976360321 train acc 0.9175575657894737\n",
            "epoch 16 batch id 77 loss 0.16694240272045135 train acc 0.9180194805194806\n",
            "epoch 16 batch id 78 loss 0.1954880952835083 train acc 0.9184695512820513\n",
            "epoch 16 batch id 79 loss 0.3073515295982361 train acc 0.9185126582278481\n",
            "epoch 16 batch id 80 loss 0.22150562703609467 train acc 0.919140625\n",
            "epoch 16 batch id 81 loss 0.22352784872055054 train acc 0.9193672839506173\n",
            "epoch 16 batch id 82 loss 0.2725234031677246 train acc 0.9193978658536586\n",
            "epoch 16 batch id 83 loss 0.31151434779167175 train acc 0.9192394578313253\n",
            "epoch 16 batch id 84 loss 0.38769081234931946 train acc 0.9192708333333334\n",
            "epoch 16 batch id 85 loss 0.21853166818618774 train acc 0.919485294117647\n",
            "epoch 16 batch id 86 loss 0.3623725473880768 train acc 0.918968023255814\n",
            "epoch 16 batch id 87 loss 0.5883231163024902 train acc 0.9182830459770115\n",
            "epoch 16 batch id 88 loss 0.29652881622314453 train acc 0.9183238636363636\n",
            "epoch 16 batch id 89 loss 0.29418110847473145 train acc 0.9180126404494382\n",
            "epoch 16 batch id 90 loss 0.18843895196914673 train acc 0.9184027777777778\n",
            "epoch 16 batch id 91 loss 0.2668549120426178 train acc 0.9186126373626373\n",
            "epoch 16 batch id 92 loss 0.28954675793647766 train acc 0.9186480978260869\n",
            "epoch 16 batch id 93 loss 0.19118532538414001 train acc 0.9188508064516129\n",
            "epoch 16 batch id 94 loss 0.17709998786449432 train acc 0.9188829787234043\n",
            "epoch 16 batch id 95 loss 0.266458123922348 train acc 0.9190789473684211\n",
            "epoch 16 batch id 96 loss 0.38478487730026245 train acc 0.9187825520833334\n",
            "epoch 16 batch id 97 loss 0.19887219369411469 train acc 0.9189755154639175\n",
            "epoch 16 batch id 98 loss 0.19615168869495392 train acc 0.9191645408163265\n",
            "epoch 16 batch id 99 loss 0.33251097798347473 train acc 0.9190340909090909\n",
            "epoch 16 batch id 100 loss 0.20514343678951263 train acc 0.919375\n",
            "epoch 16 batch id 101 loss 0.3220711052417755 train acc 0.9197091584158416\n",
            "epoch 16 batch id 102 loss 0.3439079523086548 train acc 0.9192708333333334\n",
            "epoch 16 batch id 103 loss 0.1496497541666031 train acc 0.919751213592233\n",
            "epoch 16 batch id 104 loss 0.30762261152267456 train acc 0.9197716346153846\n",
            "epoch 16 batch id 105 loss 0.25806766748428345 train acc 0.9196428571428571\n",
            "epoch 16 batch id 106 loss 0.2131580114364624 train acc 0.9196639150943396\n",
            "epoch 16 batch id 107 loss 0.4683118462562561 train acc 0.919392523364486\n",
            "epoch 16 batch id 108 loss 0.3477652668952942 train acc 0.9194155092592593\n",
            "epoch 16 batch id 109 loss 0.49755725264549255 train acc 0.9192947247706422\n",
            "epoch 16 batch id 110 loss 0.34984561800956726 train acc 0.9193181818181818\n",
            "epoch 16 batch id 111 loss 0.22912828624248505 train acc 0.9194819819819819\n",
            "epoch 16 batch id 112 loss 0.14255790412425995 train acc 0.919921875\n",
            "epoch 16 batch id 113 loss 0.18552711606025696 train acc 0.9203539823008849\n",
            "epoch 16 batch id 114 loss 0.3358801007270813 train acc 0.9199561403508771\n",
            "epoch 16 batch id 115 loss 0.1992761194705963 train acc 0.9201086956521739\n",
            "epoch 16 batch id 116 loss 0.42839515209198 train acc 0.919989224137931\n",
            "epoch 16 batch id 117 loss 0.25522834062576294 train acc 0.9200053418803419\n",
            "epoch 16 batch id 118 loss 0.2842106223106384 train acc 0.920021186440678\n",
            "epoch 16 batch id 119 loss 0.33198627829551697 train acc 0.9197741596638656\n",
            "epoch 16 batch id 120 loss 0.45455989241600037 train acc 0.91953125\n",
            "epoch 16 batch id 121 loss 0.4438682794570923 train acc 0.9194214876033058\n",
            "epoch 16 batch id 122 loss 0.21140600740909576 train acc 0.9194415983606558\n",
            "epoch 16 batch id 123 loss 0.35331687331199646 train acc 0.9192073170731707\n",
            "epoch 16 batch id 124 loss 0.143534854054451 train acc 0.9196068548387096\n",
            "epoch 16 batch id 125 loss 0.49071651697158813 train acc 0.919\n",
            "epoch 16 batch id 126 loss 0.403793066740036 train acc 0.9187748015873016\n",
            "epoch 16 batch id 127 loss 0.41282519698143005 train acc 0.9184301181102362\n",
            "epoch 16 batch id 128 loss 0.12282443046569824 train acc 0.918701171875\n",
            "epoch 16 batch id 129 loss 0.15511876344680786 train acc 0.918968023255814\n",
            "epoch 16 batch id 130 loss 0.19719374179840088 train acc 0.919110576923077\n",
            "epoch 16 batch id 131 loss 0.18752248585224152 train acc 0.9193702290076335\n",
            "epoch 16 batch id 132 loss 0.1809760183095932 train acc 0.9195075757575758\n",
            "epoch 16 batch id 133 loss 0.353467732667923 train acc 0.9197603383458647\n",
            "epoch 16 batch id 134 loss 0.26580870151519775 train acc 0.9195429104477612\n",
            "epoch 16 batch id 135 loss 0.41535136103630066 train acc 0.9194444444444444\n",
            "epoch 16 batch id 136 loss 0.19942359626293182 train acc 0.9196920955882353\n",
            "epoch 16 batch id 137 loss 0.23643085360527039 train acc 0.9197080291970803\n",
            "epoch 16 batch id 138 loss 0.23447296023368835 train acc 0.9199501811594203\n",
            "epoch 16 batch id 139 loss 0.33740392327308655 train acc 0.9199640287769785\n",
            "epoch 16 batch id 140 loss 0.3242821991443634 train acc 0.9196428571428571\n",
            "epoch 16 batch id 141 loss 0.4973917603492737 train acc 0.9193262411347518\n",
            "epoch 16 batch id 142 loss 0.0990242063999176 train acc 0.9197843309859155\n",
            "epoch 16 batch id 143 loss 0.49250075221061707 train acc 0.9196896853146853\n",
            "epoch 16 batch id 144 loss 0.32043182849884033 train acc 0.9193793402777778\n",
            "epoch 16 batch id 145 loss 0.19174374639987946 train acc 0.9193965517241379\n",
            "epoch 16 batch id 146 loss 0.3284054100513458 train acc 0.9190924657534246\n",
            "epoch 16 batch id 147 loss 0.24043448269367218 train acc 0.9193239795918368\n",
            "epoch 16 batch id 148 loss 0.37951579689979553 train acc 0.9191300675675675\n",
            "epoch 16 batch id 149 loss 0.14974966645240784 train acc 0.9194630872483222\n",
            "epoch 16 batch id 150 loss 0.29489266872406006 train acc 0.9196875\n",
            "epoch 16 batch id 151 loss 0.7518633604049683 train acc 0.9190811258278145\n",
            "epoch 16 batch id 152 loss 0.43373382091522217 train acc 0.9188939144736842\n",
            "epoch 16 batch id 153 loss 0.3601706326007843 train acc 0.9189133986928104\n",
            "epoch 16 batch id 154 loss 0.35725539922714233 train acc 0.9188311688311688\n",
            "epoch 16 batch id 155 loss 0.3679725229740143 train acc 0.91875\n",
            "epoch 16 batch id 156 loss 0.20924939215183258 train acc 0.9188701923076923\n",
            "epoch 16 batch id 157 loss 0.3515769839286804 train acc 0.9188893312101911\n",
            "epoch 16 batch id 158 loss 0.41137048602104187 train acc 0.9185126582278481\n",
            "epoch 16 batch id 159 loss 0.22367052733898163 train acc 0.9185338050314465\n",
            "epoch 16 batch id 160 loss 0.3551315665245056 train acc 0.918359375\n",
            "epoch 16 batch id 161 loss 0.3316037058830261 train acc 0.9184782608695652\n",
            "epoch 16 batch id 162 loss 0.3614170551300049 train acc 0.9183063271604939\n",
            "epoch 16 batch id 163 loss 0.28859224915504456 train acc 0.9180406441717791\n",
            "epoch 16 batch id 164 loss 0.16153889894485474 train acc 0.9183498475609756\n",
            "epoch 16 batch id 165 loss 0.21151569485664368 train acc 0.9184659090909091\n",
            "epoch 16 batch id 166 loss 0.14343002438545227 train acc 0.9187688253012049\n",
            "epoch 16 batch id 167 loss 0.34563496708869934 train acc 0.9182260479041916\n",
            "epoch 16 batch id 168 loss 0.15988308191299438 train acc 0.9183407738095238\n",
            "epoch 16 batch id 169 loss 0.2611048221588135 train acc 0.9183616863905325\n",
            "epoch 16 batch id 170 loss 0.390997976064682 train acc 0.9182904411764706\n",
            "epoch 16 batch id 171 loss 0.2742743194103241 train acc 0.9184941520467836\n",
            "epoch 16 batch id 172 loss 0.1770157665014267 train acc 0.9186954941860465\n",
            "epoch 16 batch id 173 loss 0.1590571105480194 train acc 0.9188945086705202\n",
            "epoch 16 batch id 174 loss 0.39684316515922546 train acc 0.9189116379310345\n",
            "epoch 16 batch id 175 loss 0.18802057206630707 train acc 0.9191964285714286\n",
            "epoch 16 batch id 176 loss 0.21076852083206177 train acc 0.9193892045454546\n",
            "epoch 16 batch id 177 loss 0.1387745589017868 train acc 0.9196680790960452\n",
            "epoch 16 batch id 178 loss 0.2753238379955292 train acc 0.9196804775280899\n",
            "epoch 16 batch id 179 loss 0.40128064155578613 train acc 0.9193435754189944\n",
            "epoch 16 batch id 180 loss 0.2819831371307373 train acc 0.9194444444444444\n",
            "epoch 16 batch id 181 loss 0.3362239897251129 train acc 0.9192852209944752\n",
            "epoch 16 batch id 182 loss 0.3201495110988617 train acc 0.9192135989010989\n",
            "epoch 16 batch id 183 loss 0.34310516715049744 train acc 0.9191427595628415\n",
            "epoch 16 batch id 184 loss 0.2630362808704376 train acc 0.9192425271739131\n",
            "epoch 16 batch id 185 loss 0.680957555770874 train acc 0.918918918918919\n",
            "epoch 16 batch id 186 loss 0.302726149559021 train acc 0.9188508064516129\n",
            "epoch 16 batch id 187 loss 0.10194098204374313 train acc 0.9192012032085561\n",
            "epoch 16 batch id 188 loss 0.2656252384185791 train acc 0.9191323138297872\n",
            "epoch 16 batch id 189 loss 0.5207950472831726 train acc 0.9188161375661376\n",
            "epoch 16 batch id 190 loss 0.20066224038600922 train acc 0.9189967105263158\n",
            "epoch 16 batch id 191 loss 0.18123874068260193 train acc 0.9192571989528796\n",
            "epoch 16 batch id 192 loss 0.3842027187347412 train acc 0.9192708333333334\n",
            "epoch 16 batch id 193 loss 0.33164456486701965 train acc 0.9192033678756477\n",
            "epoch 16 batch id 194 loss 0.3928487300872803 train acc 0.9188949742268041\n",
            "epoch 16 batch id 195 loss 0.3618265986442566 train acc 0.9186698717948718\n",
            "epoch 16 batch id 196 loss 0.39982715249061584 train acc 0.9186065051020408\n",
            "epoch 16 batch id 197 loss 0.24638062715530396 train acc 0.9187024111675127\n",
            "epoch 16 batch id 198 loss 0.18232928216457367 train acc 0.9189551767676768\n",
            "epoch 16 batch id 199 loss 0.39958274364471436 train acc 0.918734296482412\n",
            "epoch 16 batch id 200 loss 0.2877005636692047 train acc 0.91859375\n",
            "epoch 16 batch id 201 loss 0.28657034039497375 train acc 0.9186100746268657\n",
            "epoch 16 batch id 202 loss 0.21177130937576294 train acc 0.9187035891089109\n",
            "epoch 16 batch id 203 loss 0.23566144704818726 train acc 0.9186422413793104\n",
            "epoch 16 batch id 204 loss 0.13027876615524292 train acc 0.9188878676470589\n",
            "epoch 16 batch id 205 loss 0.32982710003852844 train acc 0.9188262195121951\n",
            "epoch 16 batch id 206 loss 0.21181902289390564 train acc 0.9189168689320388\n",
            "epoch 16 batch id 207 loss 0.09790908545255661 train acc 0.9192330917874396\n",
            "epoch 16 batch id 208 loss 0.6080843210220337 train acc 0.9186448317307693\n",
            "epoch 16 batch id 209 loss 0.1501237154006958 train acc 0.9188098086124402\n",
            "epoch 16 batch id 210 loss 0.25799575448036194 train acc 0.91875\n",
            "epoch 16 batch id 211 loss 0.2773694396018982 train acc 0.9187648104265402\n",
            "epoch 16 batch id 212 loss 0.23627705872058868 train acc 0.9188531839622641\n",
            "epoch 16 batch id 213 loss 0.2711295783519745 train acc 0.918794014084507\n",
            "epoch 16 batch id 214 loss 0.2211274355649948 train acc 0.9188814252336449\n",
            "epoch 16 batch id 215 loss 0.21272435784339905 train acc 0.9188226744186047\n",
            "epoch 16 batch id 216 loss 0.22129759192466736 train acc 0.9190538194444444\n",
            "epoch 16 batch id 217 loss 0.15060095489025116 train acc 0.9193548387096774\n",
            "epoch 16 batch id 218 loss 0.23176270723342896 train acc 0.9194380733944955\n",
            "epoch 16 batch id 219 loss 0.17177928984165192 train acc 0.9195205479452054\n",
            "epoch 16 batch id 220 loss 0.3726017475128174 train acc 0.9193892045454546\n",
            "epoch 16 batch id 221 loss 0.2942834198474884 train acc 0.9194711538461539\n",
            "epoch 16 batch id 222 loss 0.20639543235301971 train acc 0.9196227477477478\n",
            "epoch 16 batch id 223 loss 0.3095775544643402 train acc 0.9196328475336323\n",
            "epoch 16 batch id 224 loss 0.2753851115703583 train acc 0.9196428571428571\n",
            "epoch 16 batch id 225 loss 0.417481929063797 train acc 0.9194444444444444\n",
            "epoch 16 batch id 226 loss 0.41512531042099 train acc 0.9191786504424779\n",
            "epoch 16 batch id 227 loss 0.24240760505199432 train acc 0.9191905286343612\n",
            "epoch 16 batch id 228 loss 0.17503277957439423 train acc 0.9194078947368421\n",
            "epoch 16 batch id 229 loss 0.16729003190994263 train acc 0.9196233624454149\n",
            "epoch 16 batch id 230 loss 0.22236284613609314 train acc 0.9195652173913044\n",
            "epoch 16 batch id 231 loss 0.5552311539649963 train acc 0.9193722943722944\n",
            "epoch 16 batch id 232 loss 0.5173506736755371 train acc 0.9187769396551724\n",
            "epoch 16 batch id 233 loss 0.13455061614513397 train acc 0.918857296137339\n",
            "epoch 16 batch id 234 loss 0.2944220304489136 train acc 0.9188701923076923\n",
            "epoch 16 batch id 235 loss 0.3143782913684845 train acc 0.9189494680851064\n",
            "epoch 16 batch id 236 loss 0.1131042018532753 train acc 0.919094279661017\n",
            "epoch 16 batch id 237 loss 0.24525967240333557 train acc 0.9192378691983122\n",
            "epoch 16 batch id 238 loss 0.5638271570205688 train acc 0.9189863445378151\n",
            "epoch 16 batch id 239 loss 0.34681496024131775 train acc 0.9189330543933054\n",
            "epoch 16 batch id 240 loss 0.18469129502773285 train acc 0.9190104166666667\n",
            "epoch 16 batch id 241 loss 0.2198399007320404 train acc 0.9190871369294605\n",
            "epoch 16 batch id 242 loss 0.2647814154624939 train acc 0.9190986570247934\n",
            "epoch 16 batch id 243 loss 0.25708073377609253 train acc 0.9190457818930041\n",
            "epoch 16 batch id 244 loss 0.2877391278743744 train acc 0.9190573770491803\n",
            "epoch 16 batch id 245 loss 0.19072915613651276 train acc 0.9192602040816327\n",
            "epoch 16 batch id 246 loss 0.21516847610473633 train acc 0.9193978658536586\n",
            "epoch 16 batch id 247 loss 0.46660444140434265 train acc 0.9194078947368421\n",
            "epoch 16 batch id 248 loss 0.23359844088554382 train acc 0.9194178427419355\n",
            "epoch 16 batch id 249 loss 0.446649968624115 train acc 0.9191767068273092\n",
            "epoch 16 batch id 250 loss 0.31424590945243835 train acc 0.9191875\n",
            "epoch 16 batch id 251 loss 0.281305730342865 train acc 0.9192604581673307\n",
            "epoch 16 batch id 252 loss 0.4071718156337738 train acc 0.9190848214285714\n",
            "epoch 16 batch id 253 loss 0.25917258858680725 train acc 0.9192193675889329\n",
            "epoch 16 batch id 254 loss 0.3762134909629822 train acc 0.9191067913385826\n",
            "epoch 16 batch id 255 loss 0.43515416979789734 train acc 0.91875\n",
            "epoch 16 batch id 256 loss 0.377008855342865 train acc 0.91864013671875\n",
            "epoch 16 batch id 257 loss 0.1723008006811142 train acc 0.9188959143968871\n",
            "epoch 16 batch id 258 loss 0.6083762049674988 train acc 0.9186046511627907\n",
            "epoch 16 batch id 259 loss 0.2082221806049347 train acc 0.9186776061776062\n",
            "epoch 16 batch id 260 loss 0.31900495290756226 train acc 0.91875\n",
            "epoch 16 batch id 261 loss 0.44547557830810547 train acc 0.9185823754789272\n",
            "epoch 16 batch id 262 loss 0.3118065595626831 train acc 0.9186545801526718\n",
            "epoch 16 batch id 263 loss 0.55144202709198 train acc 0.9183697718631179\n",
            "epoch 16 batch id 264 loss 0.3238837718963623 train acc 0.9182054924242424\n",
            "epoch 16 batch id 265 loss 0.2501467764377594 train acc 0.9181603773584905\n",
            "epoch 16 batch id 266 loss 0.18992269039154053 train acc 0.9183505639097744\n",
            "epoch 16 batch id 267 loss 0.13698525726795197 train acc 0.9185393258426966\n",
            "epoch 16 batch id 268 loss 0.21017785370349884 train acc 0.9186683768656716\n",
            "epoch 16 batch id 269 loss 0.16422834992408752 train acc 0.9189126394052045\n",
            "epoch 16 batch id 270 loss 0.27358922362327576 train acc 0.9188657407407408\n",
            "epoch 16 batch id 271 loss 0.19785262644290924 train acc 0.9189921586715867\n",
            "epoch 16 batch id 272 loss 0.13503941893577576 train acc 0.9191176470588235\n",
            "epoch 16 batch id 273 loss 0.1249392107129097 train acc 0.919356684981685\n",
            "epoch 16 batch id 274 loss 0.38162359595298767 train acc 0.9192518248175182\n",
            "epoch 16 batch id 275 loss 0.22912289202213287 train acc 0.9192613636363637\n",
            "epoch 16 batch id 276 loss 0.3347476124763489 train acc 0.9192708333333334\n",
            "epoch 16 batch id 277 loss 0.41332074999809265 train acc 0.9192238267148014\n",
            "epoch 16 batch id 278 loss 0.2792198359966278 train acc 0.9192895683453237\n",
            "epoch 16 batch id 279 loss 0.18676237761974335 train acc 0.9193548387096774\n",
            "epoch 16 batch id 280 loss 0.43910425901412964 train acc 0.9190848214285714\n",
            "epoch 16 batch id 281 loss 0.23916566371917725 train acc 0.9190391459074733\n",
            "epoch 16 batch id 282 loss 0.28692278265953064 train acc 0.9189383865248227\n",
            "epoch 16 batch id 283 loss 0.19037356972694397 train acc 0.9189487632508834\n",
            "epoch 16 batch id 284 loss 0.1542997807264328 train acc 0.919069102112676\n",
            "epoch 16 batch id 285 loss 0.3066600263118744 train acc 0.9190241228070175\n",
            "epoch 16 batch id 286 loss 0.2522509694099426 train acc 0.9190340909090909\n",
            "epoch 16 batch id 287 loss 0.240115687251091 train acc 0.9190439895470384\n",
            "epoch 16 batch id 288 loss 0.21239586174488068 train acc 0.9191623263888888\n",
            "epoch 16 batch id 289 loss 0.3122079372406006 train acc 0.9191176470588235\n",
            "epoch 16 batch id 290 loss 0.17138102650642395 train acc 0.9192349137931034\n",
            "epoch 16 batch id 291 loss 0.282157838344574 train acc 0.9191365979381443\n",
            "epoch 16 batch id 292 loss 0.40811482071876526 train acc 0.9191994863013698\n",
            "epoch 16 batch id 293 loss 0.1176484227180481 train acc 0.9193686006825939\n",
            "epoch 16 batch id 294 loss 0.13688980042934418 train acc 0.9194302721088435\n",
            "epoch 16 batch id 295 loss 0.2325388491153717 train acc 0.9194385593220339\n",
            "epoch 16 batch id 296 loss 0.09279388934373856 train acc 0.9196579391891891\n",
            "epoch 16 batch id 297 loss 0.20598378777503967 train acc 0.919770622895623\n",
            "epoch 16 batch id 298 loss 0.4338233172893524 train acc 0.9196728187919463\n",
            "epoch 16 batch id 299 loss 0.11495927721261978 train acc 0.9198892140468228\n",
            "epoch 16 batch id 300 loss 0.2626013457775116 train acc 0.92\n",
            "epoch 16 batch id 301 loss 0.1317044198513031 train acc 0.9201619601328903\n",
            "epoch 16 batch id 302 loss 0.26352953910827637 train acc 0.9202193708609272\n",
            "epoch 16 batch id 303 loss 0.2295021265745163 train acc 0.920276402640264\n",
            "epoch 16 batch id 304 loss 0.4085828363895416 train acc 0.9201274671052632\n",
            "epoch 16 batch id 305 loss 0.30118027329444885 train acc 0.9201844262295082\n",
            "epoch 16 batch id 306 loss 0.39124611020088196 train acc 0.9201388888888888\n",
            "epoch 16 batch id 307 loss 0.3299815356731415 train acc 0.9200936482084691\n",
            "epoch 16 batch id 308 loss 0.2236662358045578 train acc 0.9200994318181818\n",
            "epoch 16 batch id 309 loss 0.16100509464740753 train acc 0.9201557443365695\n",
            "epoch 16 batch id 310 loss 0.3624440133571625 train acc 0.9201108870967742\n",
            "epoch 16 batch id 311 loss 0.17129288613796234 train acc 0.9202170418006431\n",
            "epoch 16 batch id 312 loss 0.5569393634796143 train acc 0.9201722756410257\n",
            "epoch 16 batch id 313 loss 0.12240904569625854 train acc 0.9203274760383386\n",
            "epoch 16 batch id 314 loss 0.14191323518753052 train acc 0.920531449044586\n",
            "epoch 16 batch id 315 loss 0.23268024623394012 train acc 0.9205853174603175\n",
            "epoch 16 batch id 316 loss 0.22396250069141388 train acc 0.9207377373417721\n",
            "epoch 16 batch id 317 loss 0.15154531598091125 train acc 0.920839905362776\n",
            "epoch 16 batch id 318 loss 0.13828346133232117 train acc 0.9208922955974843\n",
            "epoch 16 batch id 319 loss 0.3957020342350006 train acc 0.920846394984326\n",
            "epoch 16 batch id 320 loss 0.45896008610725403 train acc 0.920703125\n",
            "epoch 16 batch id 321 loss 0.3060172498226166 train acc 0.9205607476635514\n",
            "epoch 16 batch id 322 loss 0.2739502489566803 train acc 0.9205648291925466\n",
            "epoch 16 batch id 323 loss 0.14567922055721283 train acc 0.9207623839009288\n",
            "epoch 16 batch id 324 loss 0.20335125923156738 train acc 0.9207658179012346\n",
            "epoch 16 batch id 325 loss 0.11554767191410065 train acc 0.9209615384615385\n",
            "epoch 16 batch id 326 loss 0.20925454795360565 train acc 0.9210122699386503\n",
            "epoch 16 batch id 327 loss 0.12323404103517532 train acc 0.9211582568807339\n",
            "epoch 16 batch id 328 loss 0.2773077189922333 train acc 0.9211604420731707\n",
            "epoch 16 batch id 329 loss 0.28127557039260864 train acc 0.9211626139817629\n",
            "epoch 16 batch id 330 loss 0.34506094455718994 train acc 0.9211174242424243\n",
            "epoch 16 batch id 331 loss 0.2647872567176819 train acc 0.9209780966767371\n",
            "epoch 16 batch id 332 loss 0.2176094949245453 train acc 0.9210278614457831\n",
            "epoch 16 batch id 333 loss 0.17390671372413635 train acc 0.9211711711711712\n",
            "epoch 16 batch id 334 loss 0.14541856944561005 train acc 0.9212668413173652\n",
            "epoch 16 batch id 335 loss 0.18706358969211578 train acc 0.9213619402985075\n",
            "epoch 16 batch id 336 loss 0.20478057861328125 train acc 0.9214564732142857\n",
            "epoch 16 batch id 337 loss 0.2466430813074112 train acc 0.921411350148368\n",
            "epoch 16 batch id 338 loss 0.15115398168563843 train acc 0.9215514053254438\n",
            "epoch 16 batch id 339 loss 0.26182305812835693 train acc 0.9215984513274337\n",
            "epoch 16 batch id 340 loss 0.3403804898262024 train acc 0.9215073529411765\n",
            "epoch 16 batch id 341 loss 0.45589759945869446 train acc 0.9212793255131965\n",
            "epoch 16 batch id 342 loss 0.23942026495933533 train acc 0.921281067251462\n",
            "epoch 16 batch id 343 loss 0.23641027510166168 train acc 0.9213283527696793\n",
            "epoch 16 batch id 344 loss 0.29851916432380676 train acc 0.9214207848837209\n",
            "epoch 16 batch id 345 loss 0.16921769082546234 train acc 0.9215126811594203\n",
            "epoch 16 batch id 346 loss 0.3560359477996826 train acc 0.9213782514450867\n",
            "epoch 16 batch id 347 loss 0.12302711606025696 train acc 0.9214697406340058\n",
            "epoch 16 batch id 348 loss 0.24535387754440308 train acc 0.9214709051724138\n",
            "epoch 16 batch id 349 loss 0.12758322060108185 train acc 0.9215616045845272\n",
            "epoch 16 batch id 350 loss 0.19917720556259155 train acc 0.9216517857142857\n",
            "epoch 16 batch id 351 loss 0.38807716965675354 train acc 0.9215633903133903\n",
            "epoch 16 batch id 352 loss 0.22746218740940094 train acc 0.9216530539772727\n",
            "epoch 16 batch id 353 loss 0.12366941571235657 train acc 0.9217864730878187\n",
            "epoch 16 batch id 354 loss 0.2122417837381363 train acc 0.921919138418079\n",
            "epoch 16 batch id 355 loss 0.3060426414012909 train acc 0.921830985915493\n",
            "epoch 16 batch id 356 loss 0.11155964434146881 train acc 0.9219627808988764\n",
            "epoch 16 batch id 357 loss 0.1076773852109909 train acc 0.9220938375350141\n",
            "epoch 16 batch id 358 loss 0.22295448184013367 train acc 0.9221805167597765\n",
            "epoch 16 batch id 359 loss 0.3679634928703308 train acc 0.9221361420612814\n",
            "epoch 16 batch id 360 loss 0.11317213624715805 train acc 0.922265625\n",
            "epoch 16 batch id 361 loss 0.48240581154823303 train acc 0.9220914127423823\n",
            "epoch 16 batch id 362 loss 0.22912108898162842 train acc 0.9221339779005525\n",
            "epoch 16 batch id 363 loss 0.357812762260437 train acc 0.9220902203856749\n",
            "epoch 16 batch id 364 loss 0.24791045486927032 train acc 0.9221754807692307\n",
            "epoch 16 batch id 365 loss 0.25797566771507263 train acc 0.9221746575342465\n",
            "epoch 16 batch id 366 loss 0.46324312686920166 train acc 0.922088456284153\n",
            "epoch 16 batch id 367 loss 0.16528581082820892 train acc 0.9222155994550408\n",
            "epoch 16 batch id 368 loss 0.31265074014663696 train acc 0.922257133152174\n",
            "epoch 16 batch id 369 loss 0.22959434986114502 train acc 0.9222560975609756\n",
            "epoch 16 batch id 370 loss 0.07566127926111221 train acc 0.9224239864864865\n",
            "epoch 16 batch id 371 loss 0.24958659708499908 train acc 0.9225488544474394\n",
            "epoch 16 batch id 372 loss 0.41547468304634094 train acc 0.9223790322580645\n",
            "epoch 16 batch id 373 loss 0.13894696533679962 train acc 0.9224614611260054\n",
            "epoch 16 batch id 374 loss 0.3374927341938019 train acc 0.9223763368983957\n",
            "epoch 16 batch id 375 loss 0.25337421894073486 train acc 0.9224166666666667\n",
            "epoch 16 batch id 376 loss 0.2906933128833771 train acc 0.9224983377659575\n",
            "epoch 16 batch id 377 loss 0.12930333614349365 train acc 0.9226624668435013\n",
            "epoch 16 batch id 378 loss 0.20333059132099152 train acc 0.9227017195767195\n",
            "epoch 16 batch id 379 loss 0.45801153779029846 train acc 0.9225346306068601\n",
            "epoch 16 batch id 380 loss 0.3836047947406769 train acc 0.9226151315789474\n",
            "epoch 16 batch id 381 loss 0.1968526393175125 train acc 0.9226541994750657\n",
            "epoch 16 batch id 382 loss 0.162120059132576 train acc 0.9226930628272252\n",
            "epoch 16 batch id 383 loss 0.1907917857170105 train acc 0.9226909268929504\n",
            "epoch 16 batch id 384 loss 0.2980865240097046 train acc 0.9226888020833334\n",
            "epoch 16 batch id 385 loss 0.18016108870506287 train acc 0.9227272727272727\n",
            "epoch 16 batch id 386 loss 0.11295893043279648 train acc 0.9228060233160622\n",
            "epoch 16 batch id 387 loss 0.6285654902458191 train acc 0.9225209948320413\n",
            "epoch 16 batch id 388 loss 0.2645637094974518 train acc 0.9225596005154639\n",
            "epoch 16 batch id 389 loss 0.1744202971458435 train acc 0.9226381748071979\n",
            "epoch 16 batch id 390 loss 0.22518290579319 train acc 0.922676282051282\n",
            "epoch 16 batch id 391 loss 0.1584281027317047 train acc 0.9227941176470589\n",
            "epoch 16 batch id 392 loss 0.34395045042037964 train acc 0.9227917729591837\n",
            "epoch 16 batch id 393 loss 0.3334454596042633 train acc 0.9228689567430025\n",
            "epoch 16 batch id 394 loss 0.2641061842441559 train acc 0.9228267766497462\n",
            "epoch 16 batch id 395 loss 0.2529791593551636 train acc 0.9227848101265823\n",
            "epoch 16 batch id 396 loss 0.1694299578666687 train acc 0.9228614267676768\n",
            "epoch 16 batch id 397 loss 0.24944457411766052 train acc 0.9228982997481109\n",
            "epoch 16 batch id 398 loss 0.13464045524597168 train acc 0.9229742462311558\n",
            "epoch 16 batch id 399 loss 0.31109920144081116 train acc 0.9228931704260651\n",
            "epoch 16 batch id 400 loss 0.2202833741903305 train acc 0.9229296875\n",
            "epoch 16 batch id 401 loss 0.21284645795822144 train acc 0.9230439526184538\n",
            "epoch 16 batch id 402 loss 0.15043337643146515 train acc 0.9230799129353234\n",
            "epoch 16 batch id 403 loss 0.2415834665298462 train acc 0.9231156947890818\n",
            "epoch 16 batch id 404 loss 0.16039685904979706 train acc 0.9231899752475248\n",
            "epoch 16 batch id 405 loss 0.3059617578983307 train acc 0.9231095679012346\n",
            "epoch 16 batch id 406 loss 0.12385237216949463 train acc 0.9232219827586207\n",
            "epoch 16 batch id 407 loss 0.4266591966152191 train acc 0.9231035012285013\n",
            "epoch 16 batch id 408 loss 0.2511468529701233 train acc 0.923062193627451\n",
            "epoch 16 batch id 409 loss 0.19837236404418945 train acc 0.9230974938875306\n",
            "epoch 16 batch id 410 loss 0.16448837518692017 train acc 0.9231707317073171\n",
            "epoch 16 batch id 411 loss 0.3125026226043701 train acc 0.923205596107056\n",
            "epoch 16 batch id 412 loss 0.13457663357257843 train acc 0.9233540655339806\n",
            "epoch 16 batch id 413 loss 0.2955041825771332 train acc 0.9233504842615012\n",
            "epoch 16 batch id 414 loss 0.5253697633743286 train acc 0.9233091787439613\n",
            "epoch 16 batch id 415 loss 0.17140540480613708 train acc 0.9233810240963856\n",
            "epoch 16 batch id 416 loss 0.3732812702655792 train acc 0.9233022836538461\n",
            "epoch 16 batch id 417 loss 0.23576152324676514 train acc 0.9233363309352518\n",
            "epoch 16 batch id 418 loss 0.3560905456542969 train acc 0.9232954545454546\n",
            "epoch 16 batch id 419 loss 0.1885356605052948 train acc 0.9234412291169452\n",
            "epoch 16 batch id 420 loss 0.1097448468208313 train acc 0.9235863095238095\n",
            "epoch 16 batch id 421 loss 0.3824908435344696 train acc 0.9234709026128266\n",
            "epoch 16 batch id 422 loss 0.2767929434776306 train acc 0.923541172985782\n",
            "epoch 16 batch id 423 loss 0.19980058073997498 train acc 0.9235002955082743\n",
            "epoch 16 batch id 424 loss 0.3117956519126892 train acc 0.9235701650943396\n",
            "epoch 16 batch id 425 loss 0.17296569049358368 train acc 0.9236397058823529\n",
            "epoch 16 batch id 426 loss 0.16139240562915802 train acc 0.9236722417840375\n",
            "epoch 16 batch id 427 loss 0.4450981616973877 train acc 0.9235582552693209\n",
            "epoch 16 batch id 428 loss 0.1575428694486618 train acc 0.9236273364485982\n",
            "epoch 16 batch id 429 loss 0.2724258005619049 train acc 0.9235504079254079\n",
            "epoch 16 batch id 430 loss 0.23974624276161194 train acc 0.9235828488372093\n",
            "epoch 16 batch id 431 loss 0.37049543857574463 train acc 0.9235426334106729\n",
            "epoch 16 batch id 432 loss 0.09846008569002151 train acc 0.9236834490740741\n",
            "epoch 16 batch id 433 loss 0.17382140457630157 train acc 0.9237875288683602\n",
            "epoch 16 batch id 434 loss 0.3222714960575104 train acc 0.9238191244239631\n",
            "epoch 16 batch id 435 loss 0.33492693305015564 train acc 0.9237428160919541\n",
            "epoch 16 batch id 436 loss 0.15226434171199799 train acc 0.923774369266055\n",
            "epoch 16 batch id 437 loss 0.3430757522583008 train acc 0.9238057780320366\n",
            "epoch 16 batch id 438 loss 0.16264870762825012 train acc 0.9238727168949772\n",
            "epoch 16 batch id 439 loss 0.300178587436676 train acc 0.9239037585421412\n",
            "epoch 16 batch id 440 loss 0.36482492089271545 train acc 0.923828125\n",
            "epoch 16 batch id 441 loss 0.28768181800842285 train acc 0.9238945578231292\n",
            "epoch 16 batch id 442 loss 0.24163034558296204 train acc 0.9239253393665159\n",
            "epoch 16 batch id 443 loss 0.22719784080982208 train acc 0.9239559819413092\n",
            "epoch 16 batch id 444 loss 0.1991947591304779 train acc 0.9239864864864865\n",
            "epoch 16 batch id 445 loss 0.3012486696243286 train acc 0.9239466292134831\n",
            "epoch 16 batch id 446 loss 0.2108382284641266 train acc 0.9240120515695067\n",
            "epoch 16 batch id 447 loss 0.14168770611286163 train acc 0.9241470917225951\n",
            "epoch 16 batch id 448 loss 0.3515666425228119 train acc 0.924072265625\n",
            "epoch 16 batch id 449 loss 0.2938213348388672 train acc 0.9241369710467706\n",
            "epoch 16 batch id 450 loss 0.2256544977426529 train acc 0.9241319444444445\n",
            "epoch 16 batch id 451 loss 0.19721010327339172 train acc 0.9241269401330376\n",
            "epoch 16 batch id 452 loss 0.17897367477416992 train acc 0.9241565265486725\n",
            "epoch 16 batch id 453 loss 0.2235795110464096 train acc 0.9242204746136865\n",
            "epoch 16 batch id 454 loss 0.20029832422733307 train acc 0.9241808920704846\n",
            "epoch 16 batch id 455 loss 0.4968360662460327 train acc 0.9241414835164835\n",
            "epoch 16 batch id 456 loss 0.3114203214645386 train acc 0.9242050438596491\n",
            "epoch 16 batch id 457 loss 0.37730705738067627 train acc 0.9241657549234136\n",
            "epoch 16 batch id 458 loss 0.22599689662456512 train acc 0.9241607532751092\n",
            "epoch 16 batch id 459 loss 0.1672532856464386 train acc 0.9241898148148148\n",
            "epoch 16 batch id 460 loss 0.2213601917028427 train acc 0.9242527173913043\n",
            "epoch 16 batch id 461 loss 0.35421568155288696 train acc 0.9242136659436009\n",
            "epoch 16 batch id 462 loss 0.14164882898330688 train acc 0.924310064935065\n",
            "epoch 16 batch id 463 loss 0.3659941852092743 train acc 0.9243723002159827\n",
            "epoch 16 batch id 464 loss 0.20046579837799072 train acc 0.9243669181034483\n",
            "epoch 16 batch id 465 loss 0.17720215022563934 train acc 0.9244959677419354\n",
            "epoch 16 batch id 466 loss 0.26809221506118774 train acc 0.9244232832618026\n",
            "epoch 16 batch id 467 loss 0.3590727746486664 train acc 0.9243509100642399\n",
            "epoch 16 batch id 468 loss 0.27258825302124023 train acc 0.9243456196581197\n",
            "epoch 16 batch id 469 loss 0.30609041452407837 train acc 0.9242737206823027\n",
            "epoch 16 batch id 470 loss 0.08314327150583267 train acc 0.9244015957446808\n",
            "epoch 16 batch id 471 loss 0.26800858974456787 train acc 0.9244294055201698\n",
            "epoch 16 batch id 472 loss 0.1678917109966278 train acc 0.9244902012711864\n",
            "epoch 16 batch id 473 loss 0.2563173174858093 train acc 0.9245837737843552\n",
            "epoch 16 batch id 474 loss 0.2547680735588074 train acc 0.9246439873417721\n",
            "epoch 16 batch id 475 loss 0.11136400699615479 train acc 0.9247368421052632\n",
            "epoch 16 batch id 476 loss 0.43337389826774597 train acc 0.9246980042016807\n",
            "epoch 16 batch id 477 loss 0.30189988017082214 train acc 0.9246920859538784\n",
            "epoch 16 batch id 478 loss 0.3325536549091339 train acc 0.9246208158995816\n",
            "epoch 16 batch id 479 loss 0.21254798769950867 train acc 0.9247129436325678\n",
            "epoch 16 batch id 480 loss 0.34024596214294434 train acc 0.9245768229166667\n",
            "epoch 16 batch id 481 loss 0.4339149296283722 train acc 0.9245712058212058\n",
            "epoch 16 batch id 482 loss 0.30877870321273804 train acc 0.9245007780082988\n",
            "epoch 16 batch id 483 loss 0.31521207094192505 train acc 0.9245276915113871\n",
            "epoch 16 batch id 484 loss 0.3689177334308624 train acc 0.9244899276859504\n",
            "epoch 16 batch id 485 loss 0.19805943965911865 train acc 0.9245167525773196\n",
            "epoch 16 batch id 486 loss 0.1538556069135666 train acc 0.9245756172839507\n",
            "epoch 16 batch id 487 loss 0.2773789167404175 train acc 0.9245059034907598\n",
            "epoch 16 batch id 488 loss 0.40827131271362305 train acc 0.9244364754098361\n",
            "epoch 16 batch id 489 loss 0.3499506711959839 train acc 0.9244951431492843\n",
            "epoch 16 batch id 490 loss 0.20011484622955322 train acc 0.9245216836734694\n",
            "epoch 16 batch id 491 loss 0.1320399045944214 train acc 0.9246117617107943\n",
            "epoch 16 batch id 492 loss 0.558829665184021 train acc 0.924510924796748\n",
            "epoch 16 batch id 493 loss 0.31645339727401733 train acc 0.9244421906693712\n",
            "epoch 16 batch id 494 loss 0.2937321066856384 train acc 0.9244053643724697\n",
            "epoch 16 batch id 495 loss 0.1540893018245697 train acc 0.9244633838383839\n",
            "epoch 16 batch id 496 loss 0.29963651299476624 train acc 0.9244581653225806\n",
            "epoch 16 batch id 497 loss 0.434649258852005 train acc 0.9243586519114688\n",
            "epoch 16 batch id 498 loss 0.2049347460269928 train acc 0.9243536646586346\n",
            "epoch 16 batch id 499 loss 0.1332985758781433 train acc 0.924442635270541\n",
            "epoch 16 batch id 500 loss 0.46672528982162476 train acc 0.9243125\n",
            "epoch 16 batch id 501 loss 0.13357970118522644 train acc 0.9243700099800399\n",
            "epoch 16 batch id 502 loss 0.20379996299743652 train acc 0.9243961653386454\n",
            "epoch 16 batch id 503 loss 0.3177357614040375 train acc 0.9244843439363817\n",
            "epoch 16 batch id 504 loss 0.5452756881713867 train acc 0.9243861607142857\n",
            "epoch 16 batch id 505 loss 0.2953381836414337 train acc 0.9243193069306931\n",
            "epoch 16 batch id 506 loss 0.2143285721540451 train acc 0.9243453557312253\n",
            "epoch 16 batch id 507 loss 0.27892741560935974 train acc 0.924340483234714\n",
            "epoch 16 batch id 508 loss 0.26860034465789795 train acc 0.9243048720472441\n",
            "epoch 16 batch id 509 loss 0.24611148238182068 train acc 0.9243307956777996\n",
            "epoch 16 batch id 510 loss 0.2828006446361542 train acc 0.9243259803921569\n",
            "epoch 16 batch id 511 loss 0.2672731578350067 train acc 0.9243498198366105\n",
            "epoch 16 train acc 0.9243498198366105\n",
            "epoch 16 test acc 0.40234375\n",
            "epoch 17 batch id 1 loss 0.2594853341579437 train acc 0.9375\n",
            "epoch 17 batch id 2 loss 0.19345611333847046 train acc 0.9296875\n",
            "epoch 17 batch id 3 loss 0.20696274936199188 train acc 0.9427083333333334\n",
            "epoch 17 batch id 4 loss 0.23276561498641968 train acc 0.94140625\n",
            "epoch 17 batch id 5 loss 0.3909001350402832 train acc 0.928125\n",
            "epoch 17 batch id 6 loss 0.28352800011634827 train acc 0.9270833333333334\n",
            "epoch 17 batch id 7 loss 0.16347600519657135 train acc 0.9352678571428571\n",
            "epoch 17 batch id 8 loss 0.36543041467666626 train acc 0.9296875\n",
            "epoch 17 batch id 9 loss 0.14486515522003174 train acc 0.9305555555555556\n",
            "epoch 17 batch id 10 loss 0.1229163259267807 train acc 0.9328125\n",
            "epoch 17 batch id 11 loss 0.08235064148902893 train acc 0.9375\n",
            "epoch 17 batch id 12 loss 0.08797720074653625 train acc 0.94140625\n",
            "epoch 17 batch id 13 loss 0.20326459407806396 train acc 0.9399038461538461\n",
            "epoch 17 batch id 14 loss 0.20552875101566315 train acc 0.9408482142857143\n",
            "epoch 17 batch id 15 loss 0.20425637066364288 train acc 0.9416666666666667\n",
            "epoch 17 batch id 16 loss 0.4279448390007019 train acc 0.9404296875\n",
            "epoch 17 batch id 17 loss 0.507176399230957 train acc 0.9375\n",
            "epoch 17 batch id 18 loss 0.25099238753318787 train acc 0.9366319444444444\n",
            "epoch 17 batch id 19 loss 0.3460158109664917 train acc 0.9358552631578947\n",
            "epoch 17 batch id 20 loss 0.09916618466377258 train acc 0.93828125\n",
            "epoch 17 batch id 21 loss 0.3011811077594757 train acc 0.9367559523809523\n",
            "epoch 17 batch id 22 loss 0.49184510111808777 train acc 0.9360795454545454\n",
            "epoch 17 batch id 23 loss 0.19891001284122467 train acc 0.9354619565217391\n",
            "epoch 17 batch id 24 loss 0.46597182750701904 train acc 0.9322916666666666\n",
            "epoch 17 batch id 25 loss 0.18940287828445435 train acc 0.931875\n",
            "epoch 17 batch id 26 loss 0.2793428897857666 train acc 0.9314903846153846\n",
            "epoch 17 batch id 27 loss 0.22349894046783447 train acc 0.9317129629629629\n",
            "epoch 17 batch id 28 loss 0.14035697281360626 train acc 0.9330357142857143\n",
            "epoch 17 batch id 29 loss 0.37608128786087036 train acc 0.931573275862069\n",
            "epoch 17 batch id 30 loss 0.23679280281066895 train acc 0.93125\n",
            "epoch 17 batch id 31 loss 0.16259697079658508 train acc 0.9324596774193549\n",
            "epoch 17 batch id 32 loss 0.3870859146118164 train acc 0.93212890625\n",
            "epoch 17 batch id 33 loss 0.22671197354793549 train acc 0.9322916666666666\n",
            "epoch 17 batch id 34 loss 0.320840984582901 train acc 0.9324448529411765\n",
            "epoch 17 batch id 35 loss 0.3167057931423187 train acc 0.9308035714285714\n",
            "epoch 17 batch id 36 loss 0.2769463062286377 train acc 0.9301215277777778\n",
            "epoch 17 batch id 37 loss 0.40858370065689087 train acc 0.9294763513513513\n",
            "epoch 17 batch id 38 loss 0.2277856469154358 train acc 0.9300986842105263\n",
            "epoch 17 batch id 39 loss 0.20306207239627838 train acc 0.9310897435897436\n",
            "epoch 17 batch id 40 loss 0.1336517035961151 train acc 0.932421875\n",
            "epoch 17 batch id 41 loss 0.3792467415332794 train acc 0.9317835365853658\n",
            "epoch 17 batch id 42 loss 0.0925048366189003 train acc 0.9326636904761905\n",
            "epoch 17 batch id 43 loss 0.10439633578062057 train acc 0.9338662790697675\n",
            "epoch 17 batch id 44 loss 0.2724744379520416 train acc 0.93359375\n",
            "epoch 17 batch id 45 loss 0.3163509964942932 train acc 0.9333333333333333\n",
            "epoch 17 batch id 46 loss 0.31334713101387024 train acc 0.9341032608695652\n",
            "epoch 17 batch id 47 loss 0.1440669447183609 train acc 0.9341755319148937\n",
            "epoch 17 batch id 48 loss 0.14264024794101715 train acc 0.9348958333333334\n",
            "epoch 17 batch id 49 loss 0.11706937104463577 train acc 0.9352678571428571\n",
            "epoch 17 batch id 50 loss 0.36180707812309265 train acc 0.9346875\n",
            "epoch 17 batch id 51 loss 0.2501309812068939 train acc 0.9344362745098039\n",
            "epoch 17 batch id 52 loss 0.3143383264541626 train acc 0.9338942307692307\n",
            "epoch 17 batch id 53 loss 0.13772740960121155 train acc 0.9345518867924528\n",
            "epoch 17 batch id 54 loss 0.18635818362236023 train acc 0.9351851851851852\n",
            "epoch 17 batch id 55 loss 0.24481752514839172 train acc 0.9355113636363637\n",
            "epoch 17 batch id 56 loss 0.11327703297138214 train acc 0.9363839285714286\n",
            "epoch 17 batch id 57 loss 0.15865182876586914 train acc 0.9364035087719298\n",
            "epoch 17 batch id 58 loss 0.314840167760849 train acc 0.9361530172413793\n",
            "epoch 17 batch id 59 loss 0.23566502332687378 train acc 0.9359110169491526\n",
            "epoch 17 batch id 60 loss 0.5948861241340637 train acc 0.9341145833333333\n",
            "epoch 17 batch id 61 loss 0.2636788785457611 train acc 0.9339139344262295\n",
            "epoch 17 batch id 62 loss 0.24851377308368683 train acc 0.9337197580645161\n",
            "epoch 17 batch id 63 loss 0.23422133922576904 train acc 0.9345238095238095\n",
            "epoch 17 batch id 64 loss 0.2605269253253937 train acc 0.9345703125\n",
            "epoch 17 batch id 65 loss 0.3338220417499542 train acc 0.9338942307692307\n",
            "epoch 17 batch id 66 loss 0.31308767199516296 train acc 0.9334753787878788\n",
            "epoch 17 batch id 67 loss 0.21953047811985016 train acc 0.933768656716418\n",
            "epoch 17 batch id 68 loss 0.28724488615989685 train acc 0.9333639705882353\n",
            "epoch 17 batch id 69 loss 0.6271211504936218 train acc 0.9322916666666666\n",
            "epoch 17 batch id 70 loss 0.24860811233520508 train acc 0.9325892857142857\n",
            "epoch 17 batch id 71 loss 0.270359069108963 train acc 0.9326584507042254\n",
            "epoch 17 batch id 72 loss 0.1653093695640564 train acc 0.9327256944444444\n",
            "epoch 17 batch id 73 loss 0.38386988639831543 train acc 0.9321489726027398\n",
            "epoch 17 batch id 74 loss 0.3688628673553467 train acc 0.9320101351351351\n",
            "epoch 17 batch id 75 loss 0.25452664494514465 train acc 0.9316666666666666\n",
            "epoch 17 batch id 76 loss 0.17048314213752747 train acc 0.9321546052631579\n",
            "epoch 17 batch id 77 loss 0.2050858736038208 train acc 0.932224025974026\n",
            "epoch 17 batch id 78 loss 0.1078898012638092 train acc 0.9326923076923077\n",
            "epoch 17 batch id 79 loss 0.25966352224349976 train acc 0.932753164556962\n",
            "epoch 17 batch id 80 loss 0.10199223458766937 train acc 0.9333984375\n",
            "epoch 17 batch id 81 loss 0.2760634422302246 train acc 0.9338348765432098\n",
            "epoch 17 batch id 82 loss 0.15507754683494568 train acc 0.9340701219512195\n",
            "epoch 17 batch id 83 loss 0.47959432005882263 train acc 0.9335466867469879\n",
            "epoch 17 batch id 84 loss 0.2671812176704407 train acc 0.93359375\n",
            "epoch 17 batch id 85 loss 0.22785061597824097 train acc 0.9336397058823529\n",
            "epoch 17 batch id 86 loss 0.18010255694389343 train acc 0.9338662790697675\n",
            "epoch 17 batch id 87 loss 0.0979502946138382 train acc 0.9342672413793104\n",
            "epoch 17 batch id 88 loss 0.26262202858924866 train acc 0.9341264204545454\n",
            "epoch 17 batch id 89 loss 0.10130495578050613 train acc 0.9345154494382022\n",
            "epoch 17 batch id 90 loss 0.35004979372024536 train acc 0.9342013888888889\n",
            "epoch 17 batch id 91 loss 0.26228615641593933 train acc 0.9340659340659341\n",
            "epoch 17 batch id 92 loss 0.4209843575954437 train acc 0.93359375\n",
            "epoch 17 batch id 93 loss 0.22668208181858063 train acc 0.933635752688172\n",
            "epoch 17 batch id 94 loss 0.4223286807537079 train acc 0.933344414893617\n",
            "epoch 17 batch id 95 loss 0.1934727281332016 train acc 0.9335526315789474\n",
            "epoch 17 batch id 96 loss 0.4681224822998047 train acc 0.9329427083333334\n",
            "epoch 17 batch id 97 loss 0.17926760017871857 train acc 0.9331507731958762\n",
            "epoch 17 batch id 98 loss 0.29212358593940735 train acc 0.9330357142857143\n",
            "epoch 17 batch id 99 loss 0.1264946013689041 train acc 0.9332386363636364\n",
            "epoch 17 batch id 100 loss 0.2250603437423706 train acc 0.933125\n",
            "epoch 17 batch id 101 loss 0.12104944884777069 train acc 0.9336324257425742\n",
            "epoch 17 batch id 102 loss 0.14697496592998505 train acc 0.9339767156862745\n",
            "epoch 17 batch id 103 loss 0.15137162804603577 train acc 0.9341626213592233\n",
            "epoch 17 batch id 104 loss 0.24230889976024628 train acc 0.9341947115384616\n",
            "epoch 17 batch id 105 loss 0.37474945187568665 train acc 0.9342261904761905\n",
            "epoch 17 batch id 106 loss 0.21346250176429749 train acc 0.9341096698113207\n",
            "epoch 17 batch id 107 loss 0.33613941073417664 train acc 0.9335572429906542\n",
            "epoch 17 batch id 108 loss 0.16270315647125244 train acc 0.9337384259259259\n",
            "epoch 17 batch id 109 loss 0.415787935256958 train acc 0.9333428899082569\n",
            "epoch 17 batch id 110 loss 0.19417543709278107 train acc 0.9335227272727272\n",
            "epoch 17 batch id 111 loss 0.3514955937862396 train acc 0.9335585585585585\n",
            "epoch 17 batch id 112 loss 0.18436352908611298 train acc 0.9334542410714286\n",
            "epoch 17 batch id 113 loss 0.25867778062820435 train acc 0.9336283185840708\n",
            "epoch 17 batch id 114 loss 0.3658805787563324 train acc 0.9333881578947368\n",
            "epoch 17 batch id 115 loss 0.37235525250434875 train acc 0.9331521739130435\n",
            "epoch 17 batch id 116 loss 0.24028277397155762 train acc 0.9333243534482759\n",
            "epoch 17 batch id 117 loss 0.31258293986320496 train acc 0.9330929487179487\n",
            "epoch 17 batch id 118 loss 0.17138159275054932 train acc 0.933395127118644\n",
            "epoch 17 batch id 119 loss 0.5110664963722229 train acc 0.9329044117647058\n",
            "epoch 17 batch id 120 loss 0.19384363293647766 train acc 0.9328125\n",
            "epoch 17 batch id 121 loss 0.25262582302093506 train acc 0.9328512396694215\n",
            "epoch 17 batch id 122 loss 0.3942996561527252 train acc 0.9325051229508197\n",
            "epoch 17 batch id 123 loss 0.1222529411315918 train acc 0.9327997967479674\n",
            "epoch 17 batch id 124 loss 0.30808010697364807 train acc 0.932585685483871\n",
            "epoch 17 batch id 125 loss 0.2807808816432953 train acc 0.93225\n",
            "epoch 17 batch id 126 loss 0.239385724067688 train acc 0.9325396825396826\n",
            "epoch 17 batch id 127 loss 0.3436427414417267 train acc 0.9324557086614174\n",
            "epoch 17 batch id 128 loss 0.26157766580581665 train acc 0.9324951171875\n",
            "epoch 17 batch id 129 loss 0.1529027819633484 train acc 0.9326550387596899\n",
            "epoch 17 batch id 130 loss 0.26713886857032776 train acc 0.9325721153846154\n",
            "epoch 17 batch id 131 loss 0.15658098459243774 train acc 0.9326097328244275\n",
            "epoch 17 batch id 132 loss 0.5113016963005066 train acc 0.9320549242424242\n",
            "epoch 17 batch id 133 loss 0.3226116895675659 train acc 0.9318609022556391\n",
            "epoch 17 batch id 134 loss 0.23769067227840424 train acc 0.9321361940298507\n",
            "epoch 17 batch id 135 loss 0.2326875478029251 train acc 0.9320601851851852\n",
            "epoch 17 batch id 136 loss 0.2902023494243622 train acc 0.9319852941176471\n",
            "epoch 17 batch id 137 loss 0.33939164876937866 train acc 0.9315693430656934\n",
            "epoch 17 batch id 138 loss 0.28808358311653137 train acc 0.9314990942028986\n",
            "epoch 17 batch id 139 loss 0.3267900049686432 train acc 0.9316546762589928\n",
            "epoch 17 batch id 140 loss 0.22747552394866943 train acc 0.9315848214285715\n",
            "epoch 17 batch id 141 loss 0.3174029588699341 train acc 0.9315159574468085\n",
            "epoch 17 batch id 142 loss 0.35764408111572266 train acc 0.9313380281690141\n",
            "epoch 17 batch id 143 loss 0.29064005613327026 train acc 0.9310533216783217\n",
            "epoch 17 batch id 144 loss 0.2017914056777954 train acc 0.9310980902777778\n",
            "epoch 17 batch id 145 loss 0.2253754436969757 train acc 0.93125\n",
            "epoch 17 batch id 146 loss 0.24990162253379822 train acc 0.9311857876712328\n",
            "epoch 17 batch id 147 loss 0.19405704736709595 train acc 0.9313350340136054\n",
            "epoch 17 batch id 148 loss 0.17268258333206177 train acc 0.9313766891891891\n",
            "epoch 17 batch id 149 loss 0.12984423339366913 train acc 0.9315226510067114\n",
            "epoch 17 batch id 150 loss 0.23914611339569092 train acc 0.9314583333333334\n",
            "epoch 17 batch id 151 loss 0.20308464765548706 train acc 0.9314983443708609\n",
            "epoch 17 batch id 152 loss 0.08381550014019012 train acc 0.9317434210526315\n",
            "epoch 17 batch id 153 loss 0.3144821524620056 train acc 0.9315767973856209\n",
            "epoch 17 batch id 154 loss 0.24171961843967438 train acc 0.9316152597402597\n",
            "epoch 17 batch id 155 loss 0.12007774412631989 train acc 0.9318548387096774\n",
            "epoch 17 batch id 156 loss 0.10061854869127274 train acc 0.9321915064102564\n",
            "epoch 17 batch id 157 loss 0.2701714336872101 train acc 0.9320262738853503\n",
            "epoch 17 batch id 158 loss 0.3579269349575043 train acc 0.9317642405063291\n",
            "epoch 17 batch id 159 loss 0.07270190119743347 train acc 0.9321933962264151\n",
            "epoch 17 batch id 160 loss 0.13758325576782227 train acc 0.932421875\n",
            "epoch 17 batch id 161 loss 0.14275722205638885 train acc 0.9325504658385093\n",
            "epoch 17 batch id 162 loss 0.36906206607818604 train acc 0.9324845679012346\n",
            "epoch 17 batch id 163 loss 0.32650700211524963 train acc 0.9324194785276073\n",
            "epoch 17 batch id 164 loss 0.31788358092308044 train acc 0.9321646341463414\n",
            "epoch 17 batch id 165 loss 0.43131279945373535 train acc 0.9317234848484849\n",
            "epoch 17 batch id 166 loss 0.436400830745697 train acc 0.9311935240963856\n",
            "epoch 17 batch id 167 loss 0.2432965785264969 train acc 0.9312312874251497\n",
            "epoch 17 batch id 168 loss 0.3034166693687439 train acc 0.9310825892857143\n",
            "epoch 17 batch id 169 loss 0.22902102768421173 train acc 0.9310281065088757\n",
            "epoch 17 batch id 170 loss 0.3159172534942627 train acc 0.9309742647058824\n",
            "epoch 17 batch id 171 loss 0.24935387074947357 train acc 0.9311038011695907\n",
            "epoch 17 batch id 172 loss 0.2916065752506256 train acc 0.9309593023255814\n",
            "epoch 17 batch id 173 loss 0.08819346874952316 train acc 0.9313583815028902\n",
            "epoch 17 batch id 174 loss 0.10990653187036514 train acc 0.9314834770114943\n",
            "epoch 17 batch id 175 loss 0.37307432293891907 train acc 0.93125\n",
            "epoch 17 batch id 176 loss 0.31413733959198 train acc 0.9310191761363636\n",
            "epoch 17 batch id 177 loss 0.09911744296550751 train acc 0.9312323446327684\n",
            "epoch 17 batch id 178 loss 0.2145272046327591 train acc 0.9312675561797753\n",
            "epoch 17 batch id 179 loss 0.3643091320991516 train acc 0.9311277932960894\n",
            "epoch 17 batch id 180 loss 0.23482182621955872 train acc 0.9310763888888889\n",
            "epoch 17 batch id 181 loss 0.16751638054847717 train acc 0.9313708563535912\n",
            "epoch 17 batch id 182 loss 0.26580438017845154 train acc 0.931146978021978\n",
            "epoch 17 batch id 183 loss 0.3503994047641754 train acc 0.9307547814207651\n",
            "epoch 17 batch id 184 loss 0.3955041468143463 train acc 0.9303668478260869\n",
            "epoch 17 batch id 185 loss 0.3809829652309418 train acc 0.9300675675675676\n",
            "epoch 17 batch id 186 loss 0.21673105657100677 train acc 0.9300235215053764\n",
            "epoch 17 batch id 187 loss 0.19162483513355255 train acc 0.9300635026737968\n",
            "epoch 17 batch id 188 loss 0.12886792421340942 train acc 0.9301030585106383\n",
            "epoch 17 batch id 189 loss 0.30698588490486145 train acc 0.9301421957671958\n",
            "epoch 17 batch id 190 loss 0.12703970074653625 train acc 0.9302631578947368\n",
            "epoch 17 batch id 191 loss 0.07322026789188385 train acc 0.930628272251309\n",
            "epoch 17 batch id 192 loss 0.34553244709968567 train acc 0.9305013020833334\n",
            "epoch 17 batch id 193 loss 0.2683550715446472 train acc 0.9304566062176166\n",
            "epoch 17 batch id 194 loss 0.15414823591709137 train acc 0.9306539948453608\n",
            "epoch 17 batch id 195 loss 0.2167031615972519 train acc 0.9306891025641025\n",
            "epoch 17 batch id 196 loss 0.2628977596759796 train acc 0.9307238520408163\n",
            "epoch 17 batch id 197 loss 0.3889155387878418 train acc 0.9305996192893401\n",
            "epoch 17 batch id 198 loss 0.29737067222595215 train acc 0.9307133838383839\n",
            "epoch 17 batch id 199 loss 0.3156931698322296 train acc 0.9305904522613065\n",
            "epoch 17 batch id 200 loss 0.3882569670677185 train acc 0.930234375\n",
            "epoch 17 batch id 201 loss 0.2052006870508194 train acc 0.9302705223880597\n",
            "epoch 17 batch id 202 loss 0.3106244206428528 train acc 0.9303063118811881\n",
            "epoch 17 batch id 203 loss 0.2135106772184372 train acc 0.9304187192118226\n",
            "epoch 17 batch id 204 loss 0.34561383724212646 train acc 0.9303002450980392\n",
            "epoch 17 batch id 205 loss 0.1727057844400406 train acc 0.9302591463414634\n",
            "epoch 17 batch id 206 loss 0.08953225612640381 train acc 0.9304459951456311\n",
            "epoch 17 batch id 207 loss 0.06126575544476509 train acc 0.9307820048309179\n",
            "epoch 17 batch id 208 loss 0.3352587819099426 train acc 0.9305889423076923\n",
            "epoch 17 batch id 209 loss 0.2207712084054947 train acc 0.9306967703349283\n",
            "epoch 17 batch id 210 loss 0.09781059622764587 train acc 0.9308779761904762\n",
            "epoch 17 batch id 211 loss 0.23828132450580597 train acc 0.9309093601895735\n",
            "epoch 17 batch id 212 loss 0.47920042276382446 train acc 0.9306456367924528\n",
            "epoch 17 batch id 213 loss 0.4884861707687378 train acc 0.9303843896713615\n",
            "epoch 17 batch id 214 loss 0.13732725381851196 train acc 0.9304906542056075\n",
            "epoch 17 batch id 215 loss 0.18018051981925964 train acc 0.9306686046511627\n",
            "epoch 17 batch id 216 loss 0.1815989762544632 train acc 0.9307725694444444\n",
            "epoch 17 batch id 217 loss 0.3063185513019562 train acc 0.9308035714285714\n",
            "epoch 17 batch id 218 loss 0.40390127897262573 train acc 0.9305475917431193\n",
            "epoch 17 batch id 219 loss 0.16050752997398376 train acc 0.9307220319634704\n",
            "epoch 17 batch id 220 loss 0.24208417534828186 train acc 0.9305397727272727\n",
            "epoch 17 batch id 221 loss 0.1819913387298584 train acc 0.9306419683257918\n",
            "epoch 17 batch id 222 loss 0.15246275067329407 train acc 0.9306024774774775\n",
            "epoch 17 batch id 223 loss 0.2310059368610382 train acc 0.9304932735426009\n",
            "epoch 17 batch id 224 loss 0.1456485539674759 train acc 0.9305943080357143\n",
            "epoch 17 batch id 225 loss 0.23072431981563568 train acc 0.9304166666666667\n",
            "epoch 17 batch id 226 loss 0.2855224609375 train acc 0.9303097345132744\n",
            "epoch 17 batch id 227 loss 0.49571675062179565 train acc 0.930203744493392\n",
            "epoch 17 batch id 228 loss 0.20147205889225006 train acc 0.9302357456140351\n",
            "epoch 17 batch id 229 loss 0.2450704127550125 train acc 0.9301992358078602\n",
            "epoch 17 batch id 230 loss 0.22200903296470642 train acc 0.9302309782608695\n",
            "epoch 17 batch id 231 loss 0.2771926820278168 train acc 0.9300595238095238\n",
            "epoch 17 batch id 232 loss 0.13467854261398315 train acc 0.9301589439655172\n",
            "epoch 17 batch id 233 loss 0.260895699262619 train acc 0.9301233905579399\n",
            "epoch 17 batch id 234 loss 0.17926666140556335 train acc 0.930221688034188\n",
            "epoch 17 batch id 235 loss 0.28410884737968445 train acc 0.9303191489361702\n",
            "epoch 17 batch id 236 loss 0.20681621134281158 train acc 0.9302171610169492\n",
            "epoch 17 batch id 237 loss 0.34682497382164 train acc 0.9301819620253164\n",
            "epoch 17 batch id 238 loss 0.24047955870628357 train acc 0.9301470588235294\n",
            "epoch 17 batch id 239 loss 0.11110609024763107 train acc 0.9303739539748954\n",
            "epoch 17 batch id 240 loss 0.17395377159118652 train acc 0.93046875\n",
            "epoch 17 batch id 241 loss 0.3245250880718231 train acc 0.9305627593360996\n",
            "epoch 17 batch id 242 loss 0.19921432435512543 train acc 0.9306559917355371\n",
            "epoch 17 batch id 243 loss 0.3038610816001892 train acc 0.9305555555555556\n",
            "epoch 17 batch id 244 loss 0.3226258158683777 train acc 0.9303919057377049\n",
            "epoch 17 batch id 245 loss 0.22562098503112793 train acc 0.9304846938775511\n",
            "epoch 17 batch id 246 loss 0.3010632395744324 train acc 0.9303861788617886\n",
            "epoch 17 batch id 247 loss 0.12075076997280121 train acc 0.9304782388663968\n",
            "epoch 17 batch id 248 loss 0.1381506770849228 train acc 0.930632560483871\n",
            "epoch 17 batch id 249 loss 0.16445688903331757 train acc 0.9307228915662651\n",
            "epoch 17 batch id 250 loss 0.311455100774765 train acc 0.9305625\n",
            "epoch 17 batch id 251 loss 0.16616588830947876 train acc 0.9307768924302788\n",
            "epoch 17 batch id 252 loss 0.28229647874832153 train acc 0.9306795634920635\n",
            "epoch 17 batch id 253 loss 0.23498767614364624 train acc 0.9306447628458498\n",
            "epoch 17 batch id 254 loss 0.2168896198272705 train acc 0.9306717519685039\n",
            "epoch 17 batch id 255 loss 0.1891573965549469 train acc 0.9306985294117647\n",
            "epoch 17 batch id 256 loss 0.1490345597267151 train acc 0.930908203125\n",
            "epoch 17 batch id 257 loss 0.21278569102287292 train acc 0.9309946498054474\n",
            "epoch 17 batch id 258 loss 0.19816754758358002 train acc 0.9309593023255814\n",
            "epoch 17 batch id 259 loss 0.36266419291496277 train acc 0.930984555984556\n",
            "epoch 17 batch id 260 loss 0.19492700695991516 train acc 0.9310697115384615\n",
            "epoch 17 batch id 261 loss 0.4489852488040924 train acc 0.9308548850574713\n",
            "epoch 17 batch id 262 loss 0.31051233410835266 train acc 0.9308802480916031\n",
            "epoch 17 batch id 263 loss 0.20661498606204987 train acc 0.9309054182509505\n",
            "epoch 17 batch id 264 loss 0.17670831084251404 train acc 0.9309303977272727\n",
            "epoch 17 batch id 265 loss 0.24827469885349274 train acc 0.9308372641509434\n",
            "epoch 17 batch id 266 loss 0.5393842458724976 train acc 0.9304511278195489\n",
            "epoch 17 batch id 267 loss 0.44117385149002075 train acc 0.9303019662921348\n",
            "epoch 17 batch id 268 loss 0.5301671624183655 train acc 0.9300373134328358\n",
            "epoch 17 batch id 269 loss 0.15497568249702454 train acc 0.9301231412639405\n",
            "epoch 17 batch id 270 loss 0.18845807015895844 train acc 0.9302662037037037\n",
            "epoch 17 batch id 271 loss 0.14948336780071259 train acc 0.9303505535055351\n",
            "epoch 17 batch id 272 loss 0.17001065611839294 train acc 0.9303768382352942\n",
            "epoch 17 batch id 273 loss 0.24823322892189026 train acc 0.9304029304029304\n",
            "epoch 17 batch id 274 loss 0.1277693808078766 train acc 0.9304288321167883\n",
            "epoch 17 batch id 275 loss 0.20393723249435425 train acc 0.9305681818181818\n",
            "epoch 17 batch id 276 loss 0.15073831379413605 train acc 0.9306499094202898\n",
            "epoch 17 batch id 277 loss 0.3061293661594391 train acc 0.9305054151624549\n",
            "epoch 17 batch id 278 loss 0.2836238443851471 train acc 0.9304743705035972\n",
            "epoch 17 batch id 279 loss 0.25195151567459106 train acc 0.9304435483870968\n",
            "epoch 17 batch id 280 loss 0.4252985417842865 train acc 0.9303013392857142\n",
            "epoch 17 batch id 281 loss 0.3645963668823242 train acc 0.9302157473309609\n",
            "epoch 17 batch id 282 loss 0.25669071078300476 train acc 0.9302415780141844\n",
            "epoch 17 batch id 283 loss 0.14444591104984283 train acc 0.9303776501766784\n",
            "epoch 17 batch id 284 loss 0.16764114797115326 train acc 0.930512764084507\n",
            "epoch 17 batch id 285 loss 0.29271405935287476 train acc 0.9304276315789474\n",
            "epoch 17 batch id 286 loss 0.12267395108938217 train acc 0.9305616258741258\n",
            "epoch 17 batch id 287 loss 0.2225571721792221 train acc 0.9305313588850174\n",
            "epoch 17 batch id 288 loss 0.17311817407608032 train acc 0.9306098090277778\n",
            "epoch 17 batch id 289 loss 0.2274927794933319 train acc 0.9306336505190311\n",
            "epoch 17 batch id 290 loss 0.13147753477096558 train acc 0.9307650862068966\n",
            "epoch 17 batch id 291 loss 0.09876113384962082 train acc 0.930895618556701\n",
            "epoch 17 batch id 292 loss 0.2675243616104126 train acc 0.9308112157534246\n",
            "epoch 17 batch id 293 loss 0.20745143294334412 train acc 0.9308340443686007\n",
            "epoch 17 batch id 294 loss 0.1541580706834793 train acc 0.9309630102040817\n",
            "epoch 17 batch id 295 loss 0.3352608382701874 train acc 0.9309851694915254\n",
            "epoch 17 batch id 296 loss 0.18934307992458344 train acc 0.9310071790540541\n",
            "epoch 17 batch id 297 loss 0.44724133610725403 train acc 0.9309238215488216\n",
            "epoch 17 batch id 298 loss 0.36597418785095215 train acc 0.9308410234899329\n",
            "epoch 17 batch id 299 loss 0.14772360026836395 train acc 0.9309678093645485\n",
            "epoch 17 batch id 300 loss 0.2329200655221939 train acc 0.9309895833333334\n",
            "epoch 17 batch id 301 loss 0.1941961795091629 train acc 0.9310112126245847\n",
            "epoch 17 batch id 302 loss 0.2925727963447571 train acc 0.9310326986754967\n",
            "epoch 17 batch id 303 loss 0.2636381685733795 train acc 0.9311056105610561\n",
            "epoch 17 batch id 304 loss 0.38557127118110657 train acc 0.930921052631579\n",
            "epoch 17 batch id 305 loss 0.37322625517845154 train acc 0.930891393442623\n",
            "epoch 17 batch id 306 loss 0.2267175167798996 train acc 0.9309640522875817\n",
            "epoch 17 batch id 307 loss 0.2588919699192047 train acc 0.930832654723127\n",
            "epoch 17 batch id 308 loss 0.29573896527290344 train acc 0.9307021103896104\n",
            "epoch 17 batch id 309 loss 0.200498566031456 train acc 0.9307746763754046\n",
            "epoch 17 batch id 310 loss 0.25916075706481934 train acc 0.9308467741935483\n",
            "epoch 17 batch id 311 loss 0.37241217494010925 train acc 0.9307676848874598\n",
            "epoch 17 batch id 312 loss 0.14296606183052063 train acc 0.9308894230769231\n",
            "epoch 17 batch id 313 loss 0.42410221695899963 train acc 0.9308107028753994\n",
            "epoch 17 batch id 314 loss 0.15163321793079376 train acc 0.9309315286624203\n",
            "epoch 17 batch id 315 loss 0.10833080112934113 train acc 0.9311011904761904\n",
            "epoch 17 batch id 316 loss 0.14601564407348633 train acc 0.9312697784810127\n",
            "epoch 17 batch id 317 loss 0.30541592836380005 train acc 0.9311908517350158\n",
            "epoch 17 batch id 318 loss 0.2344597429037094 train acc 0.9311615566037735\n",
            "epoch 17 batch id 319 loss 0.2790512442588806 train acc 0.9311324451410659\n",
            "epoch 17 batch id 320 loss 0.20866118371486664 train acc 0.931201171875\n",
            "epoch 17 batch id 321 loss 0.490164190530777 train acc 0.9308313862928349\n",
            "epoch 17 batch id 322 loss 0.20614252984523773 train acc 0.9308520962732919\n",
            "epoch 17 batch id 323 loss 0.33314263820648193 train acc 0.9307275541795665\n",
            "epoch 17 batch id 324 loss 0.20285052061080933 train acc 0.9307484567901234\n",
            "epoch 17 batch id 325 loss 0.3053927421569824 train acc 0.9307211538461538\n",
            "epoch 17 batch id 326 loss 0.2566673159599304 train acc 0.9305981595092024\n",
            "epoch 17 batch id 327 loss 0.35418784618377686 train acc 0.9304759174311926\n",
            "epoch 17 batch id 328 loss 0.4866657257080078 train acc 0.9303544207317073\n",
            "epoch 17 batch id 329 loss 0.4195617437362671 train acc 0.9302336626139818\n",
            "epoch 17 batch id 330 loss 0.2780469059944153 train acc 0.9301609848484849\n",
            "epoch 17 batch id 331 loss 0.25075364112854004 train acc 0.9302303625377644\n",
            "epoch 17 batch id 332 loss 0.20913062989711761 train acc 0.9302993222891566\n",
            "epoch 17 batch id 333 loss 0.2974001169204712 train acc 0.9303209459459459\n",
            "epoch 17 batch id 334 loss 0.08628306537866592 train acc 0.930436002994012\n",
            "epoch 17 batch id 335 loss 0.21453872323036194 train acc 0.9304104477611941\n",
            "epoch 17 batch id 336 loss 0.2875508666038513 train acc 0.9303850446428571\n",
            "epoch 17 batch id 337 loss 0.1762014925479889 train acc 0.9304061572700296\n",
            "epoch 17 batch id 338 loss 0.40238896012306213 train acc 0.9303809171597633\n",
            "epoch 17 batch id 339 loss 0.21050778031349182 train acc 0.9304480088495575\n",
            "epoch 17 batch id 340 loss 0.4856961965560913 train acc 0.9303308823529411\n",
            "epoch 17 batch id 341 loss 0.35751715302467346 train acc 0.9301686217008798\n",
            "epoch 17 batch id 342 loss 0.35183587670326233 train acc 0.9301443713450293\n",
            "epoch 17 batch id 343 loss 0.12768813967704773 train acc 0.9302113702623906\n",
            "epoch 17 batch id 344 loss 0.1311679631471634 train acc 0.9303688226744186\n",
            "epoch 17 batch id 345 loss 0.2368745356798172 train acc 0.9304347826086956\n",
            "epoch 17 batch id 346 loss 0.3970301151275635 train acc 0.9302294075144508\n",
            "epoch 17 batch id 347 loss 0.1059182807803154 train acc 0.9303404178674352\n",
            "epoch 17 batch id 348 loss 0.2285117208957672 train acc 0.930316091954023\n",
            "epoch 17 batch id 349 loss 0.12235885858535767 train acc 0.9304709885386819\n",
            "epoch 17 batch id 350 loss 0.27337566018104553 train acc 0.9304017857142857\n",
            "epoch 17 batch id 351 loss 0.16000929474830627 train acc 0.9305110398860399\n",
            "epoch 17 batch id 352 loss 0.10239128023386002 train acc 0.9306196732954546\n",
            "epoch 17 batch id 353 loss 0.2811747193336487 train acc 0.9305506373937678\n",
            "epoch 17 batch id 354 loss 0.3300078809261322 train acc 0.9304378531073446\n",
            "epoch 17 batch id 355 loss 0.1602036952972412 train acc 0.9304577464788732\n",
            "epoch 17 batch id 356 loss 0.2979399561882019 train acc 0.9303897471910112\n",
            "epoch 17 batch id 357 loss 0.17385506629943848 train acc 0.9305409663865546\n",
            "epoch 17 batch id 358 loss 0.11675187945365906 train acc 0.9306913407821229\n",
            "epoch 17 batch id 359 loss 0.27264735102653503 train acc 0.930666782729805\n",
            "epoch 17 batch id 360 loss 0.32360517978668213 train acc 0.9306857638888889\n",
            "epoch 17 batch id 361 loss 0.33408311009407043 train acc 0.9306180747922438\n",
            "epoch 17 batch id 362 loss 0.23836053907871246 train acc 0.9306370856353591\n",
            "epoch 17 batch id 363 loss 0.25458014011383057 train acc 0.9306990358126722\n",
            "epoch 17 batch id 364 loss 0.12008194625377655 train acc 0.9308464972527473\n",
            "epoch 17 batch id 365 loss 0.10382385551929474 train acc 0.9309931506849315\n",
            "epoch 17 batch id 366 loss 0.23491916060447693 train acc 0.9310536202185792\n",
            "epoch 17 batch id 367 loss 0.26005664467811584 train acc 0.9310711852861036\n",
            "epoch 17 batch id 368 loss 0.1435997188091278 train acc 0.9311735733695652\n",
            "epoch 17 batch id 369 loss 0.18823783099651337 train acc 0.9311907181571816\n",
            "epoch 17 batch id 370 loss 0.3261604309082031 train acc 0.9311233108108108\n",
            "epoch 17 batch id 371 loss 0.20842425525188446 train acc 0.9311826145552561\n",
            "epoch 17 batch id 372 loss 0.22787681221961975 train acc 0.9312415994623656\n",
            "epoch 17 batch id 373 loss 0.3413082957267761 train acc 0.9311745978552279\n",
            "epoch 17 batch id 374 loss 0.34780794382095337 train acc 0.9312332887700535\n",
            "epoch 17 batch id 375 loss 0.28168052434921265 train acc 0.9311666666666667\n",
            "epoch 17 batch id 376 loss 0.2353779822587967 train acc 0.931141954787234\n",
            "epoch 17 batch id 377 loss 0.21321649849414825 train acc 0.9312002652519894\n",
            "epoch 17 batch id 378 loss 0.05035611242055893 train acc 0.9313822751322751\n",
            "epoch 17 batch id 379 loss 0.0689058005809784 train acc 0.9315220976253298\n",
            "epoch 17 batch id 380 loss 0.29031652212142944 train acc 0.9314555921052632\n",
            "epoch 17 batch id 381 loss 0.25646069645881653 train acc 0.9314304461942258\n",
            "epoch 17 batch id 382 loss 0.23838096857070923 train acc 0.9313645287958116\n",
            "epoch 17 batch id 383 loss 0.1883113831281662 train acc 0.9313397519582245\n",
            "epoch 17 batch id 384 loss 0.19192035496234894 train acc 0.931396484375\n",
            "epoch 17 batch id 385 loss 0.18511538207530975 train acc 0.9314529220779221\n",
            "epoch 17 batch id 386 loss 0.2084059715270996 train acc 0.9315090673575129\n",
            "epoch 17 batch id 387 loss 0.2690575122833252 train acc 0.931484173126615\n",
            "epoch 17 batch id 388 loss 0.2385166436433792 train acc 0.9314996778350515\n",
            "epoch 17 batch id 389 loss 0.4415584206581116 train acc 0.9312741002570694\n",
            "epoch 17 batch id 390 loss 0.44246214628219604 train acc 0.9311698717948718\n",
            "epoch 17 batch id 391 loss 0.28080886602401733 train acc 0.9311460997442456\n",
            "epoch 17 batch id 392 loss 0.4015648365020752 train acc 0.9310825892857143\n",
            "epoch 17 batch id 393 loss 0.39719581604003906 train acc 0.9310194020356234\n",
            "epoch 17 batch id 394 loss 0.24147282540798187 train acc 0.9310358502538071\n",
            "epoch 17 batch id 395 loss 0.21907202899456024 train acc 0.9310522151898735\n",
            "epoch 17 batch id 396 loss 0.15959623456001282 train acc 0.9311474116161617\n",
            "epoch 17 batch id 397 loss 0.2839779555797577 train acc 0.9312027707808564\n",
            "epoch 17 batch id 398 loss 0.1392481029033661 train acc 0.9312578517587939\n",
            "epoch 17 batch id 399 loss 0.2897184491157532 train acc 0.9311951754385965\n",
            "epoch 17 batch id 400 loss 0.2857663333415985 train acc 0.93125\n",
            "epoch 17 batch id 401 loss 0.3967433273792267 train acc 0.9310707605985037\n",
            "epoch 17 batch id 402 loss 0.22185909748077393 train acc 0.9311256218905473\n",
            "epoch 17 batch id 403 loss 0.20047235488891602 train acc 0.9312189826302729\n",
            "epoch 17 batch id 404 loss 0.4144224524497986 train acc 0.9311185024752475\n",
            "epoch 17 batch id 405 loss 0.19081251323223114 train acc 0.9310956790123457\n",
            "epoch 17 batch id 406 loss 0.20777560770511627 train acc 0.9311114532019704\n",
            "epoch 17 batch id 407 loss 0.19625994563102722 train acc 0.9312039312039312\n",
            "epoch 17 batch id 408 loss 0.13133791089057922 train acc 0.9312576593137255\n",
            "epoch 17 batch id 409 loss 0.1770170032978058 train acc 0.9312729217603912\n",
            "epoch 17 batch id 410 loss 0.25613436102867126 train acc 0.93125\n",
            "epoch 17 batch id 411 loss 0.1711079180240631 train acc 0.9313412408759124\n",
            "epoch 17 batch id 412 loss 0.29668015241622925 train acc 0.9313561893203883\n",
            "epoch 17 batch id 413 loss 0.18390682339668274 train acc 0.9314088983050848\n",
            "epoch 17 batch id 414 loss 0.21415682137012482 train acc 0.9315368357487923\n",
            "epoch 17 batch id 415 loss 0.3469716012477875 train acc 0.9314382530120482\n",
            "epoch 17 batch id 416 loss 0.232195645570755 train acc 0.9314903846153846\n",
            "epoch 17 batch id 417 loss 0.1849406659603119 train acc 0.9315047961630696\n",
            "epoch 17 batch id 418 loss 0.19098734855651855 train acc 0.9314817583732058\n",
            "epoch 17 batch id 419 loss 0.23269006609916687 train acc 0.931496121718377\n",
            "epoch 17 batch id 420 loss 0.2131980061531067 train acc 0.9315104166666667\n",
            "epoch 17 batch id 421 loss 0.1153171956539154 train acc 0.9315988717339667\n",
            "epoch 17 batch id 422 loss 0.6766992807388306 train acc 0.9313166469194313\n",
            "epoch 17 batch id 423 loss 0.3190806806087494 train acc 0.9312204491725768\n",
            "epoch 17 batch id 424 loss 0.2257663458585739 train acc 0.9312721108490566\n",
            "epoch 17 batch id 425 loss 0.24371907114982605 train acc 0.93125\n",
            "epoch 17 batch id 426 loss 0.2128313034772873 train acc 0.9313013497652582\n",
            "epoch 17 batch id 427 loss 0.5332679152488708 train acc 0.9311694964871194\n",
            "epoch 17 batch id 428 loss 0.12892550230026245 train acc 0.9312207943925234\n",
            "epoch 17 batch id 429 loss 0.17025014758110046 train acc 0.9313082750582751\n",
            "epoch 17 batch id 430 loss 0.24380116164684296 train acc 0.9312863372093023\n",
            "epoch 17 batch id 431 loss 0.3708876967430115 train acc 0.9311557424593968\n",
            "epoch 17 batch id 432 loss 0.12214919924736023 train acc 0.9312427662037037\n",
            "epoch 17 batch id 433 loss 0.16516949236392975 train acc 0.9312572170900693\n",
            "epoch 17 batch id 434 loss 0.13086959719657898 train acc 0.9313796082949308\n",
            "epoch 17 batch id 435 loss 0.3079895079135895 train acc 0.9313936781609196\n",
            "epoch 17 batch id 436 loss 0.29282712936401367 train acc 0.9313360091743119\n",
            "epoch 17 batch id 437 loss 0.29816293716430664 train acc 0.9313143592677345\n",
            "epoch 17 batch id 438 loss 0.33281227946281433 train acc 0.9312214611872146\n",
            "epoch 17 batch id 439 loss 0.20703600347042084 train acc 0.9312357630979499\n",
            "epoch 17 batch id 440 loss 0.18490992486476898 train acc 0.9313210227272727\n",
            "epoch 17 batch id 441 loss 0.340434193611145 train acc 0.9311933106575964\n",
            "epoch 17 batch id 442 loss 0.3283524513244629 train acc 0.9311368778280543\n",
            "epoch 17 batch id 443 loss 0.18813958764076233 train acc 0.9311865124153499\n",
            "epoch 17 batch id 444 loss 0.07111632823944092 train acc 0.9313063063063063\n",
            "epoch 17 batch id 445 loss 0.12513747811317444 train acc 0.9313904494382023\n",
            "epoch 17 batch id 446 loss 0.24187228083610535 train acc 0.9314041479820628\n",
            "epoch 17 batch id 447 loss 0.13778482377529144 train acc 0.93145274049217\n",
            "epoch 17 batch id 448 loss 0.24795877933502197 train acc 0.9314662388392857\n",
            "epoch 17 batch id 449 loss 0.11925521492958069 train acc 0.9315492761692651\n",
            "epoch 17 batch id 450 loss 0.24306492507457733 train acc 0.9315277777777777\n",
            "epoch 17 batch id 451 loss 0.1041993498802185 train acc 0.931644955654102\n",
            "epoch 17 batch id 452 loss 0.1571957767009735 train acc 0.931727046460177\n",
            "epoch 17 batch id 453 loss 0.20327505469322205 train acc 0.9317397902869757\n",
            "epoch 17 batch id 454 loss 0.2182234823703766 train acc 0.9316836453744494\n",
            "epoch 17 batch id 455 loss 0.2234993875026703 train acc 0.9316620879120879\n",
            "epoch 17 batch id 456 loss 0.12243759632110596 train acc 0.9317091557017544\n",
            "epoch 17 batch id 457 loss 0.17447933554649353 train acc 0.9316876367614879\n",
            "epoch 17 batch id 458 loss 0.06541519612073898 train acc 0.9317685589519651\n",
            "epoch 17 batch id 459 loss 0.10343486070632935 train acc 0.931849128540305\n",
            "epoch 17 batch id 460 loss 0.22269748151302338 train acc 0.9318274456521739\n",
            "epoch 17 batch id 461 loss 0.2887839376926422 train acc 0.9317719631236443\n",
            "epoch 17 batch id 462 loss 0.31981122493743896 train acc 0.9317167207792207\n",
            "epoch 17 batch id 463 loss 0.3185032904148102 train acc 0.931762958963283\n",
            "epoch 17 batch id 464 loss 0.2964763045310974 train acc 0.9317416487068966\n",
            "epoch 17 batch id 465 loss 0.16946625709533691 train acc 0.9318212365591397\n",
            "epoch 17 batch id 466 loss 0.2583053410053253 train acc 0.9318669527896996\n",
            "epoch 17 batch id 467 loss 0.20191843807697296 train acc 0.931945931477516\n",
            "epoch 17 batch id 468 loss 0.3692265748977661 train acc 0.9317908653846154\n",
            "epoch 17 batch id 469 loss 0.150596022605896 train acc 0.9319029850746269\n",
            "epoch 17 batch id 470 loss 0.20670661330223083 train acc 0.9319148936170213\n",
            "epoch 17 batch id 471 loss 0.16249652206897736 train acc 0.9320262738853503\n",
            "epoch 17 batch id 472 loss 0.1917908489704132 train acc 0.9320709745762712\n",
            "epoch 17 batch id 473 loss 0.26242369413375854 train acc 0.9319833509513742\n",
            "epoch 17 batch id 474 loss 0.1080859899520874 train acc 0.932060917721519\n",
            "epoch 17 batch id 475 loss 0.13576442003250122 train acc 0.9321381578947369\n",
            "epoch 17 batch id 476 loss 0.37089940905570984 train acc 0.9319852941176471\n",
            "epoch 17 batch id 477 loss 0.28029876947402954 train acc 0.9319640985324947\n",
            "epoch 17 batch id 478 loss 0.13273359835147858 train acc 0.9320083682008368\n",
            "epoch 17 batch id 479 loss 0.12472663074731827 train acc 0.9321176931106472\n",
            "epoch 17 batch id 480 loss 0.23972098529338837 train acc 0.9321614583333333\n",
            "epoch 17 batch id 481 loss 0.2586403489112854 train acc 0.9321075883575883\n",
            "epoch 17 batch id 482 loss 0.4814486503601074 train acc 0.9320215248962656\n",
            "epoch 17 batch id 483 loss 0.32028254866600037 train acc 0.9319681677018633\n",
            "epoch 17 batch id 484 loss 0.27685096859931946 train acc 0.9319473140495868\n",
            "epoch 17 batch id 485 loss 0.17104490101337433 train acc 0.9319909793814433\n",
            "epoch 17 batch id 486 loss 0.20005488395690918 train acc 0.9320023148148148\n",
            "epoch 17 batch id 487 loss 0.19990912079811096 train acc 0.9319815195071869\n",
            "epoch 17 batch id 488 loss 0.186447873711586 train acc 0.9320248463114754\n",
            "epoch 17 batch id 489 loss 0.28606969118118286 train acc 0.9320360429447853\n",
            "epoch 17 batch id 490 loss 0.45634639263153076 train acc 0.9319196428571429\n",
            "epoch 17 batch id 491 loss 0.14534184336662292 train acc 0.9319946537678208\n",
            "epoch 17 batch id 492 loss 0.3365338444709778 train acc 0.9319423272357723\n",
            "epoch 17 batch id 493 loss 0.2899932861328125 train acc 0.9318585192697769\n",
            "epoch 17 batch id 494 loss 0.07701196521520615 train acc 0.9319015688259109\n",
            "epoch 17 batch id 495 loss 0.1804891675710678 train acc 0.9319444444444445\n",
            "epoch 17 batch id 496 loss 0.27561989426612854 train acc 0.9319241431451613\n",
            "epoch 17 batch id 497 loss 0.09283621609210968 train acc 0.9319982394366197\n",
            "epoch 17 batch id 498 loss 0.06842085719108582 train acc 0.9321034136546185\n",
            "epoch 17 batch id 499 loss 0.277246356010437 train acc 0.9321142284569138\n",
            "epoch 17 batch id 500 loss 0.20881524682044983 train acc 0.932125\n",
            "epoch 17 batch id 501 loss 0.333322137594223 train acc 0.9320733532934131\n",
            "epoch 17 batch id 502 loss 0.2145663946866989 train acc 0.9320530378486056\n",
            "epoch 17 batch id 503 loss 0.21281036734580994 train acc 0.9320638667992047\n",
            "epoch 17 batch id 504 loss 0.28655752539634705 train acc 0.9319506448412699\n",
            "epoch 17 batch id 505 loss 0.20155812799930573 train acc 0.9319925742574258\n",
            "epoch 17 batch id 506 loss 0.18925689160823822 train acc 0.9320343379446641\n",
            "epoch 17 batch id 507 loss 0.15917879343032837 train acc 0.932137573964497\n",
            "epoch 17 batch id 508 loss 0.13648071885108948 train acc 0.9321788877952756\n",
            "epoch 17 batch id 509 loss 0.3795473277568817 train acc 0.9321279469548134\n",
            "epoch 17 batch id 510 loss 0.08151958137750626 train acc 0.9321997549019608\n",
            "epoch 17 batch id 511 loss 0.10570582747459412 train acc 0.9322392484391017\n",
            "epoch 17 train acc 0.9322392484391017\n",
            "epoch 17 test acc 0.4010823567708333\n",
            "epoch 18 batch id 1 loss 0.38188013434410095 train acc 0.90625\n",
            "epoch 18 batch id 2 loss 0.21258649230003357 train acc 0.9296875\n",
            "epoch 18 batch id 3 loss 0.26082542538642883 train acc 0.9166666666666666\n",
            "epoch 18 batch id 4 loss 0.07533372193574905 train acc 0.93359375\n",
            "epoch 18 batch id 5 loss 0.1106586754322052 train acc 0.9375\n",
            "epoch 18 batch id 6 loss 0.2444566935300827 train acc 0.9322916666666666\n",
            "epoch 18 batch id 7 loss 0.23015356063842773 train acc 0.9308035714285714\n",
            "epoch 18 batch id 8 loss 0.15696005523204803 train acc 0.9296875\n",
            "epoch 18 batch id 9 loss 0.31483709812164307 train acc 0.9270833333333334\n",
            "epoch 18 batch id 10 loss 0.08071219176054001 train acc 0.934375\n",
            "epoch 18 batch id 11 loss 0.4187367260456085 train acc 0.9318181818181818\n",
            "epoch 18 batch id 12 loss 0.09611327946186066 train acc 0.9348958333333334\n",
            "epoch 18 batch id 13 loss 0.1675691306591034 train acc 0.9375\n",
            "epoch 18 batch id 14 loss 0.18988953530788422 train acc 0.9375\n",
            "epoch 18 batch id 15 loss 0.34079602360725403 train acc 0.9364583333333333\n",
            "epoch 18 batch id 16 loss 0.1600319743156433 train acc 0.9384765625\n",
            "epoch 18 batch id 17 loss 0.2944682836532593 train acc 0.9384191176470589\n",
            "epoch 18 batch id 18 loss 0.14260651171207428 train acc 0.9392361111111112\n",
            "epoch 18 batch id 19 loss 0.1406460702419281 train acc 0.9407894736842105\n",
            "epoch 18 batch id 20 loss 0.2764563262462616 train acc 0.93984375\n",
            "epoch 18 batch id 21 loss 0.21542994678020477 train acc 0.9404761904761905\n",
            "epoch 18 batch id 22 loss 0.251620352268219 train acc 0.9410511363636364\n",
            "epoch 18 batch id 23 loss 0.1606912463903427 train acc 0.9402173913043478\n",
            "epoch 18 batch id 24 loss 0.19874000549316406 train acc 0.939453125\n",
            "epoch 18 batch id 25 loss 0.2149977684020996 train acc 0.939375\n",
            "epoch 18 batch id 26 loss 0.33475419878959656 train acc 0.9375\n",
            "epoch 18 batch id 27 loss 0.21453534066677094 train acc 0.9375\n",
            "epoch 18 batch id 28 loss 0.21852126717567444 train acc 0.9380580357142857\n",
            "epoch 18 batch id 29 loss 0.32730212807655334 train acc 0.9369612068965517\n",
            "epoch 18 batch id 30 loss 0.4347469210624695 train acc 0.9364583333333333\n",
            "epoch 18 batch id 31 loss 0.212284654378891 train acc 0.9354838709677419\n",
            "epoch 18 batch id 32 loss 0.2511764168739319 train acc 0.93505859375\n",
            "epoch 18 batch id 33 loss 0.3886033892631531 train acc 0.9322916666666666\n",
            "epoch 18 batch id 34 loss 0.2073889672756195 train acc 0.9324448529411765\n",
            "epoch 18 batch id 35 loss 0.09807813167572021 train acc 0.9334821428571428\n",
            "epoch 18 batch id 36 loss 0.15003088116645813 train acc 0.9340277777777778\n",
            "epoch 18 batch id 37 loss 0.2113303691148758 train acc 0.9336993243243243\n",
            "epoch 18 batch id 38 loss 0.24258750677108765 train acc 0.9337993421052632\n",
            "epoch 18 batch id 39 loss 0.2085854560136795 train acc 0.9338942307692307\n",
            "epoch 18 batch id 40 loss 0.35059842467308044 train acc 0.9328125\n",
            "epoch 18 batch id 41 loss 0.154094859957695 train acc 0.9329268292682927\n",
            "epoch 18 batch id 42 loss 0.17757472395896912 train acc 0.9334077380952381\n",
            "epoch 18 batch id 43 loss 0.1285005807876587 train acc 0.934593023255814\n",
            "epoch 18 batch id 44 loss 0.16335146129131317 train acc 0.9346590909090909\n",
            "epoch 18 batch id 45 loss 0.2559857666492462 train acc 0.9347222222222222\n",
            "epoch 18 batch id 46 loss 0.17081902921199799 train acc 0.9351222826086957\n",
            "epoch 18 batch id 47 loss 0.1794215440750122 train acc 0.9355053191489362\n",
            "epoch 18 batch id 48 loss 0.21871022880077362 train acc 0.935546875\n",
            "epoch 18 batch id 49 loss 0.12718552350997925 train acc 0.9362244897959183\n",
            "epoch 18 batch id 50 loss 0.2565932273864746 train acc 0.93625\n",
            "epoch 18 batch id 51 loss 0.13221244513988495 train acc 0.9368872549019608\n",
            "epoch 18 batch id 52 loss 0.08563020080327988 train acc 0.9381009615384616\n",
            "epoch 18 batch id 53 loss 0.16514068841934204 train acc 0.9377948113207547\n",
            "epoch 18 batch id 54 loss 0.3133490979671478 train acc 0.9366319444444444\n",
            "epoch 18 batch id 55 loss 0.2668740749359131 train acc 0.9366477272727273\n",
            "epoch 18 batch id 56 loss 0.11846286803483963 train acc 0.9372209821428571\n",
            "epoch 18 batch id 57 loss 0.3073398470878601 train acc 0.9369517543859649\n",
            "epoch 18 batch id 58 loss 0.042904578149318695 train acc 0.9380387931034483\n",
            "epoch 18 batch id 59 loss 0.23512789607048035 train acc 0.9382944915254238\n",
            "epoch 18 batch id 60 loss 0.25851866602897644 train acc 0.9380208333333333\n",
            "epoch 18 batch id 61 loss 0.17893020808696747 train acc 0.9385245901639344\n",
            "epoch 18 batch id 62 loss 0.16462837159633636 train acc 0.9387600806451613\n",
            "epoch 18 batch id 63 loss 0.22005294263362885 train acc 0.9384920634920635\n",
            "epoch 18 batch id 64 loss 0.28316935896873474 train acc 0.9384765625\n",
            "epoch 18 batch id 65 loss 0.11117497831583023 train acc 0.9391826923076924\n",
            "epoch 18 batch id 66 loss 0.09131546318531036 train acc 0.9398674242424242\n",
            "epoch 18 batch id 67 loss 0.19112750887870789 train acc 0.9398320895522388\n",
            "epoch 18 batch id 68 loss 0.2101725935935974 train acc 0.9397977941176471\n",
            "epoch 18 batch id 69 loss 0.1572309285402298 train acc 0.9397644927536232\n",
            "epoch 18 batch id 70 loss 0.20943357050418854 train acc 0.9392857142857143\n",
            "epoch 18 batch id 71 loss 0.22643904387950897 train acc 0.9392605633802817\n",
            "epoch 18 batch id 72 loss 0.13860562443733215 train acc 0.9390190972222222\n",
            "epoch 18 batch id 73 loss 0.25642862915992737 train acc 0.938570205479452\n",
            "epoch 18 batch id 74 loss 0.22317978739738464 train acc 0.9387668918918919\n",
            "epoch 18 batch id 75 loss 0.15302512049674988 train acc 0.93875\n",
            "epoch 18 batch id 76 loss 0.3320885896682739 train acc 0.9389391447368421\n",
            "epoch 18 batch id 77 loss 0.13525651395320892 train acc 0.9393262987012987\n",
            "epoch 18 batch id 78 loss 0.05691830441355705 train acc 0.9399038461538461\n",
            "epoch 18 batch id 79 loss 0.28643998503685 train acc 0.9396756329113924\n",
            "epoch 18 batch id 80 loss 0.082610122859478 train acc 0.9400390625\n",
            "epoch 18 batch id 81 loss 0.2489939033985138 train acc 0.939429012345679\n",
            "epoch 18 batch id 82 loss 0.11426302045583725 train acc 0.9395960365853658\n",
            "epoch 18 batch id 83 loss 0.18084895610809326 train acc 0.9397590361445783\n",
            "epoch 18 batch id 84 loss 0.32590252161026 train acc 0.9395461309523809\n",
            "epoch 18 batch id 85 loss 0.24725650250911713 train acc 0.939889705882353\n",
            "epoch 18 batch id 86 loss 0.14912787079811096 train acc 0.9400436046511628\n",
            "epoch 18 batch id 87 loss 0.22909648716449738 train acc 0.9401939655172413\n",
            "epoch 18 batch id 88 loss 0.2059391438961029 train acc 0.9399857954545454\n",
            "epoch 18 batch id 89 loss 0.20360155403614044 train acc 0.9397823033707865\n",
            "epoch 18 batch id 90 loss 0.43055570125579834 train acc 0.9394097222222222\n",
            "epoch 18 batch id 91 loss 0.27492183446884155 train acc 0.939217032967033\n",
            "epoch 18 batch id 92 loss 0.4783545136451721 train acc 0.9383491847826086\n",
            "epoch 18 batch id 93 loss 0.3066556453704834 train acc 0.9383400537634409\n",
            "epoch 18 batch id 94 loss 0.41108784079551697 train acc 0.9376662234042553\n",
            "epoch 18 batch id 95 loss 0.18015258014202118 train acc 0.937828947368421\n",
            "epoch 18 batch id 96 loss 0.26017603278160095 train acc 0.9378255208333334\n",
            "epoch 18 batch id 97 loss 0.4709565341472626 train acc 0.9366945876288659\n",
            "epoch 18 batch id 98 loss 0.44853082299232483 train acc 0.9360650510204082\n",
            "epoch 18 batch id 99 loss 0.36997127532958984 train acc 0.9354482323232324\n",
            "epoch 18 batch id 100 loss 0.20064842700958252 train acc 0.935625\n",
            "epoch 18 batch id 101 loss 0.28366678953170776 train acc 0.9356435643564357\n",
            "epoch 18 batch id 102 loss 0.24402302503585815 train acc 0.9352022058823529\n",
            "epoch 18 batch id 103 loss 0.2065904289484024 train acc 0.9355279126213593\n",
            "epoch 18 batch id 104 loss 0.38757890462875366 train acc 0.9350961538461539\n",
            "epoch 18 batch id 105 loss 0.06592046469449997 train acc 0.9357142857142857\n",
            "epoch 18 batch id 106 loss 0.30802276730537415 train acc 0.9351415094339622\n",
            "epoch 18 batch id 107 loss 0.16504769027233124 train acc 0.9353095794392523\n",
            "epoch 18 batch id 108 loss 0.2006261795759201 train acc 0.9353298611111112\n",
            "epoch 18 batch id 109 loss 0.21994104981422424 train acc 0.9353497706422018\n",
            "epoch 18 batch id 110 loss 0.21678589284420013 train acc 0.9352272727272727\n",
            "epoch 18 batch id 111 loss 0.28582853078842163 train acc 0.9351069819819819\n",
            "epoch 18 batch id 112 loss 0.1918942928314209 train acc 0.9352678571428571\n",
            "epoch 18 batch id 113 loss 0.2076958417892456 train acc 0.9350110619469026\n",
            "epoch 18 batch id 114 loss 0.21203301846981049 train acc 0.9353070175438597\n",
            "epoch 18 batch id 115 loss 0.45501095056533813 train acc 0.9347826086956522\n",
            "epoch 18 batch id 116 loss 0.10420994460582733 train acc 0.9349407327586207\n",
            "epoch 18 batch id 117 loss 0.2734659016132355 train acc 0.9350961538461539\n",
            "epoch 18 batch id 118 loss 0.09544795751571655 train acc 0.9355137711864406\n",
            "epoch 18 batch id 119 loss 0.17747950553894043 train acc 0.9353991596638656\n",
            "epoch 18 batch id 120 loss 0.26177188754081726 train acc 0.93515625\n",
            "epoch 18 batch id 121 loss 0.2399376630783081 train acc 0.9351756198347108\n",
            "epoch 18 batch id 122 loss 0.19034035503864288 train acc 0.9351946721311475\n",
            "epoch 18 batch id 123 loss 0.530734121799469 train acc 0.9345782520325203\n",
            "epoch 18 batch id 124 loss 0.19524838030338287 train acc 0.9347278225806451\n",
            "epoch 18 batch id 125 loss 0.18269336223602295 train acc 0.935\n",
            "epoch 18 batch id 126 loss 0.08096015453338623 train acc 0.9353918650793651\n",
            "epoch 18 batch id 127 loss 0.3438987731933594 train acc 0.9354084645669292\n",
            "epoch 18 batch id 128 loss 0.08599293977022171 train acc 0.935791015625\n",
            "epoch 18 batch id 129 loss 0.44337499141693115 train acc 0.9354408914728682\n",
            "epoch 18 batch id 130 loss 0.17780908942222595 train acc 0.9356971153846154\n",
            "epoch 18 batch id 131 loss 0.1633833348751068 train acc 0.9358301526717557\n",
            "epoch 18 batch id 132 loss 0.3697539269924164 train acc 0.9354876893939394\n",
            "epoch 18 batch id 133 loss 0.22020207345485687 train acc 0.9355028195488722\n",
            "epoch 18 batch id 134 loss 0.37197345495224 train acc 0.9352845149253731\n",
            "epoch 18 batch id 135 loss 0.09344098716974258 train acc 0.9355324074074074\n",
            "epoch 18 batch id 136 loss 0.1782604604959488 train acc 0.9357766544117647\n",
            "epoch 18 batch id 137 loss 0.3059331476688385 train acc 0.9355611313868614\n",
            "epoch 18 batch id 138 loss 0.189686119556427 train acc 0.9358016304347826\n",
            "epoch 18 batch id 139 loss 0.15053991973400116 train acc 0.9359262589928058\n",
            "epoch 18 batch id 140 loss 0.20886848866939545 train acc 0.9360491071428572\n",
            "epoch 18 batch id 141 loss 0.20470976829528809 train acc 0.9359485815602837\n",
            "epoch 18 batch id 142 loss 0.15134680271148682 train acc 0.9361795774647887\n",
            "epoch 18 batch id 143 loss 0.2099992334842682 train acc 0.9360795454545454\n",
            "epoch 18 batch id 144 loss 0.3883192539215088 train acc 0.9356553819444444\n",
            "epoch 18 batch id 145 loss 0.15249516069889069 train acc 0.9357758620689656\n",
            "epoch 18 batch id 146 loss 0.22069051861763 train acc 0.9357876712328768\n",
            "epoch 18 batch id 147 loss 0.15625110268592834 train acc 0.9361181972789115\n",
            "epoch 18 batch id 148 loss 0.21652548015117645 train acc 0.9361275337837838\n",
            "epoch 18 batch id 149 loss 0.21989384293556213 train acc 0.9363464765100671\n",
            "epoch 18 batch id 150 loss 0.08255913853645325 train acc 0.9367708333333333\n",
            "epoch 18 batch id 151 loss 0.060462601482868195 train acc 0.9371895695364238\n",
            "epoch 18 batch id 152 loss 0.09076478332281113 train acc 0.9375\n",
            "epoch 18 batch id 153 loss 0.191597118973732 train acc 0.9373978758169934\n",
            "epoch 18 batch id 154 loss 0.11327029019594193 train acc 0.937601461038961\n",
            "epoch 18 batch id 155 loss 0.22798234224319458 train acc 0.9377016129032258\n",
            "epoch 18 batch id 156 loss 0.20174983143806458 train acc 0.9377003205128205\n",
            "epoch 18 batch id 157 loss 0.23582704365253448 train acc 0.9376990445859873\n",
            "epoch 18 batch id 158 loss 0.2136382907629013 train acc 0.9377966772151899\n",
            "epoch 18 batch id 159 loss 0.14730116724967957 train acc 0.9380896226415094\n",
            "epoch 18 batch id 160 loss 0.05638986825942993 train acc 0.93837890625\n",
            "epoch 18 batch id 161 loss 0.24958094954490662 train acc 0.9382763975155279\n",
            "epoch 18 batch id 162 loss 0.16349823772907257 train acc 0.9381751543209876\n",
            "epoch 18 batch id 163 loss 0.2403811514377594 train acc 0.9380751533742331\n",
            "epoch 18 batch id 164 loss 0.2943533658981323 train acc 0.9379763719512195\n",
            "epoch 18 batch id 165 loss 0.21539266407489777 train acc 0.9382575757575757\n",
            "epoch 18 batch id 166 loss 0.11780064553022385 train acc 0.9385353915662651\n",
            "epoch 18 batch id 167 loss 0.24752627313137054 train acc 0.938622754491018\n",
            "epoch 18 batch id 168 loss 0.2442324459552765 train acc 0.9385230654761905\n",
            "epoch 18 batch id 169 loss 0.2728130519390106 train acc 0.9387019230769231\n",
            "epoch 18 batch id 170 loss 0.1344330608844757 train acc 0.9387867647058824\n",
            "epoch 18 batch id 171 loss 0.05931133031845093 train acc 0.9390533625730995\n",
            "epoch 18 batch id 172 loss 0.13584506511688232 train acc 0.9392260174418605\n",
            "epoch 18 batch id 173 loss 0.19251279532909393 train acc 0.939396676300578\n",
            "epoch 18 batch id 174 loss 0.11356651037931442 train acc 0.9396551724137931\n",
            "epoch 18 batch id 175 loss 0.39451169967651367 train acc 0.939375\n",
            "epoch 18 batch id 176 loss 0.2861086130142212 train acc 0.9392755681818182\n",
            "epoch 18 batch id 177 loss 0.2573026418685913 train acc 0.9392655367231638\n",
            "epoch 18 batch id 178 loss 0.18418438732624054 train acc 0.9393433988764045\n",
            "epoch 18 batch id 179 loss 0.11663965880870819 train acc 0.9395076815642458\n",
            "epoch 18 batch id 180 loss 0.2796420753002167 train acc 0.9394965277777778\n",
            "epoch 18 batch id 181 loss 0.36207669973373413 train acc 0.9392265193370166\n",
            "epoch 18 batch id 182 loss 0.15252654254436493 train acc 0.9393028846153846\n",
            "epoch 18 batch id 183 loss 0.262708455324173 train acc 0.9391222677595629\n",
            "epoch 18 batch id 184 loss 0.2924480736255646 train acc 0.9387737771739131\n",
            "epoch 18 batch id 185 loss 0.1990136057138443 train acc 0.9389358108108108\n",
            "epoch 18 batch id 186 loss 0.2792014479637146 train acc 0.9389280913978495\n",
            "epoch 18 batch id 187 loss 0.2724757492542267 train acc 0.9389204545454546\n",
            "epoch 18 batch id 188 loss 0.24656306207180023 train acc 0.9389960106382979\n",
            "epoch 18 batch id 189 loss 0.1847504824399948 train acc 0.9389880952380952\n",
            "epoch 18 batch id 190 loss 0.3597555160522461 train acc 0.9388980263157894\n",
            "epoch 18 batch id 191 loss 0.35222381353378296 train acc 0.9388089005235603\n",
            "epoch 18 batch id 192 loss 0.11709211766719818 train acc 0.93896484375\n",
            "epoch 18 batch id 193 loss 0.19194740056991577 train acc 0.9389572538860104\n",
            "epoch 18 batch id 194 loss 0.2908589839935303 train acc 0.938708118556701\n",
            "epoch 18 batch id 195 loss 0.2844388484954834 train acc 0.9384615384615385\n",
            "epoch 18 batch id 196 loss 0.16046689450740814 train acc 0.9386957908163265\n",
            "epoch 18 batch id 197 loss 0.2384953796863556 train acc 0.9386104060913706\n",
            "epoch 18 batch id 198 loss 0.12723545730113983 train acc 0.9386837121212122\n",
            "epoch 18 batch id 199 loss 0.23124291002750397 train acc 0.9386777638190955\n",
            "epoch 18 batch id 200 loss 0.1092989519238472 train acc 0.93890625\n",
            "epoch 18 batch id 201 loss 0.2323209047317505 train acc 0.9388215174129353\n",
            "epoch 18 batch id 202 loss 0.4968946576118469 train acc 0.9387376237623762\n",
            "epoch 18 batch id 203 loss 0.21216577291488647 train acc 0.9386545566502463\n",
            "epoch 18 batch id 204 loss 0.1119447723031044 train acc 0.9388020833333334\n",
            "epoch 18 batch id 205 loss 0.16218909621238708 train acc 0.938719512195122\n",
            "epoch 18 batch id 206 loss 0.1826697289943695 train acc 0.9387135922330098\n",
            "epoch 18 batch id 207 loss 0.35191696882247925 train acc 0.9386322463768116\n",
            "epoch 18 batch id 208 loss 0.19736117124557495 train acc 0.9387019230769231\n",
            "epoch 18 batch id 209 loss 0.09500235319137573 train acc 0.9388456937799043\n",
            "epoch 18 batch id 210 loss 0.16340960562229156 train acc 0.9388392857142858\n",
            "epoch 18 batch id 211 loss 0.3742797374725342 train acc 0.9386848341232228\n",
            "epoch 18 batch id 212 loss 0.2453894466161728 train acc 0.9386792452830188\n",
            "epoch 18 batch id 213 loss 0.13667288422584534 train acc 0.9386737089201878\n",
            "epoch 18 batch id 214 loss 0.11729162186384201 train acc 0.9388142523364486\n",
            "epoch 18 batch id 215 loss 0.3862253725528717 train acc 0.9385901162790697\n",
            "epoch 18 batch id 216 loss 0.21364499628543854 train acc 0.9384403935185185\n",
            "epoch 18 batch id 217 loss 0.175736203789711 train acc 0.938508064516129\n",
            "epoch 18 batch id 218 loss 0.17386433482170105 train acc 0.9385751146788991\n",
            "epoch 18 batch id 219 loss 0.2615816593170166 train acc 0.9384275114155252\n",
            "epoch 18 batch id 220 loss 0.11067590117454529 train acc 0.9385653409090909\n",
            "epoch 18 batch id 221 loss 0.19254781305789948 train acc 0.938560520361991\n",
            "epoch 18 batch id 222 loss 0.10954173654317856 train acc 0.9387668918918919\n",
            "epoch 18 batch id 223 loss 0.07254286110401154 train acc 0.9389013452914798\n",
            "epoch 18 batch id 224 loss 0.15574271976947784 train acc 0.93896484375\n",
            "epoch 18 batch id 225 loss 0.48300600051879883 train acc 0.9386805555555555\n",
            "epoch 18 batch id 226 loss 0.13658565282821655 train acc 0.9387444690265486\n",
            "epoch 18 batch id 227 loss 0.3357883393764496 train acc 0.9385324889867841\n",
            "epoch 18 batch id 228 loss 0.27589407563209534 train acc 0.9383223684210527\n",
            "epoch 18 batch id 229 loss 0.06231628730893135 train acc 0.9385234716157205\n",
            "epoch 18 batch id 230 loss 0.17793679237365723 train acc 0.9385869565217392\n",
            "epoch 18 batch id 231 loss 0.17742355167865753 train acc 0.9386498917748918\n",
            "epoch 18 batch id 232 loss 0.39657706022262573 train acc 0.9384428879310345\n",
            "epoch 18 batch id 233 loss 0.1536542922258377 train acc 0.9385729613733905\n",
            "epoch 18 batch id 234 loss 0.2042233794927597 train acc 0.9385683760683761\n",
            "epoch 18 batch id 235 loss 0.24769246578216553 train acc 0.9385638297872341\n",
            "epoch 18 batch id 236 loss 0.274518758058548 train acc 0.9385593220338984\n",
            "epoch 18 batch id 237 loss 0.28005239367485046 train acc 0.9385548523206751\n",
            "epoch 18 batch id 238 loss 0.21519431471824646 train acc 0.9386160714285714\n",
            "epoch 18 batch id 239 loss 0.13203637301921844 train acc 0.9386767782426778\n",
            "epoch 18 batch id 240 loss 0.14664104580879211 train acc 0.9388020833333334\n",
            "epoch 18 batch id 241 loss 0.1983383148908615 train acc 0.9388615145228216\n",
            "epoch 18 batch id 242 loss 0.40097033977508545 train acc 0.9385976239669421\n",
            "epoch 18 batch id 243 loss 0.2702866196632385 train acc 0.9385931069958847\n",
            "epoch 18 batch id 244 loss 0.3952590525150299 train acc 0.9383965163934426\n",
            "epoch 18 batch id 245 loss 0.1866575926542282 train acc 0.9384566326530612\n",
            "epoch 18 batch id 246 loss 0.16243071854114532 train acc 0.9385797764227642\n",
            "epoch 18 batch id 247 loss 0.1714746505022049 train acc 0.9385754048582996\n",
            "epoch 18 batch id 248 loss 0.1678783893585205 train acc 0.9386970766129032\n",
            "epoch 18 batch id 249 loss 0.27920371294021606 train acc 0.9386295180722891\n",
            "epoch 18 batch id 250 loss 0.16740944981575012 train acc 0.938625\n",
            "epoch 18 batch id 251 loss 0.2395833134651184 train acc 0.938496015936255\n",
            "epoch 18 batch id 252 loss 0.1509852409362793 train acc 0.9385540674603174\n",
            "epoch 18 batch id 253 loss 0.2674832046031952 train acc 0.9384881422924901\n",
            "epoch 18 batch id 254 loss 0.24818339943885803 train acc 0.9384842519685039\n",
            "epoch 18 batch id 255 loss 0.14457935094833374 train acc 0.9385416666666667\n",
            "epoch 18 batch id 256 loss 0.25412991642951965 train acc 0.9384765625\n",
            "epoch 18 batch id 257 loss 0.1406533122062683 train acc 0.9385943579766537\n",
            "epoch 18 batch id 258 loss 0.17944537103176117 train acc 0.9385295542635659\n",
            "epoch 18 batch id 259 loss 0.16861721873283386 train acc 0.9385255791505791\n",
            "epoch 18 batch id 260 loss 0.1508781611919403 train acc 0.9385817307692308\n",
            "epoch 18 batch id 261 loss 0.11079203337430954 train acc 0.9386374521072797\n",
            "epoch 18 batch id 262 loss 0.20536087453365326 train acc 0.9386331106870229\n",
            "epoch 18 batch id 263 loss 0.2579229474067688 train acc 0.9386288022813688\n",
            "epoch 18 batch id 264 loss 0.4153711795806885 train acc 0.9384469696969697\n",
            "epoch 18 batch id 265 loss 0.09881941229104996 train acc 0.938561320754717\n",
            "epoch 18 batch id 266 loss 0.046728745102882385 train acc 0.9387922932330827\n",
            "epoch 18 batch id 267 loss 0.11521411687135696 train acc 0.9388459737827716\n",
            "epoch 18 batch id 268 loss 0.20990805327892303 train acc 0.9388409514925373\n",
            "epoch 18 batch id 269 loss 0.3077130913734436 train acc 0.9387778810408922\n",
            "epoch 18 batch id 270 loss 0.19697223603725433 train acc 0.9388310185185185\n",
            "epoch 18 batch id 271 loss 0.21386294066905975 train acc 0.9389414206642066\n",
            "epoch 18 batch id 272 loss 0.3749704658985138 train acc 0.9388786764705882\n",
            "epoch 18 batch id 273 loss 0.10324841737747192 train acc 0.9390453296703297\n",
            "epoch 18 batch id 274 loss 0.16999801993370056 train acc 0.9390396897810219\n",
            "epoch 18 batch id 275 loss 0.2333776205778122 train acc 0.9389772727272727\n",
            "epoch 18 batch id 276 loss 0.24917173385620117 train acc 0.9390285326086957\n",
            "epoch 18 batch id 277 loss 0.15392999351024628 train acc 0.9390230144404332\n",
            "epoch 18 batch id 278 loss 0.14533741772174835 train acc 0.9391299460431655\n",
            "epoch 18 batch id 279 loss 0.11543866246938705 train acc 0.9392361111111112\n",
            "epoch 18 batch id 280 loss 0.1768881380558014 train acc 0.9392299107142857\n",
            "epoch 18 batch id 281 loss 0.1556146889925003 train acc 0.9393349644128114\n",
            "epoch 18 batch id 282 loss 0.11919483542442322 train acc 0.9394392730496454\n",
            "epoch 18 batch id 283 loss 0.1059691458940506 train acc 0.9395428445229682\n",
            "epoch 18 batch id 284 loss 0.24594736099243164 train acc 0.9395906690140845\n",
            "epoch 18 batch id 285 loss 0.35230714082717896 train acc 0.9394188596491229\n",
            "epoch 18 batch id 286 loss 0.23759371042251587 train acc 0.9393575174825175\n",
            "epoch 18 batch id 287 loss 0.33232352137565613 train acc 0.9391877177700348\n",
            "epoch 18 batch id 288 loss 0.3862452805042267 train acc 0.9391276041666666\n",
            "epoch 18 batch id 289 loss 0.5293011665344238 train acc 0.9389597750865052\n",
            "epoch 18 batch id 290 loss 0.028806570917367935 train acc 0.9391702586206897\n",
            "epoch 18 batch id 291 loss 0.21520325541496277 train acc 0.9392719072164949\n",
            "epoch 18 batch id 292 loss 0.17666371166706085 train acc 0.9393193493150684\n",
            "epoch 18 batch id 293 loss 0.07387319952249527 train acc 0.9394731228668942\n",
            "epoch 18 batch id 294 loss 0.2419707030057907 train acc 0.9393601190476191\n",
            "epoch 18 batch id 295 loss 0.2708626985549927 train acc 0.9393008474576271\n",
            "epoch 18 batch id 296 loss 0.31951382756233215 train acc 0.939136402027027\n",
            "epoch 18 batch id 297 loss 0.30252164602279663 train acc 0.9390782828282829\n",
            "epoch 18 batch id 298 loss 0.08996311575174332 train acc 0.9392302852348994\n",
            "epoch 18 batch id 299 loss 0.2156955599784851 train acc 0.9391722408026756\n",
            "epoch 18 batch id 300 loss 0.3391002416610718 train acc 0.9390625\n",
            "epoch 18 batch id 301 loss 0.07721571624279022 train acc 0.9391611295681063\n",
            "epoch 18 batch id 302 loss 0.12131232768297195 train acc 0.9392073675496688\n",
            "epoch 18 batch id 303 loss 0.13061094284057617 train acc 0.9393048679867987\n",
            "epoch 18 batch id 304 loss 0.22958076000213623 train acc 0.9393503289473685\n",
            "epoch 18 batch id 305 loss 0.15960830450057983 train acc 0.9394467213114754\n",
            "epoch 18 batch id 306 loss 0.07569041103124619 train acc 0.939593545751634\n",
            "epoch 18 batch id 307 loss 0.1697709709405899 train acc 0.9396376221498371\n",
            "epoch 18 batch id 308 loss 0.14074456691741943 train acc 0.9397321428571429\n",
            "epoch 18 batch id 309 loss 0.2655078172683716 train acc 0.939674352750809\n",
            "epoch 18 batch id 310 loss 0.23590026795864105 train acc 0.9395161290322581\n",
            "epoch 18 batch id 311 loss 0.07991857081651688 train acc 0.9397106109324759\n",
            "epoch 18 batch id 312 loss 0.1915617734193802 train acc 0.9397536057692307\n",
            "epoch 18 batch id 313 loss 0.42590489983558655 train acc 0.9395966453674122\n",
            "epoch 18 batch id 314 loss 0.33384737372398376 train acc 0.9394406847133758\n",
            "epoch 18 batch id 315 loss 0.35943910479545593 train acc 0.9393849206349206\n",
            "epoch 18 batch id 316 loss 0.519372820854187 train acc 0.9392306170886076\n",
            "epoch 18 batch id 317 loss 0.2989221215248108 train acc 0.9391265772870663\n",
            "epoch 18 batch id 318 loss 0.08389174938201904 train acc 0.9391705974842768\n",
            "epoch 18 batch id 319 loss 0.13291478157043457 train acc 0.93921434169279\n",
            "epoch 18 batch id 320 loss 0.1425832360982895 train acc 0.939306640625\n",
            "epoch 18 batch id 321 loss 0.11041350662708282 train acc 0.9394470404984424\n",
            "epoch 18 batch id 322 loss 0.2018449902534485 train acc 0.9395380434782609\n",
            "epoch 18 batch id 323 loss 0.4865283668041229 train acc 0.9393382352941176\n",
            "epoch 18 batch id 324 loss 0.2646870017051697 train acc 0.9393325617283951\n",
            "epoch 18 batch id 325 loss 0.09702537208795547 train acc 0.9394230769230769\n",
            "epoch 18 batch id 326 loss 0.30367913842201233 train acc 0.9393213190184049\n",
            "epoch 18 batch id 327 loss 0.18036483228206635 train acc 0.9394590978593272\n",
            "epoch 18 batch id 328 loss 0.2599295377731323 train acc 0.9394054878048781\n",
            "epoch 18 batch id 329 loss 0.07715170830488205 train acc 0.9395896656534954\n",
            "epoch 18 batch id 330 loss 0.3100254535675049 train acc 0.9393939393939394\n",
            "epoch 18 batch id 331 loss 0.38567596673965454 train acc 0.9392466012084593\n",
            "epoch 18 batch id 332 loss 0.14181900024414062 train acc 0.9393825301204819\n",
            "epoch 18 batch id 333 loss 0.20063048601150513 train acc 0.9393768768768769\n",
            "epoch 18 batch id 334 loss 0.3372414708137512 train acc 0.9392776946107785\n",
            "epoch 18 batch id 335 loss 0.17452068626880646 train acc 0.9393656716417911\n",
            "epoch 18 batch id 336 loss 0.11034438014030457 train acc 0.939453125\n",
            "epoch 18 batch id 337 loss 0.19643384218215942 train acc 0.939540059347181\n",
            "epoch 18 batch id 338 loss 0.33520448207855225 train acc 0.939534023668639\n",
            "epoch 18 batch id 339 loss 0.06792905926704407 train acc 0.9396202064896755\n",
            "epoch 18 batch id 340 loss 0.07605119794607162 train acc 0.9397058823529412\n",
            "epoch 18 batch id 341 loss 0.08814629912376404 train acc 0.9397910557184751\n",
            "epoch 18 batch id 342 loss 0.14446374773979187 train acc 0.9397386695906432\n",
            "epoch 18 batch id 343 loss 0.3486565053462982 train acc 0.9397321428571429\n",
            "epoch 18 batch id 344 loss 0.09003103524446487 train acc 0.9398164970930233\n",
            "epoch 18 batch id 345 loss 0.19543878734111786 train acc 0.9397644927536232\n",
            "epoch 18 batch id 346 loss 0.247161403298378 train acc 0.9398031069364162\n",
            "epoch 18 batch id 347 loss 0.22699588537216187 train acc 0.9397514409221902\n",
            "epoch 18 batch id 348 loss 0.20357930660247803 train acc 0.9398347701149425\n",
            "epoch 18 batch id 349 loss 0.4593830704689026 train acc 0.9397385386819485\n",
            "epoch 18 batch id 350 loss 0.370670348405838 train acc 0.9396428571428571\n",
            "epoch 18 batch id 351 loss 0.3348568081855774 train acc 0.9394586894586895\n",
            "epoch 18 batch id 352 loss 0.12255191057920456 train acc 0.9394975142045454\n",
            "epoch 18 batch id 353 loss 0.19681508839130402 train acc 0.93953611898017\n",
            "epoch 18 batch id 354 loss 0.1714027374982834 train acc 0.9395303672316384\n",
            "epoch 18 batch id 355 loss 0.10517705231904984 train acc 0.939612676056338\n",
            "epoch 18 batch id 356 loss 0.30400344729423523 train acc 0.9396067415730337\n",
            "epoch 18 batch id 357 loss 0.19447025656700134 train acc 0.9396446078431373\n",
            "epoch 18 batch id 358 loss 0.21985484659671783 train acc 0.9395949720670391\n",
            "epoch 18 batch id 359 loss 0.2786444425582886 train acc 0.93945856545961\n",
            "epoch 18 batch id 360 loss 0.2677434980869293 train acc 0.9394965277777778\n",
            "epoch 18 batch id 361 loss 0.14097246527671814 train acc 0.9395775623268698\n",
            "epoch 18 batch id 362 loss 0.2315143346786499 train acc 0.9395718232044199\n",
            "epoch 18 batch id 363 loss 0.222280815243721 train acc 0.9396522038567493\n",
            "epoch 18 batch id 364 loss 0.23221145570278168 train acc 0.9397321428571429\n",
            "epoch 18 batch id 365 loss 0.1791210174560547 train acc 0.9398116438356164\n",
            "epoch 18 batch id 366 loss 0.23517563939094543 train acc 0.9398053278688525\n",
            "epoch 18 batch id 367 loss 0.11594345420598984 train acc 0.9398841961852861\n",
            "epoch 18 batch id 368 loss 0.36244627833366394 train acc 0.9397078804347826\n",
            "epoch 18 batch id 369 loss 0.16869038343429565 train acc 0.9398289295392954\n",
            "epoch 18 batch id 370 loss 0.0788264274597168 train acc 0.9399070945945946\n",
            "epoch 18 batch id 371 loss 0.1348937451839447 train acc 0.9399848382749326\n",
            "epoch 18 batch id 372 loss 0.14993926882743835 train acc 0.9400201612903226\n",
            "epoch 18 batch id 373 loss 0.06931297481060028 train acc 0.9401390750670241\n",
            "epoch 18 batch id 374 loss 0.1880541294813156 train acc 0.9402155748663101\n",
            "epoch 18 batch id 375 loss 0.3345073461532593 train acc 0.940125\n",
            "epoch 18 batch id 376 loss 0.18179817497730255 train acc 0.9401595744680851\n",
            "epoch 18 batch id 377 loss 0.13860073685646057 train acc 0.9402768567639257\n",
            "epoch 18 batch id 378 loss 0.14846989512443542 train acc 0.9403521825396826\n",
            "epoch 18 batch id 379 loss 0.28735384345054626 train acc 0.9402622031662269\n",
            "epoch 18 batch id 380 loss 0.19177088141441345 train acc 0.9402960526315789\n",
            "epoch 18 batch id 381 loss 0.23510359227657318 train acc 0.9402477034120735\n",
            "epoch 18 batch id 382 loss 0.21704775094985962 train acc 0.9402814136125655\n",
            "epoch 18 batch id 383 loss 0.08334971964359283 train acc 0.9403149477806788\n",
            "epoch 18 batch id 384 loss 0.024299053475260735 train acc 0.9404703776041666\n",
            "epoch 18 batch id 385 loss 0.10866791009902954 train acc 0.9405844155844156\n",
            "epoch 18 batch id 386 loss 0.2819550931453705 train acc 0.9404145077720207\n",
            "epoch 18 batch id 387 loss 0.18383432924747467 train acc 0.9404473514211886\n",
            "epoch 18 batch id 388 loss 0.254773885011673 train acc 0.9404800257731959\n",
            "epoch 18 batch id 389 loss 0.12825873494148254 train acc 0.9405125321336761\n",
            "epoch 18 batch id 390 loss 0.18797147274017334 train acc 0.9405849358974359\n",
            "epoch 18 batch id 391 loss 0.10794008523225784 train acc 0.940656969309463\n",
            "epoch 18 batch id 392 loss 0.27123498916625977 train acc 0.9406489158163265\n",
            "epoch 18 batch id 393 loss 0.17542047798633575 train acc 0.9406806615776081\n",
            "epoch 18 batch id 394 loss 0.2673906683921814 train acc 0.9407122461928934\n",
            "epoch 18 batch id 395 loss 0.3808067739009857 train acc 0.940625\n",
            "epoch 18 batch id 396 loss 0.2516096830368042 train acc 0.9406171085858586\n",
            "epoch 18 batch id 397 loss 0.09726380556821823 train acc 0.9406879722921915\n",
            "epoch 18 batch id 398 loss 0.10737797617912292 train acc 0.9407192211055276\n",
            "epoch 18 batch id 399 loss 0.4410437047481537 train acc 0.9407111528822055\n",
            "epoch 18 batch id 400 loss 0.29592663049697876 train acc 0.9407421875\n",
            "epoch 18 batch id 401 loss 0.18211372196674347 train acc 0.9408120324189526\n",
            "epoch 18 batch id 402 loss 0.376910924911499 train acc 0.9407260572139303\n",
            "epoch 18 batch id 403 loss 0.19432592391967773 train acc 0.9407180521091811\n",
            "epoch 18 batch id 404 loss 0.08088471740484238 train acc 0.9407874381188119\n",
            "epoch 18 batch id 405 loss 0.1392330825328827 train acc 0.9408564814814815\n",
            "epoch 18 batch id 406 loss 0.1216672733426094 train acc 0.9408866995073891\n",
            "epoch 18 batch id 407 loss 0.5127301812171936 train acc 0.9406864250614251\n",
            "epoch 18 batch id 408 loss 0.36691737174987793 train acc 0.9405254289215687\n",
            "epoch 18 batch id 409 loss 0.1407058835029602 train acc 0.9405180317848411\n",
            "epoch 18 batch id 410 loss 0.13572166860103607 train acc 0.9405106707317074\n",
            "epoch 18 batch id 411 loss 0.26237329840660095 train acc 0.9405413625304136\n",
            "epoch 18 batch id 412 loss 0.14757248759269714 train acc 0.9405719053398058\n",
            "epoch 18 batch id 413 loss 0.09677007794380188 train acc 0.9406401331719129\n",
            "epoch 18 batch id 414 loss 0.21899545192718506 train acc 0.940594806763285\n",
            "epoch 18 batch id 415 loss 0.4304499328136444 train acc 0.9405496987951807\n",
            "epoch 18 batch id 416 loss 0.3218507468700409 train acc 0.9405048076923077\n",
            "epoch 18 batch id 417 loss 0.304116427898407 train acc 0.9404976019184652\n",
            "epoch 18 batch id 418 loss 0.23959484696388245 train acc 0.9404904306220095\n",
            "epoch 18 batch id 419 loss 0.09887917339801788 train acc 0.9405578758949881\n",
            "epoch 18 batch id 420 loss 0.22630557417869568 train acc 0.9404761904761905\n",
            "epoch 18 batch id 421 loss 0.1895831823348999 train acc 0.9405062351543944\n",
            "epoch 18 batch id 422 loss 0.13741827011108398 train acc 0.940573163507109\n",
            "epoch 18 batch id 423 loss 0.1861172616481781 train acc 0.9406028368794326\n",
            "epoch 18 batch id 424 loss 0.2708139717578888 train acc 0.9405586674528302\n",
            "epoch 18 batch id 425 loss 0.3130534291267395 train acc 0.9405882352941176\n",
            "epoch 18 batch id 426 loss 0.17992039024829865 train acc 0.940580985915493\n",
            "epoch 18 batch id 427 loss 0.11027634888887405 train acc 0.9406469555035128\n",
            "epoch 18 batch id 428 loss 0.1291709691286087 train acc 0.9407491238317757\n",
            "epoch 18 batch id 429 loss 0.09364529699087143 train acc 0.9408143939393939\n",
            "epoch 18 batch id 430 loss 0.18146802484989166 train acc 0.9408430232558139\n",
            "epoch 18 batch id 431 loss 0.27876096963882446 train acc 0.9408352668213457\n",
            "epoch 18 batch id 432 loss 0.08667413890361786 train acc 0.9408998842592593\n",
            "epoch 18 batch id 433 loss 0.11057437211275101 train acc 0.94092811778291\n",
            "epoch 18 batch id 434 loss 0.12502318620681763 train acc 0.9409562211981567\n",
            "epoch 18 batch id 435 loss 0.1817874014377594 train acc 0.9410560344827587\n",
            "epoch 18 batch id 436 loss 0.22218674421310425 train acc 0.9410120412844036\n",
            "epoch 18 batch id 437 loss 0.1251002848148346 train acc 0.9410397597254004\n",
            "epoch 18 batch id 438 loss 0.15673796832561493 train acc 0.9410673515981736\n",
            "epoch 18 batch id 439 loss 0.12375222146511078 train acc 0.9411304100227791\n",
            "epoch 18 batch id 440 loss 0.3632708489894867 train acc 0.941015625\n",
            "epoch 18 batch id 441 loss 0.09532022476196289 train acc 0.941078514739229\n",
            "epoch 18 batch id 442 loss 0.18016210198402405 train acc 0.9410350678733032\n",
            "epoch 18 batch id 443 loss 0.39838117361068726 train acc 0.9409212753950339\n",
            "epoch 18 batch id 444 loss 0.16874529421329498 train acc 0.9409135698198198\n",
            "epoch 18 batch id 445 loss 0.517997682094574 train acc 0.9408356741573034\n",
            "epoch 18 batch id 446 loss 0.1771056205034256 train acc 0.9408982623318386\n",
            "epoch 18 batch id 447 loss 0.45200473070144653 train acc 0.9407857941834452\n",
            "epoch 18 batch id 448 loss 0.07694943249225616 train acc 0.9408830915178571\n",
            "epoch 18 batch id 449 loss 0.2481752634048462 train acc 0.9408407572383074\n",
            "epoch 18 batch id 450 loss 0.2031097412109375 train acc 0.9407986111111111\n",
            "epoch 18 batch id 451 loss 0.13121794164180756 train acc 0.9408259423503326\n",
            "epoch 18 batch id 452 loss 0.09900099039077759 train acc 0.940887721238938\n",
            "epoch 18 batch id 453 loss 0.3751057982444763 train acc 0.9408112582781457\n",
            "epoch 18 batch id 454 loss 0.05427365377545357 train acc 0.9409416299559471\n",
            "epoch 18 batch id 455 loss 0.11871186643838882 train acc 0.9409684065934066\n",
            "epoch 18 batch id 456 loss 0.2303367555141449 train acc 0.9408922697368421\n",
            "epoch 18 batch id 457 loss 0.11594023555517197 train acc 0.9409874179431073\n",
            "epoch 18 batch id 458 loss 0.23493659496307373 train acc 0.9409798034934498\n",
            "epoch 18 batch id 459 loss 0.3361767530441284 train acc 0.9408700980392157\n",
            "epoch 18 batch id 460 loss 0.06883163005113602 train acc 0.9409646739130435\n",
            "epoch 18 batch id 461 loss 0.2707514762878418 train acc 0.9409232646420824\n",
            "epoch 18 batch id 462 loss 0.17489919066429138 train acc 0.9409834956709957\n",
            "epoch 18 batch id 463 loss 0.17342306673526764 train acc 0.9410097192224622\n",
            "epoch 18 batch id 464 loss 0.151204451918602 train acc 0.9410021551724138\n",
            "epoch 18 batch id 465 loss 0.2503369152545929 train acc 0.9409274193548387\n",
            "epoch 18 batch id 466 loss 0.16682466864585876 train acc 0.9409535944206009\n",
            "epoch 18 batch id 467 loss 0.12186945229768753 train acc 0.9409796573875803\n",
            "epoch 18 batch id 468 loss 0.1973404884338379 train acc 0.9409388354700855\n",
            "epoch 18 batch id 469 loss 0.15899378061294556 train acc 0.9409648187633263\n",
            "epoch 18 batch id 470 loss 0.0797465592622757 train acc 0.9410571808510638\n",
            "epoch 18 batch id 471 loss 0.08492906391620636 train acc 0.9411159766454352\n",
            "epoch 18 batch id 472 loss 0.16699732840061188 train acc 0.9411414194915254\n",
            "epoch 18 batch id 473 loss 0.03272739425301552 train acc 0.9412658562367865\n",
            "epoch 18 batch id 474 loss 0.36395955085754395 train acc 0.9411590189873418\n",
            "epoch 18 batch id 475 loss 0.2588115632534027 train acc 0.9411184210526315\n",
            "epoch 18 batch id 476 loss 0.3742836117744446 train acc 0.9410123424369747\n",
            "epoch 18 batch id 477 loss 0.2651039958000183 train acc 0.9409722222222222\n",
            "epoch 18 batch id 478 loss 0.12923496961593628 train acc 0.9409976464435147\n",
            "epoch 18 batch id 479 loss 0.24593907594680786 train acc 0.9409577244258872\n",
            "epoch 18 batch id 480 loss 0.12476825714111328 train acc 0.9409830729166667\n",
            "epoch 18 batch id 481 loss 0.17167465388774872 train acc 0.9409758316008316\n",
            "epoch 18 batch id 482 loss 0.11282727122306824 train acc 0.9410658713692946\n",
            "epoch 18 batch id 483 loss 0.19622090458869934 train acc 0.9411231884057971\n",
            "epoch 18 batch id 484 loss 0.17942485213279724 train acc 0.9411157024793388\n",
            "epoch 18 batch id 485 loss 0.3529270589351654 train acc 0.9410115979381444\n",
            "epoch 18 batch id 486 loss 0.39775219559669495 train acc 0.9409400720164609\n",
            "epoch 18 batch id 487 loss 0.3162771165370941 train acc 0.9409009240246407\n",
            "epoch 18 batch id 488 loss 0.1370076686143875 train acc 0.9409900102459017\n",
            "epoch 18 batch id 489 loss 0.06701930612325668 train acc 0.9411106850715747\n",
            "epoch 18 batch id 490 loss 0.17914560437202454 train acc 0.9411670918367347\n",
            "epoch 18 batch id 491 loss 0.11139775067567825 train acc 0.9411914460285132\n",
            "epoch 18 batch id 492 loss 0.1930219829082489 train acc 0.9411839430894309\n",
            "epoch 18 batch id 493 loss 0.24324505031108856 train acc 0.9411130831643002\n",
            "epoch 18 batch id 494 loss 0.243266761302948 train acc 0.9411057692307693\n",
            "epoch 18 batch id 495 loss 0.24412885308265686 train acc 0.9410984848484848\n",
            "epoch 18 batch id 496 loss 0.3882775604724884 train acc 0.9410597278225806\n",
            "epoch 18 batch id 497 loss 0.09733729809522629 train acc 0.9411154426559356\n",
            "epoch 18 batch id 498 loss 0.3412735164165497 train acc 0.9410768072289156\n",
            "epoch 18 batch id 499 loss 0.0821414664387703 train acc 0.9411322645290581\n",
            "epoch 18 batch id 500 loss 0.4439466893672943 train acc 0.941125\n",
            "epoch 18 batch id 501 loss 0.31659260392189026 train acc 0.9411489520958084\n",
            "epoch 18 batch id 502 loss 0.3307451009750366 train acc 0.9410483067729084\n",
            "epoch 18 batch id 503 loss 0.1343783587217331 train acc 0.9411344433399602\n",
            "epoch 18 batch id 504 loss 0.24863700568675995 train acc 0.9410652281746031\n",
            "epoch 18 batch id 505 loss 0.19896113872528076 train acc 0.9410272277227723\n",
            "epoch 18 batch id 506 loss 0.22874781489372253 train acc 0.9410202569169961\n",
            "epoch 18 batch id 507 loss 0.23856379091739655 train acc 0.9410133136094675\n",
            "epoch 18 batch id 508 loss 0.07372873276472092 train acc 0.9410986712598425\n",
            "epoch 18 batch id 509 loss 0.20008668303489685 train acc 0.9411222986247544\n",
            "epoch 18 batch id 510 loss 0.19828523695468903 train acc 0.9411458333333333\n",
            "epoch 18 batch id 511 loss 0.06468484550714493 train acc 0.9412299451744168\n",
            "epoch 18 train acc 0.9412299451744168\n",
            "epoch 18 test acc 0.4003499348958333\n",
            "epoch 19 batch id 1 loss 0.18493208289146423 train acc 0.953125\n",
            "epoch 19 batch id 2 loss 0.24434462189674377 train acc 0.9375\n",
            "epoch 19 batch id 3 loss 0.18523642420768738 train acc 0.9427083333333334\n",
            "epoch 19 batch id 4 loss 0.07256175577640533 train acc 0.94921875\n",
            "epoch 19 batch id 5 loss 0.22497707605361938 train acc 0.946875\n",
            "epoch 19 batch id 6 loss 0.19501028954982758 train acc 0.9427083333333334\n",
            "epoch 19 batch id 7 loss 0.3407621383666992 train acc 0.9352678571428571\n",
            "epoch 19 batch id 8 loss 0.1567411571741104 train acc 0.9375\n",
            "epoch 19 batch id 9 loss 0.155867800116539 train acc 0.9409722222222222\n",
            "epoch 19 batch id 10 loss 0.11650604754686356 train acc 0.94375\n",
            "epoch 19 batch id 11 loss 0.25771182775497437 train acc 0.9431818181818182\n",
            "epoch 19 batch id 12 loss 0.2836115062236786 train acc 0.9388020833333334\n",
            "epoch 19 batch id 13 loss 0.4019264876842499 train acc 0.9350961538461539\n",
            "epoch 19 batch id 14 loss 0.1804969310760498 train acc 0.9363839285714286\n",
            "epoch 19 batch id 15 loss 0.056148238480091095 train acc 0.940625\n",
            "epoch 19 batch id 16 loss 0.065572589635849 train acc 0.9443359375\n",
            "epoch 19 batch id 17 loss 0.11565777659416199 train acc 0.9439338235294118\n",
            "epoch 19 batch id 18 loss 0.2466461956501007 train acc 0.9435763888888888\n",
            "epoch 19 batch id 19 loss 0.25162220001220703 train acc 0.9424342105263158\n",
            "epoch 19 batch id 20 loss 0.23714926838874817 train acc 0.94296875\n",
            "epoch 19 batch id 21 loss 0.13039524853229523 train acc 0.9434523809523809\n",
            "epoch 19 batch id 22 loss 0.15371312201023102 train acc 0.9446022727272727\n",
            "epoch 19 batch id 23 loss 0.3460808992385864 train acc 0.9422554347826086\n",
            "epoch 19 batch id 24 loss 0.17499104142189026 train acc 0.9427083333333334\n",
            "epoch 19 batch id 25 loss 0.11216147243976593 train acc 0.94375\n",
            "epoch 19 batch id 26 loss 0.10194794833660126 train acc 0.9447115384615384\n",
            "epoch 19 batch id 27 loss 0.19022643566131592 train acc 0.9444444444444444\n",
            "epoch 19 batch id 28 loss 0.23928774893283844 train acc 0.9436383928571429\n",
            "epoch 19 batch id 29 loss 0.18873269855976105 train acc 0.9439655172413793\n",
            "epoch 19 batch id 30 loss 0.1624741554260254 train acc 0.9432291666666667\n",
            "epoch 19 batch id 31 loss 0.18798460066318512 train acc 0.9430443548387096\n",
            "epoch 19 batch id 32 loss 0.1604836881160736 train acc 0.943359375\n",
            "epoch 19 batch id 33 loss 0.06522474437952042 train acc 0.9441287878787878\n",
            "epoch 19 batch id 34 loss 0.15084165334701538 train acc 0.9448529411764706\n",
            "epoch 19 batch id 35 loss 0.13378143310546875 train acc 0.9450892857142857\n",
            "epoch 19 batch id 36 loss 0.2519948482513428 train acc 0.9431423611111112\n",
            "epoch 19 batch id 37 loss 0.2198162078857422 train acc 0.9429898648648649\n",
            "epoch 19 batch id 38 loss 0.29375383257865906 train acc 0.9428453947368421\n",
            "epoch 19 batch id 39 loss 0.12377981841564178 train acc 0.9431089743589743\n",
            "epoch 19 batch id 40 loss 0.06732651591300964 train acc 0.944140625\n",
            "epoch 19 batch id 41 loss 0.13370175659656525 train acc 0.944359756097561\n",
            "epoch 19 batch id 42 loss 0.08063241094350815 train acc 0.9449404761904762\n",
            "epoch 19 batch id 43 loss 0.10876597464084625 train acc 0.9451308139534884\n",
            "epoch 19 batch id 44 loss 0.13147807121276855 train acc 0.9449573863636364\n",
            "epoch 19 batch id 45 loss 0.15428924560546875 train acc 0.9454861111111111\n",
            "epoch 19 batch id 46 loss 0.12707370519638062 train acc 0.9456521739130435\n",
            "epoch 19 batch id 47 loss 0.0984676331281662 train acc 0.9468085106382979\n",
            "epoch 19 batch id 48 loss 0.3161422312259674 train acc 0.9466145833333334\n",
            "epoch 19 batch id 49 loss 0.15024106204509735 train acc 0.9470663265306123\n",
            "epoch 19 batch id 50 loss 0.0689554214477539 train acc 0.9478125\n",
            "epoch 19 batch id 51 loss 0.24438877403736115 train acc 0.9482230392156863\n",
            "epoch 19 batch id 52 loss 0.29044267535209656 train acc 0.9483173076923077\n",
            "epoch 19 batch id 53 loss 0.1837267130613327 train acc 0.9484080188679245\n",
            "epoch 19 batch id 54 loss 0.2508071959018707 train acc 0.9482060185185185\n",
            "epoch 19 batch id 55 loss 0.4253849387168884 train acc 0.9471590909090909\n",
            "epoch 19 batch id 56 loss 0.18223139643669128 train acc 0.947265625\n",
            "epoch 19 batch id 57 loss 0.07445124536752701 train acc 0.9479166666666666\n",
            "epoch 19 batch id 58 loss 0.3678814768791199 train acc 0.947198275862069\n",
            "epoch 19 batch id 59 loss 0.24998266994953156 train acc 0.9465042372881356\n",
            "epoch 19 batch id 60 loss 0.1794717013835907 train acc 0.9466145833333334\n",
            "epoch 19 batch id 61 loss 0.357679545879364 train acc 0.945952868852459\n",
            "epoch 19 batch id 62 loss 0.23650968074798584 train acc 0.9458165322580645\n",
            "epoch 19 batch id 63 loss 0.27436363697052 train acc 0.9454365079365079\n",
            "epoch 19 batch id 64 loss 0.08310374617576599 train acc 0.946044921875\n",
            "epoch 19 batch id 65 loss 0.10315399616956711 train acc 0.9461538461538461\n",
            "epoch 19 batch id 66 loss 0.2583784759044647 train acc 0.9457859848484849\n",
            "epoch 19 batch id 67 loss 0.36453261971473694 train acc 0.9456623134328358\n",
            "epoch 19 batch id 68 loss 0.28947913646698 train acc 0.9453125\n",
            "epoch 19 batch id 69 loss 0.188385471701622 train acc 0.9451992753623188\n",
            "epoch 19 batch id 70 loss 0.3835638165473938 train acc 0.9446428571428571\n",
            "epoch 19 batch id 71 loss 0.16267001628875732 train acc 0.944762323943662\n",
            "epoch 19 batch id 72 loss 0.07397221773862839 train acc 0.9453125\n",
            "epoch 19 batch id 73 loss 0.2333606630563736 train acc 0.9452054794520548\n",
            "epoch 19 batch id 74 loss 0.2004626989364624 train acc 0.9451013513513513\n",
            "epoch 19 batch id 75 loss 0.07145056128501892 train acc 0.945625\n",
            "epoch 19 batch id 76 loss 0.2732720971107483 train acc 0.9451069078947368\n",
            "epoch 19 batch id 77 loss 0.17065881192684174 train acc 0.9450081168831169\n",
            "epoch 19 batch id 78 loss 0.10953959822654724 train acc 0.9451121794871795\n",
            "epoch 19 batch id 79 loss 0.11740681529045105 train acc 0.9452136075949367\n",
            "epoch 19 batch id 80 loss 0.25725308060646057 train acc 0.944140625\n",
            "epoch 19 batch id 81 loss 0.13333803415298462 train acc 0.9444444444444444\n",
            "epoch 19 batch id 82 loss 0.24455270171165466 train acc 0.944359756097561\n",
            "epoch 19 batch id 83 loss 0.10654456168413162 train acc 0.9442771084337349\n",
            "epoch 19 batch id 84 loss 0.09055804461240768 train acc 0.9445684523809523\n",
            "epoch 19 batch id 85 loss 0.10198020935058594 train acc 0.9450367647058824\n",
            "epoch 19 batch id 86 loss 0.5070788264274597 train acc 0.9442223837209303\n",
            "epoch 19 batch id 87 loss 0.15497943758964539 train acc 0.9445043103448276\n",
            "epoch 19 batch id 88 loss 0.1631147265434265 train acc 0.9447798295454546\n",
            "epoch 19 batch id 89 loss 0.14943362772464752 train acc 0.9452247191011236\n",
            "epoch 19 batch id 90 loss 0.20993681252002716 train acc 0.9449652777777777\n",
            "epoch 19 batch id 91 loss 0.26598623394966125 train acc 0.9448832417582418\n",
            "epoch 19 batch id 92 loss 0.06570178270339966 train acc 0.9453125\n",
            "epoch 19 batch id 93 loss 0.14586979150772095 train acc 0.9455645161290323\n",
            "epoch 19 batch id 94 loss 0.11187180876731873 train acc 0.945811170212766\n",
            "epoch 19 batch id 95 loss 0.12733246386051178 train acc 0.9460526315789474\n",
            "epoch 19 batch id 96 loss 0.1948356032371521 train acc 0.9462890625\n",
            "epoch 19 batch id 97 loss 0.25489160418510437 train acc 0.9455541237113402\n",
            "epoch 19 batch id 98 loss 0.14873115718364716 train acc 0.9453125\n",
            "epoch 19 batch id 99 loss 0.08328089118003845 train acc 0.9457070707070707\n",
            "epoch 19 batch id 100 loss 0.1519329696893692 train acc 0.9459375\n",
            "epoch 19 batch id 101 loss 0.16499140858650208 train acc 0.9460086633663366\n",
            "epoch 19 batch id 102 loss 0.2514500021934509 train acc 0.9459252450980392\n",
            "epoch 19 batch id 103 loss 0.06758539378643036 train acc 0.9462985436893204\n",
            "epoch 19 batch id 104 loss 0.2902083694934845 train acc 0.9459134615384616\n",
            "epoch 19 batch id 105 loss 0.2849676311016083 train acc 0.9459821428571429\n",
            "epoch 19 batch id 106 loss 0.07943153381347656 train acc 0.9463443396226415\n",
            "epoch 19 batch id 107 loss 0.1391810178756714 train acc 0.9464077102803738\n",
            "epoch 19 batch id 108 loss 0.06566308438777924 train acc 0.9467592592592593\n",
            "epoch 19 batch id 109 loss 0.24123515188694 train acc 0.9466743119266054\n",
            "epoch 19 batch id 110 loss 0.20388075709342957 train acc 0.946590909090909\n",
            "epoch 19 batch id 111 loss 0.2619321048259735 train acc 0.9463682432432432\n",
            "epoch 19 batch id 112 loss 0.10732445865869522 train acc 0.9462890625\n",
            "epoch 19 batch id 113 loss 0.14466886222362518 train acc 0.9462112831858407\n",
            "epoch 19 batch id 114 loss 0.07143258303403854 train acc 0.9466831140350878\n",
            "epoch 19 batch id 115 loss 0.22800785303115845 train acc 0.9467391304347826\n",
            "epoch 19 batch id 116 loss 0.16974997520446777 train acc 0.9465247844827587\n",
            "epoch 19 batch id 117 loss 0.26869654655456543 train acc 0.9460470085470085\n",
            "epoch 19 batch id 118 loss 0.04274090379476547 train acc 0.9465042372881356\n",
            "epoch 19 batch id 119 loss 0.12523379921913147 train acc 0.9466911764705882\n",
            "epoch 19 batch id 120 loss 0.1935357302427292 train acc 0.9466145833333334\n",
            "epoch 19 batch id 121 loss 0.2876151204109192 train acc 0.9465392561983471\n",
            "epoch 19 batch id 122 loss 0.22415956854820251 train acc 0.9467213114754098\n",
            "epoch 19 batch id 123 loss 0.0946054756641388 train acc 0.9467733739837398\n",
            "epoch 19 batch id 124 loss 0.19666458666324615 train acc 0.9469506048387096\n",
            "epoch 19 batch id 125 loss 0.04563501477241516 train acc 0.947375\n",
            "epoch 19 batch id 126 loss 0.2586680054664612 train acc 0.9474206349206349\n",
            "epoch 19 batch id 127 loss 0.37327077984809875 train acc 0.9468503937007874\n",
            "epoch 19 batch id 128 loss 0.16302038729190826 train acc 0.947021484375\n",
            "epoch 19 batch id 129 loss 0.12030888348817825 train acc 0.9471899224806202\n",
            "epoch 19 batch id 130 loss 0.33107423782348633 train acc 0.9469951923076924\n",
            "epoch 19 batch id 131 loss 0.15041594207286835 train acc 0.9470419847328244\n",
            "epoch 19 batch id 132 loss 0.11562621593475342 train acc 0.9472064393939394\n",
            "epoch 19 batch id 133 loss 0.09913363307714462 train acc 0.947250939849624\n",
            "epoch 19 batch id 134 loss 0.10347972810268402 train acc 0.9475279850746269\n",
            "epoch 19 batch id 135 loss 0.21556638181209564 train acc 0.9474537037037037\n",
            "epoch 19 batch id 136 loss 0.10504818707704544 train acc 0.9476102941176471\n",
            "epoch 19 batch id 137 loss 0.1486811637878418 train acc 0.9476505474452555\n",
            "epoch 19 batch id 138 loss 0.23967641592025757 train acc 0.947463768115942\n",
            "epoch 19 batch id 139 loss 0.22907154262065887 train acc 0.9476169064748201\n",
            "epoch 19 batch id 140 loss 0.1373985856771469 train acc 0.94765625\n",
            "epoch 19 batch id 141 loss 0.27658069133758545 train acc 0.947584219858156\n",
            "epoch 19 batch id 142 loss 0.26341691613197327 train acc 0.9474031690140845\n",
            "epoch 19 batch id 143 loss 0.15036314725875854 train acc 0.947333916083916\n",
            "epoch 19 batch id 144 loss 0.2642636001110077 train acc 0.9471571180555556\n",
            "epoch 19 batch id 145 loss 0.2992558479309082 train acc 0.9467672413793103\n",
            "epoch 19 batch id 146 loss 0.20247630774974823 train acc 0.9467037671232876\n",
            "epoch 19 batch id 147 loss 0.11682683229446411 train acc 0.9468537414965986\n",
            "epoch 19 batch id 148 loss 0.1504662185907364 train acc 0.9470016891891891\n",
            "epoch 19 batch id 149 loss 0.05893531069159508 train acc 0.9473573825503355\n",
            "epoch 19 batch id 150 loss 0.27372100949287415 train acc 0.9472916666666666\n",
            "epoch 19 batch id 151 loss 0.31104332208633423 train acc 0.9470198675496688\n",
            "epoch 19 batch id 152 loss 0.057049088180065155 train acc 0.947265625\n",
            "epoch 19 batch id 153 loss 0.12343625724315643 train acc 0.9473039215686274\n",
            "epoch 19 batch id 154 loss 0.06949702650308609 train acc 0.9475446428571429\n",
            "epoch 19 batch id 155 loss 0.13423125445842743 train acc 0.9476814516129032\n",
            "epoch 19 batch id 156 loss 0.4079446494579315 train acc 0.9470152243589743\n",
            "epoch 19 batch id 157 loss 0.06870876997709274 train acc 0.9473527070063694\n",
            "epoch 19 batch id 158 loss 0.08131931722164154 train acc 0.9475870253164557\n",
            "epoch 19 batch id 159 loss 0.39319220185279846 train acc 0.9472287735849056\n",
            "epoch 19 batch id 160 loss 0.17999142408370972 train acc 0.947265625\n",
            "epoch 19 batch id 161 loss 0.30171337723731995 train acc 0.9472049689440993\n",
            "epoch 19 batch id 162 loss 0.09629736840724945 train acc 0.9474344135802469\n",
            "epoch 19 batch id 163 loss 0.08380439877510071 train acc 0.9476610429447853\n",
            "epoch 19 batch id 164 loss 0.19405198097229004 train acc 0.9476943597560976\n",
            "epoch 19 batch id 165 loss 0.24685652554035187 train acc 0.9477272727272728\n",
            "epoch 19 batch id 166 loss 0.31203266978263855 train acc 0.9473832831325302\n",
            "epoch 19 batch id 167 loss 0.48375403881073 train acc 0.9470434131736527\n",
            "epoch 19 batch id 168 loss 0.29240334033966064 train acc 0.9467075892857143\n",
            "epoch 19 batch id 169 loss 0.40522798895835876 train acc 0.9460059171597633\n",
            "epoch 19 batch id 170 loss 0.1838381290435791 train acc 0.9459558823529411\n",
            "epoch 19 batch id 171 loss 0.21892665326595306 train acc 0.9458150584795322\n",
            "epoch 19 batch id 172 loss 0.16141851246356964 train acc 0.9457667151162791\n",
            "epoch 19 batch id 173 loss 0.2120533585548401 train acc 0.945628612716763\n",
            "epoch 19 batch id 174 loss 0.22084000706672668 train acc 0.9454920977011494\n",
            "epoch 19 batch id 175 loss 0.1856752336025238 train acc 0.9454464285714286\n",
            "epoch 19 batch id 176 loss 0.10667858272790909 train acc 0.9456676136363636\n",
            "epoch 19 batch id 177 loss 0.30765989422798157 train acc 0.9454449152542372\n",
            "epoch 19 batch id 178 loss 0.302663654088974 train acc 0.9454002808988764\n",
            "epoch 19 batch id 179 loss 0.15931013226509094 train acc 0.94544343575419\n",
            "epoch 19 batch id 180 loss 0.14973251521587372 train acc 0.9454861111111111\n",
            "epoch 19 batch id 181 loss 0.1401432752609253 train acc 0.945614640883978\n",
            "epoch 19 batch id 182 loss 0.1549844741821289 train acc 0.9457417582417582\n",
            "epoch 19 batch id 183 loss 0.3007354736328125 train acc 0.9456113387978142\n",
            "epoch 19 batch id 184 loss 0.1708783656358719 train acc 0.9453974184782609\n",
            "epoch 19 batch id 185 loss 0.31596893072128296 train acc 0.9452702702702702\n",
            "epoch 19 batch id 186 loss 0.23835037648677826 train acc 0.9453125\n",
            "epoch 19 batch id 187 loss 0.25920405983924866 train acc 0.9453542780748663\n",
            "epoch 19 batch id 188 loss 0.20158004760742188 train acc 0.9453125\n",
            "epoch 19 batch id 189 loss 0.5748438835144043 train acc 0.9447751322751323\n",
            "epoch 19 batch id 190 loss 0.10595065355300903 train acc 0.944983552631579\n",
            "epoch 19 batch id 191 loss 0.15704356133937836 train acc 0.9450261780104712\n",
            "epoch 19 batch id 192 loss 0.0648915022611618 train acc 0.9452311197916666\n",
            "epoch 19 batch id 193 loss 0.18765337765216827 train acc 0.9452720207253886\n",
            "epoch 19 batch id 194 loss 0.08538966625928879 train acc 0.9453930412371134\n",
            "epoch 19 batch id 195 loss 0.22934061288833618 train acc 0.9453525641025641\n",
            "epoch 19 batch id 196 loss 0.21806733310222626 train acc 0.9452327806122449\n",
            "epoch 19 batch id 197 loss 0.18982861936092377 train acc 0.9454314720812182\n",
            "epoch 19 batch id 198 loss 0.1428874135017395 train acc 0.9454703282828283\n",
            "epoch 19 batch id 199 loss 0.38566577434539795 train acc 0.9454302763819096\n",
            "epoch 19 batch id 200 loss 0.10022547841072083 train acc 0.945546875\n",
            "epoch 19 batch id 201 loss 0.285046249628067 train acc 0.9456623134328358\n",
            "epoch 19 batch id 202 loss 0.20027926564216614 train acc 0.9455445544554455\n",
            "epoch 19 batch id 203 loss 0.21661944687366486 train acc 0.9455818965517241\n",
            "epoch 19 batch id 204 loss 0.16465367376804352 train acc 0.9457720588235294\n",
            "epoch 19 batch id 205 loss 0.22971157729625702 train acc 0.9456554878048781\n",
            "epoch 19 batch id 206 loss 0.26289457082748413 train acc 0.9456158980582524\n",
            "epoch 19 batch id 207 loss 0.2542414665222168 train acc 0.9455012077294686\n",
            "epoch 19 batch id 208 loss 0.1104905754327774 train acc 0.9456129807692307\n",
            "epoch 19 batch id 209 loss 0.25619879364967346 train acc 0.9456489234449761\n",
            "epoch 19 batch id 210 loss 0.2300880402326584 train acc 0.945610119047619\n",
            "epoch 19 batch id 211 loss 0.31442975997924805 train acc 0.9454235781990521\n",
            "epoch 19 batch id 212 loss 0.2730814218521118 train acc 0.9453862028301887\n",
            "epoch 19 batch id 213 loss 0.17000256478786469 train acc 0.9454958920187794\n",
            "epoch 19 batch id 214 loss 0.17103949189186096 train acc 0.9455315420560748\n",
            "epoch 19 batch id 215 loss 0.37005260586738586 train acc 0.9453488372093023\n",
            "epoch 19 batch id 216 loss 0.09327421337366104 train acc 0.9455295138888888\n",
            "epoch 19 batch id 217 loss 0.1308261603116989 train acc 0.9457085253456221\n",
            "epoch 19 batch id 218 loss 0.1640007644891739 train acc 0.945670871559633\n",
            "epoch 19 batch id 219 loss 0.33727988600730896 train acc 0.9455622146118722\n",
            "epoch 19 batch id 220 loss 0.11284133046865463 train acc 0.9455965909090909\n",
            "epoch 19 batch id 221 loss 0.3531736731529236 train acc 0.9454892533936652\n",
            "epoch 19 batch id 222 loss 0.16216705739498138 train acc 0.9455236486486487\n",
            "epoch 19 batch id 223 loss 0.2923869788646698 train acc 0.945347533632287\n",
            "epoch 19 batch id 224 loss 0.16650447249412537 train acc 0.9453822544642857\n",
            "epoch 19 batch id 225 loss 0.10623951256275177 train acc 0.9454861111111111\n",
            "epoch 19 batch id 226 loss 0.07837378978729248 train acc 0.9456581858407079\n",
            "epoch 19 batch id 227 loss 0.41865748167037964 train acc 0.9454845814977973\n",
            "epoch 19 batch id 228 loss 0.3638305366039276 train acc 0.9453125\n",
            "epoch 19 batch id 229 loss 0.15284883975982666 train acc 0.945346615720524\n",
            "epoch 19 batch id 230 loss 0.13419638574123383 train acc 0.9455163043478261\n",
            "epoch 19 batch id 231 loss 0.15684978663921356 train acc 0.9454816017316018\n",
            "epoch 19 batch id 232 loss 0.13634446263313293 train acc 0.9455145474137931\n",
            "epoch 19 batch id 233 loss 0.15122143924236298 train acc 0.9455472103004292\n",
            "epoch 19 batch id 234 loss 0.23484636843204498 train acc 0.9454460470085471\n",
            "epoch 19 batch id 235 loss 0.054511863738298416 train acc 0.9456117021276595\n",
            "epoch 19 batch id 236 loss 0.18290965259075165 train acc 0.9455773305084746\n",
            "epoch 19 batch id 237 loss 0.17952480912208557 train acc 0.9455432489451476\n",
            "epoch 19 batch id 238 loss 0.2453453093767166 train acc 0.9453781512605042\n",
            "epoch 19 batch id 239 loss 0.13125230371952057 train acc 0.9453451882845189\n",
            "epoch 19 batch id 240 loss 0.15471108257770538 train acc 0.9453125\n",
            "epoch 19 batch id 241 loss 0.40455275774002075 train acc 0.9451504149377593\n",
            "epoch 19 batch id 242 loss 0.06721428036689758 train acc 0.9452479338842975\n",
            "epoch 19 batch id 243 loss 0.3986567258834839 train acc 0.9449588477366255\n",
            "epoch 19 batch id 244 loss 0.16472195088863373 train acc 0.9449923155737705\n",
            "epoch 19 batch id 245 loss 0.22990331053733826 train acc 0.9450255102040817\n",
            "epoch 19 batch id 246 loss 0.08699478209018707 train acc 0.9451854674796748\n",
            "epoch 19 batch id 247 loss 0.16680210828781128 train acc 0.9451543522267206\n",
            "epoch 19 batch id 248 loss 0.08566790819168091 train acc 0.9452494959677419\n",
            "epoch 19 batch id 249 loss 0.3871498107910156 train acc 0.9450928714859438\n",
            "epoch 19 batch id 250 loss 0.3590591549873352 train acc 0.9449375\n",
            "epoch 19 batch id 251 loss 0.1326141655445099 train acc 0.9450323705179283\n",
            "epoch 19 batch id 252 loss 0.18079273402690887 train acc 0.9450024801587301\n",
            "epoch 19 batch id 253 loss 0.1945260763168335 train acc 0.9450345849802372\n",
            "epoch 19 batch id 254 loss 0.3158425986766815 train acc 0.9450049212598425\n",
            "epoch 19 batch id 255 loss 0.14105743169784546 train acc 0.9450367647058824\n",
            "epoch 19 batch id 256 loss 0.18290670216083527 train acc 0.9449462890625\n",
            "epoch 19 batch id 257 loss 0.43885356187820435 train acc 0.9448565175097277\n",
            "epoch 19 batch id 258 loss 0.08886229991912842 train acc 0.9450702519379846\n",
            "epoch 19 batch id 259 loss 0.18864044547080994 train acc 0.9450410231660231\n",
            "epoch 19 batch id 260 loss 0.1447581946849823 train acc 0.9451322115384615\n",
            "epoch 19 batch id 261 loss 0.4459565281867981 train acc 0.9448036398467433\n",
            "epoch 19 batch id 262 loss 0.31017300486564636 train acc 0.9447161259541985\n",
            "epoch 19 batch id 263 loss 0.2264493703842163 train acc 0.9446886882129277\n",
            "epoch 19 batch id 264 loss 0.17390310764312744 train acc 0.9446614583333334\n",
            "epoch 19 batch id 265 loss 0.16884185373783112 train acc 0.944752358490566\n",
            "epoch 19 batch id 266 loss 0.1963939517736435 train acc 0.9447250939849624\n",
            "epoch 19 batch id 267 loss 0.1703631579875946 train acc 0.9447565543071161\n",
            "epoch 19 batch id 268 loss 0.15630222856998444 train acc 0.9447877798507462\n",
            "epoch 19 batch id 269 loss 0.23356856405735016 train acc 0.9447026022304833\n",
            "epoch 19 batch id 270 loss 0.10421023517847061 train acc 0.9447337962962963\n",
            "epoch 19 batch id 271 loss 0.14118081331253052 train acc 0.9447647601476015\n",
            "epoch 19 batch id 272 loss 0.053117986768484116 train acc 0.9449103860294118\n",
            "epoch 19 batch id 273 loss 0.16756027936935425 train acc 0.9448260073260073\n",
            "epoch 19 batch id 274 loss 0.10040010511875153 train acc 0.9448562956204379\n",
            "epoch 19 batch id 275 loss 0.13977254927158356 train acc 0.9448863636363637\n",
            "epoch 19 batch id 276 loss 0.0922396332025528 train acc 0.9449728260869565\n",
            "epoch 19 batch id 277 loss 0.18687273561954498 train acc 0.9450022563176895\n",
            "epoch 19 batch id 278 loss 0.043691981583833694 train acc 0.9452000899280576\n",
            "epoch 19 batch id 279 loss 0.1913437396287918 train acc 0.9451724910394266\n",
            "epoch 19 batch id 280 loss 0.3498975336551666 train acc 0.9449776785714286\n",
            "epoch 19 batch id 281 loss 0.3586595356464386 train acc 0.9448954626334519\n",
            "epoch 19 batch id 282 loss 0.1445256471633911 train acc 0.9449800531914894\n",
            "epoch 19 batch id 283 loss 0.10258553922176361 train acc 0.9450640459363958\n",
            "epoch 19 batch id 284 loss 0.3241683840751648 train acc 0.9449823943661971\n",
            "epoch 19 batch id 285 loss 0.13452596962451935 train acc 0.9449013157894737\n",
            "epoch 19 batch id 286 loss 0.2706720530986786 train acc 0.9447115384615384\n",
            "epoch 19 batch id 287 loss 0.09142525494098663 train acc 0.9447952961672473\n",
            "epoch 19 batch id 288 loss 0.13884715735912323 train acc 0.9448784722222222\n",
            "epoch 19 batch id 289 loss 0.15651877224445343 train acc 0.9448529411764706\n",
            "epoch 19 batch id 290 loss 0.08327565342187881 train acc 0.9449353448275862\n",
            "epoch 19 batch id 291 loss 0.0628911703824997 train acc 0.9450708762886598\n",
            "epoch 19 batch id 292 loss 0.1019941121339798 train acc 0.9451519691780822\n",
            "epoch 19 batch id 293 loss 0.18922467529773712 train acc 0.9450725255972696\n",
            "epoch 19 batch id 294 loss 0.10454969108104706 train acc 0.9451530612244898\n",
            "epoch 19 batch id 295 loss 0.10160115361213684 train acc 0.9452330508474577\n",
            "epoch 19 batch id 296 loss 0.19146741926670074 train acc 0.9452069256756757\n",
            "epoch 19 batch id 297 loss 0.35232487320899963 train acc 0.945128367003367\n",
            "epoch 19 batch id 298 loss 0.21960310637950897 train acc 0.9451027684563759\n",
            "epoch 19 batch id 299 loss 0.2178134024143219 train acc 0.9450773411371237\n",
            "epoch 19 batch id 300 loss 0.2439993917942047 train acc 0.9450520833333333\n",
            "epoch 19 batch id 301 loss 0.10884543508291245 train acc 0.9451308139534884\n",
            "epoch 19 batch id 302 loss 0.10359745472669601 train acc 0.945260761589404\n",
            "epoch 19 batch id 303 loss 0.10975625365972519 train acc 0.9452867161716172\n",
            "epoch 19 batch id 304 loss 0.24115261435508728 train acc 0.9451069078947368\n",
            "epoch 19 batch id 305 loss 0.10647708177566528 train acc 0.9451844262295082\n",
            "epoch 19 batch id 306 loss 0.07151153683662415 train acc 0.9453635620915033\n",
            "epoch 19 batch id 307 loss 0.07167712599039078 train acc 0.9455415309446255\n",
            "epoch 19 batch id 308 loss 0.18685419857501984 train acc 0.9454646915584416\n",
            "epoch 19 batch id 309 loss 0.04447735473513603 train acc 0.9456411812297735\n",
            "epoch 19 batch id 310 loss 0.1762637346982956 train acc 0.9456653225806452\n",
            "epoch 19 batch id 311 loss 0.27621138095855713 train acc 0.9454381028938906\n",
            "epoch 19 batch id 312 loss 0.13077682256698608 train acc 0.9454627403846154\n",
            "epoch 19 batch id 313 loss 0.5630610585212708 train acc 0.9453374600638977\n",
            "epoch 19 batch id 314 loss 0.26716679334640503 train acc 0.9453622611464968\n",
            "epoch 19 batch id 315 loss 0.1870420128107071 train acc 0.9453869047619048\n",
            "epoch 19 batch id 316 loss 0.2661189138889313 train acc 0.9453619462025317\n",
            "epoch 19 batch id 317 loss 0.22937598824501038 train acc 0.9453371451104101\n",
            "epoch 19 batch id 318 loss 0.2852489650249481 train acc 0.9453125\n",
            "epoch 19 batch id 319 loss 0.15624509751796722 train acc 0.9453369905956113\n",
            "epoch 19 batch id 320 loss 0.2151595801115036 train acc 0.9453125\n",
            "epoch 19 batch id 321 loss 0.23285670578479767 train acc 0.9452394859813084\n",
            "epoch 19 batch id 322 loss 0.10447344183921814 train acc 0.9453125\n",
            "epoch 19 batch id 323 loss 0.06937886774539948 train acc 0.9454818111455109\n",
            "epoch 19 batch id 324 loss 0.08069565892219543 train acc 0.9456500771604939\n",
            "epoch 19 batch id 325 loss 0.276943176984787 train acc 0.9455288461538461\n",
            "epoch 19 batch id 326 loss 0.2543225586414337 train acc 0.9454562883435583\n",
            "epoch 19 batch id 327 loss 0.17735522985458374 train acc 0.9454797400611621\n",
            "epoch 19 batch id 328 loss 0.08134486526250839 train acc 0.9456459603658537\n",
            "epoch 19 batch id 329 loss 0.24136531352996826 train acc 0.9456212006079028\n",
            "epoch 19 batch id 330 loss 0.09166910499334335 train acc 0.9457386363636363\n",
            "epoch 19 batch id 331 loss 0.2827543318271637 train acc 0.9456665407854985\n",
            "epoch 19 batch id 332 loss 0.03942350298166275 train acc 0.9458301957831325\n",
            "epoch 19 batch id 333 loss 0.27982014417648315 train acc 0.9458051801801802\n",
            "epoch 19 batch id 334 loss 0.1717977523803711 train acc 0.9459206586826348\n",
            "epoch 19 batch id 335 loss 0.323230117559433 train acc 0.9458022388059701\n",
            "epoch 19 batch id 336 loss 0.26321274042129517 train acc 0.9458240327380952\n",
            "epoch 19 batch id 337 loss 0.120118148624897 train acc 0.9459384272997032\n",
            "epoch 19 batch id 338 loss 0.0551791675388813 train acc 0.9460521449704142\n",
            "epoch 19 batch id 339 loss 0.22738058865070343 train acc 0.9460730088495575\n",
            "epoch 19 batch id 340 loss 0.26557621359825134 train acc 0.9460477941176471\n",
            "epoch 19 batch id 341 loss 0.36200833320617676 train acc 0.9459310850439883\n",
            "epoch 19 batch id 342 loss 0.27410808205604553 train acc 0.9458607456140351\n",
            "epoch 19 batch id 343 loss 0.40236997604370117 train acc 0.9456541545189504\n",
            "epoch 19 batch id 344 loss 0.09205559641122818 train acc 0.9457212936046512\n",
            "epoch 19 batch id 345 loss 0.3083457946777344 train acc 0.945606884057971\n",
            "epoch 19 batch id 346 loss 0.10088513791561127 train acc 0.9456737716763006\n",
            "epoch 19 batch id 347 loss 0.165693998336792 train acc 0.9456952449567724\n",
            "epoch 19 batch id 348 loss 0.3012145757675171 train acc 0.9457165948275862\n",
            "epoch 19 batch id 349 loss 0.4150569438934326 train acc 0.9456482808022922\n",
            "epoch 19 batch id 350 loss 0.09349186718463898 train acc 0.9456696428571428\n",
            "epoch 19 batch id 351 loss 0.16363337635993958 train acc 0.9457353988603988\n",
            "epoch 19 batch id 352 loss 0.06530049443244934 train acc 0.9458451704545454\n",
            "epoch 19 batch id 353 loss 0.23700666427612305 train acc 0.9457330028328612\n",
            "epoch 19 batch id 354 loss 0.16445083916187286 train acc 0.9457097457627118\n",
            "epoch 19 batch id 355 loss 0.32928264141082764 train acc 0.9456426056338029\n",
            "epoch 19 batch id 356 loss 0.062214747071266174 train acc 0.945751404494382\n",
            "epoch 19 batch id 357 loss 0.3317399024963379 train acc 0.9455969887955182\n",
            "epoch 19 batch id 358 loss 0.039097800850868225 train acc 0.9457489525139665\n",
            "epoch 19 batch id 359 loss 0.09820787608623505 train acc 0.9457694986072424\n",
            "epoch 19 batch id 360 loss 0.12896029651165009 train acc 0.9457899305555556\n",
            "epoch 19 batch id 361 loss 0.1182728037238121 train acc 0.9458968144044322\n",
            "epoch 19 batch id 362 loss 0.12018890678882599 train acc 0.9459599447513812\n",
            "epoch 19 batch id 363 loss 0.34299230575561523 train acc 0.9458935950413223\n",
            "epoch 19 batch id 364 loss 0.15345105528831482 train acc 0.9457846840659341\n",
            "epoch 19 batch id 365 loss 0.22989456355571747 train acc 0.9457619863013699\n",
            "epoch 19 batch id 366 loss 0.2632543444633484 train acc 0.9456540300546448\n",
            "epoch 19 batch id 367 loss 0.21856337785720825 train acc 0.9455466621253406\n",
            "epoch 19 batch id 368 loss 0.3979714810848236 train acc 0.9454823369565217\n",
            "epoch 19 batch id 369 loss 0.09314018487930298 train acc 0.9455453929539296\n",
            "epoch 19 batch id 370 loss 0.13343845307826996 train acc 0.9456081081081081\n",
            "epoch 19 batch id 371 loss 0.2295309156179428 train acc 0.9456283692722371\n",
            "epoch 19 batch id 372 loss 0.11581988632678986 train acc 0.9456905241935484\n",
            "epoch 19 batch id 373 loss 0.32898369431495667 train acc 0.9456685656836461\n",
            "epoch 19 batch id 374 loss 0.27318379282951355 train acc 0.9455213903743316\n",
            "epoch 19 batch id 375 loss 0.13481271266937256 train acc 0.9455\n",
            "epoch 19 batch id 376 loss 0.037456072866916656 train acc 0.9456033909574468\n",
            "epoch 19 batch id 377 loss 0.2071034014225006 train acc 0.9455818965517241\n",
            "epoch 19 batch id 378 loss 0.23903395235538483 train acc 0.945477843915344\n",
            "epoch 19 batch id 379 loss 0.18961426615715027 train acc 0.9454980211081794\n",
            "epoch 19 batch id 380 loss 0.15036848187446594 train acc 0.9455180921052632\n",
            "epoch 19 batch id 381 loss 0.29491713643074036 train acc 0.9454560367454068\n",
            "epoch 19 batch id 382 loss 0.07413852214813232 train acc 0.9455579188481675\n",
            "epoch 19 batch id 383 loss 0.1360798329114914 train acc 0.9456184725848564\n",
            "epoch 19 batch id 384 loss 0.20772616565227509 train acc 0.9456380208333334\n",
            "epoch 19 batch id 385 loss 0.11531294882297516 train acc 0.9456168831168831\n",
            "epoch 19 batch id 386 loss 0.28680655360221863 train acc 0.945514896373057\n",
            "epoch 19 batch id 387 loss 0.11683524399995804 train acc 0.9455345607235142\n",
            "epoch 19 batch id 388 loss 0.13163886964321136 train acc 0.9455138530927835\n",
            "epoch 19 batch id 389 loss 0.12026041746139526 train acc 0.9456137532133676\n",
            "epoch 19 batch id 390 loss 0.12605783343315125 train acc 0.9457131410256411\n",
            "epoch 19 batch id 391 loss 0.16572880744934082 train acc 0.9457720588235294\n",
            "epoch 19 batch id 392 loss 0.2195373922586441 train acc 0.9457110969387755\n",
            "epoch 19 batch id 393 loss 0.1426648050546646 train acc 0.945729961832061\n",
            "epoch 19 batch id 394 loss 0.2352079302072525 train acc 0.945748730964467\n",
            "epoch 19 batch id 395 loss 0.07288193702697754 train acc 0.9458860759493671\n",
            "epoch 19 batch id 396 loss 0.14755477011203766 train acc 0.9458254419191919\n",
            "epoch 19 batch id 397 loss 0.2665080726146698 train acc 0.9457651133501259\n",
            "epoch 19 batch id 398 loss 0.08457047492265701 train acc 0.9458621231155779\n",
            "epoch 19 batch id 399 loss 0.16051487624645233 train acc 0.9459194862155389\n",
            "epoch 19 batch id 400 loss 0.24288439750671387 train acc 0.9458984375\n",
            "epoch 19 batch id 401 loss 0.07872843742370605 train acc 0.9459943890274314\n",
            "epoch 19 batch id 402 loss 0.11480610072612762 train acc 0.9460509950248757\n",
            "epoch 19 batch id 403 loss 0.1400146633386612 train acc 0.9460685483870968\n",
            "epoch 19 batch id 404 loss 0.1385120451450348 train acc 0.9460860148514851\n",
            "epoch 19 batch id 405 loss 0.28716641664505005 train acc 0.9459876543209876\n",
            "epoch 19 batch id 406 loss 0.15089517831802368 train acc 0.9460052339901478\n",
            "epoch 19 batch id 407 loss 0.29247862100601196 train acc 0.9459843366093366\n",
            "epoch 19 batch id 408 loss 0.1421099454164505 train acc 0.9460018382352942\n",
            "epoch 19 batch id 409 loss 0.10881242901086807 train acc 0.9459810513447433\n",
            "epoch 19 batch id 410 loss 0.2736058533191681 train acc 0.9458841463414634\n",
            "epoch 19 batch id 411 loss 0.14700742065906525 train acc 0.9459017639902676\n",
            "epoch 19 batch id 412 loss 0.12404002249240875 train acc 0.9458813713592233\n",
            "epoch 19 batch id 413 loss 0.28406238555908203 train acc 0.9458232445520581\n",
            "epoch 19 batch id 414 loss 0.36711132526397705 train acc 0.9458031400966184\n",
            "epoch 19 batch id 415 loss 0.07290806621313095 train acc 0.9458584337349397\n",
            "epoch 19 batch id 416 loss 0.13894261419773102 train acc 0.9458759014423077\n",
            "epoch 19 batch id 417 loss 0.2051038146018982 train acc 0.9458558153477218\n",
            "epoch 19 batch id 418 loss 0.20261819660663605 train acc 0.9457610645933014\n",
            "epoch 19 batch id 419 loss 0.10717058181762695 train acc 0.9458159307875895\n",
            "epoch 19 batch id 420 loss 0.2295665293931961 train acc 0.9457589285714286\n",
            "epoch 19 batch id 421 loss 0.09585125744342804 train acc 0.9457764251781473\n",
            "epoch 19 batch id 422 loss 0.2854127287864685 train acc 0.9457568127962085\n",
            "epoch 19 batch id 423 loss 0.05992725491523743 train acc 0.945848108747045\n",
            "epoch 19 batch id 424 loss 0.1282413750886917 train acc 0.9458652712264151\n",
            "epoch 19 batch id 425 loss 0.326469361782074 train acc 0.9457720588235294\n",
            "epoch 19 batch id 426 loss 0.31138235330581665 train acc 0.9456426056338029\n",
            "epoch 19 batch id 427 loss 0.2717762291431427 train acc 0.9456235362997658\n",
            "epoch 19 batch id 428 loss 0.3168443441390991 train acc 0.9456410630841121\n",
            "epoch 19 batch id 429 loss 0.19447997212409973 train acc 0.9455856643356644\n",
            "epoch 19 batch id 430 loss 0.3620167672634125 train acc 0.945530523255814\n",
            "epoch 19 batch id 431 loss 0.138885498046875 train acc 0.9456206496519721\n",
            "epoch 19 batch id 432 loss 0.3046961724758148 train acc 0.9456018518518519\n",
            "epoch 19 batch id 433 loss 0.19124844670295715 train acc 0.9456192263279446\n",
            "epoch 19 batch id 434 loss 0.1878710240125656 train acc 0.9456365207373272\n",
            "epoch 19 batch id 435 loss 0.21728962659835815 train acc 0.9456537356321839\n",
            "epoch 19 batch id 436 loss 0.16922812163829803 train acc 0.9457425458715596\n",
            "epoch 19 batch id 437 loss 0.09536954015493393 train acc 0.9458309496567505\n",
            "epoch 19 batch id 438 loss 0.21601812541484833 train acc 0.9457762557077626\n",
            "epoch 19 batch id 439 loss 0.11933673173189163 train acc 0.9458641799544419\n",
            "epoch 19 batch id 440 loss 0.32322394847869873 train acc 0.9458096590909091\n",
            "epoch 19 batch id 441 loss 0.29805490374565125 train acc 0.9457908163265306\n",
            "epoch 19 batch id 442 loss 0.3197473883628845 train acc 0.9458074095022625\n",
            "epoch 19 batch id 443 loss 0.3290640711784363 train acc 0.9457181151241535\n",
            "epoch 19 batch id 444 loss 0.19113031029701233 train acc 0.9456644144144144\n",
            "epoch 19 batch id 445 loss 0.13028904795646667 train acc 0.9457162921348314\n",
            "epoch 19 batch id 446 loss 0.07367616146802902 train acc 0.9458029708520179\n",
            "epoch 19 batch id 447 loss 0.21291802823543549 train acc 0.9458892617449665\n",
            "epoch 19 batch id 448 loss 0.2189367413520813 train acc 0.9458705357142857\n",
            "epoch 19 batch id 449 loss 0.15382005274295807 train acc 0.9458170935412027\n",
            "epoch 19 batch id 450 loss 0.0898580327630043 train acc 0.9458680555555555\n",
            "epoch 19 batch id 451 loss 0.27828988432884216 train acc 0.9458495011086474\n",
            "epoch 19 batch id 452 loss 0.18584507703781128 train acc 0.9458655973451328\n",
            "epoch 19 batch id 453 loss 0.2370196282863617 train acc 0.9458816225165563\n",
            "epoch 19 batch id 454 loss 0.12418204545974731 train acc 0.9458631607929515\n",
            "epoch 19 batch id 455 loss 0.21333914995193481 train acc 0.9458104395604395\n",
            "epoch 19 batch id 456 loss 0.15530936419963837 train acc 0.9458264802631579\n",
            "epoch 19 batch id 457 loss 0.12645477056503296 train acc 0.9458766411378556\n",
            "epoch 19 batch id 458 loss 0.2685528099536896 train acc 0.9458583515283843\n",
            "epoch 19 batch id 459 loss 0.2375480681657791 train acc 0.9458401416122004\n",
            "epoch 19 batch id 460 loss 0.19300299882888794 train acc 0.9458220108695652\n",
            "epoch 19 batch id 461 loss 0.21739575266838074 train acc 0.9457361713665944\n",
            "epoch 19 batch id 462 loss 0.18551766872406006 train acc 0.9457521645021645\n",
            "epoch 19 batch id 463 loss 0.10853508114814758 train acc 0.9457680885529157\n",
            "epoch 19 batch id 464 loss 0.19390304386615753 train acc 0.9457165948275862\n",
            "epoch 19 batch id 465 loss 0.0791693851351738 train acc 0.9457997311827957\n",
            "epoch 19 batch id 466 loss 0.2240646928548813 train acc 0.9457483905579399\n",
            "epoch 19 batch id 467 loss 0.1608852595090866 train acc 0.9457641862955032\n",
            "epoch 19 batch id 468 loss 0.13236592710018158 train acc 0.9458133012820513\n",
            "epoch 19 batch id 469 loss 0.17388135194778442 train acc 0.9458622068230277\n",
            "epoch 19 batch id 470 loss 0.13080976903438568 train acc 0.9459109042553191\n",
            "epoch 19 batch id 471 loss 0.15793652832508087 train acc 0.9458930467091295\n",
            "epoch 19 batch id 472 loss 0.11915042996406555 train acc 0.9459414724576272\n",
            "epoch 19 batch id 473 loss 0.11704517155885696 train acc 0.9459896934460887\n",
            "epoch 19 batch id 474 loss 0.315630167722702 train acc 0.9459717827004219\n",
            "epoch 19 batch id 475 loss 0.20676778256893158 train acc 0.9459539473684211\n",
            "epoch 19 batch id 476 loss 0.2885012924671173 train acc 0.9458377100840336\n",
            "epoch 19 batch id 477 loss 0.11627723276615143 train acc 0.9458857442348009\n",
            "epoch 19 batch id 478 loss 0.08782820403575897 train acc 0.9459662656903766\n",
            "epoch 19 batch id 479 loss 0.0956704318523407 train acc 0.9460138308977035\n",
            "epoch 19 batch id 480 loss 0.3226126432418823 train acc 0.94599609375\n",
            "epoch 19 batch id 481 loss 0.15450572967529297 train acc 0.9460109147609148\n",
            "epoch 19 batch id 482 loss 0.1753774732351303 train acc 0.946058091286307\n",
            "epoch 19 batch id 483 loss 0.09337778389453888 train acc 0.9461050724637681\n",
            "epoch 19 batch id 484 loss 0.19281063973903656 train acc 0.9460872933884298\n",
            "epoch 19 batch id 485 loss 0.2580881714820862 train acc 0.946069587628866\n",
            "epoch 19 batch id 486 loss 0.1073819249868393 train acc 0.946116255144033\n",
            "epoch 19 batch id 487 loss 0.21937158703804016 train acc 0.946066478439425\n",
            "epoch 19 batch id 488 loss 0.13980823755264282 train acc 0.9460809426229508\n",
            "epoch 19 batch id 489 loss 0.19984111189842224 train acc 0.9460953476482618\n",
            "epoch 19 batch id 490 loss 0.2667951285839081 train acc 0.9460140306122449\n",
            "epoch 19 batch id 491 loss 0.19548152387142181 train acc 0.9459966904276986\n",
            "epoch 19 batch id 492 loss 0.11950284987688065 train acc 0.9460111788617886\n",
            "epoch 19 batch id 493 loss 0.1438896507024765 train acc 0.9460256085192698\n",
            "epoch 19 batch id 494 loss 0.1678021252155304 train acc 0.946039979757085\n",
            "epoch 19 batch id 495 loss 0.20902013778686523 train acc 0.9459911616161616\n",
            "epoch 19 batch id 496 loss 0.10434939712285995 train acc 0.9460370463709677\n",
            "epoch 19 batch id 497 loss 0.21257847547531128 train acc 0.9460827464788732\n",
            "epoch 19 batch id 498 loss 0.13736261427402496 train acc 0.9461282630522089\n",
            "epoch 19 batch id 499 loss 0.2541758716106415 train acc 0.9460483466933868\n",
            "epoch 19 batch id 500 loss 0.14115913212299347 train acc 0.94609375\n",
            "epoch 19 batch id 501 loss 0.13282296061515808 train acc 0.9461077844311377\n",
            "epoch 19 batch id 502 loss 0.078682079911232 train acc 0.9461840139442231\n",
            "epoch 19 batch id 503 loss 0.3373759090900421 train acc 0.9460735586481114\n",
            "epoch 19 batch id 504 loss 0.15831072628498077 train acc 0.9460875496031746\n",
            "epoch 19 batch id 505 loss 0.1747605949640274 train acc 0.9460705445544555\n",
            "epoch 19 batch id 506 loss 0.11878463625907898 train acc 0.9461153656126482\n",
            "epoch 19 batch id 507 loss 0.27348437905311584 train acc 0.9460367357001972\n",
            "epoch 19 batch id 508 loss 0.07013292610645294 train acc 0.9460814468503937\n",
            "epoch 19 batch id 509 loss 0.2648848295211792 train acc 0.9460952848722987\n",
            "epoch 19 batch id 510 loss 0.20243915915489197 train acc 0.946109068627451\n",
            "epoch 19 batch id 511 loss 0.21459077298641205 train acc 0.9461524050259373\n",
            "epoch 19 train acc 0.9461524050259373\n",
            "epoch 19 test acc 0.4001057942708333\n",
            "epoch 20 batch id 1 loss 0.1988804042339325 train acc 0.96875\n",
            "epoch 20 batch id 2 loss 0.057132281363010406 train acc 0.984375\n",
            "epoch 20 batch id 3 loss 0.18662691116333008 train acc 0.9791666666666666\n",
            "epoch 20 batch id 4 loss 0.2217561900615692 train acc 0.9765625\n",
            "epoch 20 batch id 5 loss 0.16193605959415436 train acc 0.96875\n",
            "epoch 20 batch id 6 loss 0.10431687533855438 train acc 0.96875\n",
            "epoch 20 batch id 7 loss 0.10397231578826904 train acc 0.9665178571428571\n",
            "epoch 20 batch id 8 loss 0.16525085270404816 train acc 0.96484375\n",
            "epoch 20 batch id 9 loss 0.12831264734268188 train acc 0.9652777777777778\n",
            "epoch 20 batch id 10 loss 0.2401396930217743 train acc 0.9609375\n",
            "epoch 20 batch id 11 loss 0.10640915483236313 train acc 0.9602272727272727\n",
            "epoch 20 batch id 12 loss 0.24054348468780518 train acc 0.95703125\n",
            "epoch 20 batch id 13 loss 0.07590837776660919 train acc 0.9591346153846154\n",
            "epoch 20 batch id 14 loss 0.1772000938653946 train acc 0.9598214285714286\n",
            "epoch 20 batch id 15 loss 0.2528515160083771 train acc 0.9572916666666667\n",
            "epoch 20 batch id 16 loss 0.16212095320224762 train acc 0.9560546875\n",
            "epoch 20 batch id 17 loss 0.10483288019895554 train acc 0.9568014705882353\n",
            "epoch 20 batch id 18 loss 0.08883385360240936 train acc 0.9583333333333334\n",
            "epoch 20 batch id 19 loss 0.12622934579849243 train acc 0.9580592105263158\n",
            "epoch 20 batch id 20 loss 0.21486937999725342 train acc 0.9578125\n",
            "epoch 20 batch id 21 loss 0.21101468801498413 train acc 0.9568452380952381\n",
            "epoch 20 batch id 22 loss 0.10054336488246918 train acc 0.9573863636363636\n",
            "epoch 20 batch id 23 loss 0.24636873602867126 train acc 0.9565217391304348\n",
            "epoch 20 batch id 24 loss 0.09690666943788528 train acc 0.9563802083333334\n",
            "epoch 20 batch id 25 loss 0.12475533038377762 train acc 0.9575\n",
            "epoch 20 batch id 26 loss 0.15840071439743042 train acc 0.9567307692307693\n",
            "epoch 20 batch id 27 loss 0.11193134635686874 train acc 0.9565972222222222\n",
            "epoch 20 batch id 28 loss 0.33758804202079773 train acc 0.9547991071428571\n",
            "epoch 20 batch id 29 loss 0.1363852173089981 train acc 0.9552801724137931\n",
            "epoch 20 batch id 30 loss 0.12222424894571304 train acc 0.9557291666666666\n",
            "epoch 20 batch id 31 loss 0.1781018227338791 train acc 0.9546370967741935\n",
            "epoch 20 batch id 32 loss 0.19260746240615845 train acc 0.9541015625\n",
            "epoch 20 batch id 33 loss 0.24511440098285675 train acc 0.9540719696969697\n",
            "epoch 20 batch id 34 loss 0.4617930054664612 train acc 0.9508272058823529\n",
            "epoch 20 batch id 35 loss 0.29212895035743713 train acc 0.9504464285714286\n",
            "epoch 20 batch id 36 loss 0.22398695349693298 train acc 0.9496527777777778\n",
            "epoch 20 batch id 37 loss 0.2467978596687317 train acc 0.948902027027027\n",
            "epoch 20 batch id 38 loss 0.08629460632801056 train acc 0.9502467105263158\n",
            "epoch 20 batch id 39 loss 0.22321432828903198 train acc 0.9499198717948718\n",
            "epoch 20 batch id 40 loss 0.14309976994991302 train acc 0.950390625\n",
            "epoch 20 batch id 41 loss 0.3914779722690582 train acc 0.9485518292682927\n",
            "epoch 20 batch id 42 loss 0.12091933190822601 train acc 0.9486607142857143\n",
            "epoch 20 batch id 43 loss 0.2941421568393707 train acc 0.9487645348837209\n",
            "epoch 20 batch id 44 loss 0.3486779034137726 train acc 0.9470880681818182\n",
            "epoch 20 batch id 45 loss 0.1610492765903473 train acc 0.9475694444444445\n",
            "epoch 20 batch id 46 loss 0.15200762450695038 train acc 0.9480298913043478\n",
            "epoch 20 batch id 47 loss 0.057548023760318756 train acc 0.9491356382978723\n",
            "epoch 20 batch id 48 loss 0.2613496482372284 train acc 0.9488932291666666\n",
            "epoch 20 batch id 49 loss 0.13980229198932648 train acc 0.9489795918367347\n",
            "epoch 20 batch id 50 loss 0.24051576852798462 train acc 0.9484375\n",
            "epoch 20 batch id 51 loss 0.2431258112192154 train acc 0.9485294117647058\n",
            "epoch 20 batch id 52 loss 0.049745023250579834 train acc 0.9495192307692307\n",
            "epoch 20 batch id 53 loss 0.1342218667268753 train acc 0.9498820754716981\n",
            "epoch 20 batch id 54 loss 0.10665957629680634 train acc 0.9505208333333334\n",
            "epoch 20 batch id 55 loss 0.37481871247291565 train acc 0.9502840909090909\n",
            "epoch 20 batch id 56 loss 0.09021710604429245 train acc 0.9503348214285714\n",
            "epoch 20 batch id 57 loss 0.09653927385807037 train acc 0.9506578947368421\n",
            "epoch 20 batch id 58 loss 0.09124382585287094 train acc 0.9509698275862069\n",
            "epoch 20 batch id 59 loss 0.04007132723927498 train acc 0.9518008474576272\n",
            "epoch 20 batch id 60 loss 0.1716422438621521 train acc 0.9515625\n",
            "epoch 20 batch id 61 loss 0.1345169097185135 train acc 0.951844262295082\n",
            "epoch 20 batch id 62 loss 0.0980677679181099 train acc 0.952116935483871\n",
            "epoch 20 batch id 63 loss 0.16632789373397827 train acc 0.9523809523809523\n",
            "epoch 20 batch id 64 loss 0.06657111644744873 train acc 0.95263671875\n",
            "epoch 20 batch id 65 loss 0.10014548152685165 train acc 0.9528846153846153\n",
            "epoch 20 batch id 66 loss 0.13762305676937103 train acc 0.9528882575757576\n",
            "epoch 20 batch id 67 loss 0.15013575553894043 train acc 0.953125\n",
            "epoch 20 batch id 68 loss 0.06856122612953186 train acc 0.9535845588235294\n",
            "epoch 20 batch id 69 loss 0.25331348180770874 train acc 0.9526721014492754\n",
            "epoch 20 batch id 70 loss 0.18166504800319672 train acc 0.9522321428571429\n",
            "epoch 20 batch id 71 loss 0.19394764304161072 train acc 0.952024647887324\n",
            "epoch 20 batch id 72 loss 0.07578207552433014 train acc 0.9524739583333334\n",
            "epoch 20 batch id 73 loss 0.13361260294914246 train acc 0.9526969178082192\n",
            "epoch 20 batch id 74 loss 0.29264071583747864 train acc 0.9524915540540541\n",
            "epoch 20 batch id 75 loss 0.08970704674720764 train acc 0.9529166666666666\n",
            "epoch 20 batch id 76 loss 0.3332885205745697 train acc 0.9525082236842105\n",
            "epoch 20 batch id 77 loss 0.1497040092945099 train acc 0.9523133116883117\n",
            "epoch 20 batch id 78 loss 0.12872570753097534 train acc 0.952323717948718\n",
            "epoch 20 batch id 79 loss 0.20646603405475616 train acc 0.9527294303797469\n",
            "epoch 20 batch id 80 loss 0.287541002035141 train acc 0.95234375\n",
            "epoch 20 batch id 81 loss 0.06826182454824448 train acc 0.9527391975308642\n",
            "epoch 20 batch id 82 loss 0.1655271351337433 train acc 0.9529344512195121\n",
            "epoch 20 batch id 83 loss 0.10286092758178711 train acc 0.9529367469879518\n",
            "epoch 20 batch id 84 loss 0.13336330652236938 train acc 0.953125\n",
            "epoch 20 batch id 85 loss 0.15769213438034058 train acc 0.953125\n",
            "epoch 20 batch id 86 loss 0.09329618513584137 train acc 0.9533066860465116\n",
            "epoch 20 batch id 87 loss 0.3425682485103607 train acc 0.9527658045977011\n",
            "epoch 20 batch id 88 loss 0.09125901758670807 train acc 0.9527698863636364\n",
            "epoch 20 batch id 89 loss 0.27087831497192383 train acc 0.9525983146067416\n",
            "epoch 20 batch id 90 loss 0.19201144576072693 train acc 0.9526041666666667\n",
            "epoch 20 batch id 91 loss 0.32757705450057983 train acc 0.9524381868131868\n",
            "epoch 20 batch id 92 loss 0.14809325337409973 train acc 0.9522758152173914\n",
            "epoch 20 batch id 93 loss 0.3071485757827759 train acc 0.9517809139784946\n",
            "epoch 20 batch id 94 loss 0.10173290222883224 train acc 0.9519614361702128\n",
            "epoch 20 batch id 95 loss 0.45067745447158813 train acc 0.9506578947368421\n",
            "epoch 20 batch id 96 loss 0.305885910987854 train acc 0.9500325520833334\n",
            "epoch 20 batch id 97 loss 0.3772137463092804 train acc 0.9499033505154639\n",
            "epoch 20 batch id 98 loss 0.16857869923114777 train acc 0.9499362244897959\n",
            "epoch 20 batch id 99 loss 0.10942324995994568 train acc 0.9501262626262627\n",
            "epoch 20 batch id 100 loss 0.18533000349998474 train acc 0.95046875\n",
            "epoch 20 batch id 101 loss 0.23016805946826935 train acc 0.9501856435643564\n",
            "epoch 20 batch id 102 loss 0.08085569739341736 train acc 0.9505208333333334\n",
            "epoch 20 batch id 103 loss 0.2338571846485138 train acc 0.9505461165048543\n",
            "epoch 20 batch id 104 loss 0.14072692394256592 train acc 0.9507211538461539\n",
            "epoch 20 batch id 105 loss 0.2318987101316452 train acc 0.950595238095238\n",
            "epoch 20 batch id 106 loss 0.3221694231033325 train acc 0.9500294811320755\n",
            "epoch 20 batch id 107 loss 0.10335705429315567 train acc 0.9503504672897196\n",
            "epoch 20 batch id 108 loss 0.1759016066789627 train acc 0.9503761574074074\n",
            "epoch 20 batch id 109 loss 0.1450890153646469 train acc 0.950401376146789\n",
            "epoch 20 batch id 110 loss 0.13090039789676666 train acc 0.9502840909090909\n",
            "epoch 20 batch id 111 loss 0.21416857838630676 train acc 0.9503096846846847\n",
            "epoch 20 batch id 112 loss 0.24467232823371887 train acc 0.9501953125\n",
            "epoch 20 batch id 113 loss 0.07365354895591736 train acc 0.9506360619469026\n",
            "epoch 20 batch id 114 loss 0.14793041348457336 train acc 0.9506578947368421\n",
            "epoch 20 batch id 115 loss 0.056785453110933304 train acc 0.9510869565217391\n",
            "epoch 20 batch id 116 loss 0.15148866176605225 train acc 0.9509698275862069\n",
            "epoch 20 batch id 117 loss 0.2718918025493622 train acc 0.9505876068376068\n",
            "epoch 20 batch id 118 loss 0.2831607758998871 train acc 0.9504766949152542\n",
            "epoch 20 batch id 119 loss 0.11753793060779572 train acc 0.9504989495798319\n",
            "epoch 20 batch id 120 loss 0.08277328312397003 train acc 0.95078125\n",
            "epoch 20 batch id 121 loss 0.027181271463632584 train acc 0.9511880165289256\n",
            "epoch 20 batch id 122 loss 0.3421472907066345 train acc 0.9508196721311475\n",
            "epoch 20 batch id 123 loss 0.12811487913131714 train acc 0.9509654471544715\n",
            "epoch 20 batch id 124 loss 0.04881772771477699 train acc 0.9512348790322581\n",
            "epoch 20 batch id 125 loss 0.25459015369415283 train acc 0.951125\n",
            "epoch 20 batch id 126 loss 0.19177764654159546 train acc 0.951140873015873\n",
            "epoch 20 batch id 127 loss 0.14366064965724945 train acc 0.9511564960629921\n",
            "epoch 20 batch id 128 loss 0.1648254245519638 train acc 0.951416015625\n",
            "epoch 20 batch id 129 loss 0.09711753576993942 train acc 0.951671511627907\n",
            "epoch 20 batch id 130 loss 0.13166320323944092 train acc 0.9516826923076923\n",
            "epoch 20 batch id 131 loss 0.20813821256160736 train acc 0.9513358778625954\n",
            "epoch 20 batch id 132 loss 0.11082049459218979 train acc 0.951467803030303\n",
            "epoch 20 batch id 133 loss 0.5014241337776184 train acc 0.9508928571428571\n",
            "epoch 20 batch id 134 loss 0.0982234999537468 train acc 0.9511427238805971\n",
            "epoch 20 batch id 135 loss 0.08750350773334503 train acc 0.9513888888888888\n",
            "epoch 20 batch id 136 loss 0.2105148732662201 train acc 0.951171875\n",
            "epoch 20 batch id 137 loss 0.14551371335983276 train acc 0.9513001824817519\n",
            "epoch 20 batch id 138 loss 0.07160615175962448 train acc 0.9515398550724637\n",
            "epoch 20 batch id 139 loss 0.1836666464805603 train acc 0.9516636690647482\n",
            "epoch 20 batch id 140 loss 0.23291972279548645 train acc 0.9516741071428572\n",
            "epoch 20 batch id 141 loss 0.20052215456962585 train acc 0.9516843971631206\n",
            "epoch 20 batch id 142 loss 0.3027040958404541 train acc 0.9515845070422535\n",
            "epoch 20 batch id 143 loss 0.2733241617679596 train acc 0.951486013986014\n",
            "epoch 20 batch id 144 loss 0.3733217716217041 train acc 0.9513888888888888\n",
            "epoch 20 batch id 145 loss 0.10872771590948105 train acc 0.9515086206896551\n",
            "epoch 20 batch id 146 loss 0.271905779838562 train acc 0.9513056506849316\n",
            "epoch 20 batch id 147 loss 0.32325366139411926 train acc 0.9512117346938775\n",
            "epoch 20 batch id 148 loss 0.17114056646823883 train acc 0.9514358108108109\n",
            "epoch 20 batch id 149 loss 0.09602851420640945 train acc 0.9516568791946308\n",
            "epoch 20 batch id 150 loss 0.22995613515377045 train acc 0.9516666666666667\n",
            "epoch 20 batch id 151 loss 0.09878408163785934 train acc 0.9516763245033113\n",
            "epoch 20 batch id 152 loss 0.057288870215415955 train acc 0.9519942434210527\n",
            "epoch 20 batch id 153 loss 0.2525187134742737 train acc 0.9518995098039216\n",
            "epoch 20 batch id 154 loss 0.1360778957605362 train acc 0.9520089285714286\n",
            "epoch 20 batch id 155 loss 0.13358080387115479 train acc 0.9520161290322581\n",
            "epoch 20 batch id 156 loss 0.43863359093666077 train acc 0.9518229166666666\n",
            "epoch 20 batch id 157 loss 0.21752986311912537 train acc 0.9517316878980892\n",
            "epoch 20 batch id 158 loss 0.23963665962219238 train acc 0.9517405063291139\n",
            "epoch 20 batch id 159 loss 0.20208457112312317 train acc 0.951749213836478\n",
            "epoch 20 batch id 160 loss 0.2293475717306137 train acc 0.9517578125\n",
            "epoch 20 batch id 161 loss 0.2202960103750229 train acc 0.951766304347826\n",
            "epoch 20 batch id 162 loss 0.03588379919528961 train acc 0.9520640432098766\n",
            "epoch 20 batch id 163 loss 0.1777351349592209 train acc 0.9519746932515337\n",
            "epoch 20 batch id 164 loss 0.08844638615846634 train acc 0.952172256097561\n",
            "epoch 20 batch id 165 loss 0.2136702686548233 train acc 0.9521780303030303\n",
            "epoch 20 batch id 166 loss 0.18012644350528717 train acc 0.9522778614457831\n",
            "epoch 20 batch id 167 loss 0.32434412837028503 train acc 0.952002245508982\n",
            "epoch 20 batch id 168 loss 0.12288948893547058 train acc 0.9520089285714286\n",
            "epoch 20 batch id 169 loss 0.035242922604084015 train acc 0.952292899408284\n",
            "epoch 20 batch id 170 loss 0.24415645003318787 train acc 0.952297794117647\n",
            "epoch 20 batch id 171 loss 0.16718508303165436 train acc 0.9523026315789473\n",
            "epoch 20 batch id 172 loss 0.20361024141311646 train acc 0.9522165697674418\n",
            "epoch 20 batch id 173 loss 0.16046108305454254 train acc 0.9522218208092486\n",
            "epoch 20 batch id 174 loss 0.28413841128349304 train acc 0.9521372126436781\n",
            "epoch 20 batch id 175 loss 0.11224302649497986 train acc 0.9521428571428572\n",
            "epoch 20 batch id 176 loss 0.08844359219074249 train acc 0.9521484375\n",
            "epoch 20 batch id 177 loss 0.2857982814311981 train acc 0.9519774011299436\n",
            "epoch 20 batch id 178 loss 0.17806528508663177 train acc 0.9518082865168539\n",
            "epoch 20 batch id 179 loss 0.12449073046445847 train acc 0.9519029329608939\n",
            "epoch 20 batch id 180 loss 0.15350644290447235 train acc 0.9518229166666666\n",
            "epoch 20 batch id 181 loss 0.1461634337902069 train acc 0.9518301104972375\n",
            "epoch 20 batch id 182 loss 0.19586516916751862 train acc 0.9515796703296703\n",
            "epoch 20 batch id 183 loss 0.05417269840836525 train acc 0.951844262295082\n",
            "epoch 20 batch id 184 loss 0.26448437571525574 train acc 0.951766304347826\n",
            "epoch 20 batch id 185 loss 0.13235977292060852 train acc 0.9517736486486487\n",
            "epoch 20 batch id 186 loss 0.11887655407190323 train acc 0.9518649193548387\n",
            "epoch 20 batch id 187 loss 0.20446258783340454 train acc 0.9517881016042781\n",
            "epoch 20 batch id 188 loss 0.1263677030801773 train acc 0.9518783244680851\n",
            "epoch 20 batch id 189 loss 0.11410176008939743 train acc 0.9520502645502645\n",
            "epoch 20 batch id 190 loss 0.2833055853843689 train acc 0.951891447368421\n",
            "epoch 20 batch id 191 loss 0.24181866645812988 train acc 0.9516524869109948\n",
            "epoch 20 batch id 192 loss 0.2936651408672333 train acc 0.9513346354166666\n",
            "epoch 20 batch id 193 loss 0.2766069769859314 train acc 0.9511819948186528\n",
            "epoch 20 batch id 194 loss 0.43595290184020996 train acc 0.9510309278350515\n",
            "epoch 20 batch id 195 loss 0.3436598479747772 train acc 0.950801282051282\n",
            "epoch 20 batch id 196 loss 0.2501063942909241 train acc 0.9505739795918368\n",
            "epoch 20 batch id 197 loss 0.05424952134490013 train acc 0.9507455583756346\n",
            "epoch 20 batch id 198 loss 0.11716404557228088 train acc 0.9507575757575758\n",
            "epoch 20 batch id 199 loss 0.13761796057224274 train acc 0.9507694723618091\n",
            "epoch 20 batch id 200 loss 0.12570711970329285 train acc 0.95078125\n",
            "epoch 20 batch id 201 loss 0.2120576649904251 train acc 0.9506374378109452\n",
            "epoch 20 batch id 202 loss 0.1369878053665161 train acc 0.950572400990099\n",
            "epoch 20 batch id 203 loss 0.10573480278253555 train acc 0.9505849753694581\n",
            "epoch 20 batch id 204 loss 0.26958587765693665 train acc 0.9505208333333334\n",
            "epoch 20 batch id 205 loss 0.43297049403190613 train acc 0.9503810975609757\n",
            "epoch 20 batch id 206 loss 0.15559087693691254 train acc 0.9503944174757282\n",
            "epoch 20 batch id 207 loss 0.16695886850357056 train acc 0.9504076086956522\n",
            "epoch 20 batch id 208 loss 0.14471301436424255 train acc 0.9504206730769231\n",
            "epoch 20 batch id 209 loss 0.12694498896598816 train acc 0.9504336124401914\n",
            "epoch 20 batch id 210 loss 0.35903704166412354 train acc 0.9502232142857143\n",
            "epoch 20 batch id 211 loss 0.17201590538024902 train acc 0.9503110189573459\n",
            "epoch 20 batch id 212 loss 0.2760164439678192 train acc 0.9501768867924528\n",
            "epoch 20 batch id 213 loss 0.24673616886138916 train acc 0.9501173708920188\n",
            "epoch 20 batch id 214 loss 0.09953024238348007 train acc 0.9502044392523364\n",
            "epoch 20 batch id 215 loss 0.09372871369123459 train acc 0.9502906976744186\n",
            "epoch 20 batch id 216 loss 0.19414663314819336 train acc 0.9501591435185185\n",
            "epoch 20 batch id 217 loss 0.3215709328651428 train acc 0.9501008064516129\n",
            "epoch 20 batch id 218 loss 0.18954648077487946 train acc 0.9499713302752294\n",
            "epoch 20 batch id 219 loss 0.07671791315078735 train acc 0.9501284246575342\n",
            "epoch 20 batch id 220 loss 0.13480833172798157 train acc 0.9501420454545455\n",
            "epoch 20 batch id 221 loss 0.09492786228656769 train acc 0.9502262443438914\n",
            "epoch 20 batch id 222 loss 0.11179699748754501 train acc 0.9503096846846847\n",
            "epoch 20 batch id 223 loss 0.20734871923923492 train acc 0.9503923766816144\n",
            "epoch 20 batch id 224 loss 0.08546705543994904 train acc 0.9504743303571429\n",
            "epoch 20 batch id 225 loss 0.1939460039138794 train acc 0.9503472222222222\n",
            "epoch 20 batch id 226 loss 0.10779744386672974 train acc 0.9504286504424779\n",
            "epoch 20 batch id 227 loss 0.15269558131694794 train acc 0.9504405286343612\n",
            "epoch 20 batch id 228 loss 0.1471204161643982 train acc 0.950452302631579\n",
            "epoch 20 batch id 229 loss 0.20806249976158142 train acc 0.9504639737991266\n",
            "epoch 20 batch id 230 loss 0.14676138758659363 train acc 0.9504755434782609\n",
            "epoch 20 batch id 231 loss 0.164462149143219 train acc 0.9505546536796536\n",
            "epoch 20 batch id 232 loss 0.06401215493679047 train acc 0.9507004310344828\n",
            "epoch 20 batch id 233 loss 0.2629396617412567 train acc 0.9506437768240343\n",
            "epoch 20 batch id 234 loss 0.13174888491630554 train acc 0.9506543803418803\n",
            "epoch 20 batch id 235 loss 0.09629204869270325 train acc 0.9507313829787234\n",
            "epoch 20 batch id 236 loss 0.20816731452941895 train acc 0.9508077330508474\n",
            "epoch 20 batch id 237 loss 0.11212335526943207 train acc 0.9508834388185654\n",
            "epoch 20 batch id 238 loss 0.11658982932567596 train acc 0.9508928571428571\n",
            "epoch 20 batch id 239 loss 0.19174040853977203 train acc 0.9506406903765691\n",
            "epoch 20 batch id 240 loss 0.0879373550415039 train acc 0.95078125\n",
            "epoch 20 batch id 241 loss 0.15322408080101013 train acc 0.9508558091286307\n",
            "epoch 20 batch id 242 loss 0.0468822605907917 train acc 0.9509943181818182\n",
            "epoch 20 batch id 243 loss 0.0676952600479126 train acc 0.9511316872427984\n",
            "epoch 20 batch id 244 loss 0.05512628331780434 train acc 0.9512038934426229\n",
            "epoch 20 batch id 245 loss 0.14857147634029388 train acc 0.9510841836734694\n",
            "epoch 20 batch id 246 loss 0.2136717438697815 train acc 0.9510289634146342\n",
            "epoch 20 batch id 247 loss 0.02996685728430748 train acc 0.951163967611336\n",
            "epoch 20 batch id 248 loss 0.2549848258495331 train acc 0.9509828629032258\n",
            "epoch 20 batch id 249 loss 0.2451433539390564 train acc 0.9509914658634538\n",
            "epoch 20 batch id 250 loss 0.13099274039268494 train acc 0.951\n",
            "epoch 20 batch id 251 loss 0.2855403423309326 train acc 0.9509462151394422\n",
            "epoch 20 batch id 252 loss 0.1846400946378708 train acc 0.9508928571428571\n",
            "epoch 20 batch id 253 loss 0.13611014187335968 train acc 0.9509016798418972\n",
            "epoch 20 batch id 254 loss 0.17211037874221802 train acc 0.9508489173228346\n",
            "epoch 20 batch id 255 loss 0.11857155710458755 train acc 0.9509191176470588\n",
            "epoch 20 batch id 256 loss 0.0899498462677002 train acc 0.9510498046875\n",
            "epoch 20 batch id 257 loss 0.1837800145149231 train acc 0.9509362840466926\n",
            "epoch 20 batch id 258 loss 0.2100416123867035 train acc 0.9508842054263565\n",
            "epoch 20 batch id 259 loss 0.12190420180559158 train acc 0.950832528957529\n",
            "epoch 20 batch id 260 loss 0.0814141184091568 train acc 0.9509615384615384\n",
            "epoch 20 batch id 261 loss 0.2441152036190033 train acc 0.9508500957854407\n",
            "epoch 20 batch id 262 loss 0.12545636296272278 train acc 0.9509184160305344\n",
            "epoch 20 batch id 263 loss 0.16870394349098206 train acc 0.9510456273764258\n",
            "epoch 20 batch id 264 loss 0.08154301345348358 train acc 0.9511126893939394\n",
            "epoch 20 batch id 265 loss 0.06476983428001404 train acc 0.9512382075471698\n",
            "epoch 20 batch id 266 loss 0.17020490765571594 train acc 0.951186560150376\n",
            "epoch 20 batch id 267 loss 0.18645122647285461 train acc 0.9511352996254682\n",
            "epoch 20 batch id 268 loss 0.21133120357990265 train acc 0.9511427238805971\n",
            "epoch 20 batch id 269 loss 0.1013004258275032 train acc 0.951150092936803\n",
            "epoch 20 batch id 270 loss 0.19219517707824707 train acc 0.9510995370370371\n",
            "epoch 20 batch id 271 loss 0.1772543489933014 train acc 0.9509916974169742\n",
            "epoch 20 batch id 272 loss 0.09272785484790802 train acc 0.9509995404411765\n",
            "epoch 20 batch id 273 loss 0.08695876598358154 train acc 0.9511217948717948\n",
            "epoch 20 batch id 274 loss 0.024142274633049965 train acc 0.9513001824817519\n",
            "epoch 20 batch id 275 loss 0.08045096695423126 train acc 0.9514204545454545\n",
            "epoch 20 batch id 276 loss 0.16313308477401733 train acc 0.9514266304347826\n",
            "epoch 20 batch id 277 loss 0.128855898976326 train acc 0.9513763537906137\n",
            "epoch 20 batch id 278 loss 0.15352357923984528 train acc 0.9513826438848921\n",
            "epoch 20 batch id 279 loss 0.1357908695936203 train acc 0.9514448924731183\n",
            "epoch 20 batch id 280 loss 0.1397278755903244 train acc 0.9513392857142857\n",
            "epoch 20 batch id 281 loss 0.3050839304924011 train acc 0.9512344306049823\n",
            "epoch 20 batch id 282 loss 0.16307152807712555 train acc 0.9511857269503546\n",
            "epoch 20 batch id 283 loss 0.07991479337215424 train acc 0.9513030035335689\n",
            "epoch 20 batch id 284 loss 0.1267489492893219 train acc 0.9512544014084507\n",
            "epoch 20 batch id 285 loss 0.0645771473646164 train acc 0.9513706140350877\n",
            "epoch 20 batch id 286 loss 0.14325274527072906 train acc 0.951486013986014\n",
            "epoch 20 batch id 287 loss 0.1453067809343338 train acc 0.9514917247386759\n",
            "epoch 20 batch id 288 loss 0.13773594796657562 train acc 0.9514973958333334\n",
            "epoch 20 batch id 289 loss 0.23118938505649567 train acc 0.9514489619377162\n",
            "epoch 20 batch id 290 loss 0.20018510520458221 train acc 0.9513469827586207\n",
            "epoch 20 batch id 291 loss 0.20505361258983612 train acc 0.9512457044673539\n",
            "epoch 20 batch id 292 loss 0.20297980308532715 train acc 0.951091609589041\n",
            "epoch 20 batch id 293 loss 0.15386445820331573 train acc 0.951205204778157\n",
            "epoch 20 batch id 294 loss 0.28182804584503174 train acc 0.9510522959183674\n",
            "epoch 20 batch id 295 loss 0.219840869307518 train acc 0.9511122881355932\n",
            "epoch 20 batch id 296 loss 0.19783622026443481 train acc 0.951171875\n",
            "epoch 20 batch id 297 loss 0.13807173073291779 train acc 0.9511784511784511\n",
            "epoch 20 batch id 298 loss 0.19003239274024963 train acc 0.9511849832214765\n",
            "epoch 20 batch id 299 loss 0.09928912669420242 train acc 0.9512959866220736\n",
            "epoch 20 batch id 300 loss 0.0997719019651413 train acc 0.9513020833333333\n",
            "epoch 20 batch id 301 loss 0.16308586299419403 train acc 0.9513081395348837\n",
            "epoch 20 batch id 302 loss 0.10538524389266968 train acc 0.9513658940397351\n",
            "epoch 20 batch id 303 loss 0.1962105631828308 train acc 0.9512685643564357\n",
            "epoch 20 batch id 304 loss 0.24905268847942352 train acc 0.951171875\n",
            "epoch 20 batch id 305 loss 0.1811731606721878 train acc 0.9511782786885246\n",
            "epoch 20 batch id 306 loss 0.1149296835064888 train acc 0.9512867647058824\n",
            "epoch 20 batch id 307 loss 0.05000640079379082 train acc 0.9513436482084691\n",
            "epoch 20 batch id 308 loss 0.2659977078437805 train acc 0.9512479707792207\n",
            "epoch 20 batch id 309 loss 0.16909509897232056 train acc 0.9512540453074434\n",
            "epoch 20 batch id 310 loss 0.15158489346504211 train acc 0.9512096774193548\n",
            "epoch 20 batch id 311 loss 0.26547276973724365 train acc 0.9510651125401929\n",
            "epoch 20 batch id 312 loss 0.12109171599149704 train acc 0.9511217948717948\n",
            "epoch 20 batch id 313 loss 0.2621351480484009 train acc 0.9510782747603834\n",
            "epoch 20 batch id 314 loss 0.05376288667321205 train acc 0.9511843152866242\n",
            "epoch 20 batch id 315 loss 0.13078616559505463 train acc 0.951140873015873\n",
            "epoch 20 batch id 316 loss 0.1376808136701584 train acc 0.9511471518987342\n",
            "epoch 20 batch id 317 loss 0.09197956323623657 train acc 0.9512519716088328\n",
            "epoch 20 batch id 318 loss 0.06944739818572998 train acc 0.9513069968553459\n",
            "epoch 20 batch id 319 loss 0.10247649252414703 train acc 0.9513616771159875\n",
            "epoch 20 batch id 320 loss 0.2790273427963257 train acc 0.951171875\n",
            "epoch 20 batch id 321 loss 0.07825671136379242 train acc 0.9512753115264797\n",
            "epoch 20 batch id 322 loss 0.17405186593532562 train acc 0.9513295807453416\n",
            "epoch 20 batch id 323 loss 0.18498148024082184 train acc 0.9513351393188855\n",
            "epoch 20 batch id 324 loss 0.05375848710536957 train acc 0.9514371141975309\n",
            "epoch 20 batch id 325 loss 0.08981645107269287 train acc 0.9514903846153846\n",
            "epoch 20 batch id 326 loss 0.11839044094085693 train acc 0.9515912576687117\n",
            "epoch 20 batch id 327 loss 0.10320676863193512 train acc 0.9516915137614679\n",
            "epoch 20 batch id 328 loss 0.24446003139019012 train acc 0.9516482469512195\n",
            "epoch 20 batch id 329 loss 0.0783618837594986 train acc 0.9517477203647416\n",
            "epoch 20 batch id 330 loss 0.09556741267442703 train acc 0.9517992424242424\n",
            "epoch 20 batch id 331 loss 0.3600735366344452 train acc 0.9516144259818731\n",
            "epoch 20 batch id 332 loss 0.18064872920513153 train acc 0.9515719126506024\n",
            "epoch 20 batch id 333 loss 0.2415848672389984 train acc 0.9514827327327328\n",
            "epoch 20 batch id 334 loss 0.2580588459968567 train acc 0.9513940868263473\n",
            "epoch 20 batch id 335 loss 0.20367953181266785 train acc 0.9513992537313433\n",
            "epoch 20 batch id 336 loss 0.20486381649971008 train acc 0.9513113839285714\n",
            "epoch 20 batch id 337 loss 0.19662781059741974 train acc 0.9512704005934718\n",
            "epoch 20 batch id 338 loss 0.08469007909297943 train acc 0.9513683431952663\n",
            "epoch 20 batch id 339 loss 0.1389773041009903 train acc 0.9514657079646017\n",
            "epoch 20 batch id 340 loss 0.1324450969696045 train acc 0.9515625\n",
            "epoch 20 batch id 341 loss 0.2864514887332916 train acc 0.9514754398826979\n",
            "epoch 20 batch id 342 loss 0.11950596421957016 train acc 0.9515259502923976\n",
            "epoch 20 batch id 343 loss 0.3238292932510376 train acc 0.9513483965014577\n",
            "epoch 20 batch id 344 loss 0.2356603741645813 train acc 0.9513989825581395\n",
            "epoch 20 batch id 345 loss 0.07760250568389893 train acc 0.9514945652173913\n",
            "epoch 20 batch id 346 loss 0.07962189614772797 train acc 0.9515895953757225\n",
            "epoch 20 batch id 347 loss 0.11510211229324341 train acc 0.9515940201729106\n",
            "epoch 20 batch id 348 loss 0.06065942347049713 train acc 0.9516882183908046\n",
            "epoch 20 batch id 349 loss 0.24181433022022247 train acc 0.9515580229226361\n",
            "epoch 20 batch id 350 loss 0.30370667576789856 train acc 0.9514732142857143\n",
            "epoch 20 batch id 351 loss 0.1348249465227127 train acc 0.9514779202279202\n",
            "epoch 20 batch id 352 loss 0.28349506855010986 train acc 0.9514825994318182\n",
            "epoch 20 batch id 353 loss 0.1398744434118271 train acc 0.9515315155807366\n",
            "epoch 20 batch id 354 loss 0.19900180399417877 train acc 0.9514036016949152\n",
            "epoch 20 batch id 355 loss 0.2010193169116974 train acc 0.9514084507042253\n",
            "epoch 20 batch id 356 loss 0.1864248812198639 train acc 0.9513693820224719\n",
            "epoch 20 batch id 357 loss 0.041865985840559006 train acc 0.9514618347338936\n",
            "epoch 20 batch id 358 loss 0.16714167594909668 train acc 0.9514228351955307\n",
            "epoch 20 batch id 359 loss 0.08798917382955551 train acc 0.9514275766016713\n",
            "epoch 20 batch id 360 loss 0.2645070552825928 train acc 0.9513888888888888\n",
            "epoch 20 batch id 361 loss 0.12036275863647461 train acc 0.9513936980609419\n",
            "epoch 20 batch id 362 loss 0.2025166004896164 train acc 0.9512689917127072\n",
            "epoch 20 batch id 363 loss 0.09497638046741486 train acc 0.9513171487603306\n",
            "epoch 20 batch id 364 loss 0.1952517181634903 train acc 0.9512791895604396\n",
            "epoch 20 batch id 365 loss 0.18799446523189545 train acc 0.9513270547945205\n",
            "epoch 20 batch id 366 loss 0.1791180819272995 train acc 0.9512892759562842\n",
            "epoch 20 batch id 367 loss 0.08953462541103363 train acc 0.9513368528610354\n",
            "epoch 20 batch id 368 loss 0.057761020958423615 train acc 0.9513841711956522\n",
            "epoch 20 batch id 369 loss 0.10377172380685806 train acc 0.9514312330623306\n",
            "epoch 20 batch id 370 loss 0.05675148218870163 train acc 0.9515202702702703\n",
            "epoch 20 batch id 371 loss 0.11573752015829086 train acc 0.9516088274932615\n",
            "epoch 20 batch id 372 loss 0.10070276260375977 train acc 0.9516129032258065\n",
            "epoch 20 batch id 373 loss 0.09974809736013412 train acc 0.9516588471849866\n",
            "epoch 20 batch id 374 loss 0.17737212777137756 train acc 0.9516627673796791\n",
            "epoch 20 batch id 375 loss 0.1117369532585144 train acc 0.9516666666666667\n",
            "epoch 20 batch id 376 loss 0.11836350709199905 train acc 0.9517121010638298\n",
            "epoch 20 batch id 377 loss 0.14475610852241516 train acc 0.9517572944297082\n",
            "epoch 20 batch id 378 loss 0.1294916868209839 train acc 0.9518022486772487\n",
            "epoch 20 batch id 379 loss 0.1435108184814453 train acc 0.9518469656992085\n",
            "epoch 20 batch id 380 loss 0.07922901213169098 train acc 0.951891447368421\n",
            "epoch 20 batch id 381 loss 0.2112961709499359 train acc 0.95189468503937\n",
            "epoch 20 batch id 382 loss 0.13071098923683167 train acc 0.9519388089005235\n",
            "epoch 20 batch id 383 loss 0.07151957601308823 train acc 0.952023498694517\n",
            "epoch 20 batch id 384 loss 0.09554775059223175 train acc 0.9520263671875\n",
            "epoch 20 batch id 385 loss 0.12684768438339233 train acc 0.9520698051948052\n",
            "epoch 20 batch id 386 loss 0.11941182613372803 train acc 0.952113018134715\n",
            "epoch 20 batch id 387 loss 0.25456491112709045 train acc 0.9520752583979328\n",
            "epoch 20 batch id 388 loss 0.16284188628196716 train acc 0.9520779639175257\n",
            "epoch 20 batch id 389 loss 0.22739277780056 train acc 0.9520806555269923\n",
            "epoch 20 batch id 390 loss 0.1344386786222458 train acc 0.9520432692307692\n",
            "epoch 20 batch id 391 loss 0.09297142922878265 train acc 0.9521259590792839\n",
            "epoch 20 batch id 392 loss 0.08932802081108093 train acc 0.9522082270408163\n",
            "epoch 20 batch id 393 loss 0.13158844411373138 train acc 0.9522503180661578\n",
            "epoch 20 batch id 394 loss 0.13692378997802734 train acc 0.952292195431472\n",
            "epoch 20 batch id 395 loss 0.11492354422807693 train acc 0.9523338607594937\n",
            "epoch 20 batch id 396 loss 0.2881786823272705 train acc 0.9522964015151515\n",
            "epoch 20 batch id 397 loss 0.05746714770793915 train acc 0.9523772040302267\n",
            "epoch 20 batch id 398 loss 0.2062252163887024 train acc 0.9523790829145728\n",
            "epoch 20 batch id 399 loss 0.24964608252048492 train acc 0.9523417919799498\n",
            "epoch 20 batch id 400 loss 0.3409804105758667 train acc 0.952265625\n",
            "epoch 20 batch id 401 loss 0.15393532812595367 train acc 0.9522288029925187\n",
            "epoch 20 batch id 402 loss 0.09304209053516388 train acc 0.9522699004975125\n",
            "epoch 20 batch id 403 loss 0.1424003541469574 train acc 0.9522720223325062\n",
            "epoch 20 batch id 404 loss 0.20270711183547974 train acc 0.9522354579207921\n",
            "epoch 20 batch id 405 loss 0.15873926877975464 train acc 0.9521990740740741\n",
            "epoch 20 batch id 406 loss 0.183902308344841 train acc 0.9522398399014779\n",
            "epoch 20 batch id 407 loss 0.14871935546398163 train acc 0.9521652334152334\n",
            "epoch 20 batch id 408 loss 0.041772838681936264 train acc 0.9522441789215687\n",
            "epoch 20 batch id 409 loss 0.09762895107269287 train acc 0.9522845354523227\n",
            "epoch 20 batch id 410 loss 0.22211766242980957 train acc 0.9522484756097561\n",
            "epoch 20 batch id 411 loss 0.08135031908750534 train acc 0.9522886253041363\n",
            "epoch 20 batch id 412 loss 0.11988966912031174 train acc 0.9523285800970874\n",
            "epoch 20 batch id 413 loss 0.06194179877638817 train acc 0.9523683414043583\n",
            "epoch 20 batch id 414 loss 0.26708874106407166 train acc 0.9522569444444444\n",
            "epoch 20 batch id 415 loss 0.16106973588466644 train acc 0.9522590361445783\n",
            "epoch 20 batch id 416 loss 0.18374204635620117 train acc 0.9521859975961539\n",
            "epoch 20 batch id 417 loss 0.10389148443937302 train acc 0.9522631894484412\n",
            "epoch 20 batch id 418 loss 0.18242530524730682 train acc 0.9523026315789473\n",
            "epoch 20 batch id 419 loss 0.21599924564361572 train acc 0.9523045942720764\n",
            "epoch 20 batch id 420 loss 0.33506831526756287 train acc 0.9521577380952381\n",
            "epoch 20 batch id 421 loss 0.09375286847352982 train acc 0.9522342636579573\n",
            "epoch 20 batch id 422 loss 0.09731468558311462 train acc 0.9523104265402843\n",
            "epoch 20 batch id 423 loss 0.08777512609958649 train acc 0.9523123522458629\n",
            "epoch 20 batch id 424 loss 0.06756144762039185 train acc 0.9523511202830188\n",
            "epoch 20 batch id 425 loss 0.09281358122825623 train acc 0.9523897058823529\n",
            "epoch 20 batch id 426 loss 0.10820294916629791 train acc 0.9524281103286385\n",
            "epoch 20 batch id 427 loss 0.1517774760723114 train acc 0.9524663348946136\n",
            "epoch 20 batch id 428 loss 0.27627140283584595 train acc 0.9524313668224299\n",
            "epoch 20 batch id 429 loss 0.17032180726528168 train acc 0.9524329836829837\n",
            "epoch 20 batch id 430 loss 0.06912285089492798 train acc 0.9524709302325581\n",
            "epoch 20 batch id 431 loss 0.07925168424844742 train acc 0.9525449535962877\n",
            "epoch 20 batch id 432 loss 0.128999263048172 train acc 0.9525101273148148\n",
            "epoch 20 batch id 433 loss 0.2683040201663971 train acc 0.952439376443418\n",
            "epoch 20 batch id 434 loss 0.19444414973258972 train acc 0.9524409562211982\n",
            "epoch 20 batch id 435 loss 0.1248876228928566 train acc 0.9524425287356322\n",
            "epoch 20 batch id 436 loss 0.08789835125207901 train acc 0.9524082568807339\n",
            "epoch 20 batch id 437 loss 0.04456917569041252 train acc 0.9524814073226545\n",
            "epoch 20 batch id 438 loss 0.19086898863315582 train acc 0.9525185502283106\n",
            "epoch 20 batch id 439 loss 0.1182074099779129 train acc 0.9525911161731208\n",
            "epoch 20 batch id 440 loss 0.19675618410110474 train acc 0.9525568181818181\n",
            "epoch 20 batch id 441 loss 0.21651020646095276 train acc 0.9525581065759637\n",
            "epoch 20 batch id 442 loss 0.2135680764913559 train acc 0.9525240384615384\n",
            "epoch 20 batch id 443 loss 0.3257685601711273 train acc 0.9523843115124153\n",
            "epoch 20 batch id 444 loss 0.07816988229751587 train acc 0.9524563626126126\n",
            "epoch 20 batch id 445 loss 0.20660822093486786 train acc 0.9524578651685394\n",
            "epoch 20 batch id 446 loss 0.06507812440395355 train acc 0.9525294282511211\n",
            "epoch 20 batch id 447 loss 0.1910230666399002 train acc 0.9524608501118568\n",
            "epoch 20 batch id 448 loss 0.17225733399391174 train acc 0.9524623325892857\n",
            "epoch 20 batch id 449 loss 0.09648165106773376 train acc 0.9524986080178174\n",
            "epoch 20 batch id 450 loss 0.06312453746795654 train acc 0.9525694444444445\n",
            "epoch 20 batch id 451 loss 0.17973624169826508 train acc 0.9525360310421286\n",
            "epoch 20 batch id 452 loss 0.21948644518852234 train acc 0.9525373340707964\n",
            "epoch 20 batch id 453 loss 0.15621349215507507 train acc 0.9525386313465783\n",
            "epoch 20 batch id 454 loss 0.03752802312374115 train acc 0.9526431718061674\n",
            "epoch 20 batch id 455 loss 0.332917183637619 train acc 0.9525755494505495\n",
            "epoch 20 batch id 456 loss 0.06772587448358536 train acc 0.9526110197368421\n",
            "epoch 20 batch id 457 loss 0.1570819616317749 train acc 0.9526463347921226\n",
            "epoch 20 batch id 458 loss 0.18273232877254486 train acc 0.9526814956331878\n",
            "epoch 20 batch id 459 loss 0.10029924660921097 train acc 0.9527505446623094\n",
            "epoch 20 batch id 460 loss 0.10102126002311707 train acc 0.9527853260869565\n",
            "epoch 20 batch id 461 loss 0.13700655102729797 train acc 0.9528538503253796\n",
            "epoch 20 batch id 462 loss 0.07988414168357849 train acc 0.9528882575757576\n",
            "epoch 20 batch id 463 loss 0.1748899668455124 train acc 0.9528887688984882\n",
            "epoch 20 batch id 464 loss 0.13360103964805603 train acc 0.9528556034482759\n",
            "epoch 20 batch id 465 loss 0.037342242896556854 train acc 0.9529569892473119\n",
            "epoch 20 batch id 466 loss 0.17784565687179565 train acc 0.9529573497854077\n",
            "epoch 20 batch id 467 loss 0.18951545655727386 train acc 0.9529911670235546\n",
            "epoch 20 batch id 468 loss 0.10243360698223114 train acc 0.9530248397435898\n",
            "epoch 20 batch id 469 loss 0.09562234580516815 train acc 0.9530250533049041\n",
            "epoch 20 batch id 470 loss 0.17869503796100616 train acc 0.9530252659574469\n",
            "epoch 20 batch id 471 loss 0.14390283823013306 train acc 0.9530586518046709\n",
            "epoch 20 batch id 472 loss 0.17927592992782593 train acc 0.9530918961864406\n",
            "epoch 20 batch id 473 loss 0.15254069864749908 train acc 0.9530919661733616\n",
            "epoch 20 batch id 474 loss 0.2204827219247818 train acc 0.9529931434599156\n",
            "epoch 20 batch id 475 loss 0.1871039718389511 train acc 0.9529934210526316\n",
            "epoch 20 batch id 476 loss 0.1109737753868103 train acc 0.9530593487394958\n",
            "epoch 20 batch id 477 loss 0.28746122121810913 train acc 0.9530267295597484\n",
            "epoch 20 batch id 478 loss 0.2192603200674057 train acc 0.9530269351464435\n",
            "epoch 20 batch id 479 loss 0.14768077433109283 train acc 0.9530597599164927\n",
            "epoch 20 batch id 480 loss 0.45761898159980774 train acc 0.9529622395833334\n",
            "epoch 20 batch id 481 loss 0.22608333826065063 train acc 0.9529950623700624\n",
            "epoch 20 batch id 482 loss 0.10026269406080246 train acc 0.9530277489626556\n",
            "epoch 20 batch id 483 loss 0.2539520561695099 train acc 0.9529632505175983\n",
            "epoch 20 batch id 484 loss 0.13736960291862488 train acc 0.9528990185950413\n",
            "epoch 20 batch id 485 loss 0.1730288565158844 train acc 0.9528994845360824\n",
            "epoch 20 batch id 486 loss 0.298859179019928 train acc 0.9528677983539094\n",
            "epoch 20 batch id 487 loss 0.24250464141368866 train acc 0.9528362422997947\n",
            "epoch 20 batch id 488 loss 0.1574731469154358 train acc 0.9528368340163934\n",
            "epoch 20 batch id 489 loss 0.12254219502210617 train acc 0.9528374233128835\n",
            "epoch 20 batch id 490 loss 0.09992198646068573 train acc 0.9528698979591836\n",
            "epoch 20 batch id 491 loss 0.196243017911911 train acc 0.9528385947046843\n",
            "epoch 20 batch id 492 loss 0.03176412731409073 train acc 0.9529344512195121\n",
            "epoch 20 batch id 493 loss 0.20276567339897156 train acc 0.9528714503042597\n",
            "epoch 20 batch id 494 loss 0.07269047945737839 train acc 0.9529352226720648\n",
            "epoch 20 batch id 495 loss 0.10966205596923828 train acc 0.9529671717171717\n",
            "epoch 20 batch id 496 loss 0.26603376865386963 train acc 0.9529359879032258\n",
            "epoch 20 batch id 497 loss 0.27490630745887756 train acc 0.9528734909456741\n",
            "epoch 20 batch id 498 loss 0.19956250488758087 train acc 0.9529053714859438\n",
            "epoch 20 batch id 499 loss 0.1339922845363617 train acc 0.952937124248497\n",
            "epoch 20 batch id 500 loss 0.15591467916965485 train acc 0.9529375\n",
            "epoch 20 batch id 501 loss 0.13485603034496307 train acc 0.9529690618762475\n",
            "epoch 20 batch id 502 loss 0.14249207079410553 train acc 0.9530004980079682\n",
            "epoch 20 batch id 503 loss 0.13260087370872498 train acc 0.9530318091451292\n",
            "epoch 20 batch id 504 loss 0.0915922075510025 train acc 0.953062996031746\n",
            "epoch 20 batch id 505 loss 0.2250320315361023 train acc 0.9530940594059406\n",
            "epoch 20 batch id 506 loss 0.09547031670808792 train acc 0.953125\n",
            "epoch 20 batch id 507 loss 0.13697320222854614 train acc 0.953094181459566\n",
            "epoch 20 batch id 508 loss 0.18954457342624664 train acc 0.9530327263779528\n",
            "epoch 20 batch id 509 loss 0.3255721628665924 train acc 0.95300221021611\n",
            "epoch 20 batch id 510 loss 0.3216891288757324 train acc 0.9528186274509803\n",
            "epoch 20 batch id 511 loss 0.21721304953098297 train acc 0.9528488335973659\n",
            "epoch 20 train acc 0.9528488335973659\n",
            "epoch 20 test acc 0.3948160807291667\n",
            "epoch 21 batch id 1 loss 0.10169171541929245 train acc 0.96875\n",
            "epoch 21 batch id 2 loss 0.112153559923172 train acc 0.96875\n",
            "epoch 21 batch id 3 loss 0.22022351622581482 train acc 0.9479166666666666\n",
            "epoch 21 batch id 4 loss 0.22377334535121918 train acc 0.9453125\n",
            "epoch 21 batch id 5 loss 0.09922575205564499 train acc 0.946875\n",
            "epoch 21 batch id 6 loss 0.20000097155570984 train acc 0.9479166666666666\n",
            "epoch 21 batch id 7 loss 0.2734202742576599 train acc 0.9441964285714286\n",
            "epoch 21 batch id 8 loss 0.13509036600589752 train acc 0.9453125\n",
            "epoch 21 batch id 9 loss 0.06138501316308975 train acc 0.9496527777777778\n",
            "epoch 21 batch id 10 loss 0.10364998131990433 train acc 0.95\n",
            "epoch 21 batch id 11 loss 0.2547689974308014 train acc 0.9460227272727273\n",
            "epoch 21 batch id 12 loss 0.09041626006364822 train acc 0.9505208333333334\n",
            "epoch 21 batch id 13 loss 0.24090684950351715 train acc 0.9507211538461539\n",
            "epoch 21 batch id 14 loss 0.07031054049730301 train acc 0.953125\n",
            "epoch 21 batch id 15 loss 0.049104467034339905 train acc 0.95625\n",
            "epoch 21 batch id 16 loss 0.040282368659973145 train acc 0.958984375\n",
            "epoch 21 batch id 17 loss 0.22186847031116486 train acc 0.9577205882352942\n",
            "epoch 21 batch id 18 loss 0.13002528250217438 train acc 0.9583333333333334\n",
            "epoch 21 batch id 19 loss 0.135043203830719 train acc 0.9580592105263158\n",
            "epoch 21 batch id 20 loss 0.14857031404972076 train acc 0.95703125\n",
            "epoch 21 batch id 21 loss 0.085022933781147 train acc 0.9575892857142857\n",
            "epoch 21 batch id 22 loss 0.15220953524112701 train acc 0.9580965909090909\n",
            "epoch 21 batch id 23 loss 0.16494767367839813 train acc 0.9578804347826086\n",
            "epoch 21 batch id 24 loss 0.08852322399616241 train acc 0.9583333333333334\n",
            "epoch 21 batch id 25 loss 0.060016337782144547 train acc 0.959375\n",
            "epoch 21 batch id 26 loss 0.03711148723959923 train acc 0.9609375\n",
            "epoch 21 batch id 27 loss 0.044286973774433136 train acc 0.9618055555555556\n",
            "epoch 21 batch id 28 loss 0.09599804133176804 train acc 0.9626116071428571\n",
            "epoch 21 batch id 29 loss 0.18156245350837708 train acc 0.9622844827586207\n",
            "epoch 21 batch id 30 loss 0.05684209614992142 train acc 0.9630208333333333\n",
            "epoch 21 batch id 31 loss 0.22809159755706787 train acc 0.9627016129032258\n",
            "epoch 21 batch id 32 loss 0.05509646236896515 train acc 0.9638671875\n",
            "epoch 21 batch id 33 loss 0.13166417181491852 train acc 0.9644886363636364\n",
            "epoch 21 batch id 34 loss 0.22571487724781036 train acc 0.9636948529411765\n",
            "epoch 21 batch id 35 loss 0.1595667600631714 train acc 0.9633928571428572\n",
            "epoch 21 batch id 36 loss 0.2339055836200714 train acc 0.9626736111111112\n",
            "epoch 21 batch id 37 loss 0.09096615016460419 train acc 0.9632601351351351\n",
            "epoch 21 batch id 38 loss 0.2970081567764282 train acc 0.962171052631579\n",
            "epoch 21 batch id 39 loss 0.22707635164260864 train acc 0.9615384615384616\n",
            "epoch 21 batch id 40 loss 0.09456071257591248 train acc 0.96171875\n",
            "epoch 21 batch id 41 loss 0.24448637664318085 train acc 0.9611280487804879\n",
            "epoch 21 batch id 42 loss 0.33940446376800537 train acc 0.9601934523809523\n",
            "epoch 21 batch id 43 loss 0.11001983284950256 train acc 0.9603924418604651\n",
            "epoch 21 batch id 44 loss 0.050824057310819626 train acc 0.9609375\n",
            "epoch 21 batch id 45 loss 0.12791647017002106 train acc 0.9611111111111111\n",
            "epoch 21 batch id 46 loss 0.17001667618751526 train acc 0.9616168478260869\n",
            "epoch 21 batch id 47 loss 0.06293043494224548 train acc 0.9621010638297872\n",
            "epoch 21 batch id 48 loss 0.14807935059070587 train acc 0.9615885416666666\n",
            "epoch 21 batch id 49 loss 0.23549871146678925 train acc 0.9617346938775511\n",
            "epoch 21 batch id 50 loss 0.04293261468410492 train acc 0.9625\n",
            "epoch 21 batch id 51 loss 0.09183444082736969 train acc 0.9629289215686274\n",
            "epoch 21 batch id 52 loss 0.19150054454803467 train acc 0.9627403846153846\n",
            "epoch 21 batch id 53 loss 0.04174560308456421 train acc 0.9631485849056604\n",
            "epoch 21 batch id 54 loss 0.11563971638679504 train acc 0.9632523148148148\n",
            "epoch 21 batch id 55 loss 0.14421403408050537 train acc 0.9630681818181818\n",
            "epoch 21 batch id 56 loss 0.18400463461875916 train acc 0.9631696428571429\n",
            "epoch 21 batch id 57 loss 0.29648077487945557 train acc 0.9627192982456141\n",
            "epoch 21 batch id 58 loss 0.070955790579319 train acc 0.9630926724137931\n",
            "epoch 21 batch id 59 loss 0.05013575404882431 train acc 0.963718220338983\n",
            "epoch 21 batch id 60 loss 0.06816532462835312 train acc 0.9640625\n",
            "epoch 21 batch id 61 loss 0.06911656260490417 train acc 0.9643954918032787\n",
            "epoch 21 batch id 62 loss 0.347014844417572 train acc 0.9632056451612904\n",
            "epoch 21 batch id 63 loss 0.3658699095249176 train acc 0.9623015873015873\n",
            "epoch 21 batch id 64 loss 0.2516786456108093 train acc 0.962158203125\n",
            "epoch 21 batch id 65 loss 0.24415458738803864 train acc 0.9615384615384616\n",
            "epoch 21 batch id 66 loss 0.11308646202087402 train acc 0.9616477272727273\n",
            "epoch 21 batch id 67 loss 0.18781733512878418 train acc 0.9612873134328358\n",
            "epoch 21 batch id 68 loss 0.0914217159152031 train acc 0.9616268382352942\n",
            "epoch 21 batch id 69 loss 0.20630812644958496 train acc 0.9619565217391305\n",
            "epoch 21 batch id 70 loss 0.17016251385211945 train acc 0.9620535714285714\n",
            "epoch 21 batch id 71 loss 0.29297930002212524 train acc 0.961487676056338\n",
            "epoch 21 batch id 72 loss 0.08624634891748428 train acc 0.9618055555555556\n",
            "epoch 21 batch id 73 loss 0.23559175431728363 train acc 0.9619006849315068\n",
            "epoch 21 batch id 74 loss 0.1967451572418213 train acc 0.9613597972972973\n",
            "epoch 21 batch id 75 loss 0.07505426555871964 train acc 0.9616666666666667\n",
            "epoch 21 batch id 76 loss 0.15194158256053925 train acc 0.9619654605263158\n",
            "epoch 21 batch id 77 loss 0.06041543558239937 train acc 0.9622564935064936\n",
            "epoch 21 batch id 78 loss 0.13371099531650543 train acc 0.9623397435897436\n",
            "epoch 21 batch id 79 loss 0.050461698323488235 train acc 0.9628164556962026\n",
            "epoch 21 batch id 80 loss 0.21814511716365814 train acc 0.9626953125\n",
            "epoch 21 batch id 81 loss 0.27037718892097473 train acc 0.9625771604938271\n",
            "epoch 21 batch id 82 loss 0.044767603278160095 train acc 0.9630335365853658\n",
            "epoch 21 batch id 83 loss 0.166000634431839 train acc 0.962914156626506\n",
            "epoch 21 batch id 84 loss 0.09277580678462982 train acc 0.9631696428571429\n",
            "epoch 21 batch id 85 loss 0.16253387928009033 train acc 0.9632352941176471\n",
            "epoch 21 batch id 86 loss 0.07668405771255493 train acc 0.9634811046511628\n",
            "epoch 21 batch id 87 loss 0.2120455801486969 train acc 0.9635416666666666\n",
            "epoch 21 batch id 88 loss 0.252323180437088 train acc 0.9627130681818182\n",
            "epoch 21 batch id 89 loss 0.1410987377166748 train acc 0.9627808988764045\n",
            "epoch 21 batch id 90 loss 0.11214559525251389 train acc 0.9630208333333333\n",
            "epoch 21 batch id 91 loss 0.10934752225875854 train acc 0.9627403846153846\n",
            "epoch 21 batch id 92 loss 0.19330576062202454 train acc 0.9626358695652174\n",
            "epoch 21 batch id 93 loss 0.04977581277489662 train acc 0.962869623655914\n",
            "epoch 21 batch id 94 loss 0.14539101719856262 train acc 0.9629321808510638\n",
            "epoch 21 batch id 95 loss 0.1187773048877716 train acc 0.9631578947368421\n",
            "epoch 21 batch id 96 loss 0.0671711340546608 train acc 0.9632161458333334\n",
            "epoch 21 batch id 97 loss 0.17611753940582275 train acc 0.9632731958762887\n",
            "epoch 21 batch id 98 loss 0.13954348862171173 train acc 0.9631696428571429\n",
            "epoch 21 batch id 99 loss 0.11629382520914078 train acc 0.9633838383838383\n",
            "epoch 21 batch id 100 loss 0.11220958828926086 train acc 0.96328125\n",
            "epoch 21 batch id 101 loss 0.22133120894432068 train acc 0.963180693069307\n",
            "epoch 21 batch id 102 loss 0.03796052187681198 train acc 0.9635416666666666\n",
            "epoch 21 batch id 103 loss 0.19529323279857635 train acc 0.9634405339805825\n",
            "epoch 21 batch id 104 loss 0.1989726722240448 train acc 0.9634915865384616\n",
            "epoch 21 batch id 105 loss 0.06371647119522095 train acc 0.9636904761904762\n",
            "epoch 21 batch id 106 loss 0.22640474140644073 train acc 0.9635908018867925\n",
            "epoch 21 batch id 107 loss 0.14987537264823914 train acc 0.9636390186915887\n",
            "epoch 21 batch id 108 loss 0.11472540348768234 train acc 0.9636863425925926\n",
            "epoch 21 batch id 109 loss 0.2721976637840271 train acc 0.9634461009174312\n",
            "epoch 21 batch id 110 loss 0.07249638438224792 train acc 0.9634943181818182\n",
            "epoch 21 batch id 111 loss 0.26342904567718506 train acc 0.9631193693693694\n",
            "epoch 21 batch id 112 loss 0.23536722362041473 train acc 0.9627511160714286\n",
            "epoch 21 batch id 113 loss 0.025135541334748268 train acc 0.9630807522123894\n",
            "epoch 21 batch id 114 loss 0.18653570115566254 train acc 0.9629934210526315\n",
            "epoch 21 batch id 115 loss 0.14995361864566803 train acc 0.9631793478260869\n",
            "epoch 21 batch id 116 loss 0.16228918731212616 train acc 0.9632273706896551\n",
            "epoch 21 batch id 117 loss 0.05672265961766243 train acc 0.9635416666666666\n",
            "epoch 21 batch id 118 loss 0.108940988779068 train acc 0.963718220338983\n",
            "epoch 21 batch id 119 loss 0.1472330093383789 train acc 0.963891806722689\n",
            "epoch 21 batch id 120 loss 0.19424232840538025 train acc 0.9639322916666667\n",
            "epoch 21 batch id 121 loss 0.21152755618095398 train acc 0.9638429752066116\n",
            "epoch 21 batch id 122 loss 0.2035914808511734 train acc 0.9638831967213115\n",
            "epoch 21 batch id 123 loss 0.12966637313365936 train acc 0.9639227642276422\n",
            "epoch 21 batch id 124 loss 0.15932030975818634 train acc 0.9639616935483871\n",
            "epoch 21 batch id 125 loss 0.19481220841407776 train acc 0.96375\n",
            "epoch 21 batch id 126 loss 0.1706475168466568 train acc 0.9635416666666666\n",
            "epoch 21 batch id 127 loss 0.13623186945915222 train acc 0.9634596456692913\n",
            "epoch 21 batch id 128 loss 0.14936377108097076 train acc 0.96337890625\n",
            "epoch 21 batch id 129 loss 0.05581288039684296 train acc 0.9635416666666666\n",
            "epoch 21 batch id 130 loss 0.1468028724193573 train acc 0.9634615384615385\n",
            "epoch 21 batch id 131 loss 0.4160342216491699 train acc 0.9630248091603053\n",
            "epoch 21 batch id 132 loss 0.19304916262626648 train acc 0.9627130681818182\n",
            "epoch 21 batch id 133 loss 0.19956989586353302 train acc 0.9624060150375939\n",
            "epoch 21 batch id 134 loss 0.04652917757630348 train acc 0.9625699626865671\n",
            "epoch 21 batch id 135 loss 0.11678774654865265 train acc 0.9623842592592593\n",
            "epoch 21 batch id 136 loss 0.08136757463216782 train acc 0.9625459558823529\n",
            "epoch 21 batch id 137 loss 0.34973469376564026 train acc 0.9621350364963503\n",
            "epoch 21 batch id 138 loss 0.19474638998508453 train acc 0.9621829710144928\n",
            "epoch 21 batch id 139 loss 0.2530634105205536 train acc 0.9620053956834532\n",
            "epoch 21 batch id 140 loss 0.1676708310842514 train acc 0.9620535714285714\n",
            "epoch 21 batch id 141 loss 0.15580439567565918 train acc 0.9621010638297872\n",
            "epoch 21 batch id 142 loss 0.2212699055671692 train acc 0.9619278169014085\n",
            "epoch 21 batch id 143 loss 0.24520260095596313 train acc 0.9618662587412588\n",
            "epoch 21 batch id 144 loss 0.27328506112098694 train acc 0.9615885416666666\n",
            "epoch 21 batch id 145 loss 0.17612121999263763 train acc 0.9613146551724138\n",
            "epoch 21 batch id 146 loss 0.21721357107162476 train acc 0.9611515410958904\n",
            "epoch 21 batch id 147 loss 0.07944098114967346 train acc 0.9613095238095238\n",
            "epoch 21 batch id 148 loss 0.036078713834285736 train acc 0.9614653716216216\n",
            "epoch 21 batch id 149 loss 0.09920743107795715 train acc 0.9615142617449665\n",
            "epoch 21 batch id 150 loss 0.07548113167285919 train acc 0.9616666666666667\n",
            "epoch 21 batch id 151 loss 0.15610212087631226 train acc 0.9616100993377483\n",
            "epoch 21 batch id 152 loss 0.1265055239200592 train acc 0.9615542763157895\n",
            "epoch 21 batch id 153 loss 0.23677612841129303 train acc 0.9611928104575164\n",
            "epoch 21 batch id 154 loss 0.15125910937786102 train acc 0.961140422077922\n",
            "epoch 21 batch id 155 loss 0.03409508615732193 train acc 0.9613911290322581\n",
            "epoch 21 batch id 156 loss 0.06878148764371872 train acc 0.9614383012820513\n",
            "epoch 21 batch id 157 loss 0.21120990812778473 train acc 0.9612858280254777\n",
            "epoch 21 batch id 158 loss 0.10878505557775497 train acc 0.9612341772151899\n",
            "epoch 21 batch id 159 loss 0.22313569486141205 train acc 0.9610849056603774\n",
            "epoch 21 batch id 160 loss 0.11005916446447372 train acc 0.96103515625\n",
            "epoch 21 batch id 161 loss 0.14782483875751495 train acc 0.9610830745341615\n",
            "epoch 21 batch id 162 loss 0.2488410472869873 train acc 0.9608410493827161\n",
            "epoch 21 batch id 163 loss 0.03280029073357582 train acc 0.9610812883435583\n",
            "epoch 21 batch id 164 loss 0.18242448568344116 train acc 0.9610327743902439\n",
            "epoch 21 batch id 165 loss 0.0566566102206707 train acc 0.9610795454545454\n",
            "epoch 21 batch id 166 loss 0.2500545084476471 train acc 0.9610316265060241\n",
            "epoch 21 batch id 167 loss 0.29127827286720276 train acc 0.9609842814371258\n",
            "epoch 21 batch id 168 loss 0.10839498043060303 train acc 0.9609375\n",
            "epoch 21 batch id 169 loss 0.052179791033267975 train acc 0.9611686390532544\n",
            "epoch 21 batch id 170 loss 0.2997186779975891 train acc 0.9609375\n",
            "epoch 21 batch id 171 loss 0.39105933904647827 train acc 0.9607090643274854\n",
            "epoch 21 batch id 172 loss 0.1531323343515396 train acc 0.9606649709302325\n",
            "epoch 21 batch id 173 loss 0.10063444823026657 train acc 0.9607117052023122\n",
            "epoch 21 batch id 174 loss 0.22126637399196625 train acc 0.9605783045977011\n",
            "epoch 21 batch id 175 loss 0.10879866033792496 train acc 0.960625\n",
            "epoch 21 batch id 176 loss 0.10254839062690735 train acc 0.9606711647727273\n",
            "epoch 21 batch id 177 loss 0.0859997496008873 train acc 0.9607168079096046\n",
            "epoch 21 batch id 178 loss 0.12251115590333939 train acc 0.9607619382022472\n",
            "epoch 21 batch id 179 loss 0.11115937680006027 train acc 0.9607192737430168\n",
            "epoch 21 batch id 180 loss 0.20669648051261902 train acc 0.9606770833333333\n",
            "epoch 21 batch id 181 loss 0.1684834361076355 train acc 0.9608080110497238\n",
            "epoch 21 batch id 182 loss 0.15932334959506989 train acc 0.9607657967032966\n",
            "epoch 21 batch id 183 loss 0.11744613945484161 train acc 0.9608094262295082\n",
            "epoch 21 batch id 184 loss 0.11249779909849167 train acc 0.9608525815217391\n",
            "epoch 21 batch id 185 loss 0.07829717546701431 train acc 0.9608952702702702\n",
            "epoch 21 batch id 186 loss 0.11057030409574509 train acc 0.9608534946236559\n",
            "epoch 21 batch id 187 loss 0.08298629522323608 train acc 0.9608957219251337\n",
            "epoch 21 batch id 188 loss 0.0358014740049839 train acc 0.9611037234042553\n",
            "epoch 21 batch id 189 loss 0.1729426085948944 train acc 0.9609788359788359\n",
            "epoch 21 batch id 190 loss 0.24523095786571503 train acc 0.9610197368421053\n",
            "epoch 21 batch id 191 loss 0.08083457499742508 train acc 0.9610602094240838\n",
            "epoch 21 batch id 192 loss 0.23247873783111572 train acc 0.9609375\n",
            "epoch 21 batch id 193 loss 0.11707770079374313 train acc 0.9608970207253886\n",
            "epoch 21 batch id 194 loss 0.10429894924163818 train acc 0.9609375\n",
            "epoch 21 batch id 195 loss 0.11614368110895157 train acc 0.9608974358974359\n",
            "epoch 21 batch id 196 loss 0.3128242492675781 train acc 0.9608577806122449\n",
            "epoch 21 batch id 197 loss 0.07105796039104462 train acc 0.9609771573604061\n",
            "epoch 21 batch id 198 loss 0.16180068254470825 train acc 0.9609375\n",
            "epoch 21 batch id 199 loss 0.21201534569263458 train acc 0.9608197236180904\n",
            "epoch 21 batch id 200 loss 0.1266234964132309 train acc 0.960859375\n",
            "epoch 21 batch id 201 loss 0.10533369332551956 train acc 0.960898631840796\n",
            "epoch 21 batch id 202 loss 0.1393526941537857 train acc 0.9609375\n",
            "epoch 21 batch id 203 loss 0.10017349570989609 train acc 0.9609759852216748\n",
            "epoch 21 batch id 204 loss 0.19422778487205505 train acc 0.9609375\n",
            "epoch 21 batch id 205 loss 0.14638777077198029 train acc 0.9608993902439025\n",
            "epoch 21 batch id 206 loss 0.14002978801727295 train acc 0.9609375\n",
            "epoch 21 batch id 207 loss 0.18562522530555725 train acc 0.9608997584541062\n",
            "epoch 21 batch id 208 loss 0.15626183152198792 train acc 0.9608623798076923\n",
            "epoch 21 batch id 209 loss 0.03856915608048439 train acc 0.9609748803827751\n",
            "epoch 21 batch id 210 loss 0.40865448117256165 train acc 0.9609375\n",
            "epoch 21 batch id 211 loss 0.10434231162071228 train acc 0.9609745260663507\n",
            "epoch 21 batch id 212 loss 0.1510615199804306 train acc 0.9608637971698113\n",
            "epoch 21 batch id 213 loss 0.05107659474015236 train acc 0.9609741784037559\n",
            "epoch 21 batch id 214 loss 0.07303369045257568 train acc 0.9610105140186916\n",
            "epoch 21 batch id 215 loss 0.099406398832798 train acc 0.961046511627907\n",
            "epoch 21 batch id 216 loss 0.06536836922168732 train acc 0.9611545138888888\n",
            "epoch 21 batch id 217 loss 0.17816999554634094 train acc 0.9612615207373272\n",
            "epoch 21 batch id 218 loss 0.13577048480510712 train acc 0.961295871559633\n",
            "epoch 21 batch id 219 loss 0.1993570625782013 train acc 0.9612585616438356\n",
            "epoch 21 batch id 220 loss 0.10062873363494873 train acc 0.9612926136363636\n",
            "epoch 21 batch id 221 loss 0.12384601682424545 train acc 0.9613263574660633\n",
            "epoch 21 batch id 222 loss 0.1386215090751648 train acc 0.9612894144144144\n",
            "epoch 21 batch id 223 loss 0.20143547654151917 train acc 0.961252802690583\n",
            "epoch 21 batch id 224 loss 0.35844114422798157 train acc 0.9610770089285714\n",
            "epoch 21 batch id 225 loss 0.17537318170070648 train acc 0.9610416666666667\n",
            "epoch 21 batch id 226 loss 0.2748258411884308 train acc 0.9608683628318584\n",
            "epoch 21 batch id 227 loss 0.07659944146871567 train acc 0.9609719162995595\n",
            "epoch 21 batch id 228 loss 0.12571366131305695 train acc 0.9610060307017544\n",
            "epoch 21 batch id 229 loss 0.12447584420442581 train acc 0.960971615720524\n",
            "epoch 21 batch id 230 loss 0.09286779910326004 train acc 0.9610733695652174\n",
            "epoch 21 batch id 231 loss 0.22905418276786804 train acc 0.9609713203463204\n",
            "epoch 21 batch id 232 loss 0.1637970209121704 train acc 0.9609375\n",
            "epoch 21 batch id 233 loss 0.15909075736999512 train acc 0.9609039699570815\n",
            "epoch 21 batch id 234 loss 0.28623998165130615 train acc 0.960670405982906\n",
            "epoch 21 batch id 235 loss 0.3914543390274048 train acc 0.960438829787234\n",
            "epoch 21 batch id 236 loss 0.017582815140485764 train acc 0.9606064618644068\n",
            "epoch 21 batch id 237 loss 0.11404750496149063 train acc 0.9606408227848101\n",
            "epoch 21 batch id 238 loss 0.15693098306655884 train acc 0.9606748949579832\n",
            "epoch 21 batch id 239 loss 0.1759856790304184 train acc 0.9606433054393305\n",
            "epoch 21 batch id 240 loss 0.05831999331712723 train acc 0.9607421875\n",
            "epoch 21 batch id 241 loss 0.12654928863048553 train acc 0.9607754149377593\n",
            "epoch 21 batch id 242 loss 0.14837855100631714 train acc 0.9607438016528925\n",
            "epoch 21 batch id 243 loss 0.16656740009784698 train acc 0.9607124485596708\n",
            "epoch 21 batch id 244 loss 0.05875951796770096 train acc 0.9608094262295082\n",
            "epoch 21 batch id 245 loss 0.19406110048294067 train acc 0.9606505102040817\n",
            "epoch 21 batch id 246 loss 0.14773280918598175 train acc 0.960619918699187\n",
            "epoch 21 batch id 247 loss 0.13233357667922974 train acc 0.9605895748987854\n",
            "epoch 21 batch id 248 loss 0.12100087851285934 train acc 0.9606224798387096\n",
            "epoch 21 batch id 249 loss 0.20682960748672485 train acc 0.9604668674698795\n",
            "epoch 21 batch id 250 loss 0.0757545679807663 train acc 0.9605625\n",
            "epoch 21 batch id 251 loss 0.13760699331760406 train acc 0.9604083665338645\n",
            "epoch 21 batch id 252 loss 0.23698635399341583 train acc 0.9603174603174603\n",
            "epoch 21 batch id 253 loss 0.3634665608406067 train acc 0.9600419960474308\n",
            "epoch 21 batch id 254 loss 0.18134377896785736 train acc 0.9599532480314961\n",
            "epoch 21 batch id 255 loss 0.1076601892709732 train acc 0.9599877450980392\n",
            "epoch 21 batch id 256 loss 0.07392532378435135 train acc 0.9599609375\n",
            "epoch 21 batch id 257 loss 0.19588111340999603 train acc 0.9598735408560312\n",
            "epoch 21 batch id 258 loss 0.05647032707929611 train acc 0.959968507751938\n",
            "epoch 21 batch id 259 loss 0.17831836640834808 train acc 0.9598817567567568\n",
            "epoch 21 batch id 260 loss 0.12512391805648804 train acc 0.959795673076923\n",
            "epoch 21 batch id 261 loss 0.1499433070421219 train acc 0.9597701149425287\n",
            "epoch 21 batch id 262 loss 0.15934546291828156 train acc 0.9597447519083969\n",
            "epoch 21 batch id 263 loss 0.0830172747373581 train acc 0.9597789923954373\n",
            "epoch 21 batch id 264 loss 0.0348118394613266 train acc 0.9599313446969697\n",
            "epoch 21 batch id 265 loss 0.18576857447624207 train acc 0.9599056603773585\n",
            "epoch 21 batch id 266 loss 0.09513511508703232 train acc 0.9599389097744361\n",
            "epoch 21 batch id 267 loss 0.09986968338489532 train acc 0.9599133895131086\n",
            "epoch 21 batch id 268 loss 0.05290771648287773 train acc 0.9600046641791045\n",
            "epoch 21 batch id 269 loss 0.10138718038797379 train acc 0.9599790892193308\n",
            "epoch 21 batch id 270 loss 0.24097786843776703 train acc 0.9598958333333333\n",
            "epoch 21 batch id 271 loss 0.09859289228916168 train acc 0.9599285055350554\n",
            "epoch 21 batch id 272 loss 0.04621342197060585 train acc 0.9600183823529411\n",
            "epoch 21 batch id 273 loss 0.2174118012189865 train acc 0.9599358974358975\n",
            "epoch 21 batch id 274 loss 0.2963196635246277 train acc 0.9598540145985401\n",
            "epoch 21 batch id 275 loss 0.12724542617797852 train acc 0.9598295454545455\n",
            "epoch 21 batch id 276 loss 0.14000304043293 train acc 0.9597486413043478\n",
            "epoch 21 batch id 277 loss 0.23154915869235992 train acc 0.9597247292418772\n",
            "epoch 21 batch id 278 loss 0.16495050489902496 train acc 0.9597009892086331\n",
            "epoch 21 batch id 279 loss 0.11954016983509064 train acc 0.959733422939068\n",
            "epoch 21 batch id 280 loss 0.1314181089401245 train acc 0.9597098214285714\n",
            "epoch 21 batch id 281 loss 0.25151297450065613 train acc 0.9596307829181495\n",
            "epoch 21 batch id 282 loss 0.09612637013196945 train acc 0.9596631205673759\n",
            "epoch 21 batch id 283 loss 0.3588678240776062 train acc 0.9594743816254417\n",
            "epoch 21 batch id 284 loss 0.18435794115066528 train acc 0.9593970070422535\n",
            "epoch 21 batch id 285 loss 0.1910630464553833 train acc 0.959375\n",
            "epoch 21 batch id 286 loss 0.11394717544317245 train acc 0.9594077797202797\n",
            "epoch 21 batch id 287 loss 0.09253095835447311 train acc 0.959440331010453\n",
            "epoch 21 batch id 288 loss 0.29094234108924866 train acc 0.9593098958333334\n",
            "epoch 21 batch id 289 loss 0.20897835493087769 train acc 0.9592884948096886\n",
            "epoch 21 batch id 290 loss 0.09138575196266174 train acc 0.9593211206896551\n",
            "epoch 21 batch id 291 loss 0.17419424653053284 train acc 0.9592998281786942\n",
            "epoch 21 batch id 292 loss 0.10486972332000732 train acc 0.9592786815068494\n",
            "epoch 21 batch id 293 loss 0.1585153341293335 train acc 0.9592043515358362\n",
            "epoch 21 batch id 294 loss 0.219869464635849 train acc 0.9591305272108843\n",
            "epoch 21 batch id 295 loss 0.08770379424095154 train acc 0.9592161016949152\n",
            "epoch 21 batch id 296 loss 0.10909485816955566 train acc 0.9592483108108109\n",
            "epoch 21 batch id 297 loss 0.03354056924581528 train acc 0.9593855218855218\n",
            "epoch 21 batch id 298 loss 0.04901815578341484 train acc 0.9594693791946308\n",
            "epoch 21 batch id 299 loss 0.10456278175115585 train acc 0.9594481605351171\n",
            "epoch 21 batch id 300 loss 0.22516705095767975 train acc 0.9594791666666667\n",
            "epoch 21 batch id 301 loss 0.10236795991659164 train acc 0.9595099667774086\n",
            "epoch 21 batch id 302 loss 0.0648287758231163 train acc 0.9595923013245033\n",
            "epoch 21 batch id 303 loss 0.10212541371583939 train acc 0.9595709570957096\n",
            "epoch 21 batch id 304 loss 0.03115876391530037 train acc 0.959703947368421\n",
            "epoch 21 batch id 305 loss 0.20371954143047333 train acc 0.9595799180327869\n",
            "epoch 21 batch id 306 loss 0.0544082373380661 train acc 0.9597120098039216\n",
            "epoch 21 batch id 307 loss 0.14260627329349518 train acc 0.959792345276873\n",
            "epoch 21 batch id 308 loss 0.32225480675697327 train acc 0.959669237012987\n",
            "epoch 21 batch id 309 loss 0.2669493556022644 train acc 0.959546925566343\n",
            "epoch 21 batch id 310 loss 0.05713305622339249 train acc 0.9596270161290322\n",
            "epoch 21 batch id 311 loss 0.08301400393247604 train acc 0.9596563504823151\n",
            "epoch 21 batch id 312 loss 0.05460551008582115 train acc 0.9597355769230769\n",
            "epoch 21 batch id 313 loss 0.07843609154224396 train acc 0.9598142971246006\n",
            "epoch 21 batch id 314 loss 0.07803765684366226 train acc 0.95984275477707\n",
            "epoch 21 batch id 315 loss 0.184465229511261 train acc 0.9598710317460317\n",
            "epoch 21 batch id 316 loss 0.13412043452262878 train acc 0.9598991297468354\n",
            "epoch 21 batch id 317 loss 0.26205000281333923 train acc 0.9597298895899053\n",
            "epoch 21 batch id 318 loss 0.13457652926445007 train acc 0.9597582547169812\n",
            "epoch 21 batch id 319 loss 0.15960244834423065 train acc 0.9597374608150471\n",
            "epoch 21 batch id 320 loss 0.07426292449235916 train acc 0.95986328125\n",
            "epoch 21 batch id 321 loss 0.08362478017807007 train acc 0.9599396417445483\n",
            "epoch 21 batch id 322 loss 0.2788974940776825 train acc 0.9597729037267081\n",
            "epoch 21 batch id 323 loss 0.09538494050502777 train acc 0.9598006965944272\n",
            "epoch 21 batch id 324 loss 0.08628271520137787 train acc 0.9598283179012346\n",
            "epoch 21 batch id 325 loss 0.17153359949588776 train acc 0.9598076923076924\n",
            "epoch 21 batch id 326 loss 0.15863291919231415 train acc 0.9598351226993865\n",
            "epoch 21 batch id 327 loss 0.11739817261695862 train acc 0.9598146024464832\n",
            "epoch 21 batch id 328 loss 0.08805465698242188 train acc 0.959889481707317\n",
            "epoch 21 batch id 329 loss 0.05540632829070091 train acc 0.9600113981762918\n",
            "epoch 21 batch id 330 loss 0.06944271922111511 train acc 0.9600378787878788\n",
            "epoch 21 batch id 331 loss 0.3487246036529541 train acc 0.9599697885196374\n",
            "epoch 21 batch id 332 loss 0.07325778156518936 train acc 0.959996234939759\n",
            "epoch 21 batch id 333 loss 0.11311612278223038 train acc 0.9600225225225225\n",
            "epoch 21 batch id 334 loss 0.12384951114654541 train acc 0.9600486526946108\n",
            "epoch 21 batch id 335 loss 0.07865694910287857 train acc 0.9601212686567164\n",
            "epoch 21 batch id 336 loss 0.0740811675786972 train acc 0.9601934523809523\n",
            "epoch 21 batch id 337 loss 0.06776238232851028 train acc 0.9602652077151336\n",
            "epoch 21 batch id 338 loss 0.14464646577835083 train acc 0.9602903106508875\n",
            "epoch 21 batch id 339 loss 0.24923081696033478 train acc 0.9602230825958702\n",
            "epoch 21 batch id 340 loss 0.2658824622631073 train acc 0.960110294117647\n",
            "epoch 21 batch id 341 loss 0.0548994354903698 train acc 0.9601814516129032\n",
            "epoch 21 batch id 342 loss 0.19610337913036346 train acc 0.9601608187134503\n",
            "epoch 21 batch id 343 loss 0.16350197792053223 train acc 0.9601858600583091\n",
            "epoch 21 batch id 344 loss 0.43630146980285645 train acc 0.9600290697674418\n",
            "epoch 21 batch id 345 loss 0.1456742137670517 train acc 0.9600090579710145\n",
            "epoch 21 batch id 346 loss 0.04118800535798073 train acc 0.9600794797687862\n",
            "epoch 21 batch id 347 loss 0.026637963950634003 train acc 0.9601945244956772\n",
            "epoch 21 batch id 348 loss 0.17703887820243835 train acc 0.9601293103448276\n",
            "epoch 21 batch id 349 loss 0.21739882230758667 train acc 0.9600644699140402\n",
            "epoch 21 batch id 350 loss 0.03191256895661354 train acc 0.9601785714285714\n",
            "epoch 21 batch id 351 loss 0.17795029282569885 train acc 0.9602029914529915\n",
            "epoch 21 batch id 352 loss 0.1953798085451126 train acc 0.9601384943181818\n",
            "epoch 21 batch id 353 loss 0.1428413689136505 train acc 0.9602071529745042\n",
            "epoch 21 batch id 354 loss 0.14711466431617737 train acc 0.9602312853107344\n",
            "epoch 21 batch id 355 loss 0.087661974132061 train acc 0.9602112676056338\n",
            "epoch 21 batch id 356 loss 0.15690754354000092 train acc 0.9601474719101124\n",
            "epoch 21 batch id 357 loss 0.1652156412601471 train acc 0.9601278011204482\n",
            "epoch 21 batch id 358 loss 0.144607275724411 train acc 0.9601518854748603\n",
            "epoch 21 batch id 359 loss 0.19871053099632263 train acc 0.9600887883008357\n",
            "epoch 21 batch id 360 loss 0.16394579410552979 train acc 0.9600260416666667\n",
            "epoch 21 batch id 361 loss 0.27930817008018494 train acc 0.9600069252077562\n",
            "epoch 21 batch id 362 loss 0.14877089858055115 train acc 0.9599879143646409\n",
            "epoch 21 batch id 363 loss 0.07724694907665253 train acc 0.9600550964187328\n",
            "epoch 21 batch id 364 loss 0.1480845808982849 train acc 0.9600360576923077\n",
            "epoch 21 batch id 365 loss 0.057288430631160736 train acc 0.9600599315068493\n",
            "epoch 21 batch id 366 loss 0.17941686511039734 train acc 0.9599982923497268\n",
            "epoch 21 batch id 367 loss 0.19948597252368927 train acc 0.9599795640326976\n",
            "epoch 21 batch id 368 loss 0.14056366682052612 train acc 0.9600033967391305\n",
            "epoch 21 batch id 369 loss 0.04636738821864128 train acc 0.9600694444444444\n",
            "epoch 21 batch id 370 loss 0.15394963324069977 train acc 0.9600084459459459\n",
            "epoch 21 batch id 371 loss 0.037894297391176224 train acc 0.9601162398921833\n",
            "epoch 21 batch id 372 loss 0.13900898396968842 train acc 0.9600974462365591\n",
            "epoch 21 batch id 373 loss 0.09487153589725494 train acc 0.9601625335120644\n",
            "epoch 21 batch id 374 loss 0.14898380637168884 train acc 0.9601854946524064\n",
            "epoch 21 batch id 375 loss 0.11167500168085098 train acc 0.9601666666666666\n",
            "epoch 21 batch id 376 loss 0.25302866101264954 train acc 0.9600648271276596\n",
            "epoch 21 batch id 377 loss 0.06343954801559448 train acc 0.9601707559681698\n",
            "epoch 21 batch id 378 loss 0.12059581279754639 train acc 0.9601521164021164\n",
            "epoch 21 batch id 379 loss 0.12956871092319489 train acc 0.960174802110818\n",
            "epoch 21 batch id 380 loss 0.08169124275445938 train acc 0.9602384868421052\n",
            "epoch 21 batch id 381 loss 0.05422670766711235 train acc 0.9603428477690289\n",
            "epoch 21 batch id 382 loss 0.15939179062843323 train acc 0.9603239528795812\n",
            "epoch 21 batch id 383 loss 0.0803234726190567 train acc 0.9603459530026109\n",
            "epoch 21 batch id 384 loss 0.04540985822677612 train acc 0.9604085286458334\n",
            "epoch 21 batch id 385 loss 0.06852895021438599 train acc 0.9604301948051948\n",
            "epoch 21 batch id 386 loss 0.11245856434106827 train acc 0.9604517487046632\n",
            "epoch 21 batch id 387 loss 0.08297549933195114 train acc 0.9604731912144703\n",
            "epoch 21 batch id 388 loss 0.15177467465400696 train acc 0.9604542525773195\n",
            "epoch 21 batch id 389 loss 0.11767164617776871 train acc 0.960435411311054\n",
            "epoch 21 batch id 390 loss 0.11771061271429062 train acc 0.9604567307692308\n",
            "epoch 21 batch id 391 loss 0.046963904052972794 train acc 0.9605179028132992\n",
            "epoch 21 batch id 392 loss 0.21990500390529633 train acc 0.9605389030612245\n",
            "epoch 21 batch id 393 loss 0.09421534836292267 train acc 0.960559796437659\n",
            "epoch 21 batch id 394 loss 0.058120135217905045 train acc 0.9606202411167513\n",
            "epoch 21 batch id 395 loss 0.1307835876941681 train acc 0.9606408227848101\n",
            "epoch 21 batch id 396 loss 0.2165381759405136 train acc 0.9606218434343434\n",
            "epoch 21 batch id 397 loss 0.2403445541858673 train acc 0.9605242443324937\n",
            "epoch 21 batch id 398 loss 0.1245979517698288 train acc 0.9605449120603015\n",
            "epoch 21 batch id 399 loss 0.15346454083919525 train acc 0.9604871553884712\n",
            "epoch 21 batch id 400 loss 0.36903056502342224 train acc 0.9602734375\n",
            "epoch 21 batch id 401 loss 0.14915020763874054 train acc 0.9602945760598504\n",
            "epoch 21 batch id 402 loss 0.0709099993109703 train acc 0.9603156094527363\n",
            "epoch 21 batch id 403 loss 0.07852199673652649 train acc 0.9603753101736973\n",
            "epoch 21 batch id 404 loss 0.08810506016016006 train acc 0.9603573638613861\n",
            "epoch 21 batch id 405 loss 0.11670712381601334 train acc 0.9603780864197531\n",
            "epoch 21 batch id 406 loss 0.06811188161373138 train acc 0.9604371921182266\n",
            "epoch 21 batch id 407 loss 0.11861111223697662 train acc 0.9604960073710074\n",
            "epoch 21 batch id 408 loss 0.14710138738155365 train acc 0.9604779411764706\n",
            "epoch 21 batch id 409 loss 0.07175475358963013 train acc 0.9605745721271394\n",
            "epoch 21 batch id 410 loss 0.19640663266181946 train acc 0.9605564024390244\n",
            "epoch 21 batch id 411 loss 0.04926261678338051 train acc 0.9606143552311436\n",
            "epoch 21 batch id 412 loss 0.0654960572719574 train acc 0.9606720266990292\n",
            "epoch 21 batch id 413 loss 0.15649361908435822 train acc 0.9606537530266344\n",
            "epoch 21 batch id 414 loss 0.29960229992866516 train acc 0.960522342995169\n",
            "epoch 21 batch id 415 loss 0.07260431349277496 train acc 0.9605798192771084\n",
            "epoch 21 batch id 416 loss 0.13125067949295044 train acc 0.9605994591346154\n",
            "epoch 21 batch id 417 loss 0.09613239020109177 train acc 0.9605815347721822\n",
            "epoch 21 batch id 418 loss 0.14268402755260468 train acc 0.9605636961722488\n",
            "epoch 21 batch id 419 loss 0.3315528929233551 train acc 0.9604340692124105\n",
            "epoch 21 batch id 420 loss 0.10617394000291824 train acc 0.9604166666666667\n",
            "epoch 21 batch id 421 loss 0.2442924678325653 train acc 0.9603993467933492\n",
            "epoch 21 batch id 422 loss 0.10159264504909515 train acc 0.96041913507109\n",
            "epoch 21 batch id 423 loss 0.10388390719890594 train acc 0.960401891252955\n",
            "epoch 21 batch id 424 loss 0.03904333338141441 train acc 0.9604952830188679\n",
            "epoch 21 batch id 425 loss 0.129720076918602 train acc 0.9604411764705882\n",
            "epoch 21 batch id 426 loss 0.03232217952609062 train acc 0.9605340375586855\n",
            "epoch 21 batch id 427 loss 0.13770295679569244 train acc 0.9605166861826698\n",
            "epoch 21 batch id 428 loss 0.2387920320034027 train acc 0.9604264018691588\n",
            "epoch 21 batch id 429 loss 0.1232069730758667 train acc 0.9604458041958042\n",
            "epoch 21 batch id 430 loss 0.16316723823547363 train acc 0.9604287790697674\n",
            "epoch 21 batch id 431 loss 0.2526231110095978 train acc 0.9603755800464037\n",
            "epoch 21 batch id 432 loss 0.25291046500205994 train acc 0.9603587962962963\n",
            "epoch 21 batch id 433 loss 0.0511886291205883 train acc 0.9604503464203233\n",
            "epoch 21 batch id 434 loss 0.10075375437736511 train acc 0.9604334677419355\n",
            "epoch 21 batch id 435 loss 0.15907946228981018 train acc 0.9604166666666667\n",
            "epoch 21 batch id 436 loss 0.19824868440628052 train acc 0.9603999426605505\n",
            "epoch 21 batch id 437 loss 0.12443650513887405 train acc 0.9604190503432495\n",
            "epoch 21 batch id 438 loss 0.2026616930961609 train acc 0.9604380707762558\n",
            "epoch 21 batch id 439 loss 0.06325220316648483 train acc 0.9604925968109339\n",
            "epoch 21 batch id 440 loss 0.15529505908489227 train acc 0.9604403409090909\n",
            "epoch 21 batch id 441 loss 0.24453064799308777 train acc 0.9604237528344671\n",
            "epoch 21 batch id 442 loss 0.24731768667697906 train acc 0.9603365384615384\n",
            "epoch 21 batch id 443 loss 0.22828470170497894 train acc 0.9602849887133182\n",
            "epoch 21 batch id 444 loss 0.12350153923034668 train acc 0.9603040540540541\n",
            "epoch 21 batch id 445 loss 0.06923915445804596 train acc 0.9603932584269663\n",
            "epoch 21 batch id 446 loss 0.22892828285694122 train acc 0.960376961883408\n",
            "epoch 21 batch id 447 loss 0.12595325708389282 train acc 0.9603956935123042\n",
            "epoch 21 batch id 448 loss 0.08486033976078033 train acc 0.9604143415178571\n",
            "epoch 21 batch id 449 loss 0.0437900573015213 train acc 0.9605025055679287\n",
            "epoch 21 batch id 450 loss 0.1420569270849228 train acc 0.9604513888888889\n",
            "epoch 21 batch id 451 loss 0.05587590113282204 train acc 0.9605044345898004\n",
            "epoch 21 batch id 452 loss 0.11192832142114639 train acc 0.9605226769911505\n",
            "epoch 21 batch id 453 loss 0.20100729167461395 train acc 0.9604718543046358\n",
            "epoch 21 batch id 454 loss 0.044911328703165054 train acc 0.9605589207048458\n",
            "epoch 21 batch id 455 loss 0.15110698342323303 train acc 0.9605082417582418\n",
            "epoch 21 batch id 456 loss 0.20735637843608856 train acc 0.9604920504385965\n",
            "epoch 21 batch id 457 loss 0.32235896587371826 train acc 0.9604417396061269\n",
            "epoch 21 batch id 458 loss 0.1945856213569641 train acc 0.9604257641921398\n",
            "epoch 21 batch id 459 loss 0.37711936235427856 train acc 0.9603417755991286\n",
            "epoch 21 batch id 460 loss 0.07068916410207748 train acc 0.9603600543478261\n",
            "epoch 21 batch id 461 loss 0.24187341332435608 train acc 0.9603104663774403\n",
            "epoch 21 batch id 462 loss 0.055243439972400665 train acc 0.9603963744588745\n",
            "epoch 21 batch id 463 loss 0.09168735891580582 train acc 0.9604144168466523\n",
            "epoch 21 batch id 464 loss 0.22632230818271637 train acc 0.9603650323275862\n",
            "epoch 21 batch id 465 loss 0.22950570285320282 train acc 0.9603494623655914\n",
            "epoch 21 batch id 466 loss 0.10749655216932297 train acc 0.9604010193133047\n",
            "epoch 21 batch id 467 loss 0.12109238654375076 train acc 0.9603854389721628\n",
            "epoch 21 batch id 468 loss 0.23561403155326843 train acc 0.9603031517094017\n",
            "epoch 21 batch id 469 loss 0.13374924659729004 train acc 0.9603211620469083\n",
            "epoch 21 batch id 470 loss 0.29864686727523804 train acc 0.9602061170212766\n",
            "epoch 21 batch id 471 loss 0.18122738599777222 train acc 0.9601910828025477\n",
            "epoch 21 batch id 472 loss 0.18179698288440704 train acc 0.960209216101695\n",
            "epoch 21 batch id 473 loss 0.17343957722187042 train acc 0.9602272727272727\n",
            "epoch 21 batch id 474 loss 0.10464140772819519 train acc 0.960245253164557\n",
            "epoch 21 batch id 475 loss 0.06791424751281738 train acc 0.9602960526315789\n",
            "epoch 21 batch id 476 loss 0.13649387657642365 train acc 0.9602809873949579\n",
            "epoch 21 batch id 477 loss 0.08530937135219574 train acc 0.9603314989517819\n",
            "epoch 21 batch id 478 loss 0.11451593041419983 train acc 0.960349110878661\n",
            "epoch 21 batch id 479 loss 0.06819929927587509 train acc 0.960366649269311\n",
            "epoch 21 batch id 480 loss 0.21733781695365906 train acc 0.9603190104166667\n",
            "epoch 21 batch id 481 loss 0.2487463802099228 train acc 0.9602715696465697\n",
            "epoch 21 batch id 482 loss 0.05379756540060043 train acc 0.9602891597510373\n",
            "epoch 21 batch id 483 loss 0.09057478606700897 train acc 0.9603390269151139\n",
            "epoch 21 batch id 484 loss 0.14049392938613892 train acc 0.9603564049586777\n",
            "epoch 21 batch id 485 loss 0.09302384406328201 train acc 0.9603414948453608\n",
            "epoch 21 batch id 486 loss 0.041527070105075836 train acc 0.9603909465020576\n",
            "epoch 21 batch id 487 loss 0.1682068556547165 train acc 0.9603439425051334\n",
            "epoch 21 batch id 488 loss 0.3713105022907257 train acc 0.960265112704918\n",
            "epoch 21 batch id 489 loss 0.05432863160967827 train acc 0.9603144171779141\n",
            "epoch 21 batch id 490 loss 0.09295248985290527 train acc 0.9603316326530612\n",
            "epoch 21 batch id 491 loss 0.28947028517723083 train acc 0.9603169551934827\n",
            "epoch 21 batch id 492 loss 0.14708146452903748 train acc 0.960302337398374\n",
            "epoch 21 batch id 493 loss 0.16814035177230835 train acc 0.9602877789046653\n",
            "epoch 21 batch id 494 loss 0.1556200534105301 train acc 0.9603049089068826\n",
            "epoch 21 batch id 495 loss 0.15065863728523254 train acc 0.9603219696969697\n",
            "epoch 21 batch id 496 loss 0.1930568963289261 train acc 0.9603074596774194\n",
            "epoch 21 batch id 497 loss 0.14941862225532532 train acc 0.9602930080482898\n",
            "epoch 21 batch id 498 loss 0.0743798315525055 train acc 0.9603099899598394\n",
            "epoch 21 batch id 499 loss 0.06984665244817734 train acc 0.9603582164328658\n",
            "epoch 21 batch id 500 loss 0.09614545851945877 train acc 0.96034375\n",
            "epoch 21 batch id 501 loss 0.1064026951789856 train acc 0.9603605289421158\n",
            "epoch 21 batch id 502 loss 0.11983360350131989 train acc 0.9603772410358565\n",
            "epoch 21 batch id 503 loss 0.08281328529119492 train acc 0.9604249502982107\n",
            "epoch 21 batch id 504 loss 0.0329577699303627 train acc 0.9605034722222222\n",
            "epoch 21 batch id 505 loss 0.18847335875034332 train acc 0.9604579207920793\n",
            "epoch 21 batch id 506 loss 0.1599109172821045 train acc 0.9605051877470355\n",
            "epoch 21 batch id 507 loss 0.204749196767807 train acc 0.9604906311637081\n",
            "epoch 21 batch id 508 loss 0.2182895541191101 train acc 0.960445374015748\n",
            "epoch 21 batch id 509 loss 0.1197366714477539 train acc 0.9604923870333988\n",
            "epoch 21 batch id 510 loss 0.21973614394664764 train acc 0.9604473039215686\n",
            "epoch 21 batch id 511 loss 0.15397833287715912 train acc 0.96043151849781\n",
            "epoch 21 train acc 0.96043151849781\n",
            "epoch 21 test acc 0.4109700520833333\n",
            "epoch 22 batch id 1 loss 0.056355178356170654 train acc 0.984375\n",
            "epoch 22 batch id 2 loss 0.02379399910569191 train acc 0.9921875\n",
            "epoch 22 batch id 3 loss 0.047031696885824203 train acc 0.9895833333333334\n",
            "epoch 22 batch id 4 loss 0.1971028596162796 train acc 0.9765625\n",
            "epoch 22 batch id 5 loss 0.030380649492144585 train acc 0.98125\n",
            "epoch 22 batch id 6 loss 0.254761278629303 train acc 0.9739583333333334\n",
            "epoch 22 batch id 7 loss 0.09932209551334381 train acc 0.96875\n",
            "epoch 22 batch id 8 loss 0.28046929836273193 train acc 0.966796875\n",
            "epoch 22 batch id 9 loss 0.09069373458623886 train acc 0.9652777777777778\n",
            "epoch 22 batch id 10 loss 0.12941774725914001 train acc 0.965625\n",
            "epoch 22 batch id 11 loss 0.19756142795085907 train acc 0.9644886363636364\n",
            "epoch 22 batch id 12 loss 0.09462368488311768 train acc 0.96484375\n",
            "epoch 22 batch id 13 loss 0.14151500165462494 train acc 0.9639423076923077\n",
            "epoch 22 batch id 14 loss 0.17186260223388672 train acc 0.9631696428571429\n",
            "epoch 22 batch id 15 loss 0.056855954229831696 train acc 0.9635416666666666\n",
            "epoch 22 batch id 16 loss 0.119745172560215 train acc 0.962890625\n",
            "epoch 22 batch id 17 loss 0.24678008258342743 train acc 0.9586397058823529\n",
            "epoch 22 batch id 18 loss 0.20686043798923492 train acc 0.9583333333333334\n",
            "epoch 22 batch id 19 loss 0.30997487902641296 train acc 0.9572368421052632\n",
            "epoch 22 batch id 20 loss 0.05004505068063736 train acc 0.95859375\n",
            "epoch 22 batch id 21 loss 0.05344438925385475 train acc 0.9590773809523809\n",
            "epoch 22 batch id 22 loss 0.06175721436738968 train acc 0.9602272727272727\n",
            "epoch 22 batch id 23 loss 0.08088596910238266 train acc 0.9605978260869565\n",
            "epoch 22 batch id 24 loss 0.15159499645233154 train acc 0.9609375\n",
            "epoch 22 batch id 25 loss 0.0913214311003685 train acc 0.96125\n",
            "epoch 22 batch id 26 loss 0.027588697150349617 train acc 0.9627403846153846\n",
            "epoch 22 batch id 27 loss 0.09502927213907242 train acc 0.9629629629629629\n",
            "epoch 22 batch id 28 loss 0.11917493492364883 train acc 0.9626116071428571\n",
            "epoch 22 batch id 29 loss 0.1295391172170639 train acc 0.9622844827586207\n",
            "epoch 22 batch id 30 loss 0.145380437374115 train acc 0.9625\n",
            "epoch 22 batch id 31 loss 0.06338784843683243 train acc 0.9632056451612904\n",
            "epoch 22 batch id 32 loss 0.22017310559749603 train acc 0.96337890625\n",
            "epoch 22 batch id 33 loss 0.0745045468211174 train acc 0.9635416666666666\n",
            "epoch 22 batch id 34 loss 0.21977555751800537 train acc 0.9632352941176471\n",
            "epoch 22 batch id 35 loss 0.07102851569652557 train acc 0.9638392857142857\n",
            "epoch 22 batch id 36 loss 0.09371441602706909 train acc 0.9644097222222222\n",
            "epoch 22 batch id 37 loss 0.027656255289912224 train acc 0.9653716216216216\n",
            "epoch 22 batch id 38 loss 0.18533852696418762 train acc 0.9650493421052632\n",
            "epoch 22 batch id 39 loss 0.10202792286872864 train acc 0.9651442307692307\n",
            "epoch 22 batch id 40 loss 0.06307981163263321 train acc 0.965625\n",
            "epoch 22 batch id 41 loss 0.1624942421913147 train acc 0.9645579268292683\n",
            "epoch 22 batch id 42 loss 0.23748846352100372 train acc 0.9639136904761905\n",
            "epoch 22 batch id 43 loss 0.20882044732570648 train acc 0.9636627906976745\n",
            "epoch 22 batch id 44 loss 0.21089516580104828 train acc 0.9634232954545454\n",
            "epoch 22 batch id 45 loss 0.05991397798061371 train acc 0.9635416666666666\n",
            "epoch 22 batch id 46 loss 0.26696962118148804 train acc 0.9626358695652174\n",
            "epoch 22 batch id 47 loss 0.2812160849571228 train acc 0.961436170212766\n",
            "epoch 22 batch id 48 loss 0.09958251565694809 train acc 0.9615885416666666\n",
            "epoch 22 batch id 49 loss 0.1989872306585312 train acc 0.9607780612244898\n",
            "epoch 22 batch id 50 loss 0.09305670112371445 train acc 0.960625\n",
            "epoch 22 batch id 51 loss 0.029220543801784515 train acc 0.9613970588235294\n",
            "epoch 22 batch id 52 loss 0.08605708181858063 train acc 0.9615384615384616\n",
            "epoch 22 batch id 53 loss 0.1225750669836998 train acc 0.9607900943396226\n",
            "epoch 22 batch id 54 loss 0.13141904771327972 train acc 0.9609375\n",
            "epoch 22 batch id 55 loss 0.09957749396562576 train acc 0.9607954545454546\n",
            "epoch 22 batch id 56 loss 0.015305733308196068 train acc 0.9614955357142857\n",
            "epoch 22 batch id 57 loss 0.16434156894683838 train acc 0.9610745614035088\n",
            "epoch 22 batch id 58 loss 0.0678977444767952 train acc 0.9612068965517241\n",
            "epoch 22 batch id 59 loss 0.18281015753746033 train acc 0.9608050847457628\n",
            "epoch 22 batch id 60 loss 0.12136653810739517 train acc 0.9606770833333333\n",
            "epoch 22 batch id 61 loss 0.10300089418888092 train acc 0.9605532786885246\n",
            "epoch 22 batch id 62 loss 0.10518473386764526 train acc 0.9606854838709677\n",
            "epoch 22 batch id 63 loss 0.05077333003282547 train acc 0.9613095238095238\n",
            "epoch 22 batch id 64 loss 0.16821958124637604 train acc 0.96142578125\n",
            "epoch 22 batch id 65 loss 0.1363600194454193 train acc 0.9615384615384616\n",
            "epoch 22 batch id 66 loss 0.04283371567726135 train acc 0.9621212121212122\n",
            "epoch 22 batch id 67 loss 0.11160207539796829 train acc 0.9619869402985075\n",
            "epoch 22 batch id 68 loss 0.14210544526576996 train acc 0.9620863970588235\n",
            "epoch 22 batch id 69 loss 0.023066993802785873 train acc 0.9626358695652174\n",
            "epoch 22 batch id 70 loss 0.15939615666866302 train acc 0.9627232142857143\n",
            "epoch 22 batch id 71 loss 0.08984316140413284 train acc 0.9630281690140845\n",
            "epoch 22 batch id 72 loss 0.24361346662044525 train acc 0.9624565972222222\n",
            "epoch 22 batch id 73 loss 0.0940902829170227 train acc 0.962542808219178\n",
            "epoch 22 batch id 74 loss 0.1409013718366623 train acc 0.9628378378378378\n",
            "epoch 22 batch id 75 loss 0.09086990356445312 train acc 0.9629166666666666\n",
            "epoch 22 batch id 76 loss 0.15806837379932404 train acc 0.9629934210526315\n",
            "epoch 22 batch id 77 loss 0.2250719964504242 train acc 0.9626623376623377\n",
            "epoch 22 batch id 78 loss 0.2774803340435028 train acc 0.9621394230769231\n",
            "epoch 22 batch id 79 loss 0.04354093596339226 train acc 0.9624208860759493\n",
            "epoch 22 batch id 80 loss 0.07731646299362183 train acc 0.9626953125\n",
            "epoch 22 batch id 81 loss 0.09612562507390976 train acc 0.9627700617283951\n",
            "epoch 22 batch id 82 loss 0.14615274965763092 train acc 0.9628429878048781\n",
            "epoch 22 batch id 83 loss 0.2884722650051117 train acc 0.9625376506024096\n",
            "epoch 22 batch id 84 loss 0.047387704253196716 train acc 0.9627976190476191\n",
            "epoch 22 batch id 85 loss 0.1113935112953186 train acc 0.9625\n",
            "epoch 22 batch id 86 loss 0.15430715680122375 train acc 0.962390988372093\n",
            "epoch 22 batch id 87 loss 0.09219943732023239 train acc 0.9626436781609196\n",
            "epoch 22 batch id 88 loss 0.12224333733320236 train acc 0.962890625\n",
            "epoch 22 batch id 89 loss 0.27366337180137634 train acc 0.9626053370786517\n",
            "epoch 22 batch id 90 loss 0.160973459482193 train acc 0.9625\n",
            "epoch 22 batch id 91 loss 0.054071083664894104 train acc 0.9627403846153846\n",
            "epoch 22 batch id 92 loss 0.08462690562009811 train acc 0.9629755434782609\n",
            "epoch 22 batch id 93 loss 0.08457440137863159 train acc 0.9632056451612904\n",
            "epoch 22 batch id 94 loss 0.12351854145526886 train acc 0.9630984042553191\n",
            "epoch 22 batch id 95 loss 0.2041929066181183 train acc 0.9629934210526315\n",
            "epoch 22 batch id 96 loss 0.26558732986450195 train acc 0.962890625\n",
            "epoch 22 batch id 97 loss 0.062340304255485535 train acc 0.9629510309278351\n",
            "epoch 22 batch id 98 loss 0.08747509866952896 train acc 0.9630102040816326\n",
            "epoch 22 batch id 99 loss 0.026771346107125282 train acc 0.9633838383838383\n",
            "epoch 22 batch id 100 loss 0.19466501474380493 train acc 0.96328125\n",
            "epoch 22 batch id 101 loss 0.06455550342798233 train acc 0.963490099009901\n",
            "epoch 22 batch id 102 loss 0.056271959096193314 train acc 0.9636948529411765\n",
            "epoch 22 batch id 103 loss 0.12104662507772446 train acc 0.9637439320388349\n",
            "epoch 22 batch id 104 loss 0.13702251017093658 train acc 0.9636418269230769\n",
            "epoch 22 batch id 105 loss 0.09223546832799911 train acc 0.9636904761904762\n",
            "epoch 22 batch id 106 loss 0.10813800245523453 train acc 0.9637382075471698\n",
            "epoch 22 batch id 107 loss 0.044419221580028534 train acc 0.9640771028037384\n",
            "epoch 22 batch id 108 loss 0.10748695582151413 train acc 0.9639756944444444\n",
            "epoch 22 batch id 109 loss 0.08082509785890579 train acc 0.9641628440366973\n",
            "epoch 22 batch id 110 loss 0.12820404767990112 train acc 0.9643465909090909\n",
            "epoch 22 batch id 111 loss 0.09330523014068604 train acc 0.9643862612612613\n",
            "epoch 22 batch id 112 loss 0.1587875485420227 train acc 0.9641462053571429\n",
            "epoch 22 batch id 113 loss 0.2494221329689026 train acc 0.9636338495575221\n",
            "epoch 22 batch id 114 loss 0.19877435266971588 train acc 0.9634046052631579\n",
            "epoch 22 batch id 115 loss 0.07901385426521301 train acc 0.9634510869565217\n",
            "epoch 22 batch id 116 loss 0.06981636583805084 train acc 0.9636314655172413\n",
            "epoch 22 batch id 117 loss 0.3611027002334595 train acc 0.9631410256410257\n",
            "epoch 22 batch id 118 loss 0.0861644446849823 train acc 0.9631885593220338\n",
            "epoch 22 batch id 119 loss 0.209578275680542 train acc 0.9631039915966386\n",
            "epoch 22 batch id 120 loss 0.07964377105236053 train acc 0.96328125\n",
            "epoch 22 batch id 121 loss 0.2786092460155487 train acc 0.9629390495867769\n",
            "epoch 22 batch id 122 loss 0.1825484037399292 train acc 0.9628586065573771\n",
            "epoch 22 batch id 123 loss 0.3240325450897217 train acc 0.9627794715447154\n",
            "epoch 22 batch id 124 loss 0.05531386658549309 train acc 0.9629536290322581\n",
            "epoch 22 batch id 125 loss 0.1949349045753479 train acc 0.963\n",
            "epoch 22 batch id 126 loss 0.048951197415590286 train acc 0.9631696428571429\n",
            "epoch 22 batch id 127 loss 0.05686376243829727 train acc 0.9634596456692913\n",
            "epoch 22 batch id 128 loss 0.15089142322540283 train acc 0.96337890625\n",
            "epoch 22 batch id 129 loss 0.052464332431554794 train acc 0.9634205426356589\n",
            "epoch 22 batch id 130 loss 0.16360165178775787 train acc 0.9634615384615385\n",
            "epoch 22 batch id 131 loss 0.20037324726581573 train acc 0.9633826335877863\n",
            "epoch 22 batch id 132 loss 0.31308791041374207 train acc 0.9630681818181818\n",
            "epoch 22 batch id 133 loss 0.16779235005378723 train acc 0.962875939849624\n",
            "epoch 22 batch id 134 loss 0.17254091799259186 train acc 0.9625699626865671\n",
            "epoch 22 batch id 135 loss 0.018249472603201866 train acc 0.9628472222222222\n",
            "epoch 22 batch id 136 loss 0.04425577074289322 train acc 0.9630055147058824\n",
            "epoch 22 batch id 137 loss 0.12384433299303055 train acc 0.9630474452554745\n",
            "epoch 22 batch id 138 loss 0.10785576701164246 train acc 0.9629755434782609\n",
            "epoch 22 batch id 139 loss 0.1329869031906128 train acc 0.9629046762589928\n",
            "epoch 22 batch id 140 loss 0.12795910239219666 train acc 0.9629464285714285\n",
            "epoch 22 batch id 141 loss 0.13379068672657013 train acc 0.9629875886524822\n",
            "epoch 22 batch id 142 loss 0.19641871750354767 train acc 0.9625880281690141\n",
            "epoch 22 batch id 143 loss 0.18483923375606537 train acc 0.9625218531468531\n",
            "epoch 22 batch id 144 loss 0.06806773692369461 train acc 0.9626736111111112\n",
            "epoch 22 batch id 145 loss 0.03308090567588806 train acc 0.962823275862069\n",
            "epoch 22 batch id 146 loss 0.04452267661690712 train acc 0.9630779109589042\n",
            "epoch 22 batch id 147 loss 0.11275556683540344 train acc 0.9631164965986394\n",
            "epoch 22 batch id 148 loss 0.1403409093618393 train acc 0.9629434121621622\n",
            "epoch 22 batch id 149 loss 0.21321488916873932 train acc 0.9628775167785235\n",
            "epoch 22 batch id 150 loss 0.0201224684715271 train acc 0.963125\n",
            "epoch 22 batch id 151 loss 0.27444988489151 train acc 0.9631622516556292\n",
            "epoch 22 batch id 152 loss 0.06024777889251709 train acc 0.9633018092105263\n",
            "epoch 22 batch id 153 loss 0.055101584643125534 train acc 0.9634395424836601\n",
            "epoch 22 batch id 154 loss 0.119985431432724 train acc 0.963474025974026\n",
            "epoch 22 batch id 155 loss 0.21974895894527435 train acc 0.963508064516129\n",
            "epoch 22 batch id 156 loss 0.23618005216121674 train acc 0.9635416666666666\n",
            "epoch 22 batch id 157 loss 0.09508144855499268 train acc 0.9636743630573248\n",
            "epoch 22 batch id 158 loss 0.2572605609893799 train acc 0.9634098101265823\n",
            "epoch 22 batch id 159 loss 0.10184784233570099 train acc 0.9634433962264151\n",
            "epoch 22 batch id 160 loss 0.14752712845802307 train acc 0.96337890625\n",
            "epoch 22 batch id 161 loss 0.1632419377565384 train acc 0.9632181677018633\n",
            "epoch 22 batch id 162 loss 0.03722662851214409 train acc 0.9634452160493827\n",
            "epoch 22 batch id 163 loss 0.029598381370306015 train acc 0.9636694785276073\n",
            "epoch 22 batch id 164 loss 0.16982290148735046 train acc 0.9635099085365854\n",
            "epoch 22 batch id 165 loss 0.15875877439975739 train acc 0.9633522727272728\n",
            "epoch 22 batch id 166 loss 0.3642500936985016 train acc 0.9631024096385542\n",
            "epoch 22 batch id 167 loss 0.08349612355232239 train acc 0.9632297904191617\n",
            "epoch 22 batch id 168 loss 0.26980456709861755 train acc 0.962890625\n",
            "epoch 22 batch id 169 loss 0.1055741086602211 train acc 0.9630177514792899\n",
            "epoch 22 batch id 170 loss 0.07189256697893143 train acc 0.9631433823529412\n",
            "epoch 22 batch id 171 loss 0.069210946559906 train acc 0.9631761695906432\n",
            "epoch 22 batch id 172 loss 0.11088786274194717 train acc 0.9632085755813954\n",
            "epoch 22 batch id 173 loss 0.11198779195547104 train acc 0.963150289017341\n",
            "epoch 22 batch id 174 loss 0.16234742105007172 train acc 0.9630028735632183\n",
            "epoch 22 batch id 175 loss 0.07553117722272873 train acc 0.963125\n",
            "epoch 22 batch id 176 loss 0.1972060203552246 train acc 0.9629794034090909\n",
            "epoch 22 batch id 177 loss 0.23353642225265503 train acc 0.9628354519774012\n",
            "epoch 22 batch id 178 loss 0.10542889684438705 train acc 0.9628686797752809\n",
            "epoch 22 batch id 179 loss 0.11449648439884186 train acc 0.9629015363128491\n",
            "epoch 22 batch id 180 loss 0.05159799009561539 train acc 0.9631076388888888\n",
            "epoch 22 batch id 181 loss 0.19912858307361603 train acc 0.9628798342541437\n",
            "epoch 22 batch id 182 loss 0.1909792572259903 train acc 0.962654532967033\n",
            "epoch 22 batch id 183 loss 0.07107899338006973 train acc 0.9627732240437158\n",
            "epoch 22 batch id 184 loss 0.07645201683044434 train acc 0.962890625\n",
            "epoch 22 batch id 185 loss 0.20057035982608795 train acc 0.9629222972972973\n",
            "epoch 22 batch id 186 loss 0.2597346603870392 train acc 0.9627856182795699\n",
            "epoch 22 batch id 187 loss 0.06114725023508072 train acc 0.9629010695187166\n",
            "epoch 22 batch id 188 loss 0.1513838768005371 train acc 0.9629321808510638\n",
            "epoch 22 batch id 189 loss 0.04714692756533623 train acc 0.9630456349206349\n",
            "epoch 22 batch id 190 loss 0.11865735054016113 train acc 0.9630756578947368\n",
            "epoch 22 batch id 191 loss 0.13640792667865753 train acc 0.9631053664921466\n",
            "epoch 22 batch id 192 loss 0.027538809925317764 train acc 0.9632975260416666\n",
            "epoch 22 batch id 193 loss 0.1114019975066185 train acc 0.9634067357512953\n",
            "epoch 22 batch id 194 loss 0.10538613796234131 train acc 0.9633537371134021\n",
            "epoch 22 batch id 195 loss 0.06318818777799606 train acc 0.9633814102564102\n",
            "epoch 22 batch id 196 loss 0.09636534750461578 train acc 0.9633290816326531\n",
            "epoch 22 batch id 197 loss 0.17524392902851105 train acc 0.9632772842639594\n",
            "epoch 22 batch id 198 loss 0.1552119255065918 train acc 0.9633838383838383\n",
            "epoch 22 batch id 199 loss 0.1774725764989853 train acc 0.9633322864321608\n",
            "epoch 22 batch id 200 loss 0.10498768091201782 train acc 0.9634375\n",
            "epoch 22 batch id 201 loss 0.18148815631866455 train acc 0.9633861940298507\n",
            "epoch 22 batch id 202 loss 0.04835601896047592 train acc 0.9635674504950495\n",
            "epoch 22 batch id 203 loss 0.17470122873783112 train acc 0.9635160098522167\n",
            "epoch 22 batch id 204 loss 0.058500614017248154 train acc 0.9636182598039216\n",
            "epoch 22 batch id 205 loss 0.1323135644197464 train acc 0.9636432926829268\n",
            "epoch 22 batch id 206 loss 0.12989233434200287 train acc 0.9635922330097088\n",
            "epoch 22 batch id 207 loss 0.07052665948867798 train acc 0.9636171497584541\n",
            "epoch 22 batch id 208 loss 0.0808573067188263 train acc 0.9636418269230769\n",
            "epoch 22 batch id 209 loss 0.20526115596294403 train acc 0.963441985645933\n",
            "epoch 22 batch id 210 loss 0.06722289323806763 train acc 0.9635416666666666\n",
            "epoch 22 batch id 211 loss 0.1799897849559784 train acc 0.9634922985781991\n",
            "epoch 22 batch id 212 loss 0.19090929627418518 train acc 0.9633696933962265\n",
            "epoch 22 batch id 213 loss 0.3436856269836426 train acc 0.9632482394366197\n",
            "epoch 22 batch id 214 loss 0.19324587285518646 train acc 0.963054906542056\n",
            "epoch 22 batch id 215 loss 0.08946014195680618 train acc 0.9630813953488372\n",
            "epoch 22 batch id 216 loss 0.10848752409219742 train acc 0.9631799768518519\n",
            "epoch 22 batch id 217 loss 0.2041548192501068 train acc 0.9632056451612904\n",
            "epoch 22 batch id 218 loss 0.0562579371035099 train acc 0.963302752293578\n",
            "epoch 22 batch id 219 loss 0.18570297956466675 train acc 0.9631849315068494\n",
            "epoch 22 batch id 220 loss 0.09061050415039062 train acc 0.9632102272727273\n",
            "epoch 22 batch id 221 loss 0.053484052419662476 train acc 0.9633059954751131\n",
            "epoch 22 batch id 222 loss 0.15120874345302582 train acc 0.9633305180180181\n",
            "epoch 22 batch id 223 loss 0.15277503430843353 train acc 0.9633548206278026\n",
            "epoch 22 batch id 224 loss 0.08769071847200394 train acc 0.96337890625\n",
            "epoch 22 batch id 225 loss 0.27026882767677307 train acc 0.963125\n",
            "epoch 22 batch id 226 loss 0.2673446238040924 train acc 0.9629424778761062\n",
            "epoch 22 batch id 227 loss 0.0264897458255291 train acc 0.9631057268722467\n",
            "epoch 22 batch id 228 loss 0.10867410898208618 train acc 0.9630619517543859\n",
            "epoch 22 batch id 229 loss 0.16355137526988983 train acc 0.962950327510917\n",
            "epoch 22 batch id 230 loss 0.04616980999708176 train acc 0.9631114130434782\n",
            "epoch 22 batch id 231 loss 0.06933608651161194 train acc 0.9631358225108225\n",
            "epoch 22 batch id 232 loss 0.25525251030921936 train acc 0.9630253232758621\n",
            "epoch 22 batch id 233 loss 0.24666374921798706 train acc 0.962848712446352\n",
            "epoch 22 batch id 234 loss 0.15010002255439758 train acc 0.9628071581196581\n",
            "epoch 22 batch id 235 loss 0.2298940271139145 train acc 0.9627659574468085\n",
            "epoch 22 batch id 236 loss 0.05248715355992317 train acc 0.9628575211864406\n",
            "epoch 22 batch id 237 loss 0.1304515153169632 train acc 0.9628823839662447\n",
            "epoch 22 batch id 238 loss 0.10393830388784409 train acc 0.9628413865546218\n",
            "epoch 22 batch id 239 loss 0.06747569143772125 train acc 0.9629314853556485\n",
            "epoch 22 batch id 240 loss 0.3523027300834656 train acc 0.962890625\n",
            "epoch 22 batch id 241 loss 0.03130847215652466 train acc 0.9630446058091287\n",
            "epoch 22 batch id 242 loss 0.1438109278678894 train acc 0.9630036157024794\n",
            "epoch 22 batch id 243 loss 0.023289000615477562 train acc 0.9631558641975309\n",
            "epoch 22 batch id 244 loss 0.135374054312706 train acc 0.9631787909836066\n",
            "epoch 22 batch id 245 loss 0.10741811245679855 train acc 0.9632015306122449\n",
            "epoch 22 batch id 246 loss 0.07440730929374695 train acc 0.9632240853658537\n",
            "epoch 22 batch id 247 loss 0.11151439696550369 train acc 0.9633097165991903\n",
            "epoch 22 batch id 248 loss 0.1061587780714035 train acc 0.9633316532258065\n",
            "epoch 22 batch id 249 loss 0.2038893848657608 train acc 0.9631024096385542\n",
            "epoch 22 batch id 250 loss 0.20431774854660034 train acc 0.963\n",
            "epoch 22 batch id 251 loss 0.22371572256088257 train acc 0.962960657370518\n",
            "epoch 22 batch id 252 loss 0.3440881669521332 train acc 0.9627976190476191\n",
            "epoch 22 batch id 253 loss 0.17872747778892517 train acc 0.9628211462450593\n",
            "epoch 22 batch id 254 loss 0.21372154355049133 train acc 0.9627829724409449\n",
            "epoch 22 batch id 255 loss 0.03394034504890442 train acc 0.9629289215686274\n",
            "epoch 22 batch id 256 loss 0.10023222118616104 train acc 0.9630126953125\n",
            "epoch 22 batch id 257 loss 0.1085977703332901 train acc 0.9629742217898832\n",
            "epoch 22 batch id 258 loss 0.06103670597076416 train acc 0.9630571705426356\n",
            "epoch 22 batch id 259 loss 0.33802330493927 train acc 0.962898166023166\n",
            "epoch 22 batch id 260 loss 0.06094890832901001 train acc 0.9629206730769231\n",
            "epoch 22 batch id 261 loss 0.13458237051963806 train acc 0.9630028735632183\n",
            "epoch 22 batch id 262 loss 0.0742812231183052 train acc 0.9630844465648855\n",
            "epoch 22 batch id 263 loss 0.20279763638973236 train acc 0.9629277566539924\n",
            "epoch 22 batch id 264 loss 0.12400005757808685 train acc 0.962890625\n",
            "epoch 22 batch id 265 loss 0.12417973577976227 train acc 0.9629127358490566\n",
            "epoch 22 batch id 266 loss 0.16637365520000458 train acc 0.962875939849624\n",
            "epoch 22 batch id 267 loss 0.1657714992761612 train acc 0.9628394194756554\n",
            "epoch 22 batch id 268 loss 0.07318263500928879 train acc 0.9629197761194029\n",
            "epoch 22 batch id 269 loss 0.11380177736282349 train acc 0.9628833643122676\n",
            "epoch 22 batch id 270 loss 0.1311304122209549 train acc 0.9628472222222222\n",
            "epoch 22 batch id 271 loss 0.1688450127840042 train acc 0.9627536900369004\n",
            "epoch 22 batch id 272 loss 0.23142604529857635 train acc 0.9626034007352942\n",
            "epoch 22 batch id 273 loss 0.0776858925819397 train acc 0.9626259157509157\n",
            "epoch 22 batch id 274 loss 0.18648821115493774 train acc 0.9625342153284672\n",
            "epoch 22 batch id 275 loss 0.1371675729751587 train acc 0.9625568181818182\n",
            "epoch 22 batch id 276 loss 0.1285853385925293 train acc 0.9625226449275363\n",
            "epoch 22 batch id 277 loss 0.09880790114402771 train acc 0.9624887184115524\n",
            "epoch 22 batch id 278 loss 0.1256764680147171 train acc 0.9625112410071942\n",
            "epoch 22 batch id 279 loss 0.11272876709699631 train acc 0.9624775985663082\n",
            "epoch 22 batch id 280 loss 0.08229595422744751 train acc 0.9625558035714286\n",
            "epoch 22 batch id 281 loss 0.064488485455513 train acc 0.9626334519572953\n",
            "epoch 22 batch id 282 loss 0.05809886381030083 train acc 0.9626551418439716\n",
            "epoch 22 batch id 283 loss 0.20912009477615356 train acc 0.9625662544169611\n",
            "epoch 22 batch id 284 loss 0.08615101873874664 train acc 0.9625880281690141\n",
            "epoch 22 batch id 285 loss 0.041594814509153366 train acc 0.962609649122807\n",
            "epoch 22 batch id 286 loss 0.17175549268722534 train acc 0.9625218531468531\n",
            "epoch 22 batch id 287 loss 0.14015425741672516 train acc 0.9625979965156795\n",
            "epoch 22 batch id 288 loss 0.14359167218208313 train acc 0.9626736111111112\n",
            "epoch 22 batch id 289 loss 0.09576641023159027 train acc 0.9627487024221453\n",
            "epoch 22 batch id 290 loss 0.04025137051939964 train acc 0.9628771551724138\n",
            "epoch 22 batch id 291 loss 0.133897066116333 train acc 0.9627899484536082\n",
            "epoch 22 batch id 292 loss 0.25094327330589294 train acc 0.9627568493150684\n",
            "epoch 22 batch id 293 loss 0.09792911261320114 train acc 0.9627773037542662\n",
            "epoch 22 batch id 294 loss 0.09677615761756897 train acc 0.9627444727891157\n",
            "epoch 22 batch id 295 loss 0.19739027321338654 train acc 0.9627118644067797\n",
            "epoch 22 batch id 296 loss 0.05842197686433792 train acc 0.9627850506756757\n",
            "epoch 22 batch id 297 loss 0.12051509320735931 train acc 0.9628577441077442\n",
            "epoch 22 batch id 298 loss 0.1605808138847351 train acc 0.9628250838926175\n",
            "epoch 22 batch id 299 loss 0.10580997914075851 train acc 0.9627926421404682\n",
            "epoch 22 batch id 300 loss 0.09707508981227875 train acc 0.9627604166666667\n",
            "epoch 22 batch id 301 loss 0.03221115469932556 train acc 0.9628841362126246\n",
            "epoch 22 batch id 302 loss 0.10068078339099884 train acc 0.9628518211920529\n",
            "epoch 22 batch id 303 loss 0.08795811980962753 train acc 0.9629228547854786\n",
            "epoch 22 batch id 304 loss 0.035422392189502716 train acc 0.9630448190789473\n",
            "epoch 22 batch id 305 loss 0.0964616909623146 train acc 0.9630122950819672\n",
            "epoch 22 batch id 306 loss 0.19834673404693604 train acc 0.963031045751634\n",
            "epoch 22 batch id 307 loss 0.13301633298397064 train acc 0.9629987785016286\n",
            "epoch 22 batch id 308 loss 0.07104294002056122 train acc 0.9630681818181818\n",
            "epoch 22 batch id 309 loss 0.13978047668933868 train acc 0.9631371359223301\n",
            "epoch 22 batch id 310 loss 0.17733772099018097 train acc 0.9631552419354839\n",
            "epoch 22 batch id 311 loss 0.23313702642917633 train acc 0.9631229903536977\n",
            "epoch 22 batch id 312 loss 0.13516928255558014 train acc 0.9630408653846154\n",
            "epoch 22 batch id 313 loss 0.14693626761436462 train acc 0.9630591054313099\n",
            "epoch 22 batch id 314 loss 0.09443767368793488 train acc 0.963077229299363\n",
            "epoch 22 batch id 315 loss 0.20854270458221436 train acc 0.9629960317460318\n",
            "epoch 22 batch id 316 loss 0.0547085739672184 train acc 0.9630636867088608\n",
            "epoch 22 batch id 317 loss 0.09960026293992996 train acc 0.9630816246056783\n",
            "epoch 22 batch id 318 loss 0.14892879128456116 train acc 0.9630994496855346\n",
            "epoch 22 batch id 319 loss 0.06680391728878021 train acc 0.963166144200627\n",
            "epoch 22 batch id 320 loss 0.05430102348327637 train acc 0.963232421875\n",
            "epoch 22 batch id 321 loss 0.13919343054294586 train acc 0.9632496105919003\n",
            "epoch 22 batch id 322 loss 0.36628830432891846 train acc 0.9632181677018633\n",
            "epoch 22 batch id 323 loss 0.07322808355093002 train acc 0.9632352941176471\n",
            "epoch 22 batch id 324 loss 0.09288235008716583 train acc 0.9632523148148148\n",
            "epoch 22 batch id 325 loss 0.08087311685085297 train acc 0.9632692307692308\n",
            "epoch 22 batch id 326 loss 0.13852213323116302 train acc 0.9632381134969326\n",
            "epoch 22 batch id 327 loss 0.2266894280910492 train acc 0.9632549694189603\n",
            "epoch 22 batch id 328 loss 0.2405015230178833 train acc 0.9632240853658537\n",
            "epoch 22 batch id 329 loss 0.07323583960533142 train acc 0.9632883738601824\n",
            "epoch 22 batch id 330 loss 0.16354866325855255 train acc 0.9632102272727273\n",
            "epoch 22 batch id 331 loss 0.07391788810491562 train acc 0.9632269637462235\n",
            "epoch 22 batch id 332 loss 0.08934007585048676 train acc 0.9631965361445783\n",
            "epoch 22 batch id 333 loss 0.19695252180099487 train acc 0.9631662912912913\n",
            "epoch 22 batch id 334 loss 0.06630045175552368 train acc 0.9631830089820359\n",
            "epoch 22 batch id 335 loss 0.10247847437858582 train acc 0.9631529850746269\n",
            "epoch 22 batch id 336 loss 0.2008715122938156 train acc 0.9631231398809523\n",
            "epoch 22 batch id 337 loss 0.05480363965034485 train acc 0.9631862017804155\n",
            "epoch 22 batch id 338 loss 0.15458938479423523 train acc 0.9632026627218935\n",
            "epoch 22 batch id 339 loss 0.19643756747245789 train acc 0.9631729351032449\n",
            "epoch 22 batch id 340 loss 0.07958395034074783 train acc 0.9632352941176471\n",
            "epoch 22 batch id 341 loss 0.2691996693611145 train acc 0.9631140029325513\n",
            "epoch 22 batch id 342 loss 0.17994572222232819 train acc 0.9630847953216374\n",
            "epoch 22 batch id 343 loss 0.13343167304992676 train acc 0.9630557580174927\n",
            "epoch 22 batch id 344 loss 0.09529930353164673 train acc 0.9630723110465116\n",
            "epoch 22 batch id 345 loss 0.05699458718299866 train acc 0.9631340579710145\n",
            "epoch 22 batch id 346 loss 0.23725298047065735 train acc 0.9631051300578035\n",
            "epoch 22 batch id 347 loss 0.1083756610751152 train acc 0.9631664265129684\n",
            "epoch 22 batch id 348 loss 0.1801276057958603 train acc 0.9630028735632183\n",
            "epoch 22 batch id 349 loss 0.07731320708990097 train acc 0.963064111747851\n",
            "epoch 22 batch id 350 loss 0.06945572048425674 train acc 0.9630803571428571\n",
            "epoch 22 batch id 351 loss 0.0975608378648758 train acc 0.96309650997151\n",
            "epoch 22 batch id 352 loss 0.02349567599594593 train acc 0.9632013494318182\n",
            "epoch 22 batch id 353 loss 0.18670086562633514 train acc 0.9631285410764873\n",
            "epoch 22 batch id 354 loss 0.18767444789409637 train acc 0.9630561440677966\n",
            "epoch 22 batch id 355 loss 0.23392944037914276 train acc 0.9629841549295775\n",
            "epoch 22 batch id 356 loss 0.06424271315336227 train acc 0.9630003511235955\n",
            "epoch 22 batch id 357 loss 0.02656586281955242 train acc 0.9631039915966386\n",
            "epoch 22 batch id 358 loss 0.044474657624959946 train acc 0.963163407821229\n",
            "epoch 22 batch id 359 loss 0.12490354478359222 train acc 0.9631789693593314\n",
            "epoch 22 batch id 360 loss 0.2999872863292694 train acc 0.9631510416666667\n",
            "epoch 22 batch id 361 loss 0.03463470935821533 train acc 0.9632098337950139\n",
            "epoch 22 batch id 362 loss 0.08697592467069626 train acc 0.963225138121547\n",
            "epoch 22 batch id 363 loss 0.3191036581993103 train acc 0.9631542699724518\n",
            "epoch 22 batch id 364 loss 0.14663594961166382 train acc 0.963126717032967\n",
            "epoch 22 batch id 365 loss 0.15943151712417603 train acc 0.9630993150684931\n",
            "epoch 22 batch id 366 loss 0.05631837248802185 train acc 0.9631574453551912\n",
            "epoch 22 batch id 367 loss 0.03689641132950783 train acc 0.963257833787466\n",
            "epoch 22 batch id 368 loss 0.06029565632343292 train acc 0.963272758152174\n",
            "epoch 22 batch id 369 loss 0.08550020307302475 train acc 0.963329945799458\n",
            "epoch 22 batch id 370 loss 0.19749796390533447 train acc 0.9632601351351351\n",
            "epoch 22 batch id 371 loss 0.03395190089941025 train acc 0.9633170485175202\n",
            "epoch 22 batch id 372 loss 0.14915135502815247 train acc 0.9632896505376344\n",
            "epoch 22 batch id 373 loss 0.19253791868686676 train acc 0.963304289544236\n",
            "epoch 22 batch id 374 loss 0.10358679294586182 train acc 0.9632352941176471\n",
            "epoch 22 batch id 375 loss 0.060754917562007904 train acc 0.96325\n",
            "epoch 22 batch id 376 loss 0.11177437007427216 train acc 0.9632646276595744\n",
            "epoch 22 batch id 377 loss 0.10430178046226501 train acc 0.9632377320954907\n",
            "epoch 22 batch id 378 loss 0.03265687823295593 train acc 0.9633349867724867\n",
            "epoch 22 batch id 379 loss 0.3010803163051605 train acc 0.963266820580475\n",
            "epoch 22 batch id 380 loss 0.030514776706695557 train acc 0.9633223684210527\n",
            "epoch 22 batch id 381 loss 0.177548348903656 train acc 0.963254593175853\n",
            "epoch 22 batch id 382 loss 0.057218678295612335 train acc 0.9633098821989529\n",
            "epoch 22 batch id 383 loss 0.1676369607448578 train acc 0.9632832898172323\n",
            "epoch 22 batch id 384 loss 0.06780647486448288 train acc 0.9633382161458334\n",
            "epoch 22 batch id 385 loss 0.1718045324087143 train acc 0.9633116883116883\n",
            "epoch 22 batch id 386 loss 0.04006281867623329 train acc 0.9634067357512953\n",
            "epoch 22 batch id 387 loss 0.3676498234272003 train acc 0.9631782945736435\n",
            "epoch 22 batch id 388 loss 0.20906412601470947 train acc 0.9631523840206185\n",
            "epoch 22 batch id 389 loss 0.3652132749557495 train acc 0.9630462724935732\n",
            "epoch 22 batch id 390 loss 0.06594526767730713 train acc 0.9630608974358974\n",
            "epoch 22 batch id 391 loss 0.05006536468863487 train acc 0.9631154092071611\n",
            "epoch 22 batch id 392 loss 0.15442036092281342 train acc 0.9631297831632653\n",
            "epoch 22 batch id 393 loss 0.1716371327638626 train acc 0.9631043256997456\n",
            "epoch 22 batch id 394 loss 0.07908400893211365 train acc 0.963118654822335\n",
            "epoch 22 batch id 395 loss 0.11168164759874344 train acc 0.9631329113924051\n",
            "epoch 22 batch id 396 loss 0.3137541115283966 train acc 0.9630287247474747\n",
            "epoch 22 batch id 397 loss 0.0827912911772728 train acc 0.9630824937027708\n",
            "epoch 22 batch id 398 loss 0.25018951296806335 train acc 0.9629789572864321\n",
            "epoch 22 batch id 399 loss 0.03251874819397926 train acc 0.9630717418546366\n",
            "epoch 22 batch id 400 loss 0.22633764147758484 train acc 0.96296875\n",
            "epoch 22 batch id 401 loss 0.0672232061624527 train acc 0.9629831670822943\n",
            "epoch 22 batch id 402 loss 0.15045695006847382 train acc 0.962997512437811\n",
            "epoch 22 batch id 403 loss 0.13163311779499054 train acc 0.9629730148883374\n",
            "epoch 22 batch id 404 loss 0.025339419022202492 train acc 0.9630646658415841\n",
            "epoch 22 batch id 405 loss 0.1747598648071289 train acc 0.9630015432098765\n",
            "epoch 22 batch id 406 loss 0.04885338991880417 train acc 0.9630926724137931\n",
            "epoch 22 batch id 407 loss 0.06941390782594681 train acc 0.9631449631449631\n",
            "epoch 22 batch id 408 loss 0.026355143636465073 train acc 0.9632352941176471\n",
            "epoch 22 batch id 409 loss 0.24814417958259583 train acc 0.9632105745721271\n",
            "epoch 22 batch id 410 loss 0.13911300897598267 train acc 0.9631478658536585\n",
            "epoch 22 batch id 411 loss 0.04150065407156944 train acc 0.9632375304136253\n",
            "epoch 22 batch id 412 loss 0.08255068957805634 train acc 0.9632888349514563\n",
            "epoch 22 batch id 413 loss 0.08500447869300842 train acc 0.9633398910411622\n",
            "epoch 22 batch id 414 loss 0.059898100793361664 train acc 0.9633529589371981\n",
            "epoch 22 batch id 415 loss 0.13772988319396973 train acc 0.9634036144578313\n",
            "epoch 22 batch id 416 loss 0.11872135102748871 train acc 0.9634164663461539\n",
            "epoch 22 batch id 417 loss 0.25972989201545715 train acc 0.9633917865707434\n",
            "epoch 22 batch id 418 loss 0.0941961258649826 train acc 0.9633672248803827\n",
            "epoch 22 batch id 419 loss 0.42397281527519226 train acc 0.9633427804295943\n",
            "epoch 22 batch id 420 loss 0.031962305307388306 train acc 0.9634300595238096\n",
            "epoch 22 batch id 421 loss 0.1413150429725647 train acc 0.963479809976247\n",
            "epoch 22 batch id 422 loss 0.13481779396533966 train acc 0.9634182464454977\n",
            "epoch 22 batch id 423 loss 0.14993295073509216 train acc 0.9633939125295509\n",
            "epoch 22 batch id 424 loss 0.08773911744356155 train acc 0.9634433962264151\n",
            "epoch 22 batch id 425 loss 0.18904446065425873 train acc 0.9634558823529412\n",
            "epoch 22 batch id 426 loss 0.10862565040588379 train acc 0.9634683098591549\n",
            "epoch 22 batch id 427 loss 0.14889249205589294 train acc 0.9634440866510539\n",
            "epoch 22 batch id 428 loss 0.09958847612142563 train acc 0.963419976635514\n",
            "epoch 22 batch id 429 loss 0.14279744029045105 train acc 0.9633959790209791\n",
            "epoch 22 batch id 430 loss 0.16159026324748993 train acc 0.9633357558139535\n",
            "epoch 22 batch id 431 loss 0.08556464314460754 train acc 0.9633845707656613\n",
            "epoch 22 batch id 432 loss 0.09852948784828186 train acc 0.9633608217592593\n",
            "epoch 22 batch id 433 loss 0.09655909985303879 train acc 0.9634093533487298\n",
            "epoch 22 batch id 434 loss 0.05823368951678276 train acc 0.9634576612903226\n",
            "epoch 22 batch id 435 loss 0.05490606650710106 train acc 0.9635057471264368\n",
            "epoch 22 batch id 436 loss 0.05068488046526909 train acc 0.9635536123853211\n",
            "epoch 22 batch id 437 loss 0.18122215569019318 train acc 0.9635297482837528\n",
            "epoch 22 batch id 438 loss 0.09757599234580994 train acc 0.9635416666666666\n",
            "epoch 22 batch id 439 loss 0.44973164796829224 train acc 0.9634111617312073\n",
            "epoch 22 batch id 440 loss 0.1330663114786148 train acc 0.9634588068181819\n",
            "epoch 22 batch id 441 loss 0.06386105716228485 train acc 0.9634708049886621\n",
            "epoch 22 batch id 442 loss 0.09722312539815903 train acc 0.9635180995475113\n",
            "epoch 22 batch id 443 loss 0.16161686182022095 train acc 0.9634946388261851\n",
            "epoch 22 batch id 444 loss 0.06974218785762787 train acc 0.9635416666666666\n",
            "epoch 22 batch id 445 loss 0.05939678102731705 train acc 0.9635884831460674\n",
            "epoch 22 batch id 446 loss 0.14647094905376434 train acc 0.9636000560538116\n",
            "epoch 22 batch id 447 loss 0.10357694327831268 train acc 0.963611577181208\n",
            "epoch 22 batch id 448 loss 0.03156976401805878 train acc 0.9636579241071429\n",
            "epoch 22 batch id 449 loss 0.2088291198015213 train acc 0.9635996659242761\n",
            "epoch 22 batch id 450 loss 0.12698134779930115 train acc 0.9635416666666666\n",
            "epoch 22 batch id 451 loss 0.12008632719516754 train acc 0.9635185698447893\n",
            "epoch 22 batch id 452 loss 0.09215133637189865 train acc 0.9635647123893806\n",
            "epoch 22 batch id 453 loss 0.03863198682665825 train acc 0.9636451434878587\n",
            "epoch 22 batch id 454 loss 0.14442093670368195 train acc 0.9636219713656388\n",
            "epoch 22 batch id 455 loss 0.06322822719812393 train acc 0.9636675824175824\n",
            "epoch 22 batch id 456 loss 0.20873813331127167 train acc 0.9636444627192983\n",
            "epoch 22 batch id 457 loss 0.20320428907871246 train acc 0.9636556345733042\n",
            "epoch 22 batch id 458 loss 0.06874126940965652 train acc 0.9637008733624454\n",
            "epoch 22 batch id 459 loss 0.09184207767248154 train acc 0.9637118736383442\n",
            "epoch 22 batch id 460 loss 0.07028507441282272 train acc 0.9637567934782608\n",
            "epoch 22 batch id 461 loss 0.04559151083230972 train acc 0.9638015184381779\n",
            "epoch 22 batch id 462 loss 0.18714691698551178 train acc 0.9638122294372294\n",
            "epoch 22 batch id 463 loss 0.0492965504527092 train acc 0.9638566414686826\n",
            "epoch 22 batch id 464 loss 0.08959250152111053 train acc 0.9639008620689655\n",
            "epoch 22 batch id 465 loss 0.18598288297653198 train acc 0.9639112903225806\n",
            "epoch 22 batch id 466 loss 0.2575637996196747 train acc 0.9638546137339056\n",
            "epoch 22 batch id 467 loss 0.12377952039241791 train acc 0.963865096359743\n",
            "epoch 22 batch id 468 loss 0.10126756876707077 train acc 0.9638755341880342\n",
            "epoch 22 batch id 469 loss 0.04420270025730133 train acc 0.9639192430703625\n",
            "epoch 22 batch id 470 loss 0.2015579789876938 train acc 0.9639295212765957\n",
            "epoch 22 batch id 471 loss 0.04915373772382736 train acc 0.9639397558386412\n",
            "epoch 22 batch id 472 loss 0.11497096717357635 train acc 0.9639499470338984\n",
            "epoch 22 batch id 473 loss 0.35584717988967896 train acc 0.9638940274841438\n",
            "epoch 22 batch id 474 loss 0.11914707720279694 train acc 0.9639372362869199\n",
            "epoch 22 batch id 475 loss 0.1068001464009285 train acc 0.9639802631578948\n",
            "epoch 22 batch id 476 loss 0.08690308779478073 train acc 0.9639902836134454\n",
            "epoch 22 batch id 477 loss 0.11696873605251312 train acc 0.9640002620545073\n",
            "epoch 22 batch id 478 loss 0.06583746522665024 train acc 0.9640428870292888\n",
            "epoch 22 batch id 479 loss 0.16902825236320496 train acc 0.9639874739039666\n",
            "epoch 22 batch id 480 loss 0.045782484114170074 train acc 0.9640299479166666\n",
            "epoch 22 batch id 481 loss 0.049568671733140945 train acc 0.9640722453222453\n",
            "epoch 22 batch id 482 loss 0.18733428418636322 train acc 0.9639846991701245\n",
            "epoch 22 batch id 483 loss 0.067693330347538 train acc 0.9640269151138716\n",
            "epoch 22 batch id 484 loss 0.18947695195674896 train acc 0.9639721074380165\n",
            "epoch 22 batch id 485 loss 0.15198901295661926 train acc 0.9639819587628866\n",
            "epoch 22 batch id 486 loss 0.12687897682189941 train acc 0.9639596193415638\n",
            "epoch 22 batch id 487 loss 0.04042656347155571 train acc 0.9640015400410678\n",
            "epoch 22 batch id 488 loss 0.02683210000395775 train acc 0.9640753073770492\n",
            "epoch 22 batch id 489 loss 0.04327717050909996 train acc 0.964148773006135\n",
            "epoch 22 batch id 490 loss 0.06452955305576324 train acc 0.9641900510204081\n",
            "epoch 22 batch id 491 loss 0.058204904198646545 train acc 0.9642311608961304\n",
            "epoch 22 batch id 492 loss 0.04432433843612671 train acc 0.9642721036585366\n",
            "epoch 22 batch id 493 loss 0.12985046207904816 train acc 0.9642811866125761\n",
            "epoch 22 batch id 494 loss 0.18932278454303741 train acc 0.9642586032388664\n",
            "epoch 22 batch id 495 loss 0.03506946936249733 train acc 0.9643308080808081\n",
            "epoch 22 batch id 496 loss 0.19456396996974945 train acc 0.9643082157258065\n",
            "epoch 22 batch id 497 loss 0.07400712370872498 train acc 0.9643171529175051\n",
            "epoch 22 batch id 498 loss 0.2721090614795685 train acc 0.9642633032128514\n",
            "epoch 22 batch id 499 loss 0.27024269104003906 train acc 0.9641783567134269\n",
            "epoch 22 batch id 500 loss 0.1686389148235321 train acc 0.9641875\n",
            "epoch 22 batch id 501 loss 0.11033383756875992 train acc 0.9642277944111777\n",
            "epoch 22 batch id 502 loss 0.24866421520709991 train acc 0.9642368027888446\n",
            "epoch 22 batch id 503 loss 0.04346441850066185 train acc 0.9643079025844931\n",
            "epoch 22 batch id 504 loss 0.2662796378135681 train acc 0.9642547123015873\n",
            "epoch 22 batch id 505 loss 0.2289394736289978 train acc 0.9642326732673268\n",
            "epoch 22 batch id 506 loss 0.04227782040834427 train acc 0.9642724802371542\n",
            "epoch 22 batch id 507 loss 0.10704348981380463 train acc 0.9642504930966469\n",
            "epoch 22 batch id 508 loss 0.26039889454841614 train acc 0.9641978346456693\n",
            "epoch 22 batch id 509 loss 0.1203555092215538 train acc 0.9641760805500982\n",
            "epoch 22 batch id 510 loss 0.21146173775196075 train acc 0.9641237745098039\n",
            "epoch 22 batch id 511 loss 0.23129303753376007 train acc 0.96410079442736\n",
            "epoch 22 train acc 0.96410079442736\n",
            "epoch 22 test acc 0.3976236979166667\n",
            "epoch 23 batch id 1 loss 0.08114985376596451 train acc 0.96875\n",
            "epoch 23 batch id 2 loss 0.05690374970436096 train acc 0.984375\n",
            "epoch 23 batch id 3 loss 0.03822297975420952 train acc 0.984375\n",
            "epoch 23 batch id 4 loss 0.02305234596133232 train acc 0.98828125\n",
            "epoch 23 batch id 5 loss 0.1404283195734024 train acc 0.984375\n",
            "epoch 23 batch id 6 loss 0.14004993438720703 train acc 0.9765625\n",
            "epoch 23 batch id 7 loss 0.15629926323890686 train acc 0.9732142857142857\n",
            "epoch 23 batch id 8 loss 0.15521548688411713 train acc 0.970703125\n",
            "epoch 23 batch id 9 loss 0.11123306304216385 train acc 0.9704861111111112\n",
            "epoch 23 batch id 10 loss 0.09726037085056305 train acc 0.9703125\n",
            "epoch 23 batch id 11 loss 0.08526577800512314 train acc 0.9715909090909091\n",
            "epoch 23 batch id 12 loss 0.14387032389640808 train acc 0.9713541666666666\n",
            "epoch 23 batch id 13 loss 0.17632867395877838 train acc 0.9699519230769231\n",
            "epoch 23 batch id 14 loss 0.15511062741279602 train acc 0.96875\n",
            "epoch 23 batch id 15 loss 0.08817430585622787 train acc 0.96875\n",
            "epoch 23 batch id 16 loss 0.07973028719425201 train acc 0.96875\n",
            "epoch 23 batch id 17 loss 0.04757857322692871 train acc 0.9696691176470589\n",
            "epoch 23 batch id 18 loss 0.10321231186389923 train acc 0.9704861111111112\n",
            "epoch 23 batch id 19 loss 0.09469064325094223 train acc 0.9703947368421053\n",
            "epoch 23 batch id 20 loss 0.07491914182901382 train acc 0.9703125\n",
            "epoch 23 batch id 21 loss 0.19973249733448029 train acc 0.96875\n",
            "epoch 23 batch id 22 loss 0.19859856367111206 train acc 0.9680397727272727\n",
            "epoch 23 batch id 23 loss 0.07334856688976288 train acc 0.9680706521739131\n",
            "epoch 23 batch id 24 loss 0.17524802684783936 train acc 0.9674479166666666\n",
            "epoch 23 batch id 25 loss 0.07208587229251862 train acc 0.9675\n",
            "epoch 23 batch id 26 loss 0.16485264897346497 train acc 0.9675480769230769\n",
            "epoch 23 batch id 27 loss 0.012112857773900032 train acc 0.96875\n",
            "epoch 23 batch id 28 loss 0.15912921726703644 train acc 0.96875\n",
            "epoch 23 batch id 29 loss 0.15434302389621735 train acc 0.9676724137931034\n",
            "epoch 23 batch id 30 loss 0.2530379593372345 train acc 0.9671875\n",
            "epoch 23 batch id 31 loss 0.048715922981500626 train acc 0.967741935483871\n",
            "epoch 23 batch id 32 loss 0.15602333843708038 train acc 0.96728515625\n",
            "epoch 23 batch id 33 loss 0.03451346233487129 train acc 0.9678030303030303\n",
            "epoch 23 batch id 34 loss 0.0787549838423729 train acc 0.9678308823529411\n",
            "epoch 23 batch id 35 loss 0.23710155487060547 train acc 0.9660714285714286\n",
            "epoch 23 batch id 36 loss 0.2084607630968094 train acc 0.9657118055555556\n",
            "epoch 23 batch id 37 loss 0.08390620350837708 train acc 0.9662162162162162\n",
            "epoch 23 batch id 38 loss 0.2219397872686386 train acc 0.9646381578947368\n",
            "epoch 23 batch id 39 loss 0.07186577469110489 train acc 0.9647435897435898\n",
            "epoch 23 batch id 40 loss 0.040664881467819214 train acc 0.965625\n",
            "epoch 23 batch id 41 loss 0.08403050154447556 train acc 0.9657012195121951\n",
            "epoch 23 batch id 42 loss 0.2763325273990631 train acc 0.9654017857142857\n",
            "epoch 23 batch id 43 loss 0.11937010288238525 train acc 0.9651162790697675\n",
            "epoch 23 batch id 44 loss 0.1150120422244072 train acc 0.9655539772727273\n",
            "epoch 23 batch id 45 loss 0.13519008457660675 train acc 0.965625\n",
            "epoch 23 batch id 46 loss 0.2500007152557373 train acc 0.9653532608695652\n",
            "epoch 23 batch id 47 loss 0.17418719828128815 train acc 0.9647606382978723\n",
            "epoch 23 batch id 48 loss 0.046675123274326324 train acc 0.9651692708333334\n",
            "epoch 23 batch id 49 loss 0.11788646876811981 train acc 0.9655612244897959\n",
            "epoch 23 batch id 50 loss 0.119754359126091 train acc 0.9653125\n",
            "epoch 23 batch id 51 loss 0.029138455167412758 train acc 0.9659926470588235\n",
            "epoch 23 batch id 52 loss 0.07383474707603455 train acc 0.9663461538461539\n",
            "epoch 23 batch id 53 loss 0.10905178636312485 train acc 0.9663915094339622\n",
            "epoch 23 batch id 54 loss 0.1582283079624176 train acc 0.9664351851851852\n",
            "epoch 23 batch id 55 loss 0.09617746621370316 train acc 0.9664772727272727\n",
            "epoch 23 batch id 56 loss 0.05395535007119179 train acc 0.966796875\n",
            "epoch 23 batch id 57 loss 0.03270793333649635 train acc 0.9673793859649122\n",
            "epoch 23 batch id 58 loss 0.18116264045238495 train acc 0.9671336206896551\n",
            "epoch 23 batch id 59 loss 0.12805625796318054 train acc 0.9666313559322034\n",
            "epoch 23 batch id 60 loss 0.121970035135746 train acc 0.9666666666666667\n",
            "epoch 23 batch id 61 loss 0.09460847079753876 train acc 0.9664446721311475\n",
            "epoch 23 batch id 62 loss 0.023598428815603256 train acc 0.9669858870967742\n",
            "epoch 23 batch id 63 loss 0.057890478521585464 train acc 0.9672619047619048\n",
            "epoch 23 batch id 64 loss 0.04163840040564537 train acc 0.9677734375\n",
            "epoch 23 batch id 65 loss 0.13662180304527283 train acc 0.9673076923076923\n",
            "epoch 23 batch id 66 loss 0.21089878678321838 train acc 0.9668560606060606\n",
            "epoch 23 batch id 67 loss 0.09080708771944046 train acc 0.9668843283582089\n",
            "epoch 23 batch id 68 loss 0.043644096702337265 train acc 0.9671415441176471\n",
            "epoch 23 batch id 69 loss 0.03421524167060852 train acc 0.9676177536231884\n",
            "epoch 23 batch id 70 loss 0.22965070605278015 train acc 0.9676339285714286\n",
            "epoch 23 batch id 71 loss 0.08630697429180145 train acc 0.9674295774647887\n",
            "epoch 23 batch id 72 loss 0.0643705502152443 train acc 0.9674479166666666\n",
            "epoch 23 batch id 73 loss 0.18262208998203278 train acc 0.967679794520548\n",
            "epoch 23 batch id 74 loss 0.12525039911270142 train acc 0.9676942567567568\n",
            "epoch 23 batch id 75 loss 0.07711521536111832 train acc 0.9679166666666666\n",
            "epoch 23 batch id 76 loss 0.10596718639135361 train acc 0.9677220394736842\n",
            "epoch 23 batch id 77 loss 0.07537426799535751 train acc 0.9677353896103896\n",
            "epoch 23 batch id 78 loss 0.1894083470106125 train acc 0.9671474358974359\n",
            "epoch 23 batch id 79 loss 0.12480701506137848 train acc 0.9673655063291139\n",
            "epoch 23 batch id 80 loss 0.12859532237052917 train acc 0.967578125\n",
            "epoch 23 batch id 81 loss 0.12795144319534302 train acc 0.9675925925925926\n",
            "epoch 23 batch id 82 loss 0.20270201563835144 train acc 0.9668445121951219\n",
            "epoch 23 batch id 83 loss 0.30108219385147095 train acc 0.9663027108433735\n",
            "epoch 23 batch id 84 loss 0.03517746925354004 train acc 0.9667038690476191\n",
            "epoch 23 batch id 85 loss 0.05656522884964943 train acc 0.9667279411764705\n",
            "epoch 23 batch id 86 loss 0.03806909918785095 train acc 0.9671148255813954\n",
            "epoch 23 batch id 87 loss 0.10999061167240143 train acc 0.9671336206896551\n",
            "epoch 23 batch id 88 loss 0.0993550568819046 train acc 0.9671519886363636\n",
            "epoch 23 batch id 89 loss 0.03369637578725815 train acc 0.9675210674157303\n",
            "epoch 23 batch id 90 loss 0.09967712312936783 train acc 0.9675347222222223\n",
            "epoch 23 batch id 91 loss 0.14631947875022888 train acc 0.9673763736263736\n",
            "epoch 23 batch id 92 loss 0.24509833753108978 train acc 0.9668817934782609\n",
            "epoch 23 batch id 93 loss 0.19226400554180145 train acc 0.9667338709677419\n",
            "epoch 23 batch id 94 loss 0.03307146206498146 train acc 0.9670877659574468\n",
            "epoch 23 batch id 95 loss 0.25047680735588074 train acc 0.9671052631578947\n",
            "epoch 23 batch id 96 loss 0.17072249948978424 train acc 0.9669596354166666\n",
            "epoch 23 batch id 97 loss 0.10197892040014267 train acc 0.9668170103092784\n",
            "epoch 23 batch id 98 loss 0.13377554714679718 train acc 0.9666772959183674\n",
            "epoch 23 batch id 99 loss 0.02570922113955021 train acc 0.9670138888888888\n",
            "epoch 23 batch id 100 loss 0.11492722481489182 train acc 0.966875\n",
            "epoch 23 batch id 101 loss 0.1994832307100296 train acc 0.9667388613861386\n",
            "epoch 23 batch id 102 loss 0.043812625110149384 train acc 0.9670649509803921\n",
            "epoch 23 batch id 103 loss 0.13688041269779205 train acc 0.9667779126213593\n",
            "epoch 23 batch id 104 loss 0.052456166595220566 train acc 0.966796875\n",
            "epoch 23 batch id 105 loss 0.04789486899971962 train acc 0.9671130952380952\n",
            "epoch 23 batch id 106 loss 0.0840286836028099 train acc 0.9671285377358491\n",
            "epoch 23 batch id 107 loss 0.07188574969768524 train acc 0.9672897196261683\n",
            "epoch 23 batch id 108 loss 0.08245882391929626 train acc 0.9674479166666666\n",
            "epoch 23 batch id 109 loss 0.17437052726745605 train acc 0.9671731651376146\n",
            "epoch 23 batch id 110 loss 0.17629756033420563 train acc 0.9667613636363637\n",
            "epoch 23 batch id 111 loss 0.09144850075244904 train acc 0.966920045045045\n",
            "epoch 23 batch id 112 loss 0.11027581989765167 train acc 0.966796875\n",
            "epoch 23 batch id 113 loss 0.18512395024299622 train acc 0.9665376106194691\n",
            "epoch 23 batch id 114 loss 0.11778388172388077 train acc 0.9665570175438597\n",
            "epoch 23 batch id 115 loss 0.07669652253389359 train acc 0.9667119565217391\n",
            "epoch 23 batch id 116 loss 0.25630590319633484 train acc 0.9664601293103449\n",
            "epoch 23 batch id 117 loss 0.09412141889333725 train acc 0.9664797008547008\n",
            "epoch 23 batch id 118 loss 0.06115400418639183 train acc 0.9666313559322034\n",
            "epoch 23 batch id 119 loss 0.18156594038009644 train acc 0.9665178571428571\n",
            "epoch 23 batch id 120 loss 0.02491823211312294 train acc 0.966796875\n",
            "epoch 23 batch id 121 loss 0.008407985791563988 train acc 0.9670712809917356\n",
            "epoch 23 batch id 122 loss 0.1448647379875183 train acc 0.9668288934426229\n",
            "epoch 23 batch id 123 loss 0.07059422135353088 train acc 0.9669715447154471\n",
            "epoch 23 batch id 124 loss 0.09465740621089935 train acc 0.9668598790322581\n",
            "epoch 23 batch id 125 loss 0.20121295750141144 train acc 0.96675\n",
            "epoch 23 batch id 126 loss 0.12941357493400574 train acc 0.966765873015873\n",
            "epoch 23 batch id 127 loss 0.0262445118278265 train acc 0.9670275590551181\n",
            "epoch 23 batch id 128 loss 0.09809906780719757 train acc 0.967041015625\n",
            "epoch 23 batch id 129 loss 0.15695655345916748 train acc 0.9669331395348837\n",
            "epoch 23 batch id 130 loss 0.04317884147167206 train acc 0.9670673076923076\n",
            "epoch 23 batch id 131 loss 0.10207311809062958 train acc 0.9669608778625954\n",
            "epoch 23 batch id 132 loss 0.11600322276353836 train acc 0.9669744318181818\n",
            "epoch 23 batch id 133 loss 0.10778778791427612 train acc 0.9668703007518797\n",
            "epoch 23 batch id 134 loss 0.07667536288499832 train acc 0.9670009328358209\n",
            "epoch 23 batch id 135 loss 0.015476650558412075 train acc 0.9672453703703704\n",
            "epoch 23 batch id 136 loss 0.08636271953582764 train acc 0.9673713235294118\n",
            "epoch 23 batch id 137 loss 0.18969881534576416 train acc 0.9671532846715328\n",
            "epoch 23 batch id 138 loss 0.08399127423763275 train acc 0.9672780797101449\n",
            "epoch 23 batch id 139 loss 0.07912269979715347 train acc 0.9671762589928058\n",
            "epoch 23 batch id 140 loss 0.15285463631153107 train acc 0.9672991071428572\n",
            "epoch 23 batch id 141 loss 0.08643096685409546 train acc 0.9673093971631206\n",
            "epoch 23 batch id 142 loss 0.3116060495376587 train acc 0.9670994718309859\n",
            "epoch 23 batch id 143 loss 0.20556028187274933 train acc 0.9670017482517482\n",
            "epoch 23 batch id 144 loss 0.19472621381282806 train acc 0.9669053819444444\n",
            "epoch 23 batch id 145 loss 0.04000360518693924 train acc 0.9670258620689656\n",
            "epoch 23 batch id 146 loss 0.05770769342780113 train acc 0.967144691780822\n",
            "epoch 23 batch id 147 loss 0.12927061319351196 train acc 0.9670493197278912\n",
            "epoch 23 batch id 148 loss 0.23649047315120697 train acc 0.9669552364864865\n",
            "epoch 23 batch id 149 loss 0.08707071095705032 train acc 0.9668624161073825\n",
            "epoch 23 batch id 150 loss 0.10106067359447479 train acc 0.9669791666666666\n",
            "epoch 23 batch id 151 loss 0.2022659331560135 train acc 0.9668874172185431\n",
            "epoch 23 batch id 152 loss 0.04977484047412872 train acc 0.9670024671052632\n",
            "epoch 23 batch id 153 loss 0.06199614703655243 train acc 0.9670138888888888\n",
            "epoch 23 batch id 154 loss 0.013825280591845512 train acc 0.9672280844155844\n",
            "epoch 23 batch id 155 loss 0.2925284802913666 train acc 0.9671370967741936\n",
            "epoch 23 batch id 156 loss 0.17494875192642212 train acc 0.9672475961538461\n",
            "epoch 23 batch id 157 loss 0.13293585181236267 train acc 0.9672571656050956\n",
            "epoch 23 batch id 158 loss 0.43680131435394287 train acc 0.9668710443037974\n",
            "epoch 23 batch id 159 loss 0.07741166651248932 train acc 0.9668828616352201\n",
            "epoch 23 batch id 160 loss 0.18271133303642273 train acc 0.96689453125\n",
            "epoch 23 batch id 161 loss 0.21597902476787567 train acc 0.9668090062111802\n",
            "epoch 23 batch id 162 loss 0.07139565050601959 train acc 0.966820987654321\n",
            "epoch 23 batch id 163 loss 0.18590180575847626 train acc 0.9666411042944786\n",
            "epoch 23 batch id 164 loss 0.014432089403271675 train acc 0.9668445121951219\n",
            "epoch 23 batch id 165 loss 0.14487405121326447 train acc 0.9668560606060606\n",
            "epoch 23 batch id 166 loss 0.12783512473106384 train acc 0.966773343373494\n",
            "epoch 23 batch id 167 loss 0.0962023064494133 train acc 0.9666916167664671\n",
            "epoch 23 batch id 168 loss 0.020250970497727394 train acc 0.9668898809523809\n",
            "epoch 23 batch id 169 loss 0.05112878233194351 train acc 0.9669008875739645\n",
            "epoch 23 batch id 170 loss 0.07448484748601913 train acc 0.9670036764705883\n",
            "epoch 23 batch id 171 loss 0.07620274275541306 train acc 0.9671052631578947\n",
            "epoch 23 batch id 172 loss 0.10508012771606445 train acc 0.9672056686046512\n",
            "epoch 23 batch id 173 loss 0.03622663393616676 train acc 0.9673049132947977\n",
            "epoch 23 batch id 174 loss 0.10079431533813477 train acc 0.9671336206896551\n",
            "epoch 23 batch id 175 loss 0.08473759889602661 train acc 0.9671428571428572\n",
            "epoch 23 batch id 176 loss 0.10759376734495163 train acc 0.9670632102272727\n",
            "epoch 23 batch id 177 loss 0.18602213263511658 train acc 0.9669844632768362\n",
            "epoch 23 batch id 178 loss 0.08293421566486359 train acc 0.9669943820224719\n",
            "epoch 23 batch id 179 loss 0.01836586557328701 train acc 0.9671787709497207\n",
            "epoch 23 batch id 180 loss 0.28424981236457825 train acc 0.9670138888888888\n",
            "epoch 23 batch id 181 loss 0.019838130101561546 train acc 0.9671961325966851\n",
            "epoch 23 batch id 182 loss 0.03879272937774658 train acc 0.967290521978022\n",
            "epoch 23 batch id 183 loss 0.1769738644361496 train acc 0.9672984972677595\n",
            "epoch 23 batch id 184 loss 0.05107538402080536 train acc 0.967391304347826\n",
            "epoch 23 batch id 185 loss 0.09405580163002014 train acc 0.9673141891891892\n",
            "epoch 23 batch id 186 loss 0.02083715796470642 train acc 0.9674899193548387\n",
            "epoch 23 batch id 187 loss 0.04878690093755722 train acc 0.9675802139037433\n",
            "epoch 23 batch id 188 loss 0.1542596071958542 train acc 0.9672539893617021\n",
            "epoch 23 batch id 189 loss 0.1277090162038803 train acc 0.9673445767195767\n",
            "epoch 23 batch id 190 loss 0.1879003494977951 train acc 0.9673519736842106\n",
            "epoch 23 batch id 191 loss 0.28379932045936584 train acc 0.9670320680628273\n",
            "epoch 23 batch id 192 loss 0.06594561040401459 train acc 0.9671223958333334\n",
            "epoch 23 batch id 193 loss 0.06928080320358276 train acc 0.9672117875647669\n",
            "epoch 23 batch id 194 loss 0.05439244955778122 train acc 0.9673002577319587\n",
            "epoch 23 batch id 195 loss 0.188508078455925 train acc 0.967227564102564\n",
            "epoch 23 batch id 196 loss 0.09370890259742737 train acc 0.9673150510204082\n",
            "epoch 23 batch id 197 loss 0.1117551177740097 train acc 0.9673223350253807\n",
            "epoch 23 batch id 198 loss 0.10959828644990921 train acc 0.9674084595959596\n",
            "epoch 23 batch id 199 loss 0.07623035460710526 train acc 0.9674152010050251\n",
            "epoch 23 batch id 200 loss 0.08638670295476913 train acc 0.967421875\n",
            "epoch 23 batch id 201 loss 0.14460653066635132 train acc 0.9673507462686567\n",
            "epoch 23 batch id 202 loss 0.16060765087604523 train acc 0.9673576732673267\n",
            "epoch 23 batch id 203 loss 0.15990689396858215 train acc 0.9673645320197044\n",
            "epoch 23 batch id 204 loss 0.08170012384653091 train acc 0.9673713235294118\n",
            "epoch 23 batch id 205 loss 0.10244310647249222 train acc 0.9674542682926829\n",
            "epoch 23 batch id 206 loss 0.20574675500392914 train acc 0.9673847087378641\n",
            "epoch 23 batch id 207 loss 0.028057929128408432 train acc 0.9674667874396136\n",
            "epoch 23 batch id 208 loss 0.22371694445610046 train acc 0.9672475961538461\n",
            "epoch 23 batch id 209 loss 0.27284806966781616 train acc 0.9671800239234449\n",
            "epoch 23 batch id 210 loss 0.18391726911067963 train acc 0.9671130952380952\n",
            "epoch 23 batch id 211 loss 0.0860758051276207 train acc 0.9671208530805687\n",
            "epoch 23 batch id 212 loss 0.30851268768310547 train acc 0.9669811320754716\n",
            "epoch 23 batch id 213 loss 0.11986815929412842 train acc 0.9669894366197183\n",
            "epoch 23 batch id 214 loss 0.08234602957963943 train acc 0.9670706775700935\n",
            "epoch 23 batch id 215 loss 0.040926478803157806 train acc 0.9672238372093023\n",
            "epoch 23 batch id 216 loss 0.1597142517566681 train acc 0.9670862268518519\n",
            "epoch 23 batch id 217 loss 0.030525220558047295 train acc 0.9671658986175116\n",
            "epoch 23 batch id 218 loss 0.07284015417098999 train acc 0.9671014908256881\n",
            "epoch 23 batch id 219 loss 0.07217203825712204 train acc 0.9670376712328768\n",
            "epoch 23 batch id 220 loss 0.15551447868347168 train acc 0.9669744318181818\n",
            "epoch 23 batch id 221 loss 0.059826839715242386 train acc 0.9670531674208145\n",
            "epoch 23 batch id 222 loss 0.11881458759307861 train acc 0.9670608108108109\n",
            "epoch 23 batch id 223 loss 0.07233748584985733 train acc 0.9671384529147982\n",
            "epoch 23 batch id 224 loss 0.10648464411497116 train acc 0.9670758928571429\n",
            "epoch 23 batch id 225 loss 0.28928545117378235 train acc 0.9668055555555556\n",
            "epoch 23 batch id 226 loss 0.12867401540279388 train acc 0.9667450221238938\n",
            "epoch 23 batch id 227 loss 0.32751405239105225 train acc 0.9666850220264317\n",
            "epoch 23 batch id 228 loss 0.17710016667842865 train acc 0.9666255482456141\n",
            "epoch 23 batch id 229 loss 0.17883963882923126 train acc 0.9664301310043668\n",
            "epoch 23 batch id 230 loss 0.25690388679504395 train acc 0.9663722826086957\n",
            "epoch 23 batch id 231 loss 0.15782135725021362 train acc 0.966314935064935\n",
            "epoch 23 batch id 232 loss 0.19337254762649536 train acc 0.9660560344827587\n",
            "epoch 23 batch id 233 loss 0.13190710544586182 train acc 0.9660675965665236\n",
            "epoch 23 batch id 234 loss 0.22992254793643951 train acc 0.9658787393162394\n",
            "epoch 23 batch id 235 loss 0.03553234040737152 train acc 0.9659574468085106\n",
            "epoch 23 batch id 236 loss 0.12215662747621536 train acc 0.9659030720338984\n",
            "epoch 23 batch id 237 loss 0.025378569960594177 train acc 0.96604694092827\n",
            "epoch 23 batch id 238 loss 0.1375388205051422 train acc 0.965795693277311\n",
            "epoch 23 batch id 239 loss 0.07699284702539444 train acc 0.9658080543933054\n",
            "epoch 23 batch id 240 loss 0.1411036103963852 train acc 0.9657552083333333\n",
            "epoch 23 batch id 241 loss 0.12483058124780655 train acc 0.965832468879668\n",
            "epoch 23 batch id 242 loss 0.0722135528922081 train acc 0.9659090909090909\n",
            "epoch 23 batch id 243 loss 0.07997891306877136 train acc 0.9659207818930041\n",
            "epoch 23 batch id 244 loss 0.02251335047185421 train acc 0.9660604508196722\n",
            "epoch 23 batch id 245 loss 0.13093894720077515 train acc 0.9660714285714286\n",
            "epoch 23 batch id 246 loss 0.14202305674552917 train acc 0.9660188008130082\n",
            "epoch 23 batch id 247 loss 0.042204663157463074 train acc 0.9660931174089069\n",
            "epoch 23 batch id 248 loss 0.0664183720946312 train acc 0.9661038306451613\n",
            "epoch 23 batch id 249 loss 0.061609167605638504 train acc 0.9661144578313253\n",
            "epoch 23 batch id 250 loss 0.02656637877225876 train acc 0.96625\n",
            "epoch 23 batch id 251 loss 0.06969920545816422 train acc 0.9663222111553785\n",
            "epoch 23 batch id 252 loss 0.14727623760700226 train acc 0.9662078373015873\n",
            "epoch 23 batch id 253 loss 0.23034965991973877 train acc 0.9661561264822134\n",
            "epoch 23 batch id 254 loss 0.027340728789567947 train acc 0.9662893700787402\n",
            "epoch 23 batch id 255 loss 0.08953196555376053 train acc 0.9662990196078431\n",
            "epoch 23 batch id 256 loss 0.2767859995365143 train acc 0.96600341796875\n",
            "epoch 23 batch id 257 loss 0.02581588365137577 train acc 0.966135700389105\n",
            "epoch 23 batch id 258 loss 0.05803189426660538 train acc 0.9662063953488372\n",
            "epoch 23 batch id 259 loss 0.1327570229768753 train acc 0.9662162162162162\n",
            "epoch 23 batch id 260 loss 0.23822744190692902 train acc 0.9661658653846154\n",
            "epoch 23 batch id 261 loss 0.017756441608071327 train acc 0.9662954980842912\n",
            "epoch 23 batch id 262 loss 0.05389421805739403 train acc 0.9663645038167938\n",
            "epoch 23 batch id 263 loss 0.11998841166496277 train acc 0.966254752851711\n",
            "epoch 23 batch id 264 loss 0.13990937173366547 train acc 0.9662050189393939\n",
            "epoch 23 batch id 265 loss 0.03139892593026161 train acc 0.9663325471698113\n",
            "epoch 23 batch id 266 loss 0.03632419556379318 train acc 0.9664591165413534\n",
            "epoch 23 batch id 267 loss 0.2189592868089676 train acc 0.9663506554307116\n",
            "epoch 23 batch id 268 loss 0.05585964769124985 train acc 0.9664179104477612\n",
            "epoch 23 batch id 269 loss 0.07423650473356247 train acc 0.9664265799256505\n",
            "epoch 23 batch id 270 loss 0.19354768097400665 train acc 0.9663773148148148\n",
            "epoch 23 batch id 271 loss 0.07505951076745987 train acc 0.9663284132841329\n",
            "epoch 23 batch id 272 loss 0.05389753729104996 train acc 0.9663947610294118\n",
            "epoch 23 batch id 273 loss 0.059908196330070496 train acc 0.9664606227106227\n",
            "epoch 23 batch id 274 loss 0.2072570025920868 train acc 0.9663549270072993\n",
            "epoch 23 batch id 275 loss 0.03256457298994064 train acc 0.9664772727272727\n",
            "epoch 23 batch id 276 loss 0.06788063049316406 train acc 0.9665421195652174\n",
            "epoch 23 batch id 277 loss 0.10757755488157272 train acc 0.9665500902527075\n",
            "epoch 23 batch id 278 loss 0.1343066543340683 train acc 0.9665580035971223\n",
            "epoch 23 batch id 279 loss 0.018354224041104317 train acc 0.9666778673835126\n",
            "epoch 23 batch id 280 loss 0.1409527212381363 train acc 0.9666852678571428\n",
            "epoch 23 batch id 281 loss 0.0819237157702446 train acc 0.966692615658363\n",
            "epoch 23 batch id 282 loss 0.049339842051267624 train acc 0.9667553191489362\n",
            "epoch 23 batch id 283 loss 0.32955580949783325 train acc 0.9667071554770318\n",
            "epoch 23 batch id 284 loss 0.10259713977575302 train acc 0.9666593309859155\n",
            "epoch 23 batch id 285 loss 0.042940687388181686 train acc 0.9667214912280702\n",
            "epoch 23 batch id 286 loss 0.2130972445011139 train acc 0.9666193181818182\n",
            "epoch 23 batch id 287 loss 0.11177340149879456 train acc 0.966572299651568\n",
            "epoch 23 batch id 288 loss 0.21331289410591125 train acc 0.9664713541666666\n",
            "epoch 23 batch id 289 loss 0.09778278321027756 train acc 0.9664251730103807\n",
            "epoch 23 batch id 290 loss 0.04338085278868675 train acc 0.9664870689655173\n",
            "epoch 23 batch id 291 loss 0.19124796986579895 train acc 0.9664411512027491\n",
            "epoch 23 batch id 292 loss 0.07119745761156082 train acc 0.9665025684931506\n",
            "epoch 23 batch id 293 loss 0.04965544492006302 train acc 0.966563566552901\n",
            "epoch 23 batch id 294 loss 0.1087687686085701 train acc 0.9665710034013606\n",
            "epoch 23 batch id 295 loss 0.043266233056783676 train acc 0.9666313559322034\n",
            "epoch 23 batch id 296 loss 0.043210577219724655 train acc 0.9666913006756757\n",
            "epoch 23 batch id 297 loss 0.037515200674533844 train acc 0.9668034511784511\n",
            "epoch 23 batch id 298 loss 0.19103311002254486 train acc 0.9667575503355704\n",
            "epoch 23 batch id 299 loss 0.27088868618011475 train acc 0.9666596989966555\n",
            "epoch 23 batch id 300 loss 0.15900138020515442 train acc 0.9665104166666667\n",
            "epoch 23 batch id 301 loss 0.2749924063682556 train acc 0.9664659468438538\n",
            "epoch 23 batch id 302 loss 0.06866138428449631 train acc 0.9664217715231788\n",
            "epoch 23 batch id 303 loss 0.1849079430103302 train acc 0.9662747524752475\n",
            "epoch 23 batch id 304 loss 0.09439806640148163 train acc 0.9662828947368421\n",
            "epoch 23 batch id 305 loss 0.035571157932281494 train acc 0.9663422131147541\n",
            "epoch 23 batch id 306 loss 0.08824802190065384 train acc 0.9663500816993464\n",
            "epoch 23 batch id 307 loss 0.24621738493442535 train acc 0.966307003257329\n",
            "epoch 23 batch id 308 loss 0.10337520390748978 train acc 0.9662642045454546\n",
            "epoch 23 batch id 309 loss 0.1443231850862503 train acc 0.9662216828478964\n",
            "epoch 23 batch id 310 loss 0.025094063952565193 train acc 0.9663306451612903\n",
            "epoch 23 batch id 311 loss 0.11723055690526962 train acc 0.966338424437299\n",
            "epoch 23 batch id 312 loss 0.0607263408601284 train acc 0.9663461538461539\n",
            "epoch 23 batch id 313 loss 0.23515239357948303 train acc 0.9663039137380192\n",
            "epoch 23 batch id 314 loss 0.08235827833414078 train acc 0.9663614649681529\n",
            "epoch 23 batch id 315 loss 0.05444785952568054 train acc 0.9664186507936507\n",
            "epoch 23 batch id 316 loss 0.048619795590639114 train acc 0.9664754746835443\n",
            "epoch 23 batch id 317 loss 0.04899032041430473 train acc 0.9665319400630915\n",
            "epoch 23 batch id 318 loss 0.17528760433197021 train acc 0.9665389150943396\n",
            "epoch 23 batch id 319 loss 0.039379119873046875 train acc 0.9665948275862069\n",
            "epoch 23 batch id 320 loss 0.040437933057546616 train acc 0.966650390625\n",
            "epoch 23 batch id 321 loss 0.09939491003751755 train acc 0.9667056074766355\n",
            "epoch 23 batch id 322 loss 0.04544071853160858 train acc 0.9667604813664596\n",
            "epoch 23 batch id 323 loss 0.18177898228168488 train acc 0.9666215170278638\n",
            "epoch 23 batch id 324 loss 0.14846722781658173 train acc 0.9665798611111112\n",
            "epoch 23 batch id 325 loss 0.11268606036901474 train acc 0.9664903846153846\n",
            "epoch 23 batch id 326 loss 0.022786930203437805 train acc 0.9665931748466258\n",
            "epoch 23 batch id 327 loss 0.11832261085510254 train acc 0.9665997706422018\n",
            "epoch 23 batch id 328 loss 0.26374122500419617 train acc 0.9665586890243902\n",
            "epoch 23 batch id 329 loss 0.03168351575732231 train acc 0.9666603343465046\n",
            "epoch 23 batch id 330 loss 0.01672603189945221 train acc 0.9667613636363637\n",
            "epoch 23 batch id 331 loss 0.16587677597999573 train acc 0.9666729607250756\n",
            "epoch 23 batch id 332 loss 0.05890440195798874 train acc 0.966773343373494\n",
            "epoch 23 batch id 333 loss 0.1503535807132721 train acc 0.9666854354354354\n",
            "epoch 23 batch id 334 loss 0.06463542580604553 train acc 0.9667383982035929\n",
            "epoch 23 batch id 335 loss 0.1984308362007141 train acc 0.9666511194029851\n",
            "epoch 23 batch id 336 loss 0.1720712035894394 train acc 0.9666108630952381\n",
            "epoch 23 batch id 337 loss 0.15481287240982056 train acc 0.9665708456973294\n",
            "epoch 23 batch id 338 loss 0.03048097901046276 train acc 0.9666697485207101\n",
            "epoch 23 batch id 339 loss 0.02466810680925846 train acc 0.9667680678466076\n",
            "epoch 23 batch id 340 loss 0.10603459179401398 train acc 0.9667738970588236\n",
            "epoch 23 batch id 341 loss 0.12688255310058594 train acc 0.9667796920821115\n",
            "epoch 23 batch id 342 loss 0.14080683887004852 train acc 0.9667854532163743\n",
            "epoch 23 batch id 343 loss 0.26057669520378113 train acc 0.9667456268221575\n",
            "epoch 23 batch id 344 loss 0.025399181991815567 train acc 0.9668422965116279\n",
            "epoch 23 batch id 345 loss 0.020718125626444817 train acc 0.9669384057971014\n",
            "epoch 23 batch id 346 loss 0.040027085691690445 train acc 0.9669888005780347\n",
            "epoch 23 batch id 347 loss 0.03022187016904354 train acc 0.9670839337175793\n",
            "epoch 23 batch id 348 loss 0.14984938502311707 train acc 0.9670887212643678\n",
            "epoch 23 batch id 349 loss 0.24908792972564697 train acc 0.9670487106017192\n",
            "epoch 23 batch id 350 loss 0.15269455313682556 train acc 0.9670535714285714\n",
            "epoch 23 batch id 351 loss 0.238078311085701 train acc 0.9670138888888888\n",
            "epoch 23 batch id 352 loss 0.15593193471431732 train acc 0.9670188210227273\n",
            "epoch 23 batch id 353 loss 0.14298774302005768 train acc 0.9669351983002833\n",
            "epoch 23 batch id 354 loss 0.4391314685344696 train acc 0.9667637711864406\n",
            "epoch 23 batch id 355 loss 0.09610001742839813 train acc 0.9668133802816902\n",
            "epoch 23 batch id 356 loss 0.029701927676796913 train acc 0.9668627106741573\n",
            "epoch 23 batch id 357 loss 0.07932408154010773 train acc 0.9668679971988795\n",
            "epoch 23 batch id 358 loss 0.25435152649879456 train acc 0.9667859636871509\n",
            "epoch 23 batch id 359 loss 0.12420289218425751 train acc 0.9668349582172702\n",
            "epoch 23 batch id 360 loss 0.09595300257205963 train acc 0.9668402777777778\n",
            "epoch 23 batch id 361 loss 0.03232740983366966 train acc 0.9668888504155124\n",
            "epoch 23 batch id 362 loss 0.12869511544704437 train acc 0.9668076657458563\n",
            "epoch 23 batch id 363 loss 0.25991520285606384 train acc 0.9667699724517906\n",
            "epoch 23 batch id 364 loss 0.181085467338562 train acc 0.9667324862637363\n",
            "epoch 23 batch id 365 loss 0.16359616816043854 train acc 0.9667808219178082\n",
            "epoch 23 batch id 366 loss 0.03655392676591873 train acc 0.9668715846994536\n",
            "epoch 23 batch id 367 loss 0.14543306827545166 train acc 0.966791553133515\n",
            "epoch 23 batch id 368 loss 0.15260259807109833 train acc 0.966796875\n",
            "epoch 23 batch id 369 loss 0.020988352596759796 train acc 0.9668868563685636\n",
            "epoch 23 batch id 370 loss 0.04583074524998665 train acc 0.9669763513513514\n",
            "epoch 23 batch id 371 loss 0.09338749945163727 train acc 0.9670232479784366\n",
            "epoch 23 batch id 372 loss 0.10561453551054001 train acc 0.9670278897849462\n",
            "epoch 23 batch id 373 loss 0.12867522239685059 train acc 0.9670325067024129\n",
            "epoch 23 batch id 374 loss 0.005525651853531599 train acc 0.9671206550802139\n",
            "epoch 23 batch id 375 loss 0.14683562517166138 train acc 0.9670833333333333\n",
            "epoch 23 batch id 376 loss 0.18660660088062286 train acc 0.9670046542553191\n",
            "epoch 23 batch id 377 loss 0.02827121689915657 train acc 0.967092175066313\n",
            "epoch 23 batch id 378 loss 0.09276729077100754 train acc 0.9670965608465608\n",
            "epoch 23 batch id 379 loss 0.04405736178159714 train acc 0.9671833773087071\n",
            "epoch 23 batch id 380 loss 0.1368459016084671 train acc 0.9671463815789474\n",
            "epoch 23 batch id 381 loss 0.14507806301116943 train acc 0.9671095800524935\n",
            "epoch 23 batch id 382 loss 0.1293889284133911 train acc 0.967154777486911\n",
            "epoch 23 batch id 383 loss 0.11573328822851181 train acc 0.9671589425587467\n",
            "epoch 23 batch id 384 loss 0.19311222434043884 train acc 0.9671223958333334\n",
            "epoch 23 batch id 385 loss 0.154131218791008 train acc 0.9671266233766234\n",
            "epoch 23 batch id 386 loss 0.22320593893527985 train acc 0.9670903497409327\n",
            "epoch 23 batch id 387 loss 0.027607223019003868 train acc 0.9671753875968992\n",
            "epoch 23 batch id 388 loss 0.04085657373070717 train acc 0.9672197164948454\n",
            "epoch 23 batch id 389 loss 0.08432833850383759 train acc 0.9672236503856041\n",
            "epoch 23 batch id 390 loss 0.1580384373664856 train acc 0.9671073717948718\n",
            "epoch 23 batch id 391 loss 0.15405647456645966 train acc 0.9671515345268542\n",
            "epoch 23 batch id 392 loss 0.03291267901659012 train acc 0.9671954719387755\n",
            "epoch 23 batch id 393 loss 0.06863098591566086 train acc 0.967199427480916\n",
            "epoch 23 batch id 394 loss 0.03198131173849106 train acc 0.9672430203045685\n",
            "epoch 23 batch id 395 loss 0.06423014402389526 train acc 0.967246835443038\n",
            "epoch 23 batch id 396 loss 0.24296800792217255 train acc 0.96713226010101\n",
            "epoch 23 batch id 397 loss 0.03244664892554283 train acc 0.9671756926952141\n",
            "epoch 23 batch id 398 loss 0.11408128589391708 train acc 0.9671796482412061\n",
            "epoch 23 batch id 399 loss 0.06555413454771042 train acc 0.9671444235588973\n",
            "epoch 23 batch id 400 loss 0.1969822645187378 train acc 0.9671484375\n",
            "epoch 23 batch id 401 loss 0.08758591115474701 train acc 0.9671913965087282\n",
            "epoch 23 batch id 402 loss 0.08763585984706879 train acc 0.9671564054726368\n",
            "epoch 23 batch id 403 loss 0.0341554619371891 train acc 0.9672379032258065\n",
            "epoch 23 batch id 404 loss 0.03763946145772934 train acc 0.9672803217821783\n",
            "epoch 23 batch id 405 loss 0.1678389459848404 train acc 0.967283950617284\n",
            "epoch 23 batch id 406 loss 0.06272948533296585 train acc 0.9672875615763546\n",
            "epoch 23 batch id 407 loss 0.06626209616661072 train acc 0.9672911547911548\n",
            "epoch 23 batch id 408 loss 0.15059621632099152 train acc 0.9672564338235294\n",
            "epoch 23 batch id 409 loss 0.04417061433196068 train acc 0.9673364914425427\n",
            "epoch 23 batch id 410 loss 0.02361167222261429 train acc 0.9674161585365854\n",
            "epoch 23 batch id 411 loss 0.16553589701652527 train acc 0.9674574209245742\n",
            "epoch 23 batch id 412 loss 0.1183626726269722 train acc 0.9674605582524272\n",
            "epoch 23 batch id 413 loss 0.08085598796606064 train acc 0.9675015133171913\n",
            "epoch 23 batch id 414 loss 0.14198845624923706 train acc 0.9674667874396136\n",
            "epoch 23 batch id 415 loss 0.07607715576887131 train acc 0.967507530120482\n",
            "epoch 23 batch id 416 loss 0.09493263810873032 train acc 0.9675480769230769\n",
            "epoch 23 batch id 417 loss 0.07131297141313553 train acc 0.9675884292565947\n",
            "epoch 23 batch id 418 loss 0.027044782415032387 train acc 0.9676659688995215\n",
            "epoch 23 batch id 419 loss 0.11761951446533203 train acc 0.9676685560859188\n",
            "epoch 23 batch id 420 loss 0.09823265671730042 train acc 0.967671130952381\n",
            "epoch 23 batch id 421 loss 0.07567548751831055 train acc 0.9676736935866983\n",
            "epoch 23 batch id 422 loss 0.12457454204559326 train acc 0.9676762440758294\n",
            "epoch 23 batch id 423 loss 0.13356459140777588 train acc 0.9676418439716312\n",
            "epoch 23 batch id 424 loss 0.09738287329673767 train acc 0.9676076061320755\n",
            "epoch 23 batch id 425 loss 0.1956692337989807 train acc 0.9675735294117647\n",
            "epoch 23 batch id 426 loss 0.07727615535259247 train acc 0.9676129694835681\n",
            "epoch 23 batch id 427 loss 0.18592469394207 train acc 0.967652224824356\n",
            "epoch 23 batch id 428 loss 0.10102873295545578 train acc 0.9676547897196262\n",
            "epoch 23 batch id 429 loss 0.14262372255325317 train acc 0.9675844988344988\n",
            "epoch 23 batch id 430 loss 0.09235332161188126 train acc 0.9675872093023256\n",
            "epoch 23 batch id 431 loss 0.05396454781293869 train acc 0.9676261600928074\n",
            "epoch 23 batch id 432 loss 0.0867612212896347 train acc 0.9676287615740741\n",
            "epoch 23 batch id 433 loss 0.07962579280138016 train acc 0.9676674364896074\n",
            "epoch 23 batch id 434 loss 0.21912038326263428 train acc 0.9676699308755761\n",
            "epoch 23 batch id 435 loss 0.01364538911730051 train acc 0.9677442528735632\n",
            "epoch 23 batch id 436 loss 0.07821834832429886 train acc 0.9677107224770642\n",
            "epoch 23 batch id 437 loss 0.1676752269268036 train acc 0.9677131006864989\n",
            "epoch 23 batch id 438 loss 0.30034351348876953 train acc 0.967679794520548\n",
            "epoch 23 batch id 439 loss 0.07195145636796951 train acc 0.9677178246013668\n",
            "epoch 23 batch id 440 loss 0.39323973655700684 train acc 0.967578125\n",
            "epoch 23 batch id 441 loss 0.15182489156723022 train acc 0.9675099206349206\n",
            "epoch 23 batch id 442 loss 0.13248363137245178 train acc 0.9674773755656109\n",
            "epoch 23 batch id 443 loss 0.13467276096343994 train acc 0.9674449774266366\n",
            "epoch 23 batch id 444 loss 0.2376544028520584 train acc 0.9674127252252253\n",
            "epoch 23 batch id 445 loss 0.028448177501559258 train acc 0.9674859550561797\n",
            "epoch 23 batch id 446 loss 0.08284105360507965 train acc 0.9675238228699552\n",
            "epoch 23 batch id 447 loss 0.048152483999729156 train acc 0.9675615212527964\n",
            "epoch 23 batch id 448 loss 0.05549919232726097 train acc 0.9675990513392857\n",
            "epoch 23 batch id 449 loss 0.2027157098054886 train acc 0.9676016146993318\n",
            "epoch 23 batch id 450 loss 0.21583141386508942 train acc 0.9675\n",
            "epoch 23 batch id 451 loss 0.01755083166062832 train acc 0.9675720620842572\n",
            "epoch 23 batch id 452 loss 0.17155031859874725 train acc 0.9675746681415929\n",
            "epoch 23 batch id 453 loss 0.0724169909954071 train acc 0.9675772626931567\n",
            "epoch 23 batch id 454 loss 0.07534805685281754 train acc 0.9676142621145375\n",
            "epoch 23 batch id 455 loss 0.05279260128736496 train acc 0.9676854395604395\n",
            "epoch 23 batch id 456 loss 0.18502406775951385 train acc 0.9676535087719298\n",
            "epoch 23 batch id 457 loss 0.16931693255901337 train acc 0.9675875273522976\n",
            "epoch 23 batch id 458 loss 0.062245599925518036 train acc 0.9675900655021834\n",
            "epoch 23 batch id 459 loss 0.08870714902877808 train acc 0.9675925925925926\n",
            "epoch 23 batch id 460 loss 0.09437713027000427 train acc 0.9676290760869565\n",
            "epoch 23 batch id 461 loss 0.11341677606105804 train acc 0.9676654013015185\n",
            "epoch 23 batch id 462 loss 0.04449708014726639 train acc 0.9677015692640693\n",
            "epoch 23 batch id 463 loss 0.05394364520907402 train acc 0.9677038336933045\n",
            "epoch 23 batch id 464 loss 0.1598764806985855 train acc 0.9676724137931034\n",
            "epoch 23 batch id 465 loss 0.19873358309268951 train acc 0.9676411290322581\n",
            "epoch 23 batch id 466 loss 0.0819350928068161 train acc 0.967643508583691\n",
            "epoch 23 batch id 467 loss 0.08212820440530777 train acc 0.9676793361884368\n",
            "epoch 23 batch id 468 loss 0.105288565158844 train acc 0.9676482371794872\n",
            "epoch 23 batch id 469 loss 0.03330876678228378 train acc 0.9676839019189766\n",
            "epoch 23 batch id 470 loss 0.09188321232795715 train acc 0.9676861702127659\n",
            "epoch 23 batch id 471 loss 0.15551036596298218 train acc 0.9676220806794055\n",
            "epoch 23 batch id 472 loss 0.031069893389940262 train acc 0.9676906779661016\n",
            "epoch 23 batch id 473 loss 0.09306373447179794 train acc 0.9676929175475687\n",
            "epoch 23 batch id 474 loss 0.08473825454711914 train acc 0.9676621835443038\n",
            "epoch 23 batch id 475 loss 0.262071430683136 train acc 0.9675657894736842\n",
            "epoch 23 batch id 476 loss 0.024817978963255882 train acc 0.9676339285714286\n",
            "epoch 23 batch id 477 loss 0.0975586399435997 train acc 0.9676690251572327\n",
            "epoch 23 batch id 478 loss 0.032498572021722794 train acc 0.9677366631799164\n",
            "epoch 23 batch id 479 loss 0.04189806431531906 train acc 0.967804018789144\n",
            "epoch 23 batch id 480 loss 0.15930573642253876 train acc 0.9677408854166667\n",
            "epoch 23 batch id 481 loss 0.08776092529296875 train acc 0.9677754677754677\n",
            "epoch 23 batch id 482 loss 0.29136306047439575 train acc 0.9677450726141079\n",
            "epoch 23 batch id 483 loss 0.11424162983894348 train acc 0.9677471532091098\n",
            "epoch 23 batch id 484 loss 0.05369291082024574 train acc 0.9677815082644629\n",
            "epoch 23 batch id 485 loss 0.13429640233516693 train acc 0.9678157216494845\n",
            "epoch 23 batch id 486 loss 0.10638576745986938 train acc 0.9678497942386831\n",
            "epoch 23 batch id 487 loss 0.04014714062213898 train acc 0.967883726899384\n",
            "epoch 23 batch id 488 loss 0.10681778192520142 train acc 0.9678855020491803\n",
            "epoch 23 batch id 489 loss 0.09235493093729019 train acc 0.9678872699386503\n",
            "epoch 23 batch id 490 loss 0.04188332334160805 train acc 0.967920918367347\n",
            "epoch 23 batch id 491 loss 0.1366419643163681 train acc 0.9678907841140529\n",
            "epoch 23 batch id 492 loss 0.10025464743375778 train acc 0.9678925304878049\n",
            "epoch 23 batch id 493 loss 0.055438168346881866 train acc 0.9678942697768763\n",
            "epoch 23 batch id 494 loss 0.011220982298254967 train acc 0.9679592611336032\n",
            "epoch 23 batch id 495 loss 0.15260258316993713 train acc 0.9679608585858586\n",
            "epoch 23 batch id 496 loss 0.03496841341257095 train acc 0.9680254536290323\n",
            "epoch 23 batch id 497 loss 0.2050042301416397 train acc 0.9679954728370221\n",
            "epoch 23 batch id 498 loss 0.07856151461601257 train acc 0.9680283634538153\n",
            "epoch 23 batch id 499 loss 0.07579609006643295 train acc 0.9680298096192385\n",
            "epoch 23 batch id 500 loss 0.06704981625080109 train acc 0.9680625\n",
            "epoch 23 batch id 501 loss 0.2256035953760147 train acc 0.9679703093812375\n",
            "epoch 23 batch id 502 loss 0.11238391697406769 train acc 0.9679718625498008\n",
            "epoch 23 batch id 503 loss 0.21433652937412262 train acc 0.9679734095427436\n",
            "epoch 23 batch id 504 loss 0.11662358045578003 train acc 0.9680059523809523\n",
            "epoch 23 batch id 505 loss 0.21934685111045837 train acc 0.9679764851485149\n",
            "epoch 23 batch id 506 loss 0.049316272139549255 train acc 0.9680088932806324\n",
            "epoch 23 batch id 507 loss 0.17904317378997803 train acc 0.9679795364891519\n",
            "epoch 23 batch id 508 loss 0.02577231079339981 train acc 0.9680425688976378\n",
            "epoch 23 batch id 509 loss 0.032470978796482086 train acc 0.9681053536345776\n",
            "epoch 23 batch id 510 loss 0.015967393293976784 train acc 0.9681678921568627\n",
            "epoch 23 batch id 511 loss 0.19422492384910583 train acc 0.968105935296493\n",
            "epoch 23 train acc 0.968105935296493\n",
            "epoch 23 test acc 0.4061279296875\n",
            "epoch 24 batch id 1 loss 0.016345608979463577 train acc 1.0\n",
            "epoch 24 batch id 2 loss 0.10856657475233078 train acc 0.984375\n",
            "epoch 24 batch id 3 loss 0.1198042631149292 train acc 0.9791666666666666\n",
            "epoch 24 batch id 4 loss 0.19968217611312866 train acc 0.96484375\n",
            "epoch 24 batch id 5 loss 0.018791425973176956 train acc 0.971875\n",
            "epoch 24 batch id 6 loss 0.2030576467514038 train acc 0.9713541666666666\n",
            "epoch 24 batch id 7 loss 0.05929460749030113 train acc 0.9709821428571429\n",
            "epoch 24 batch id 8 loss 0.11225020885467529 train acc 0.970703125\n",
            "epoch 24 batch id 9 loss 0.05035378038883209 train acc 0.9722222222222222\n",
            "epoch 24 batch id 10 loss 0.05704808980226517 train acc 0.971875\n",
            "epoch 24 batch id 11 loss 0.09766827523708344 train acc 0.9730113636363636\n",
            "epoch 24 batch id 12 loss 0.1261547952890396 train acc 0.9713541666666666\n",
            "epoch 24 batch id 13 loss 0.12866364419460297 train acc 0.96875\n",
            "epoch 24 batch id 14 loss 0.05210696905851364 train acc 0.9698660714285714\n",
            "epoch 24 batch id 15 loss 0.11810044944286346 train acc 0.9697916666666667\n",
            "epoch 24 batch id 16 loss 0.27010607719421387 train acc 0.9677734375\n",
            "epoch 24 batch id 17 loss 0.1366862803697586 train acc 0.9669117647058824\n",
            "epoch 24 batch id 18 loss 0.1482160985469818 train acc 0.9670138888888888\n",
            "epoch 24 batch id 19 loss 0.03644139692187309 train acc 0.96875\n",
            "epoch 24 batch id 20 loss 0.07141034305095673 train acc 0.96953125\n",
            "epoch 24 batch id 21 loss 0.20233280956745148 train acc 0.9665178571428571\n",
            "epoch 24 batch id 22 loss 0.06370976567268372 train acc 0.9673295454545454\n",
            "epoch 24 batch id 23 loss 0.08953026682138443 train acc 0.967391304347826\n",
            "epoch 24 batch id 24 loss 0.09299684315919876 train acc 0.9674479166666666\n",
            "epoch 24 batch id 25 loss 0.15931472182273865 train acc 0.966875\n",
            "epoch 24 batch id 26 loss 0.10119009017944336 train acc 0.9657451923076923\n",
            "epoch 24 batch id 27 loss 0.09831755608320236 train acc 0.9658564814814815\n",
            "epoch 24 batch id 28 loss 0.0881045013666153 train acc 0.9659598214285714\n",
            "epoch 24 batch id 29 loss 0.09161511063575745 train acc 0.9665948275862069\n",
            "epoch 24 batch id 30 loss 0.046979326754808426 train acc 0.9671875\n",
            "epoch 24 batch id 31 loss 0.05496646836400032 train acc 0.9672379032258065\n",
            "epoch 24 batch id 32 loss 0.01519769337028265 train acc 0.96826171875\n",
            "epoch 24 batch id 33 loss 0.1426534205675125 train acc 0.9678030303030303\n",
            "epoch 24 batch id 34 loss 0.1435171663761139 train acc 0.9673713235294118\n",
            "epoch 24 batch id 35 loss 0.048173464834690094 train acc 0.9678571428571429\n",
            "epoch 24 batch id 36 loss 0.04082049801945686 train acc 0.9683159722222222\n",
            "epoch 24 batch id 37 loss 0.04762933403253555 train acc 0.96875\n",
            "epoch 24 batch id 38 loss 0.020865200087428093 train acc 0.9695723684210527\n",
            "epoch 24 batch id 39 loss 0.10955046862363815 train acc 0.969551282051282\n",
            "epoch 24 batch id 40 loss 0.03869112953543663 train acc 0.9703125\n",
            "epoch 24 batch id 41 loss 0.032394956797361374 train acc 0.9710365853658537\n",
            "epoch 24 batch id 42 loss 0.1256977766752243 train acc 0.9709821428571429\n",
            "epoch 24 batch id 43 loss 0.03603482246398926 train acc 0.971656976744186\n",
            "epoch 24 batch id 44 loss 0.06878309696912766 train acc 0.9719460227272727\n",
            "epoch 24 batch id 45 loss 0.09323546290397644 train acc 0.9722222222222222\n",
            "epoch 24 batch id 46 loss 0.06138079985976219 train acc 0.9721467391304348\n",
            "epoch 24 batch id 47 loss 0.34051018953323364 train acc 0.9710771276595744\n",
            "epoch 24 batch id 48 loss 0.25665342807769775 train acc 0.970703125\n",
            "epoch 24 batch id 49 loss 0.07993394881486893 train acc 0.9709821428571429\n",
            "epoch 24 batch id 50 loss 0.18826903402805328 train acc 0.970625\n",
            "epoch 24 batch id 51 loss 0.12910355627536774 train acc 0.9705882352941176\n",
            "epoch 24 batch id 52 loss 0.12359969317913055 train acc 0.9699519230769231\n",
            "epoch 24 batch id 53 loss 0.2587116062641144 train acc 0.9690448113207547\n",
            "epoch 24 batch id 54 loss 0.01604899950325489 train acc 0.9696180555555556\n",
            "epoch 24 batch id 55 loss 0.04667414352297783 train acc 0.9698863636363636\n",
            "epoch 24 batch id 56 loss 0.11945301294326782 train acc 0.9698660714285714\n",
            "epoch 24 batch id 57 loss 0.05987916514277458 train acc 0.9701206140350878\n",
            "epoch 24 batch id 58 loss 0.07629066705703735 train acc 0.9698275862068966\n",
            "epoch 24 batch id 59 loss 0.0784502923488617 train acc 0.9700741525423728\n",
            "epoch 24 batch id 60 loss 0.044636353850364685 train acc 0.9705729166666667\n",
            "epoch 24 batch id 61 loss 0.03948640823364258 train acc 0.9710553278688525\n",
            "epoch 24 batch id 62 loss 0.04829683527350426 train acc 0.9715221774193549\n",
            "epoch 24 batch id 63 loss 0.30675747990608215 train acc 0.9712301587301587\n",
            "epoch 24 batch id 64 loss 0.012482755817472935 train acc 0.9716796875\n",
            "epoch 24 batch id 65 loss 0.025817256420850754 train acc 0.9721153846153846\n",
            "epoch 24 batch id 66 loss 0.12489362061023712 train acc 0.9715909090909091\n",
            "epoch 24 batch id 67 loss 0.046627845615148544 train acc 0.9717817164179104\n",
            "epoch 24 batch id 68 loss 0.10588406771421432 train acc 0.9717371323529411\n",
            "epoch 24 batch id 69 loss 0.20571288466453552 train acc 0.9719202898550725\n",
            "epoch 24 batch id 70 loss 0.26200947165489197 train acc 0.9714285714285714\n",
            "epoch 24 batch id 71 loss 0.19150012731552124 train acc 0.9711707746478874\n",
            "epoch 24 batch id 72 loss 0.1458517462015152 train acc 0.9711371527777778\n",
            "epoch 24 batch id 73 loss 0.07234090566635132 train acc 0.9711044520547946\n",
            "epoch 24 batch id 74 loss 0.149124875664711 train acc 0.9710726351351351\n",
            "epoch 24 batch id 75 loss 0.08651073276996613 train acc 0.9710416666666667\n",
            "epoch 24 batch id 76 loss 0.03432745113968849 train acc 0.971422697368421\n",
            "epoch 24 batch id 77 loss 0.09429875761270523 train acc 0.971387987012987\n",
            "epoch 24 batch id 78 loss 0.3152484595775604 train acc 0.9705528846153846\n",
            "epoch 24 batch id 79 loss 0.08723555505275726 train acc 0.9703322784810127\n",
            "epoch 24 batch id 80 loss 0.20001131296157837 train acc 0.9701171875\n",
            "epoch 24 batch id 81 loss 0.02200271748006344 train acc 0.9704861111111112\n",
            "epoch 24 batch id 82 loss 0.0918438583612442 train acc 0.9706554878048781\n",
            "epoch 24 batch id 83 loss 0.012740645557641983 train acc 0.9710090361445783\n",
            "epoch 24 batch id 84 loss 0.07844270020723343 train acc 0.9711681547619048\n",
            "epoch 24 batch id 85 loss 0.20335061848163605 train acc 0.9709558823529412\n",
            "epoch 24 batch id 86 loss 0.03881644085049629 train acc 0.9711119186046512\n",
            "epoch 24 batch id 87 loss 0.11860112100839615 train acc 0.9710847701149425\n",
            "epoch 24 batch id 88 loss 0.11800867319107056 train acc 0.9712357954545454\n",
            "epoch 24 batch id 89 loss 0.05048360303044319 train acc 0.9713834269662921\n",
            "epoch 24 batch id 90 loss 0.1771116554737091 train acc 0.9713541666666666\n",
            "epoch 24 batch id 91 loss 0.1852916181087494 train acc 0.9711538461538461\n",
            "epoch 24 batch id 92 loss 0.09994389861822128 train acc 0.9709578804347826\n",
            "epoch 24 batch id 93 loss 0.06848608702421188 train acc 0.9709341397849462\n",
            "epoch 24 batch id 94 loss 0.18008439242839813 train acc 0.9709109042553191\n",
            "epoch 24 batch id 95 loss 0.11959642916917801 train acc 0.9708881578947368\n",
            "epoch 24 batch id 96 loss 0.08472254872322083 train acc 0.9708658854166666\n",
            "epoch 24 batch id 97 loss 0.03661466762423515 train acc 0.9710051546391752\n",
            "epoch 24 batch id 98 loss 0.09137079119682312 train acc 0.9711415816326531\n",
            "epoch 24 batch id 99 loss 0.10523535311222076 train acc 0.9709595959595959\n",
            "epoch 24 batch id 100 loss 0.2707265615463257 train acc 0.970625\n",
            "epoch 24 batch id 101 loss 0.09009448438882828 train acc 0.9706064356435643\n",
            "epoch 24 batch id 102 loss 0.3225678503513336 train acc 0.9701286764705882\n",
            "epoch 24 batch id 103 loss 0.14981266856193542 train acc 0.9698118932038835\n",
            "epoch 24 batch id 104 loss 0.10516897588968277 train acc 0.9696514423076923\n",
            "epoch 24 batch id 105 loss 0.08836207538843155 train acc 0.9696428571428571\n",
            "epoch 24 batch id 106 loss 0.16242718696594238 train acc 0.9693396226415094\n",
            "epoch 24 batch id 107 loss 0.04725688695907593 train acc 0.9694801401869159\n",
            "epoch 24 batch id 108 loss 0.05932685360312462 train acc 0.9696180555555556\n",
            "epoch 24 batch id 109 loss 0.11537883430719376 train acc 0.9696100917431193\n",
            "epoch 24 batch id 110 loss 0.051962386816740036 train acc 0.9698863636363636\n",
            "epoch 24 batch id 111 loss 0.14997535943984985 train acc 0.9697353603603603\n",
            "epoch 24 batch id 112 loss 0.10327152907848358 train acc 0.9695870535714286\n",
            "epoch 24 batch id 113 loss 0.05639054998755455 train acc 0.9697179203539823\n",
            "epoch 24 batch id 114 loss 0.08587659150362015 train acc 0.9697094298245614\n",
            "epoch 24 batch id 115 loss 0.07938402146100998 train acc 0.9697010869565217\n",
            "epoch 24 batch id 116 loss 0.08885779231786728 train acc 0.9695581896551724\n",
            "epoch 24 batch id 117 loss 0.21334901452064514 train acc 0.969017094017094\n",
            "epoch 24 batch id 118 loss 0.07432177662849426 train acc 0.9690148305084746\n",
            "epoch 24 batch id 119 loss 0.16613319516181946 train acc 0.9690126050420168\n",
            "epoch 24 batch id 120 loss 0.07840798795223236 train acc 0.969140625\n",
            "epoch 24 batch id 121 loss 0.17469583451747894 train acc 0.96900826446281\n",
            "epoch 24 batch id 122 loss 0.4088601768016815 train acc 0.9686219262295082\n",
            "epoch 24 batch id 123 loss 0.12598486244678497 train acc 0.9686229674796748\n",
            "epoch 24 batch id 124 loss 0.28356489539146423 train acc 0.9682459677419355\n",
            "epoch 24 batch id 125 loss 0.14452335238456726 train acc 0.968\n",
            "epoch 24 batch id 126 loss 0.2530716359615326 train acc 0.9677579365079365\n",
            "epoch 24 batch id 127 loss 0.12116651237010956 train acc 0.967888779527559\n",
            "epoch 24 batch id 128 loss 0.1653575748205185 train acc 0.9678955078125\n",
            "epoch 24 batch id 129 loss 0.056473392993211746 train acc 0.9679021317829457\n",
            "epoch 24 batch id 130 loss 0.11293371021747589 train acc 0.9680288461538461\n",
            "epoch 24 batch id 131 loss 0.21733161807060242 train acc 0.9679150763358778\n",
            "epoch 24 batch id 132 loss 0.048161499202251434 train acc 0.9680397727272727\n",
            "epoch 24 batch id 133 loss 0.06477268040180206 train acc 0.9680451127819549\n",
            "epoch 24 batch id 134 loss 0.16520631313323975 train acc 0.9680503731343284\n",
            "epoch 24 batch id 135 loss 0.0637408122420311 train acc 0.9680555555555556\n",
            "epoch 24 batch id 136 loss 0.029533758759498596 train acc 0.9682904411764706\n",
            "epoch 24 batch id 137 loss 0.03807779774069786 train acc 0.9684078467153284\n",
            "epoch 24 batch id 138 loss 0.08751889318227768 train acc 0.9685235507246377\n",
            "epoch 24 batch id 139 loss 0.10162373632192612 train acc 0.9685251798561151\n",
            "epoch 24 batch id 140 loss 0.17886175215244293 train acc 0.9684151785714286\n",
            "epoch 24 batch id 141 loss 0.022705793380737305 train acc 0.9686391843971631\n",
            "epoch 24 batch id 142 loss 0.05286248028278351 train acc 0.96875\n",
            "epoch 24 batch id 143 loss 0.08721676468849182 train acc 0.9688592657342657\n",
            "epoch 24 batch id 144 loss 0.024159351363778114 train acc 0.9690755208333334\n",
            "epoch 24 batch id 145 loss 0.06907320022583008 train acc 0.9691810344827586\n",
            "epoch 24 batch id 146 loss 0.06011294201016426 train acc 0.969285102739726\n",
            "epoch 24 batch id 147 loss 0.023039400577545166 train acc 0.9694940476190477\n",
            "epoch 24 batch id 148 loss 0.04073303937911987 train acc 0.969700168918919\n",
            "epoch 24 batch id 149 loss 0.17306175827980042 train acc 0.9695889261744967\n",
            "epoch 24 batch id 150 loss 0.05883372947573662 train acc 0.9696875\n",
            "epoch 24 batch id 151 loss 0.051969531923532486 train acc 0.9698882450331126\n",
            "epoch 24 batch id 152 loss 0.10229666531085968 train acc 0.9696751644736842\n",
            "epoch 24 batch id 153 loss 0.05417778715491295 train acc 0.9697712418300654\n",
            "epoch 24 batch id 154 loss 0.049568742513656616 train acc 0.9699675324675324\n",
            "epoch 24 batch id 155 loss 0.16137449443340302 train acc 0.9698588709677419\n",
            "epoch 24 batch id 156 loss 0.374594509601593 train acc 0.9696514423076923\n",
            "epoch 24 batch id 157 loss 0.045147377997636795 train acc 0.9697452229299363\n",
            "epoch 24 batch id 158 loss 0.1253906637430191 train acc 0.9697389240506329\n",
            "epoch 24 batch id 159 loss 0.07526730746030807 train acc 0.9698309748427673\n",
            "epoch 24 batch id 160 loss 0.06496665626764297 train acc 0.969921875\n",
            "epoch 24 batch id 161 loss 0.11984455585479736 train acc 0.9699145962732919\n",
            "epoch 24 batch id 162 loss 0.19339092075824738 train acc 0.9697145061728395\n",
            "epoch 24 batch id 163 loss 0.24062146246433258 train acc 0.9696127300613497\n",
            "epoch 24 batch id 164 loss 0.08547267317771912 train acc 0.969702743902439\n",
            "epoch 24 batch id 165 loss 0.15004636347293854 train acc 0.9697916666666667\n",
            "epoch 24 batch id 166 loss 0.025102851912379265 train acc 0.9699736445783133\n",
            "epoch 24 batch id 167 loss 0.08282310515642166 train acc 0.9699663173652695\n",
            "epoch 24 batch id 168 loss 0.025763269513845444 train acc 0.9701450892857143\n",
            "epoch 24 batch id 169 loss 0.19565147161483765 train acc 0.9699519230769231\n",
            "epoch 24 batch id 170 loss 0.20300139486789703 train acc 0.9697610294117647\n",
            "epoch 24 batch id 171 loss 0.020075209438800812 train acc 0.9699378654970761\n",
            "epoch 24 batch id 172 loss 0.04198411479592323 train acc 0.9700218023255814\n",
            "epoch 24 batch id 173 loss 0.08177191764116287 train acc 0.9701047687861272\n",
            "epoch 24 batch id 174 loss 0.1436130702495575 train acc 0.9700969827586207\n",
            "epoch 24 batch id 175 loss 0.20639553666114807 train acc 0.9700892857142858\n",
            "epoch 24 batch id 176 loss 0.015752209350466728 train acc 0.9702592329545454\n",
            "epoch 24 batch id 177 loss 0.050995077937841415 train acc 0.9703389830508474\n",
            "epoch 24 batch id 178 loss 0.09966190904378891 train acc 0.9704178370786517\n",
            "epoch 24 batch id 179 loss 0.09241026639938354 train acc 0.9704958100558659\n",
            "epoch 24 batch id 180 loss 0.19806034862995148 train acc 0.9703125\n",
            "epoch 24 batch id 181 loss 0.08854469656944275 train acc 0.9703038674033149\n",
            "epoch 24 batch id 182 loss 0.13715049624443054 train acc 0.9702953296703297\n",
            "epoch 24 batch id 183 loss 0.04683997109532356 train acc 0.9702868852459017\n",
            "epoch 24 batch id 184 loss 0.10208398103713989 train acc 0.9703634510869565\n",
            "epoch 24 batch id 185 loss 0.00788293406367302 train acc 0.9705236486486486\n",
            "epoch 24 batch id 186 loss 0.07833375781774521 train acc 0.9705141129032258\n",
            "epoch 24 batch id 187 loss 0.106532521545887 train acc 0.970504679144385\n",
            "epoch 24 batch id 188 loss 0.05043460428714752 train acc 0.9705784574468085\n",
            "epoch 24 batch id 189 loss 0.1682310700416565 train acc 0.970568783068783\n",
            "epoch 24 batch id 190 loss 0.10169090330600739 train acc 0.9705592105263158\n",
            "epoch 24 batch id 191 loss 0.17698659002780914 train acc 0.9703861256544503\n",
            "epoch 24 batch id 192 loss 0.13261719048023224 train acc 0.9703776041666666\n",
            "epoch 24 batch id 193 loss 0.1030171737074852 train acc 0.9702882124352331\n",
            "epoch 24 batch id 194 loss 0.09628153592348099 train acc 0.970360824742268\n",
            "epoch 24 batch id 195 loss 0.06833703815937042 train acc 0.9704326923076924\n",
            "epoch 24 batch id 196 loss 0.25364062190055847 train acc 0.9701849489795918\n",
            "epoch 24 batch id 197 loss 0.16325992345809937 train acc 0.9700983502538071\n",
            "epoch 24 batch id 198 loss 0.20031195878982544 train acc 0.9699337121212122\n",
            "epoch 24 batch id 199 loss 0.21371512115001678 train acc 0.9698492462311558\n",
            "epoch 24 batch id 200 loss 0.2123418003320694 train acc 0.969609375\n",
            "epoch 24 batch id 201 loss 0.1019463986158371 train acc 0.9696050995024875\n",
            "epoch 24 batch id 202 loss 0.07822935283184052 train acc 0.9696008663366337\n",
            "epoch 24 batch id 203 loss 0.03438648581504822 train acc 0.9697506157635468\n",
            "epoch 24 batch id 204 loss 0.13360056281089783 train acc 0.9695925245098039\n",
            "epoch 24 batch id 205 loss 0.2060304880142212 train acc 0.9695121951219512\n",
            "epoch 24 batch id 206 loss 0.10636922717094421 train acc 0.9695084951456311\n",
            "epoch 24 batch id 207 loss 0.04363397881388664 train acc 0.9695803140096618\n",
            "epoch 24 batch id 208 loss 0.14618119597434998 train acc 0.9695763221153846\n",
            "epoch 24 batch id 209 loss 0.03168274834752083 train acc 0.9697218899521531\n",
            "epoch 24 batch id 210 loss 0.1138208732008934 train acc 0.9697172619047619\n",
            "epoch 24 batch id 211 loss 0.13506394624710083 train acc 0.9697126777251185\n",
            "epoch 24 batch id 212 loss 0.03860986605286598 train acc 0.9697818396226415\n",
            "epoch 24 batch id 213 loss 0.10480892658233643 train acc 0.9697036384976526\n",
            "epoch 24 batch id 214 loss 0.015637913718819618 train acc 0.9698452102803738\n",
            "epoch 24 batch id 215 loss 0.23412516713142395 train acc 0.9697674418604652\n",
            "epoch 24 batch id 216 loss 0.03275436908006668 train acc 0.9698350694444444\n",
            "epoch 24 batch id 217 loss 0.15335002541542053 train acc 0.9696860599078341\n",
            "epoch 24 batch id 218 loss 0.030169205740094185 train acc 0.9698251146788991\n",
            "epoch 24 batch id 219 loss 0.19391445815563202 train acc 0.9696775114155252\n",
            "epoch 24 batch id 220 loss 0.08832157403230667 train acc 0.9696732954545455\n",
            "epoch 24 batch id 221 loss 0.09825420379638672 train acc 0.9696691176470589\n",
            "epoch 24 batch id 222 loss 0.07863669097423553 train acc 0.9697353603603603\n",
            "epoch 24 batch id 223 loss 0.179625004529953 train acc 0.9697309417040358\n",
            "epoch 24 batch id 224 loss 0.03539974242448807 train acc 0.9697963169642857\n",
            "epoch 24 batch id 225 loss 0.06905842572450638 train acc 0.9698611111111111\n",
            "epoch 24 batch id 226 loss 0.05097508057951927 train acc 0.9699253318584071\n",
            "epoch 24 batch id 227 loss 0.18704290688037872 train acc 0.9697824889867841\n",
            "epoch 24 batch id 228 loss 0.23276779055595398 train acc 0.9695723684210527\n",
            "epoch 24 batch id 229 loss 0.12646199762821198 train acc 0.9695687772925764\n",
            "epoch 24 batch id 230 loss 0.05465555936098099 train acc 0.969633152173913\n",
            "epoch 24 batch id 231 loss 0.044659849256277084 train acc 0.9696969696969697\n",
            "epoch 24 batch id 232 loss 0.25995689630508423 train acc 0.9696255387931034\n",
            "epoch 24 batch id 233 loss 0.028659915551543236 train acc 0.9696888412017167\n",
            "epoch 24 batch id 234 loss 0.018915865570306778 train acc 0.9698183760683761\n",
            "epoch 24 batch id 235 loss 0.06668754667043686 train acc 0.9698803191489361\n",
            "epoch 24 batch id 236 loss 0.1234617754817009 train acc 0.969875529661017\n",
            "epoch 24 batch id 237 loss 0.07873930037021637 train acc 0.9699367088607594\n",
            "epoch 24 batch id 238 loss 0.08513471484184265 train acc 0.9698660714285714\n",
            "epoch 24 batch id 239 loss 0.02157628908753395 train acc 0.9699267782426778\n",
            "epoch 24 batch id 240 loss 0.04107028618454933 train acc 0.9700520833333334\n",
            "epoch 24 batch id 241 loss 0.06950457394123077 train acc 0.9701115145228216\n",
            "epoch 24 batch id 242 loss 0.06275300681591034 train acc 0.9701704545454546\n",
            "epoch 24 batch id 243 loss 0.041483018547296524 train acc 0.9702289094650206\n",
            "epoch 24 batch id 244 loss 0.10786154866218567 train acc 0.9701588114754098\n",
            "epoch 24 batch id 245 loss 0.1979246288537979 train acc 0.9700255102040817\n",
            "epoch 24 batch id 246 loss 0.02863861247897148 train acc 0.9700838414634146\n",
            "epoch 24 batch id 247 loss 0.05096180737018585 train acc 0.9702049595141701\n",
            "epoch 24 batch id 248 loss 0.0327407531440258 train acc 0.9703251008064516\n",
            "epoch 24 batch id 249 loss 0.014614187180995941 train acc 0.9704442771084337\n",
            "epoch 24 batch id 250 loss 0.03465912863612175 train acc 0.9705625\n",
            "epoch 24 batch id 251 loss 0.11978858709335327 train acc 0.9706175298804781\n",
            "epoch 24 batch id 252 loss 0.15797755122184753 train acc 0.9706101190476191\n",
            "epoch 24 batch id 253 loss 0.04518142715096474 train acc 0.9707262845849802\n",
            "epoch 24 batch id 254 loss 0.04041772335767746 train acc 0.9707800196850394\n",
            "epoch 24 batch id 255 loss 0.17095719277858734 train acc 0.9705882352941176\n",
            "epoch 24 batch id 256 loss 0.24657253921031952 train acc 0.97039794921875\n",
            "epoch 24 batch id 257 loss 0.18368229269981384 train acc 0.9703307392996109\n",
            "epoch 24 batch id 258 loss 0.17750957608222961 train acc 0.970203488372093\n",
            "epoch 24 batch id 259 loss 0.12353894859552383 train acc 0.9701978764478765\n",
            "epoch 24 batch id 260 loss 0.08615811914205551 train acc 0.9701923076923077\n",
            "epoch 24 batch id 261 loss 0.11128473281860352 train acc 0.9701269157088123\n",
            "epoch 24 batch id 262 loss 0.07642734795808792 train acc 0.9700620229007634\n",
            "epoch 24 batch id 263 loss 0.048676975071430206 train acc 0.9701164448669202\n",
            "epoch 24 batch id 264 loss 0.07228429615497589 train acc 0.9701704545454546\n",
            "epoch 24 batch id 265 loss 0.24496111273765564 train acc 0.9700471698113208\n",
            "epoch 24 batch id 266 loss 0.13219113647937775 train acc 0.9700422932330827\n",
            "epoch 24 batch id 267 loss 0.13348576426506042 train acc 0.9700959737827716\n",
            "epoch 24 batch id 268 loss 0.01843765564262867 train acc 0.9702075559701493\n",
            "epoch 24 batch id 269 loss 0.06016172096133232 train acc 0.9702602230483272\n",
            "epoch 24 batch id 270 loss 0.21092800796031952 train acc 0.9701388888888889\n",
            "epoch 24 batch id 271 loss 0.0742189958691597 train acc 0.9701337638376384\n",
            "epoch 24 batch id 272 loss 0.09619581699371338 train acc 0.9701286764705882\n",
            "epoch 24 batch id 273 loss 0.07071052491664886 train acc 0.9701808608058609\n",
            "epoch 24 batch id 274 loss 0.09963668137788773 train acc 0.9701756386861314\n",
            "epoch 24 batch id 275 loss 0.04610805585980415 train acc 0.9702272727272727\n",
            "epoch 24 batch id 276 loss 0.06018191948533058 train acc 0.9702785326086957\n",
            "epoch 24 batch id 277 loss 0.0235849991440773 train acc 0.9703858303249098\n",
            "epoch 24 batch id 278 loss 0.07217828929424286 train acc 0.9703799460431655\n",
            "epoch 24 batch id 279 loss 0.14447332918643951 train acc 0.9703741039426523\n",
            "epoch 24 batch id 280 loss 0.3398037254810333 train acc 0.9702008928571428\n",
            "epoch 24 batch id 281 loss 0.061992671340703964 train acc 0.9701957295373665\n",
            "epoch 24 batch id 282 loss 0.02080656588077545 train acc 0.9703014184397163\n",
            "epoch 24 batch id 283 loss 0.1623712033033371 train acc 0.9701855123674912\n",
            "epoch 24 batch id 284 loss 0.054956723004579544 train acc 0.9702354753521126\n",
            "epoch 24 batch id 285 loss 0.023018574342131615 train acc 0.9703399122807017\n",
            "epoch 24 batch id 286 loss 0.21111902594566345 train acc 0.9702797202797203\n",
            "epoch 24 batch id 287 loss 0.06100371479988098 train acc 0.9703288327526133\n",
            "epoch 24 batch id 288 loss 0.22057703137397766 train acc 0.9702690972222222\n",
            "epoch 24 batch id 289 loss 0.08252805471420288 train acc 0.9703179065743944\n",
            "epoch 24 batch id 290 loss 0.026442907750606537 train acc 0.9703663793103449\n",
            "epoch 24 batch id 291 loss 0.0964399203658104 train acc 0.970360824742268\n",
            "epoch 24 batch id 292 loss 0.06456120312213898 train acc 0.970355308219178\n",
            "epoch 24 batch id 293 loss 0.0074856518767774105 train acc 0.9704564846416383\n",
            "epoch 24 batch id 294 loss 0.041238266974687576 train acc 0.9705038265306123\n",
            "epoch 24 batch id 295 loss 0.01872936263680458 train acc 0.970603813559322\n",
            "epoch 24 batch id 296 loss 0.09142821282148361 train acc 0.9705975506756757\n",
            "epoch 24 batch id 297 loss 0.04017045348882675 train acc 0.9706965488215489\n",
            "epoch 24 batch id 298 loss 0.05506112053990364 train acc 0.9707424496644296\n",
            "epoch 24 batch id 299 loss 0.09628130495548248 train acc 0.9707357859531772\n",
            "epoch 24 batch id 300 loss 0.11870251595973969 train acc 0.97078125\n",
            "epoch 24 batch id 301 loss 0.22241127490997314 train acc 0.9706706810631229\n",
            "epoch 24 batch id 302 loss 0.13724157214164734 train acc 0.9706643211920529\n",
            "epoch 24 batch id 303 loss 0.03580332174897194 train acc 0.9707095709570958\n",
            "epoch 24 batch id 304 loss 0.03766272962093353 train acc 0.9707545230263158\n",
            "epoch 24 batch id 305 loss 0.06793991476297379 train acc 0.9707991803278688\n",
            "epoch 24 batch id 306 loss 0.009140826761722565 train acc 0.9708946078431373\n",
            "epoch 24 batch id 307 loss 0.0309229027479887 train acc 0.9709385179153095\n",
            "epoch 24 batch id 308 loss 0.19279545545578003 train acc 0.9709314123376623\n",
            "epoch 24 batch id 309 loss 0.049516670405864716 train acc 0.9709749190938511\n",
            "epoch 24 batch id 310 loss 0.0573892779648304 train acc 0.9710181451612904\n",
            "epoch 24 batch id 311 loss 0.06791064888238907 train acc 0.9710108520900321\n",
            "epoch 24 batch id 312 loss 0.07494106143712997 train acc 0.9710036057692307\n",
            "epoch 24 batch id 313 loss 0.0782693400979042 train acc 0.9709964057507987\n",
            "epoch 24 batch id 314 loss 0.09287834167480469 train acc 0.9710390127388535\n",
            "epoch 24 batch id 315 loss 0.09102852642536163 train acc 0.971031746031746\n",
            "epoch 24 batch id 316 loss 0.014245903119444847 train acc 0.971123417721519\n",
            "epoch 24 batch id 317 loss 0.03157251700758934 train acc 0.9711652208201893\n",
            "epoch 24 batch id 318 loss 0.17452333867549896 train acc 0.9711084905660378\n",
            "epoch 24 batch id 319 loss 0.10226844996213913 train acc 0.9710521159874608\n",
            "epoch 24 batch id 320 loss 0.027960145846009254 train acc 0.971142578125\n",
            "epoch 24 batch id 321 loss 0.04698573052883148 train acc 0.9711351246105919\n",
            "epoch 24 batch id 322 loss 0.1495322585105896 train acc 0.9710791925465838\n",
            "epoch 24 batch id 323 loss 0.06336626410484314 train acc 0.9711203560371517\n",
            "epoch 24 batch id 324 loss 0.057772282510995865 train acc 0.9711612654320988\n",
            "epoch 24 batch id 325 loss 0.11902335286140442 train acc 0.9712019230769231\n",
            "epoch 24 batch id 326 loss 0.036393459886312485 train acc 0.9712423312883436\n",
            "epoch 24 batch id 327 loss 0.07287055253982544 train acc 0.9712824923547401\n",
            "epoch 24 batch id 328 loss 0.07835055142641068 train acc 0.9713224085365854\n",
            "epoch 24 batch id 329 loss 0.046750981360673904 train acc 0.9713620820668692\n",
            "epoch 24 batch id 330 loss 0.07311633229255676 train acc 0.9713541666666666\n",
            "epoch 24 batch id 331 loss 0.0977117121219635 train acc 0.9713462990936556\n",
            "epoch 24 batch id 332 loss 0.013752322643995285 train acc 0.9714326054216867\n",
            "epoch 24 batch id 333 loss 0.2204379290342331 train acc 0.9712837837837838\n",
            "epoch 24 batch id 334 loss 0.18986830115318298 train acc 0.9712294161676647\n",
            "epoch 24 batch id 335 loss 0.032769933342933655 train acc 0.9713152985074627\n",
            "epoch 24 batch id 336 loss 0.10819068551063538 train acc 0.9713541666666666\n",
            "epoch 24 batch id 337 loss 0.022261984646320343 train acc 0.9714391691394659\n",
            "epoch 24 batch id 338 loss 0.1280355006456375 train acc 0.9713849852071006\n",
            "epoch 24 batch id 339 loss 0.0797424241900444 train acc 0.9713772123893806\n",
            "epoch 24 batch id 340 loss 0.2858240306377411 train acc 0.9712316176470588\n",
            "epoch 24 batch id 341 loss 0.1047576367855072 train acc 0.971224340175953\n",
            "epoch 24 batch id 342 loss 0.19041301310062408 train acc 0.9712171052631579\n",
            "epoch 24 batch id 343 loss 0.02162082865834236 train acc 0.9713010204081632\n",
            "epoch 24 batch id 344 loss 0.11137737333774567 train acc 0.9713390261627907\n",
            "epoch 24 batch id 345 loss 0.10365334153175354 train acc 0.9713315217391304\n",
            "epoch 24 batch id 346 loss 0.03411973640322685 train acc 0.9714143786127167\n",
            "epoch 24 batch id 347 loss 0.01609557867050171 train acc 0.9714967579250721\n",
            "epoch 24 batch id 348 loss 0.04004611819982529 train acc 0.9715337643678161\n",
            "epoch 24 batch id 349 loss 0.3150469660758972 train acc 0.9713467048710601\n",
            "epoch 24 batch id 350 loss 0.021433362737298012 train acc 0.9714285714285714\n",
            "epoch 24 batch id 351 loss 0.0876808613538742 train acc 0.9713764245014245\n",
            "epoch 24 batch id 352 loss 0.2045261412858963 train acc 0.9713245738636364\n",
            "epoch 24 batch id 353 loss 0.04047951102256775 train acc 0.9713615439093485\n",
            "epoch 24 batch id 354 loss 0.03687193617224693 train acc 0.9714424435028248\n",
            "epoch 24 batch id 355 loss 0.05208530277013779 train acc 0.9714788732394366\n",
            "epoch 24 batch id 356 loss 0.11381930857896805 train acc 0.9714712078651685\n",
            "epoch 24 batch id 357 loss 0.06927376985549927 train acc 0.9714635854341737\n",
            "epoch 24 batch id 358 loss 0.055659882724285126 train acc 0.9714996508379888\n",
            "epoch 24 batch id 359 loss 0.09177771210670471 train acc 0.9714049442896936\n",
            "epoch 24 batch id 360 loss 0.04737448692321777 train acc 0.9714409722222223\n",
            "epoch 24 batch id 361 loss 0.0862853080034256 train acc 0.9714768005540166\n",
            "epoch 24 batch id 362 loss 0.014658377505838871 train acc 0.9715555939226519\n",
            "epoch 24 batch id 363 loss 0.1752050518989563 train acc 0.9714617768595041\n",
            "epoch 24 batch id 364 loss 0.054639920592308044 train acc 0.9714972527472527\n",
            "epoch 24 batch id 365 loss 0.24926920235157013 train acc 0.9714897260273972\n",
            "epoch 24 batch id 366 loss 0.08457992225885391 train acc 0.9715249316939891\n",
            "epoch 24 batch id 367 loss 0.1178538128733635 train acc 0.9715599455040872\n",
            "epoch 24 batch id 368 loss 0.02006700448691845 train acc 0.9716372282608695\n",
            "epoch 24 batch id 369 loss 0.092495858669281 train acc 0.971629403794038\n",
            "epoch 24 batch id 370 loss 0.0280014518648386 train acc 0.971706081081081\n",
            "epoch 24 batch id 371 loss 0.06871084868907928 train acc 0.9716981132075472\n",
            "epoch 24 batch id 372 loss 0.0922473818063736 train acc 0.971690188172043\n",
            "epoch 24 batch id 373 loss 0.034500107169151306 train acc 0.9717660857908847\n",
            "epoch 24 batch id 374 loss 0.04386270046234131 train acc 0.9717997994652406\n",
            "epoch 24 batch id 375 loss 0.018472399562597275 train acc 0.971875\n",
            "epoch 24 batch id 376 loss 0.08388405293226242 train acc 0.971908244680851\n",
            "epoch 24 batch id 377 loss 0.03372194617986679 train acc 0.9719413129973474\n",
            "epoch 24 batch id 378 loss 0.062060412019491196 train acc 0.9719328703703703\n",
            "epoch 24 batch id 379 loss 0.048978690057992935 train acc 0.9720069261213721\n",
            "epoch 24 batch id 380 loss 0.09499142318964005 train acc 0.9719983552631579\n",
            "epoch 24 batch id 381 loss 0.03162249177694321 train acc 0.9720718503937008\n",
            "epoch 24 batch id 382 loss 0.08872261643409729 train acc 0.972104057591623\n",
            "epoch 24 batch id 383 loss 0.17474623024463654 train acc 0.9721360966057441\n",
            "epoch 24 batch id 384 loss 0.05011336877942085 train acc 0.9721272786458334\n",
            "epoch 24 batch id 385 loss 0.12812286615371704 train acc 0.9720779220779221\n",
            "epoch 24 batch id 386 loss 0.05611572414636612 train acc 0.9721097797927462\n",
            "epoch 24 batch id 387 loss 0.07992145419120789 train acc 0.9721010981912145\n",
            "epoch 24 batch id 388 loss 0.07630626857280731 train acc 0.9720521907216495\n",
            "epoch 24 batch id 389 loss 0.05108488351106644 train acc 0.9720838688946015\n",
            "epoch 24 batch id 390 loss 0.11210398375988007 train acc 0.9720352564102565\n",
            "epoch 24 batch id 391 loss 0.013056062161922455 train acc 0.9721067774936062\n",
            "epoch 24 batch id 392 loss 0.09864429384469986 train acc 0.9721380739795918\n",
            "epoch 24 batch id 393 loss 0.05776229500770569 train acc 0.9721294529262087\n",
            "epoch 24 batch id 394 loss 0.11241596937179565 train acc 0.9720812182741116\n",
            "epoch 24 batch id 395 loss 0.029198383912444115 train acc 0.9721123417721519\n",
            "epoch 24 batch id 396 loss 0.06840639561414719 train acc 0.9721433080808081\n",
            "epoch 24 batch id 397 loss 0.056807197630405426 train acc 0.9721741183879093\n",
            "epoch 24 batch id 398 loss 0.008588734082877636 train acc 0.9722440326633166\n",
            "epoch 24 batch id 399 loss 0.16196280717849731 train acc 0.9721961152882206\n",
            "epoch 24 batch id 400 loss 0.06559377163648605 train acc 0.9722265625\n",
            "epoch 24 batch id 401 loss 0.1878456324338913 train acc 0.972178927680798\n",
            "epoch 24 batch id 402 loss 0.09517377614974976 train acc 0.9722092661691543\n",
            "epoch 24 batch id 403 loss 0.14176572859287262 train acc 0.9721619106699751\n",
            "epoch 24 batch id 404 loss 0.18291440606117249 train acc 0.9721147896039604\n",
            "epoch 24 batch id 405 loss 0.20253890752792358 train acc 0.9719907407407408\n",
            "epoch 24 batch id 406 loss 0.2435988336801529 train acc 0.9719442733990148\n",
            "epoch 24 batch id 407 loss 0.08979952335357666 train acc 0.9718980343980343\n",
            "epoch 24 batch id 408 loss 0.21368487179279327 train acc 0.9718137254901961\n",
            "epoch 24 batch id 409 loss 0.08086373656988144 train acc 0.9717680317848411\n",
            "epoch 24 batch id 410 loss 0.021204618737101555 train acc 0.9718368902439024\n",
            "epoch 24 batch id 411 loss 0.10484641045331955 train acc 0.9718673965936739\n",
            "epoch 24 batch id 412 loss 0.08572888374328613 train acc 0.9718598300970874\n",
            "epoch 24 batch id 413 loss 0.050082650035619736 train acc 0.9718901331719129\n",
            "epoch 24 batch id 414 loss 0.19880276918411255 train acc 0.9718070652173914\n",
            "epoch 24 batch id 415 loss 0.18081462383270264 train acc 0.9716867469879518\n",
            "epoch 24 batch id 416 loss 0.0895640030503273 train acc 0.9716421274038461\n",
            "epoch 24 batch id 417 loss 0.13621298968791962 train acc 0.9716351918465228\n",
            "epoch 24 batch id 418 loss 0.08571973443031311 train acc 0.9716282894736842\n",
            "epoch 24 batch id 419 loss 0.15382499992847443 train acc 0.9716214200477327\n",
            "epoch 24 batch id 420 loss 0.04744259640574455 train acc 0.9716517857142857\n",
            "epoch 24 batch id 421 loss 0.17027953267097473 train acc 0.9716448931116389\n",
            "epoch 24 batch id 422 loss 0.09304018318653107 train acc 0.9716380331753555\n",
            "epoch 24 batch id 423 loss 0.08911731094121933 train acc 0.9716312056737588\n",
            "epoch 24 batch id 424 loss 0.08818138390779495 train acc 0.9715875589622641\n",
            "epoch 24 batch id 425 loss 0.31222328543663025 train acc 0.9714338235294118\n",
            "epoch 24 batch id 426 loss 0.048225291073322296 train acc 0.9714642018779343\n",
            "epoch 24 batch id 427 loss 0.10701755434274673 train acc 0.9714578454332553\n",
            "epoch 24 batch id 428 loss 0.28384092450141907 train acc 0.9713419976635514\n",
            "epoch 24 batch id 429 loss 0.08103879541158676 train acc 0.9713723776223776\n",
            "epoch 24 batch id 430 loss 0.08250662684440613 train acc 0.9713662790697675\n",
            "epoch 24 batch id 431 loss 0.03716389089822769 train acc 0.9713964617169374\n",
            "epoch 24 batch id 432 loss 0.06328827887773514 train acc 0.9713903356481481\n",
            "epoch 24 batch id 433 loss 0.11852462589740753 train acc 0.9714203233256351\n",
            "epoch 24 batch id 434 loss 0.04385457560420036 train acc 0.9714861751152074\n",
            "epoch 24 batch id 435 loss 0.2093178629875183 train acc 0.9715158045977011\n",
            "epoch 24 batch id 436 loss 0.032406941056251526 train acc 0.9715811353211009\n",
            "epoch 24 batch id 437 loss 0.05021822452545166 train acc 0.9716104118993135\n",
            "epoch 24 batch id 438 loss 0.10452159494161606 train acc 0.9716395547945206\n",
            "epoch 24 batch id 439 loss 0.06627606600522995 train acc 0.971632972665148\n",
            "epoch 24 batch id 440 loss 0.08888659626245499 train acc 0.9716619318181818\n",
            "epoch 24 batch id 441 loss 0.00976236816495657 train acc 0.9717261904761905\n",
            "epoch 24 batch id 442 loss 0.03035375475883484 train acc 0.9717548076923077\n",
            "epoch 24 batch id 443 loss 0.06648318469524384 train acc 0.9717480248306998\n",
            "epoch 24 batch id 444 loss 0.055642686784267426 train acc 0.9717412725225225\n",
            "epoch 24 batch id 445 loss 0.06623785942792892 train acc 0.9717696629213484\n",
            "epoch 24 batch id 446 loss 0.13432654738426208 train acc 0.9717979260089686\n",
            "epoch 24 batch id 447 loss 0.013457993045449257 train acc 0.9718610178970917\n",
            "epoch 24 batch id 448 loss 0.08390814065933228 train acc 0.9718889508928571\n",
            "epoch 24 batch id 449 loss 0.1280122846364975 train acc 0.971777561247216\n",
            "epoch 24 batch id 450 loss 0.09584009647369385 train acc 0.9717708333333334\n",
            "epoch 24 batch id 451 loss 0.04854406416416168 train acc 0.9718334257206208\n",
            "epoch 24 batch id 452 loss 0.08496622741222382 train acc 0.9718266039823009\n",
            "epoch 24 batch id 453 loss 0.02117060497403145 train acc 0.9718887969094923\n",
            "epoch 24 batch id 454 loss 0.047929614782333374 train acc 0.9718818832599119\n",
            "epoch 24 batch id 455 loss 0.139950692653656 train acc 0.9718063186813187\n",
            "epoch 24 batch id 456 loss 0.04871256276965141 train acc 0.9718338815789473\n",
            "epoch 24 batch id 457 loss 0.01894073747098446 train acc 0.9718955142231948\n",
            "epoch 24 batch id 458 loss 0.0919707715511322 train acc 0.9718886462882096\n",
            "epoch 24 batch id 459 loss 0.06632488965988159 train acc 0.971881808278867\n",
            "epoch 24 batch id 460 loss 0.11722948402166367 train acc 0.9718410326086957\n",
            "epoch 24 batch id 461 loss 0.05246355012059212 train acc 0.9718682212581344\n",
            "epoch 24 batch id 462 loss 0.1077389270067215 train acc 0.9718614718614719\n",
            "epoch 24 batch id 463 loss 0.09385600686073303 train acc 0.9718210043196545\n",
            "epoch 24 batch id 464 loss 0.06138615682721138 train acc 0.9718143857758621\n",
            "epoch 24 batch id 465 loss 0.18552690744400024 train acc 0.9717069892473118\n",
            "epoch 24 batch id 466 loss 0.06421518325805664 train acc 0.9717341738197425\n",
            "epoch 24 batch id 467 loss 0.04667162522673607 train acc 0.9717277837259101\n",
            "epoch 24 batch id 468 loss 0.042891841381788254 train acc 0.9717548076923077\n",
            "epoch 24 batch id 469 loss 0.0947580561041832 train acc 0.9717484008528785\n",
            "epoch 24 batch id 470 loss 0.08809590339660645 train acc 0.9717752659574468\n",
            "epoch 24 batch id 471 loss 0.10741164535284042 train acc 0.9717024946921444\n",
            "epoch 24 batch id 472 loss 0.08030281960964203 train acc 0.9716962394067796\n",
            "epoch 24 batch id 473 loss 0.13728132843971252 train acc 0.9716900105708245\n",
            "epoch 24 batch id 474 loss 0.041541993618011475 train acc 0.9717167721518988\n",
            "epoch 24 batch id 475 loss 0.28804653882980347 train acc 0.9715789473684211\n",
            "epoch 24 batch id 476 loss 0.2340949922800064 train acc 0.9715073529411765\n",
            "epoch 24 batch id 477 loss 0.05030537024140358 train acc 0.9715343291404612\n",
            "epoch 24 batch id 478 loss 0.0774083137512207 train acc 0.9715611924686193\n",
            "epoch 24 batch id 479 loss 0.24255086481571198 train acc 0.9714900835073069\n",
            "epoch 24 batch id 480 loss 0.07090878486633301 train acc 0.971484375\n",
            "epoch 24 batch id 481 loss 0.09344599395990372 train acc 0.9714137214137214\n",
            "epoch 24 batch id 482 loss 0.0582268126308918 train acc 0.9714081950207469\n",
            "epoch 24 batch id 483 loss 0.11948347091674805 train acc 0.9714026915113871\n",
            "epoch 24 batch id 484 loss 0.017272748053073883 train acc 0.9714617768595041\n",
            "epoch 24 batch id 485 loss 0.02358807623386383 train acc 0.971520618556701\n",
            "epoch 24 batch id 486 loss 0.08174868673086166 train acc 0.9715149176954733\n",
            "epoch 24 batch id 487 loss 0.14399653673171997 train acc 0.9715092402464066\n",
            "epoch 24 batch id 488 loss 0.021435264497995377 train acc 0.9715676229508197\n",
            "epoch 24 batch id 489 loss 0.051200319081544876 train acc 0.9715618609406953\n",
            "epoch 24 batch id 490 loss 0.23574775457382202 train acc 0.9715242346938775\n",
            "epoch 24 batch id 491 loss 0.07803762704133987 train acc 0.971518584521385\n",
            "epoch 24 batch id 492 loss 0.052035633474588394 train acc 0.9715447154471545\n",
            "epoch 24 batch id 493 loss 0.14147886633872986 train acc 0.9715073529411765\n",
            "epoch 24 batch id 494 loss 0.22083093225955963 train acc 0.9714701417004049\n",
            "epoch 24 batch id 495 loss 0.17262575030326843 train acc 0.9714646464646465\n",
            "epoch 24 batch id 496 loss 0.12191262096166611 train acc 0.9714276713709677\n",
            "epoch 24 batch id 497 loss 0.03993947058916092 train acc 0.9714537223340041\n",
            "epoch 24 batch id 498 loss 0.10769101232290268 train acc 0.9714482931726908\n",
            "epoch 24 batch id 499 loss 0.05095302686095238 train acc 0.9715055110220441\n",
            "epoch 24 batch id 500 loss 0.06931228190660477 train acc 0.9715\n",
            "epoch 24 batch id 501 loss 0.06881341338157654 train acc 0.9715256986027944\n",
            "epoch 24 batch id 502 loss 0.0350484699010849 train acc 0.9715824203187251\n",
            "epoch 24 batch id 503 loss 0.03738071024417877 train acc 0.971638916500994\n",
            "epoch 24 batch id 504 loss 0.07911542803049088 train acc 0.9716641865079365\n",
            "epoch 24 batch id 505 loss 0.011564189568161964 train acc 0.971720297029703\n",
            "epoch 24 batch id 506 loss 0.017727239057421684 train acc 0.971776185770751\n",
            "epoch 24 batch id 507 loss 0.05741051957011223 train acc 0.9717702169625246\n",
            "epoch 24 batch id 508 loss 0.0388929508626461 train acc 0.971795029527559\n",
            "epoch 24 batch id 509 loss 0.043022457510232925 train acc 0.9718197445972495\n",
            "epoch 24 batch id 510 loss 0.018177034333348274 train acc 0.971875\n",
            "epoch 24 batch id 511 loss 0.22917473316192627 train acc 0.9718679138321996\n",
            "epoch 24 train acc 0.9718679138321996\n",
            "epoch 24 test acc 0.4100748697916667\n",
            "epoch 25 batch id 1 loss 0.05386697128415108 train acc 0.984375\n",
            "epoch 25 batch id 2 loss 0.0213189497590065 train acc 0.9921875\n",
            "epoch 25 batch id 3 loss 0.028400655835866928 train acc 0.9895833333333334\n",
            "epoch 25 batch id 4 loss 0.11946345120668411 train acc 0.9765625\n",
            "epoch 25 batch id 5 loss 0.11855845153331757 train acc 0.971875\n",
            "epoch 25 batch id 6 loss 0.08519746363162994 train acc 0.9713541666666666\n",
            "epoch 25 batch id 7 loss 0.24763493239879608 train acc 0.96875\n",
            "epoch 25 batch id 8 loss 0.02257606014609337 train acc 0.97265625\n",
            "epoch 25 batch id 9 loss 0.034791357815265656 train acc 0.9739583333333334\n",
            "epoch 25 batch id 10 loss 0.0420880988240242 train acc 0.975\n",
            "epoch 25 batch id 11 loss 0.1864650398492813 train acc 0.9744318181818182\n",
            "epoch 25 batch id 12 loss 0.09782856702804565 train acc 0.9739583333333334\n",
            "epoch 25 batch id 13 loss 0.138737291097641 train acc 0.9735576923076923\n",
            "epoch 25 batch id 14 loss 0.07117023319005966 train acc 0.9743303571428571\n",
            "epoch 25 batch id 15 loss 0.05386143550276756 train acc 0.9739583333333334\n",
            "epoch 25 batch id 16 loss 0.1066216304898262 train acc 0.974609375\n",
            "epoch 25 batch id 17 loss 0.06701897829771042 train acc 0.9751838235294118\n",
            "epoch 25 batch id 18 loss 0.10652169585227966 train acc 0.9748263888888888\n",
            "epoch 25 batch id 19 loss 0.21498019993305206 train acc 0.9736842105263158\n",
            "epoch 25 batch id 20 loss 0.08965423703193665 train acc 0.9734375\n",
            "epoch 25 batch id 21 loss 0.022711578756570816 train acc 0.9747023809523809\n",
            "epoch 25 batch id 22 loss 0.02012239582836628 train acc 0.9758522727272727\n",
            "epoch 25 batch id 23 loss 0.18311071395874023 train acc 0.9748641304347826\n",
            "epoch 25 batch id 24 loss 0.07351841032505035 train acc 0.9752604166666666\n",
            "epoch 25 batch id 25 loss 0.20486654341220856 train acc 0.974375\n",
            "epoch 25 batch id 26 loss 0.030534859746694565 train acc 0.9747596153846154\n",
            "epoch 25 batch id 27 loss 0.05241917073726654 train acc 0.9751157407407407\n",
            "epoch 25 batch id 28 loss 0.09714312851428986 train acc 0.9748883928571429\n",
            "epoch 25 batch id 29 loss 0.11193685233592987 train acc 0.974676724137931\n",
            "epoch 25 batch id 30 loss 0.042768824845552444 train acc 0.975\n",
            "epoch 25 batch id 31 loss 0.11897175014019012 train acc 0.9747983870967742\n",
            "epoch 25 batch id 32 loss 0.35341212153434753 train acc 0.97314453125\n",
            "epoch 25 batch id 33 loss 0.07320696115493774 train acc 0.9734848484848485\n",
            "epoch 25 batch id 34 loss 0.11802361160516739 train acc 0.9728860294117647\n",
            "epoch 25 batch id 35 loss 0.06522969156503677 train acc 0.9727678571428572\n",
            "epoch 25 batch id 36 loss 0.1639488786458969 train acc 0.9713541666666666\n",
            "epoch 25 batch id 37 loss 0.19592133164405823 train acc 0.9708614864864865\n",
            "epoch 25 batch id 38 loss 0.048470232635736465 train acc 0.9712171052631579\n",
            "epoch 25 batch id 39 loss 0.023157596588134766 train acc 0.9715544871794872\n",
            "epoch 25 batch id 40 loss 0.10660089552402496 train acc 0.97109375\n",
            "epoch 25 batch id 41 loss 0.035381805151700974 train acc 0.9714176829268293\n",
            "epoch 25 batch id 42 loss 0.02645207569003105 train acc 0.9717261904761905\n",
            "epoch 25 batch id 43 loss 0.06089581176638603 train acc 0.9720203488372093\n",
            "epoch 25 batch id 44 loss 0.012937651015818119 train acc 0.97265625\n",
            "epoch 25 batch id 45 loss 0.21187005937099457 train acc 0.9722222222222222\n",
            "epoch 25 batch id 46 loss 0.05742373690009117 train acc 0.9728260869565217\n",
            "epoch 25 batch id 47 loss 0.07349181920289993 train acc 0.9730718085106383\n",
            "epoch 25 batch id 48 loss 0.03793841227889061 train acc 0.9736328125\n",
            "epoch 25 batch id 49 loss 0.07488857209682465 train acc 0.9732142857142857\n",
            "epoch 25 batch id 50 loss 0.15245755016803741 train acc 0.973125\n",
            "epoch 25 batch id 51 loss 0.11409489810466766 train acc 0.9727328431372549\n",
            "epoch 25 batch id 52 loss 0.12521754205226898 train acc 0.97265625\n",
            "epoch 25 batch id 53 loss 0.06875018775463104 train acc 0.972877358490566\n",
            "epoch 25 batch id 54 loss 0.010127518326044083 train acc 0.9733796296296297\n",
            "epoch 25 batch id 55 loss 0.02514883689582348 train acc 0.9738636363636364\n",
            "epoch 25 batch id 56 loss 0.11047113686800003 train acc 0.9740513392857143\n",
            "epoch 25 batch id 57 loss 0.020651504397392273 train acc 0.9745065789473685\n",
            "epoch 25 batch id 58 loss 0.18268494307994843 train acc 0.9744073275862069\n",
            "epoch 25 batch id 59 loss 0.05347118154168129 train acc 0.9743114406779662\n",
            "epoch 25 batch id 60 loss 0.15160280466079712 train acc 0.9739583333333334\n",
            "epoch 25 batch id 61 loss 0.054216399788856506 train acc 0.9741290983606558\n",
            "epoch 25 batch id 62 loss 0.04211963713169098 train acc 0.9745463709677419\n",
            "epoch 25 batch id 63 loss 0.06898751109838486 train acc 0.9747023809523809\n",
            "epoch 25 batch id 64 loss 0.06994268298149109 train acc 0.974853515625\n",
            "epoch 25 batch id 65 loss 0.03594216704368591 train acc 0.9752403846153846\n",
            "epoch 25 batch id 66 loss 0.03177743777632713 train acc 0.9753787878787878\n",
            "epoch 25 batch id 67 loss 0.09489219635725021 train acc 0.9750466417910447\n",
            "epoch 25 batch id 68 loss 0.4147370755672455 train acc 0.9738051470588235\n",
            "epoch 25 batch id 69 loss 0.0693313255906105 train acc 0.9739583333333334\n",
            "epoch 25 batch id 70 loss 0.03488045558333397 train acc 0.9743303571428571\n",
            "epoch 25 batch id 71 loss 0.03297853469848633 train acc 0.9746919014084507\n",
            "epoch 25 batch id 72 loss 0.07702784985303879 train acc 0.9748263888888888\n",
            "epoch 25 batch id 73 loss 0.012447109445929527 train acc 0.9751712328767124\n",
            "epoch 25 batch id 74 loss 0.24898314476013184 train acc 0.9750844594594594\n",
            "epoch 25 batch id 75 loss 0.12052147835493088 train acc 0.9752083333333333\n",
            "epoch 25 batch id 76 loss 0.2278674691915512 train acc 0.975328947368421\n",
            "epoch 25 batch id 77 loss 0.0191474761813879 train acc 0.9756493506493507\n",
            "epoch 25 batch id 78 loss 0.12102652341127396 train acc 0.9753605769230769\n",
            "epoch 25 batch id 79 loss 0.14631378650665283 train acc 0.9752768987341772\n",
            "epoch 25 batch id 80 loss 0.15760096907615662 train acc 0.9751953125\n",
            "epoch 25 batch id 81 loss 0.04539220780134201 train acc 0.9753086419753086\n",
            "epoch 25 batch id 82 loss 0.1108962744474411 train acc 0.9752286585365854\n",
            "epoch 25 batch id 83 loss 0.08034711331129074 train acc 0.9747740963855421\n",
            "epoch 25 batch id 84 loss 0.22478584945201874 train acc 0.9745163690476191\n",
            "epoch 25 batch id 85 loss 0.19998207688331604 train acc 0.9742647058823529\n",
            "epoch 25 batch id 86 loss 0.11969002336263657 train acc 0.9743822674418605\n",
            "epoch 25 batch id 87 loss 0.18996459245681763 train acc 0.9735991379310345\n",
            "epoch 25 batch id 88 loss 0.12962360680103302 train acc 0.9735440340909091\n",
            "epoch 25 batch id 89 loss 0.09317342191934586 train acc 0.9734901685393258\n",
            "epoch 25 batch id 90 loss 0.042225051671266556 train acc 0.9736111111111111\n",
            "epoch 25 batch id 91 loss 0.04087525233626366 train acc 0.9737293956043956\n",
            "epoch 25 batch id 92 loss 0.1764371246099472 train acc 0.9735054347826086\n",
            "epoch 25 batch id 93 loss 0.08682698011398315 train acc 0.9734543010752689\n",
            "epoch 25 batch id 94 loss 0.35445383191108704 train acc 0.9732380319148937\n",
            "epoch 25 batch id 95 loss 0.17094524204730988 train acc 0.9731907894736842\n",
            "epoch 25 batch id 96 loss 0.08413508534431458 train acc 0.97314453125\n",
            "epoch 25 batch id 97 loss 0.021040575578808784 train acc 0.9734213917525774\n",
            "epoch 25 batch id 98 loss 0.1518193483352661 train acc 0.9733737244897959\n",
            "epoch 25 batch id 99 loss 0.04482436925172806 train acc 0.9734848484848485\n",
            "epoch 25 batch id 100 loss 0.060008082538843155 train acc 0.97359375\n",
            "epoch 25 batch id 101 loss 0.08334231376647949 train acc 0.973700495049505\n",
            "epoch 25 batch id 102 loss 0.061597030609846115 train acc 0.9738051470588235\n",
            "epoch 25 batch id 103 loss 0.10688546299934387 train acc 0.9736043689320388\n",
            "epoch 25 batch id 104 loss 0.1869550347328186 train acc 0.9734074519230769\n",
            "epoch 25 batch id 105 loss 0.2995866537094116 train acc 0.9729166666666667\n",
            "epoch 25 batch id 106 loss 0.22666627168655396 train acc 0.9727299528301887\n",
            "epoch 25 batch id 107 loss 0.046065665781497955 train acc 0.9728387850467289\n",
            "epoch 25 batch id 108 loss 0.1524791419506073 train acc 0.9723668981481481\n",
            "epoch 25 batch id 109 loss 0.04275763779878616 train acc 0.9724770642201835\n",
            "epoch 25 batch id 110 loss 0.09901276230812073 train acc 0.9725852272727272\n",
            "epoch 25 batch id 111 loss 0.08179443329572678 train acc 0.9726914414414415\n",
            "epoch 25 batch id 112 loss 0.316150426864624 train acc 0.9723772321428571\n",
            "epoch 25 batch id 113 loss 0.19156600534915924 train acc 0.9723451327433629\n",
            "epoch 25 batch id 114 loss 0.12971949577331543 train acc 0.9721765350877193\n",
            "epoch 25 batch id 115 loss 0.08351308852434158 train acc 0.9721467391304348\n",
            "epoch 25 batch id 116 loss 0.12675543129444122 train acc 0.9718480603448276\n",
            "epoch 25 batch id 117 loss 0.10232275724411011 train acc 0.9718215811965812\n",
            "epoch 25 batch id 118 loss 0.04490014538168907 train acc 0.971927966101695\n",
            "epoch 25 batch id 119 loss 0.02393212728202343 train acc 0.9721638655462185\n",
            "epoch 25 batch id 120 loss 0.03924309089779854 train acc 0.972265625\n",
            "epoch 25 batch id 121 loss 0.10321329534053802 train acc 0.9722365702479339\n",
            "epoch 25 batch id 122 loss 0.09381698817014694 train acc 0.9722079918032787\n",
            "epoch 25 batch id 123 loss 0.07282242923974991 train acc 0.9721798780487805\n",
            "epoch 25 batch id 124 loss 0.09219744801521301 train acc 0.9721522177419355\n",
            "epoch 25 batch id 125 loss 0.1318063884973526 train acc 0.972125\n",
            "epoch 25 batch id 126 loss 0.11559109389781952 train acc 0.9720982142857143\n",
            "epoch 25 batch id 127 loss 0.12329478561878204 train acc 0.9720718503937008\n",
            "epoch 25 batch id 128 loss 0.04643864557147026 train acc 0.97216796875\n",
            "epoch 25 batch id 129 loss 0.046739645302295685 train acc 0.9722625968992248\n",
            "epoch 25 batch id 130 loss 0.06918129324913025 train acc 0.9723557692307693\n",
            "epoch 25 batch id 131 loss 0.0662308931350708 train acc 0.9724475190839694\n",
            "epoch 25 batch id 132 loss 0.07567986845970154 train acc 0.9725378787878788\n",
            "epoch 25 batch id 133 loss 0.05242355912923813 train acc 0.9726268796992481\n",
            "epoch 25 batch id 134 loss 0.12868060171604156 train acc 0.972597947761194\n",
            "epoch 25 batch id 135 loss 0.06000630185008049 train acc 0.9726851851851852\n",
            "epoch 25 batch id 136 loss 0.015477744862437248 train acc 0.9728860294117647\n",
            "epoch 25 batch id 137 loss 0.10706087946891785 train acc 0.9728558394160584\n",
            "epoch 25 batch id 138 loss 0.05760175362229347 train acc 0.9728260869565217\n",
            "epoch 25 batch id 139 loss 0.17136630415916443 train acc 0.9725719424460432\n",
            "epoch 25 batch id 140 loss 0.11061457544565201 train acc 0.97265625\n",
            "epoch 25 batch id 141 loss 0.22770605981349945 train acc 0.9722960992907801\n",
            "epoch 25 batch id 142 loss 0.05998745188117027 train acc 0.972381161971831\n",
            "epoch 25 batch id 143 loss 0.05543183535337448 train acc 0.972465034965035\n",
            "epoch 25 batch id 144 loss 0.10756868869066238 train acc 0.9723307291666666\n",
            "epoch 25 batch id 145 loss 0.14614593982696533 train acc 0.9723060344827587\n",
            "epoch 25 batch id 146 loss 0.08811032027006149 train acc 0.9722816780821918\n",
            "epoch 25 batch id 147 loss 0.06507433950901031 train acc 0.9723639455782312\n",
            "epoch 25 batch id 148 loss 0.1235114261507988 train acc 0.972339527027027\n",
            "epoch 25 batch id 149 loss 0.062470920383930206 train acc 0.9723154362416108\n",
            "epoch 25 batch id 150 loss 0.06831182539463043 train acc 0.9723958333333333\n",
            "epoch 25 batch id 151 loss 0.02430851384997368 train acc 0.9724751655629139\n",
            "epoch 25 batch id 152 loss 0.05010313168168068 train acc 0.9725534539473685\n",
            "epoch 25 batch id 153 loss 0.042628608644008636 train acc 0.9726307189542484\n",
            "epoch 25 batch id 154 loss 0.10699144750833511 train acc 0.9725040584415584\n",
            "epoch 25 batch id 155 loss 0.15613579750061035 train acc 0.9723790322580645\n",
            "epoch 25 batch id 156 loss 0.13136231899261475 train acc 0.9723557692307693\n",
            "epoch 25 batch id 157 loss 0.11416467279195786 train acc 0.9722332802547771\n",
            "epoch 25 batch id 158 loss 0.11729607731103897 train acc 0.9720134493670886\n",
            "epoch 25 batch id 159 loss 0.018274402245879173 train acc 0.972189465408805\n",
            "epoch 25 batch id 160 loss 0.047164808958768845 train acc 0.972265625\n",
            "epoch 25 batch id 161 loss 0.053005438297986984 train acc 0.9723408385093167\n",
            "epoch 25 batch id 162 loss 0.11812590807676315 train acc 0.9724151234567902\n",
            "epoch 25 batch id 163 loss 0.09823986887931824 train acc 0.9723926380368099\n",
            "epoch 25 batch id 164 loss 0.030557207763195038 train acc 0.9724657012195121\n",
            "epoch 25 batch id 165 loss 0.11041399091482162 train acc 0.9723484848484848\n",
            "epoch 25 batch id 166 loss 0.10196347534656525 train acc 0.9723268072289156\n",
            "epoch 25 batch id 167 loss 0.041952818632125854 train acc 0.9723989520958084\n",
            "epoch 25 batch id 168 loss 0.09975677728652954 train acc 0.9723772321428571\n",
            "epoch 25 batch id 169 loss 0.09367543458938599 train acc 0.9723557692307693\n",
            "epoch 25 batch id 170 loss 0.0962173193693161 train acc 0.9724264705882353\n",
            "epoch 25 batch id 171 loss 0.05120866745710373 train acc 0.9724963450292398\n",
            "epoch 25 batch id 172 loss 0.037388332188129425 train acc 0.97265625\n",
            "epoch 25 batch id 173 loss 0.015801820904016495 train acc 0.9728143063583815\n",
            "epoch 25 batch id 174 loss 0.05082184076309204 train acc 0.9727909482758621\n",
            "epoch 25 batch id 175 loss 0.06997089087963104 train acc 0.9726785714285714\n",
            "epoch 25 batch id 176 loss 0.04187887907028198 train acc 0.9727450284090909\n",
            "epoch 25 batch id 177 loss 0.1090608611702919 train acc 0.9726341807909604\n",
            "epoch 25 batch id 178 loss 0.15845459699630737 train acc 0.972436797752809\n",
            "epoch 25 batch id 179 loss 0.18583068251609802 train acc 0.9723289106145251\n",
            "epoch 25 batch id 180 loss 0.07236048579216003 train acc 0.9723958333333333\n",
            "epoch 25 batch id 181 loss 0.020114896818995476 train acc 0.9725483425414365\n",
            "epoch 25 batch id 182 loss 0.125862255692482 train acc 0.9726133241758241\n",
            "epoch 25 batch id 183 loss 0.08134140819311142 train acc 0.9725922131147541\n",
            "epoch 25 batch id 184 loss 0.035120874643325806 train acc 0.9727411684782609\n",
            "epoch 25 batch id 185 loss 0.02146955020725727 train acc 0.9728885135135135\n",
            "epoch 25 batch id 186 loss 0.04757775366306305 train acc 0.9729502688172043\n",
            "epoch 25 batch id 187 loss 0.06263166666030884 train acc 0.9730113636363636\n",
            "epoch 25 batch id 188 loss 0.07869475334882736 train acc 0.972905585106383\n",
            "epoch 25 batch id 189 loss 0.12023834884166718 train acc 0.972718253968254\n",
            "epoch 25 batch id 190 loss 0.0970240905880928 train acc 0.9726973684210526\n",
            "epoch 25 batch id 191 loss 0.20831766724586487 train acc 0.9725948952879581\n",
            "epoch 25 batch id 192 loss 0.02611462026834488 train acc 0.9727376302083334\n",
            "epoch 25 batch id 193 loss 0.01082435343414545 train acc 0.9728788860103627\n",
            "epoch 25 batch id 194 loss 0.04123751074075699 train acc 0.9730186855670103\n",
            "epoch 25 batch id 195 loss 0.09750954806804657 train acc 0.9729166666666667\n",
            "epoch 25 batch id 196 loss 0.056553855538368225 train acc 0.9729751275510204\n",
            "epoch 25 batch id 197 loss 0.06465780735015869 train acc 0.9730329949238579\n",
            "epoch 25 batch id 198 loss 0.07814812660217285 train acc 0.9730113636363636\n",
            "epoch 25 batch id 199 loss 0.0404985174536705 train acc 0.9730684673366834\n",
            "epoch 25 batch id 200 loss 0.07975691556930542 train acc 0.973046875\n",
            "epoch 25 batch id 201 loss 0.08067069947719574 train acc 0.9731032338308457\n",
            "epoch 25 batch id 202 loss 0.1283545196056366 train acc 0.9730043316831684\n",
            "epoch 25 batch id 203 loss 0.09273453056812286 train acc 0.9729833743842364\n",
            "epoch 25 batch id 204 loss 0.12444444000720978 train acc 0.9729626225490197\n",
            "epoch 25 batch id 205 loss 0.1913171261548996 train acc 0.9728658536585366\n",
            "epoch 25 batch id 206 loss 0.10102836042642593 train acc 0.9728458737864077\n",
            "epoch 25 batch id 207 loss 0.0569830983877182 train acc 0.9729015700483091\n",
            "epoch 25 batch id 208 loss 0.02869025059044361 train acc 0.9730318509615384\n",
            "epoch 25 batch id 209 loss 0.12637591361999512 train acc 0.9729366028708134\n",
            "epoch 25 batch id 210 loss 0.15393027663230896 train acc 0.9729166666666667\n",
            "epoch 25 batch id 211 loss 0.013693109154701233 train acc 0.9730450236966824\n",
            "epoch 25 batch id 212 loss 0.30778586864471436 train acc 0.9730247641509434\n",
            "epoch 25 batch id 213 loss 0.18524055182933807 train acc 0.972931338028169\n",
            "epoch 25 batch id 214 loss 0.09887468069791794 train acc 0.9729117990654206\n",
            "epoch 25 batch id 215 loss 0.09653554111719131 train acc 0.9729651162790698\n",
            "epoch 25 batch id 216 loss 0.022823642939329147 train acc 0.9730902777777778\n",
            "epoch 25 batch id 217 loss 0.07454125583171844 train acc 0.9730702764976958\n",
            "epoch 25 batch id 218 loss 0.010099086910486221 train acc 0.9731938073394495\n",
            "epoch 25 batch id 219 loss 0.13676010072231293 train acc 0.9730308219178082\n",
            "epoch 25 batch id 220 loss 0.11073148995637894 train acc 0.9730113636363636\n",
            "epoch 25 batch id 221 loss 0.1423691064119339 train acc 0.9729920814479638\n",
            "epoch 25 batch id 222 loss 0.22272062301635742 train acc 0.9728322072072072\n",
            "epoch 25 batch id 223 loss 0.045433271676301956 train acc 0.9728139013452914\n",
            "epoch 25 batch id 224 loss 0.2856193780899048 train acc 0.9727260044642857\n",
            "epoch 25 batch id 225 loss 0.1305282562971115 train acc 0.9725694444444445\n",
            "epoch 25 batch id 226 loss 0.11629491299390793 train acc 0.9725525442477876\n",
            "epoch 25 batch id 227 loss 0.06578970700502396 train acc 0.9725357929515418\n",
            "epoch 25 batch id 228 loss 0.0775066465139389 train acc 0.9725191885964912\n",
            "epoch 25 batch id 229 loss 0.011786826886236668 train acc 0.972639192139738\n",
            "epoch 25 batch id 230 loss 0.009145190007984638 train acc 0.972758152173913\n",
            "epoch 25 batch id 231 loss 0.04122592508792877 train acc 0.9728084415584416\n",
            "epoch 25 batch id 232 loss 0.009845013730227947 train acc 0.9729256465517241\n",
            "epoch 25 batch id 233 loss 0.0744977816939354 train acc 0.9729077253218884\n",
            "epoch 25 batch id 234 loss 0.04216586798429489 train acc 0.9730235042735043\n",
            "epoch 25 batch id 235 loss 0.030555054545402527 train acc 0.9730718085106383\n",
            "epoch 25 batch id 236 loss 0.02282913401722908 train acc 0.9731859110169492\n",
            "epoch 25 batch id 237 loss 0.018289778381586075 train acc 0.9732990506329114\n",
            "epoch 25 batch id 238 loss 0.21287307143211365 train acc 0.9732142857142857\n",
            "epoch 25 batch id 239 loss 0.10432446002960205 train acc 0.973130230125523\n",
            "epoch 25 batch id 240 loss 0.07909861207008362 train acc 0.9731770833333333\n",
            "epoch 25 batch id 241 loss 0.10369163006544113 train acc 0.9730938796680498\n",
            "epoch 25 batch id 242 loss 0.08586974442005157 train acc 0.9730759297520661\n",
            "epoch 25 batch id 243 loss 0.07523971050977707 train acc 0.9730581275720165\n",
            "epoch 25 batch id 244 loss 0.03948839753866196 train acc 0.9731045081967213\n",
            "epoch 25 batch id 245 loss 0.05150223895907402 train acc 0.9731505102040816\n",
            "epoch 25 batch id 246 loss 0.015068287029862404 train acc 0.9732596544715447\n",
            "epoch 25 batch id 247 loss 0.09638774394989014 train acc 0.9731781376518218\n",
            "epoch 25 batch id 248 loss 0.025538958609104156 train acc 0.9732862903225806\n",
            "epoch 25 batch id 249 loss 0.2728992700576782 train acc 0.9731425702811245\n",
            "epoch 25 batch id 250 loss 0.16192933917045593 train acc 0.9730625\n",
            "epoch 25 batch id 251 loss 0.23480257391929626 train acc 0.9729830677290837\n",
            "epoch 25 batch id 252 loss 0.029371222481131554 train acc 0.9730282738095238\n",
            "epoch 25 batch id 253 loss 0.07383080571889877 train acc 0.9730731225296443\n",
            "epoch 25 batch id 254 loss 0.019764423370361328 train acc 0.9731791338582677\n",
            "epoch 25 batch id 255 loss 0.08498819172382355 train acc 0.9732230392156863\n",
            "epoch 25 batch id 256 loss 0.12665581703186035 train acc 0.97320556640625\n",
            "epoch 25 batch id 257 loss 0.05168905481696129 train acc 0.9732490272373541\n",
            "epoch 25 batch id 258 loss 0.028804155066609383 train acc 0.9732921511627907\n",
            "epoch 25 batch id 259 loss 0.06580646336078644 train acc 0.9733349420849421\n",
            "epoch 25 batch id 260 loss 0.17335295677185059 train acc 0.9733173076923077\n",
            "epoch 25 batch id 261 loss 0.03990328684449196 train acc 0.9734195402298851\n",
            "epoch 25 batch id 262 loss 0.1554143875837326 train acc 0.9732824427480916\n",
            "epoch 25 batch id 263 loss 0.37010762095451355 train acc 0.9731463878326996\n",
            "epoch 25 batch id 264 loss 0.23471291363239288 train acc 0.9731297348484849\n",
            "epoch 25 batch id 265 loss 0.047323185950517654 train acc 0.9731721698113207\n",
            "epoch 25 batch id 266 loss 0.08363351970911026 train acc 0.9731555451127819\n",
            "epoch 25 batch id 267 loss 0.1008729487657547 train acc 0.9731390449438202\n",
            "epoch 25 batch id 268 loss 0.0696781650185585 train acc 0.9731226679104478\n",
            "epoch 25 batch id 269 loss 0.08195100724697113 train acc 0.9731064126394052\n",
            "epoch 25 batch id 270 loss 0.10387574881315231 train acc 0.9731481481481481\n",
            "epoch 25 batch id 271 loss 0.049885015934705734 train acc 0.9731895756457565\n",
            "epoch 25 batch id 272 loss 0.08367469906806946 train acc 0.9732306985294118\n",
            "epoch 25 batch id 273 loss 0.18574941158294678 train acc 0.9730998168498168\n",
            "epoch 25 batch id 274 loss 0.10211209207773209 train acc 0.9731409671532847\n",
            "epoch 25 batch id 275 loss 0.05998005345463753 train acc 0.973125\n",
            "epoch 25 batch id 276 loss 0.012389568611979485 train acc 0.9732223731884058\n",
            "epoch 25 batch id 277 loss 0.08981112390756607 train acc 0.9732626353790613\n",
            "epoch 25 batch id 278 loss 0.07652781903743744 train acc 0.9733026079136691\n",
            "epoch 25 batch id 279 loss 0.0367044061422348 train acc 0.9733982974910395\n",
            "epoch 25 batch id 280 loss 0.09711796790361404 train acc 0.9734375\n",
            "epoch 25 batch id 281 loss 0.0687931627035141 train acc 0.9734208185053381\n",
            "epoch 25 batch id 282 loss 0.021448710933327675 train acc 0.9734596631205674\n",
            "epoch 25 batch id 283 loss 0.11774443835020065 train acc 0.9734982332155477\n",
            "epoch 25 batch id 284 loss 0.04087536782026291 train acc 0.9735365316901409\n",
            "epoch 25 batch id 285 loss 0.01566278003156185 train acc 0.9736293859649123\n",
            "epoch 25 batch id 286 loss 0.09155399352312088 train acc 0.973666958041958\n",
            "epoch 25 batch id 287 loss 0.010546848177909851 train acc 0.9737587108013938\n",
            "epoch 25 batch id 288 loss 0.03873894363641739 train acc 0.9737413194444444\n",
            "epoch 25 batch id 289 loss 0.09183675050735474 train acc 0.9737781141868512\n",
            "epoch 25 batch id 290 loss 0.12889277935028076 train acc 0.973760775862069\n",
            "epoch 25 batch id 291 loss 0.12003134191036224 train acc 0.9737972508591065\n",
            "epoch 25 batch id 292 loss 0.10230599343776703 train acc 0.9737799657534246\n",
            "epoch 25 batch id 293 loss 0.0948575958609581 train acc 0.9738161262798635\n",
            "epoch 25 batch id 294 loss 0.11532299965620041 train acc 0.9737988945578231\n",
            "epoch 25 batch id 295 loss 0.05903880298137665 train acc 0.9738347457627119\n",
            "epoch 25 batch id 296 loss 0.06208062544465065 train acc 0.9738175675675675\n",
            "epoch 25 batch id 297 loss 0.0946461632847786 train acc 0.9738531144781145\n",
            "epoch 25 batch id 298 loss 0.05518524348735809 train acc 0.973888422818792\n",
            "epoch 25 batch id 299 loss 0.05371353030204773 train acc 0.9739234949832776\n",
            "epoch 25 batch id 300 loss 0.07635090500116348 train acc 0.9738541666666667\n",
            "epoch 25 batch id 301 loss 0.1297382414340973 train acc 0.9737852990033222\n",
            "epoch 25 batch id 302 loss 0.11813224107027054 train acc 0.9738203642384106\n",
            "epoch 25 batch id 303 loss 0.1506085842847824 train acc 0.9737520627062707\n",
            "epoch 25 batch id 304 loss 0.030969223007559776 train acc 0.9738384046052632\n",
            "epoch 25 batch id 305 loss 0.08335189521312714 train acc 0.9738217213114754\n",
            "epoch 25 batch id 306 loss 0.039837971329689026 train acc 0.9739072712418301\n",
            "epoch 25 batch id 307 loss 0.007115283515304327 train acc 0.9739922638436482\n",
            "epoch 25 batch id 308 loss 0.10286498814821243 train acc 0.9739752435064936\n",
            "epoch 25 batch id 309 loss 0.05949719622731209 train acc 0.9740088996763754\n",
            "epoch 25 batch id 310 loss 0.03387349471449852 train acc 0.9740423387096774\n",
            "epoch 25 batch id 311 loss 0.1704365611076355 train acc 0.9739248392282959\n",
            "epoch 25 batch id 312 loss 0.1136263981461525 train acc 0.9739082532051282\n",
            "epoch 25 batch id 313 loss 0.16002315282821655 train acc 0.9738418530351438\n",
            "epoch 25 batch id 314 loss 0.08523304760456085 train acc 0.9738256369426752\n",
            "epoch 25 batch id 315 loss 0.027923407033085823 train acc 0.973859126984127\n",
            "epoch 25 batch id 316 loss 0.17294806241989136 train acc 0.9738429588607594\n",
            "epoch 25 batch id 317 loss 0.014526212587952614 train acc 0.9739254731861199\n",
            "epoch 25 batch id 318 loss 0.05060872435569763 train acc 0.9740074685534591\n",
            "epoch 25 batch id 319 loss 0.033211033791303635 train acc 0.9740889498432602\n",
            "epoch 25 batch id 320 loss 0.026411261409521103 train acc 0.974169921875\n",
            "epoch 25 batch id 321 loss 0.026288211345672607 train acc 0.9742503894080997\n",
            "epoch 25 batch id 322 loss 0.05252755433320999 train acc 0.9742818322981367\n",
            "epoch 25 batch id 323 loss 0.06187480315566063 train acc 0.974313080495356\n",
            "epoch 25 batch id 324 loss 0.029443174600601196 train acc 0.9743923611111112\n",
            "epoch 25 batch id 325 loss 0.14289017021656036 train acc 0.974423076923077\n",
            "epoch 25 batch id 326 loss 0.08164937049150467 train acc 0.9744536042944786\n",
            "epoch 25 batch id 327 loss 0.015622653067111969 train acc 0.9745317278287462\n",
            "epoch 25 batch id 328 loss 0.05594105273485184 train acc 0.9745617378048781\n",
            "epoch 25 batch id 329 loss 0.03662402182817459 train acc 0.9746390577507599\n",
            "epoch 25 batch id 330 loss 0.279972642660141 train acc 0.9744791666666667\n",
            "epoch 25 batch id 331 loss 0.02338816411793232 train acc 0.9745562688821753\n",
            "epoch 25 batch id 332 loss 0.03141342103481293 train acc 0.974632906626506\n",
            "epoch 25 batch id 333 loss 0.046554084867239 train acc 0.9746621621621622\n",
            "epoch 25 batch id 334 loss 0.19006767868995667 train acc 0.9745508982035929\n",
            "epoch 25 batch id 335 loss 0.020357461646199226 train acc 0.9746268656716418\n",
            "epoch 25 batch id 336 loss 0.10563506186008453 train acc 0.9746558779761905\n",
            "epoch 25 batch id 337 loss 0.06805125623941422 train acc 0.974638353115727\n",
            "epoch 25 batch id 338 loss 0.019581018015742302 train acc 0.9747133875739645\n",
            "epoch 25 batch id 339 loss 0.10310279577970505 train acc 0.974695796460177\n",
            "epoch 25 batch id 340 loss 0.012087122537195683 train acc 0.9747702205882353\n",
            "epoch 25 batch id 341 loss 0.12963366508483887 train acc 0.9747525659824047\n",
            "epoch 25 batch id 342 loss 0.16067591309547424 train acc 0.974735014619883\n",
            "epoch 25 batch id 343 loss 0.06279082596302032 train acc 0.9747175655976676\n",
            "epoch 25 batch id 344 loss 0.04408867284655571 train acc 0.9747456395348837\n",
            "epoch 25 batch id 345 loss 0.3246079981327057 train acc 0.9745923913043478\n",
            "epoch 25 batch id 346 loss 0.14610548317432404 train acc 0.9745303468208093\n",
            "epoch 25 batch id 347 loss 0.023725256323814392 train acc 0.9746037463976945\n",
            "epoch 25 batch id 348 loss 0.10910479724407196 train acc 0.9745869252873564\n",
            "epoch 25 batch id 349 loss 0.21209080517292023 train acc 0.974480659025788\n",
            "epoch 25 batch id 350 loss 0.03693012893199921 train acc 0.9745089285714286\n",
            "epoch 25 batch id 351 loss 0.0204024575650692 train acc 0.9745815527065527\n",
            "epoch 25 batch id 352 loss 0.02149464190006256 train acc 0.9746537642045454\n",
            "epoch 25 batch id 353 loss 0.08403385430574417 train acc 0.9746813031161473\n",
            "epoch 25 batch id 354 loss 0.054881203919649124 train acc 0.974708686440678\n",
            "epoch 25 batch id 355 loss 0.08806010335683823 train acc 0.9746919014084507\n",
            "epoch 25 batch id 356 loss 0.03760082274675369 train acc 0.9747191011235955\n",
            "epoch 25 batch id 357 loss 0.031863290816545486 train acc 0.9747899159663865\n",
            "epoch 25 batch id 358 loss 0.04943043738603592 train acc 0.9748166899441341\n",
            "epoch 25 batch id 359 loss 0.02354922518134117 train acc 0.9748868384401114\n",
            "epoch 25 batch id 360 loss 0.13931193947792053 train acc 0.9748697916666667\n",
            "epoch 25 batch id 361 loss 0.10398659855127335 train acc 0.9748528393351801\n",
            "epoch 25 batch id 362 loss 0.1079782247543335 train acc 0.9748359806629834\n",
            "epoch 25 batch id 363 loss 0.019819194450974464 train acc 0.974905303030303\n",
            "epoch 25 batch id 364 loss 0.1416569948196411 train acc 0.9748883928571429\n",
            "epoch 25 batch id 365 loss 0.02788892388343811 train acc 0.9749143835616438\n",
            "epoch 25 batch id 366 loss 0.02708834409713745 train acc 0.9749829234972678\n",
            "epoch 25 batch id 367 loss 0.10962385684251785 train acc 0.975008514986376\n",
            "epoch 25 batch id 368 loss 0.04529034346342087 train acc 0.9750339673913043\n",
            "epoch 25 batch id 369 loss 0.018964078277349472 train acc 0.9751016260162602\n",
            "epoch 25 batch id 370 loss 0.020062055438756943 train acc 0.9751689189189189\n",
            "epoch 25 batch id 371 loss 0.009945955127477646 train acc 0.9752358490566038\n",
            "epoch 25 batch id 372 loss 0.2481672465801239 train acc 0.9751344086021505\n",
            "epoch 25 batch id 373 loss 0.40696144104003906 train acc 0.9750754021447721\n",
            "epoch 25 batch id 374 loss 0.16649772226810455 train acc 0.9750584893048129\n",
            "epoch 25 batch id 375 loss 0.010186515748500824 train acc 0.975125\n",
            "epoch 25 batch id 376 loss 0.03393585607409477 train acc 0.9751911569148937\n",
            "epoch 25 batch id 377 loss 0.07085475325584412 train acc 0.9752155172413793\n",
            "epoch 25 batch id 378 loss 0.02988710068166256 train acc 0.9752397486772487\n",
            "epoch 25 batch id 379 loss 0.17046529054641724 train acc 0.9751401715039578\n",
            "epoch 25 batch id 380 loss 0.1901780068874359 train acc 0.9750411184210527\n",
            "epoch 25 batch id 381 loss 0.10427261888980865 train acc 0.9750246062992126\n",
            "epoch 25 batch id 382 loss 0.03028973750770092 train acc 0.9750490837696335\n",
            "epoch 25 batch id 383 loss 0.17335160076618195 train acc 0.975032637075718\n",
            "epoch 25 batch id 384 loss 0.029810629785060883 train acc 0.9750569661458334\n",
            "epoch 25 batch id 385 loss 0.12835954129695892 train acc 0.975\n",
            "epoch 25 batch id 386 loss 0.016740765422582626 train acc 0.9750647668393783\n",
            "epoch 25 batch id 387 loss 0.039113983511924744 train acc 0.9750888242894057\n",
            "epoch 25 batch id 388 loss 0.09622776508331299 train acc 0.9750724871134021\n",
            "epoch 25 batch id 389 loss 0.07293187081813812 train acc 0.975056233933162\n",
            "epoch 25 batch id 390 loss 0.12593717873096466 train acc 0.975040064102564\n",
            "epoch 25 batch id 391 loss 0.18616020679473877 train acc 0.9749840153452686\n",
            "epoch 25 batch id 392 loss 0.015318065881729126 train acc 0.9750478316326531\n",
            "epoch 25 batch id 393 loss 0.012626086361706257 train acc 0.9751113231552163\n",
            "epoch 25 batch id 394 loss 0.042501918971538544 train acc 0.9751348350253807\n",
            "epoch 25 batch id 395 loss 0.033463746309280396 train acc 0.9751977848101265\n",
            "epoch 25 batch id 396 loss 0.208877831697464 train acc 0.9751420454545454\n",
            "epoch 25 batch id 397 loss 0.04071040451526642 train acc 0.9751653022670025\n",
            "epoch 25 batch id 398 loss 0.17526140809059143 train acc 0.9751491834170855\n",
            "epoch 25 batch id 399 loss 0.030362417921423912 train acc 0.975172305764411\n",
            "epoch 25 batch id 400 loss 0.02151624485850334 train acc 0.9751953125\n",
            "epoch 25 batch id 401 loss 0.041131049394607544 train acc 0.975218204488778\n",
            "epoch 25 batch id 402 loss 0.1855868697166443 train acc 0.9751632462686567\n",
            "epoch 25 batch id 403 loss 0.0407368540763855 train acc 0.9751861042183623\n",
            "epoch 25 batch id 404 loss 0.07389060407876968 train acc 0.975208849009901\n",
            "epoch 25 batch id 405 loss 0.02020973339676857 train acc 0.975270061728395\n",
            "epoch 25 batch id 406 loss 0.03162013739347458 train acc 0.9752924876847291\n",
            "epoch 25 batch id 407 loss 0.10904388129711151 train acc 0.9752764127764127\n",
            "epoch 25 batch id 408 loss 0.08778762817382812 train acc 0.9752604166666666\n",
            "epoch 25 batch id 409 loss 0.09580680727958679 train acc 0.9752062958435208\n",
            "epoch 25 batch id 410 loss 0.0642031580209732 train acc 0.9751905487804878\n",
            "epoch 25 batch id 411 loss 0.0993911400437355 train acc 0.9751368613138686\n",
            "epoch 25 batch id 412 loss 0.11871740967035294 train acc 0.975121359223301\n",
            "epoch 25 batch id 413 loss 0.06089348718523979 train acc 0.9751437651331719\n",
            "epoch 25 batch id 414 loss 0.037544261664152145 train acc 0.9751660628019324\n",
            "epoch 25 batch id 415 loss 0.13841113448143005 train acc 0.9751129518072289\n",
            "epoch 25 batch id 416 loss 0.12688302993774414 train acc 0.9750225360576923\n",
            "epoch 25 batch id 417 loss 0.31676897406578064 train acc 0.9748950839328537\n",
            "epoch 25 batch id 418 loss 0.14331863820552826 train acc 0.9748056220095693\n",
            "epoch 25 batch id 419 loss 0.019389668479561806 train acc 0.9748657517899761\n",
            "epoch 25 batch id 420 loss 0.09099194407463074 train acc 0.9748511904761905\n",
            "epoch 25 batch id 421 loss 0.08143169432878494 train acc 0.9748366983372921\n",
            "epoch 25 batch id 422 loss 0.039181411266326904 train acc 0.974896327014218\n",
            "epoch 25 batch id 423 loss 0.1172616109251976 train acc 0.9749187352245863\n",
            "epoch 25 batch id 424 loss 0.07200825959444046 train acc 0.9749041863207547\n",
            "epoch 25 batch id 425 loss 0.06994885951280594 train acc 0.9749264705882353\n",
            "epoch 25 batch id 426 loss 0.07165882736444473 train acc 0.9749486502347418\n",
            "epoch 25 batch id 427 loss 0.11711761355400085 train acc 0.9749341334894613\n",
            "epoch 25 batch id 428 loss 0.26990675926208496 train acc 0.9747371495327103\n",
            "epoch 25 batch id 429 loss 0.019444288685917854 train acc 0.9747960372960373\n",
            "epoch 25 batch id 430 loss 0.041145917028188705 train acc 0.9748183139534884\n",
            "epoch 25 batch id 431 loss 0.17703133821487427 train acc 0.974695475638051\n",
            "epoch 25 batch id 432 loss 0.19960187375545502 train acc 0.974609375\n",
            "epoch 25 batch id 433 loss 0.020178498700261116 train acc 0.9746680138568129\n",
            "epoch 25 batch id 434 loss 0.05853293091058731 train acc 0.9746903801843319\n",
            "epoch 25 batch id 435 loss 0.13108746707439423 train acc 0.974676724137931\n",
            "epoch 25 batch id 436 loss 0.04763144627213478 train acc 0.9746989678899083\n",
            "epoch 25 batch id 437 loss 0.07106395810842514 train acc 0.9746853546910755\n",
            "epoch 25 batch id 438 loss 0.06298714876174927 train acc 0.9747074771689498\n",
            "epoch 25 batch id 439 loss 0.02151876501739025 train acc 0.9747650911161732\n",
            "epoch 25 batch id 440 loss 0.04759873449802399 train acc 0.9747514204545454\n",
            "epoch 25 batch id 441 loss 0.053025517612695694 train acc 0.9747732426303855\n",
            "epoch 25 batch id 442 loss 0.179397314786911 train acc 0.9747949660633484\n",
            "epoch 25 batch id 443 loss 0.06101889908313751 train acc 0.9747813205417607\n",
            "epoch 25 batch id 444 loss 0.1774575263261795 train acc 0.9747677364864865\n",
            "epoch 25 batch id 445 loss 0.14319004118442535 train acc 0.9747191011235955\n",
            "epoch 25 batch id 446 loss 0.10658778995275497 train acc 0.9746706838565022\n",
            "epoch 25 batch id 447 loss 0.14764881134033203 train acc 0.9746574384787472\n",
            "epoch 25 batch id 448 loss 0.0940639078617096 train acc 0.9746791294642857\n",
            "epoch 25 batch id 449 loss 0.07337766885757446 train acc 0.9747007238307349\n",
            "epoch 25 batch id 450 loss 0.2188345491886139 train acc 0.9746180555555556\n",
            "epoch 25 batch id 451 loss 0.13503514230251312 train acc 0.974605044345898\n",
            "epoch 25 batch id 452 loss 0.05291392654180527 train acc 0.9745920907079646\n",
            "epoch 25 batch id 453 loss 0.1582430899143219 train acc 0.9746136865342163\n",
            "epoch 25 batch id 454 loss 0.16826701164245605 train acc 0.9745663546255506\n",
            "epoch 25 batch id 455 loss 0.17774233222007751 train acc 0.9745535714285715\n",
            "epoch 25 batch id 456 loss 0.17105087637901306 train acc 0.9745065789473685\n",
            "epoch 25 batch id 457 loss 0.009578696452081203 train acc 0.9745623632385121\n",
            "epoch 25 batch id 458 loss 0.21233396232128143 train acc 0.9744814410480349\n",
            "epoch 25 batch id 459 loss 0.11290933191776276 train acc 0.974468954248366\n",
            "epoch 25 batch id 460 loss 0.03446308523416519 train acc 0.9745244565217391\n",
            "epoch 25 batch id 461 loss 0.07840903848409653 train acc 0.9745458242950108\n",
            "epoch 25 batch id 462 loss 0.07703091949224472 train acc 0.9745670995670995\n",
            "epoch 25 batch id 463 loss 0.04232892021536827 train acc 0.974588282937365\n",
            "epoch 25 batch id 464 loss 0.1947828084230423 train acc 0.974542025862069\n",
            "epoch 25 batch id 465 loss 0.046737439930438995 train acc 0.9745631720430108\n",
            "epoch 25 batch id 466 loss 0.12662461400032043 train acc 0.9745171673819742\n",
            "epoch 25 batch id 467 loss 0.06645499169826508 train acc 0.9745382762312634\n",
            "epoch 25 batch id 468 loss 0.018847670406103134 train acc 0.9745926816239316\n",
            "epoch 25 batch id 469 loss 0.08738624304533005 train acc 0.9745802238805971\n",
            "epoch 25 batch id 470 loss 0.041940975934267044 train acc 0.9746343085106383\n",
            "epoch 25 batch id 471 loss 0.014567028731107712 train acc 0.9746881634819533\n",
            "epoch 25 batch id 472 loss 0.09377330541610718 train acc 0.974708686440678\n",
            "epoch 25 batch id 473 loss 0.11092185229063034 train acc 0.974696088794926\n",
            "epoch 25 batch id 474 loss 0.16090171039104462 train acc 0.9746835443037974\n",
            "epoch 25 batch id 475 loss 0.15017259120941162 train acc 0.9746710526315789\n",
            "epoch 25 batch id 476 loss 0.06779418140649796 train acc 0.9746914390756303\n",
            "epoch 25 batch id 477 loss 0.10816563665866852 train acc 0.9747117400419287\n",
            "epoch 25 batch id 478 loss 0.09539614617824554 train acc 0.9746992677824268\n",
            "epoch 25 batch id 479 loss 0.06356215476989746 train acc 0.9746868475991649\n",
            "epoch 25 batch id 480 loss 0.21788389980793 train acc 0.9746419270833333\n",
            "epoch 25 batch id 481 loss 0.02356504276394844 train acc 0.9746946465696466\n",
            "epoch 25 batch id 482 loss 0.04987882822751999 train acc 0.9747147302904564\n",
            "epoch 25 batch id 483 loss 0.05143428221344948 train acc 0.9747347308488613\n",
            "epoch 25 batch id 484 loss 0.12413562834262848 train acc 0.9747223657024794\n",
            "epoch 25 batch id 485 loss 0.08037841320037842 train acc 0.9747422680412371\n",
            "epoch 25 batch id 486 loss 0.13002659380435944 train acc 0.9747299382716049\n",
            "epoch 25 batch id 487 loss 0.12525656819343567 train acc 0.974717659137577\n",
            "epoch 25 batch id 488 loss 0.09317353367805481 train acc 0.9747054303278688\n",
            "epoch 25 batch id 489 loss 0.11053114384412766 train acc 0.9746932515337423\n",
            "epoch 25 batch id 490 loss 0.06528421491384506 train acc 0.9746811224489796\n",
            "epoch 25 batch id 491 loss 0.026288054883480072 train acc 0.9747326883910387\n",
            "epoch 25 batch id 492 loss 0.07937063276767731 train acc 0.9747205284552846\n",
            "epoch 25 batch id 493 loss 0.0698169469833374 train acc 0.9747401115618661\n",
            "epoch 25 batch id 494 loss 0.07727015763521194 train acc 0.9747596153846154\n",
            "epoch 25 batch id 495 loss 0.07567822933197021 train acc 0.9747790404040404\n",
            "epoch 25 batch id 496 loss 0.14593234658241272 train acc 0.9747353830645161\n",
            "epoch 25 batch id 497 loss 0.09225081652402878 train acc 0.9747233400402414\n",
            "epoch 25 batch id 498 loss 0.0317397378385067 train acc 0.9747427208835341\n",
            "epoch 25 batch id 499 loss 0.02018200233578682 train acc 0.9747620240480962\n",
            "epoch 25 batch id 500 loss 0.061468835920095444 train acc 0.97475\n",
            "epoch 25 batch id 501 loss 0.029547642916440964 train acc 0.9748003992015968\n",
            "epoch 25 batch id 502 loss 0.09508608281612396 train acc 0.9747883466135459\n",
            "epoch 25 batch id 503 loss 0.0659424215555191 train acc 0.9748384691848907\n",
            "epoch 25 batch id 504 loss 0.14836148917675018 train acc 0.9748573908730159\n",
            "epoch 25 batch id 505 loss 0.0451459139585495 train acc 0.9748762376237624\n",
            "epoch 25 batch id 506 loss 0.028402242809534073 train acc 0.9749258893280632\n",
            "epoch 25 batch id 507 loss 0.08126538246870041 train acc 0.974944526627219\n",
            "epoch 25 batch id 508 loss 0.043174270540475845 train acc 0.9749938484251969\n",
            "epoch 25 batch id 509 loss 0.017257677391171455 train acc 0.9750429764243614\n",
            "epoch 25 batch id 510 loss 0.09355596452951431 train acc 0.9750306372549019\n",
            "epoch 25 batch id 511 loss 0.040102750062942505 train acc 0.9750484383251017\n",
            "epoch 25 train acc 0.9750484383251017\n",
            "epoch 25 test acc 0.3956705729166667\n",
            "epoch 26 batch id 1 loss 0.0441608801484108 train acc 0.984375\n",
            "epoch 26 batch id 2 loss 0.027417533099651337 train acc 0.9921875\n",
            "epoch 26 batch id 3 loss 0.062489528208971024 train acc 0.9895833333333334\n",
            "epoch 26 batch id 4 loss 0.024136891588568687 train acc 0.9921875\n",
            "epoch 26 batch id 5 loss 0.13966518640518188 train acc 0.984375\n",
            "epoch 26 batch id 6 loss 0.13461865484714508 train acc 0.9791666666666666\n",
            "epoch 26 batch id 7 loss 0.13397514820098877 train acc 0.9754464285714286\n",
            "epoch 26 batch id 8 loss 0.09896551072597504 train acc 0.97265625\n",
            "epoch 26 batch id 9 loss 0.06338159739971161 train acc 0.9739583333333334\n",
            "epoch 26 batch id 10 loss 0.21305087208747864 train acc 0.975\n",
            "epoch 26 batch id 11 loss 0.11855728179216385 train acc 0.9744318181818182\n",
            "epoch 26 batch id 12 loss 0.07251444458961487 train acc 0.9739583333333334\n",
            "epoch 26 batch id 13 loss 0.03523845598101616 train acc 0.9759615384615384\n",
            "epoch 26 batch id 14 loss 0.03437681496143341 train acc 0.9776785714285714\n",
            "epoch 26 batch id 15 loss 0.0423094742000103 train acc 0.978125\n",
            "epoch 26 batch id 16 loss 0.22596696019172668 train acc 0.9755859375\n",
            "epoch 26 batch id 17 loss 0.12620384991168976 train acc 0.9751838235294118\n",
            "epoch 26 batch id 18 loss 0.055375970900058746 train acc 0.9756944444444444\n",
            "epoch 26 batch id 19 loss 0.3572533130645752 train acc 0.9736842105263158\n",
            "epoch 26 batch id 20 loss 0.056762486696243286 train acc 0.97421875\n",
            "epoch 26 batch id 21 loss 0.08015858381986618 train acc 0.9747023809523809\n",
            "epoch 26 batch id 22 loss 0.11096995323896408 train acc 0.9744318181818182\n",
            "epoch 26 batch id 23 loss 0.05957907438278198 train acc 0.9748641304347826\n",
            "epoch 26 batch id 24 loss 0.1150522530078888 train acc 0.9739583333333334\n",
            "epoch 26 batch id 25 loss 0.016061661764979362 train acc 0.975\n",
            "epoch 26 batch id 26 loss 0.10018759965896606 train acc 0.9747596153846154\n",
            "epoch 26 batch id 27 loss 0.04312322288751602 train acc 0.9756944444444444\n",
            "epoch 26 batch id 28 loss 0.09441402554512024 train acc 0.9760044642857143\n",
            "epoch 26 batch id 29 loss 0.01689951866865158 train acc 0.9768318965517241\n",
            "epoch 26 batch id 30 loss 0.14751915633678436 train acc 0.9765625\n",
            "epoch 26 batch id 31 loss 0.0304329302161932 train acc 0.9768145161290323\n",
            "epoch 26 batch id 32 loss 0.030140947550535202 train acc 0.9775390625\n",
            "epoch 26 batch id 33 loss 0.027749449014663696 train acc 0.978219696969697\n",
            "epoch 26 batch id 34 loss 0.04709099605679512 train acc 0.9779411764705882\n",
            "epoch 26 batch id 35 loss 0.20200052857398987 train acc 0.9767857142857143\n",
            "epoch 26 batch id 36 loss 0.1719512939453125 train acc 0.9761284722222222\n",
            "epoch 26 batch id 37 loss 0.0268842950463295 train acc 0.9767736486486487\n",
            "epoch 26 batch id 38 loss 0.011646633967757225 train acc 0.9773848684210527\n",
            "epoch 26 batch id 39 loss 0.1361590027809143 train acc 0.9767628205128205\n",
            "epoch 26 batch id 40 loss 0.1819712519645691 train acc 0.9765625\n",
            "epoch 26 batch id 41 loss 0.08016075193881989 train acc 0.9767530487804879\n",
            "epoch 26 batch id 42 loss 0.04940679296851158 train acc 0.9769345238095238\n",
            "epoch 26 batch id 43 loss 0.027409778907895088 train acc 0.9774709302325582\n",
            "epoch 26 batch id 44 loss 0.009848191402852535 train acc 0.9779829545454546\n",
            "epoch 26 batch id 45 loss 0.04814663901925087 train acc 0.978125\n",
            "epoch 26 batch id 46 loss 0.05353395268321037 train acc 0.9782608695652174\n",
            "epoch 26 batch id 47 loss 0.02809879742562771 train acc 0.9783909574468085\n",
            "epoch 26 batch id 48 loss 0.01693190075457096 train acc 0.9788411458333334\n",
            "epoch 26 batch id 49 loss 0.043852608650922775 train acc 0.9789540816326531\n",
            "epoch 26 batch id 50 loss 0.016146624460816383 train acc 0.979375\n",
            "epoch 26 batch id 51 loss 0.02399553917348385 train acc 0.9794730392156863\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_4063412/633954888.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/UROP/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/UROP/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.train()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "      \n",
        "#         if batch_id % log_interval == 0:\n",
        "        print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
        "\n",
        "    model.eval()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        test_acc += calc_accuracy(out, label)\n",
        "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1b27268",
      "metadata": {
        "id": "f1b27268"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "UROP",
      "language": "python",
      "name": "urop"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Kobert_final_final.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}