{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BLSTMATT_test60.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"2gHXTEBOgPFr"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","\n","from PIL import Image\n","import numpy as np\n","import time\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"MW8JFUoxgTJQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","\n","filePath = '/content/drive/MyDrive/aispark/서윤_trainset.txt'\n","\n","with open(filePath, 'rb') as lf:\n","    readList = pickle.load(lf)\n","    print(readList)\n","trainset = readList"],"metadata":{"id":"rTat5t2TguLv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from random import shuffle\n","\n","shuffle(trainset)\n","valset = trainset[4000:4500]\n","testset = trainset[4500:]\n","trainset = trainset[:4000]\n","\n","partition = {'train': trainset, 'val':valset, 'test':testset}"],"metadata":{"id":"7KmG1xQpZP7T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size =32\n","learning_rate = 0.001\n","epochs = 10\n","image_size = 715\n","input_size = 100\n","label_size = 63"],"metadata":{"id":"I84Vu8LIgzrP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_loader = torch.utils.data.DataLoader(partition['train'], \n","                                              batch_size=32, \n","                                              shuffle=True, num_workers=2)\n","\n","dataiter = iter(train_loader)\n","\n","images, labels = dataiter.next()\n","\n","images.size() #배치사이즈:32,  이미지 너비: 100, 시퀀스 크기 : 715"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LmOKXGYAcB4C","outputId":"c51e64cc-fe6f-41a0-cae4-d053108dafba","executionInfo":{"status":"ok","timestamp":1649401199948,"user_tz":-540,"elapsed":827,"user":{"displayName":"‍장서윤(학부생-AI빅데이터융합경영학과)","userId":"02936049384203671931"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 100, 715])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":[""],"metadata":{"id":"jBVh27Y_-Q4W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GXEwYFne_iu4","outputId":"dc8543c6-8324-41ef-b7b5-1002cf8b4cb7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["class BLSTMATT(nn.Module): # 100, \n","    def __init__(self, input_size, label_size, batch_size, num_layer=2):\n","        super(BLSTMATT, self).__init__()\n","        self.blstm = torch.nn.LSTM(input_size, input_size, num_layer, bidirectional=True, batch_first=True)\n","        self.h0 = torch.zeros(2 * num_layer, batch_size, input_size).cuda()\n","        self.c0 = torch.zeros(2 * num_layer, batch_size, input_size).cuda()\n","        self.softmax = nn.Softmax(dim=2)\n","        self.tanh = nn.Tanh()\n","        self.batch_size = batch_size\n","        self.hidden_size = input_size \n","        self.loss = nn.CrossEntropyLoss()\n","        self.w = torch.zeros(input_size).cuda()\n","\n","        self.embedding_dropout = nn.Dropout(0.3)\n","        self.lstm_dropout = nn.Dropout(0.3)\n","        self.attention_dropout = nn.Dropout(0.5)\n","\n","        self.fc = nn.Sequential(nn.Linear(input_size, label_size))\n","\n","    def Att_layer(self, H):\n","        M = self.tanh(H)\n","        alpha = self.softmax(torch.bmm(M, self.w.repeat(self.batch_size, 1, 1).transpose(1, 2)))\n","        res = self.tanh(torch.bmm(alpha.transpose(1,2), H))\n","        return res\n","\n","    def forward(self, x_input):\n","        x_input = self.embedding_dropout(x_input)\n","        h, _ = self.blstm(x_input, (self.h0, self.c0))\n","        h = h[:,:,self.hidden_size:] + h[:,:,:self.hidden_size]\n","        h = self.lstm_dropout(h)\n","        atth = self.Att_layer(h)\n","        atth = self.attention_dropout(atth)\n","        out = self.fc(atth)\n","        out = self.softmax(out)\n","\n","        return out.view(self.batch_size, -1)\n","        print(out)"],"metadata":{"id":"rhbbI0seCxZI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = BLSTMATT(100, 63, 32, 1).cuda()#input_size, label_size, batch_size, num_layer=2\n","model"],"metadata":{"id":"PlVykoogZQnB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b31ea2b0-898e-4c88-9654-eaea9f819206"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BLSTMATT(\n","  (blstm): LSTM(100, 100, batch_first=True, bidirectional=True)\n","  (softmax): Softmax(dim=2)\n","  (tanh): Tanh()\n","  (loss): CrossEntropyLoss()\n","  (embedding_dropout): Dropout(p=0.3, inplace=False)\n","  (lstm_dropout): Dropout(p=0.3, inplace=False)\n","  (attention_dropout): Dropout(p=0.5, inplace=False)\n","  (fc): Sequential(\n","    (0): Linear(in_features=100, out_features=63, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":102}]},{"cell_type":"code","source":["valid_loader =  torch.utils.data.DataLoader(partition['val'], \n","                                              batch_size=32, \n","                                              shuffle=False, num_workers=2,\n","                                            drop_last=True)\n","\n","\n","dataiter = iter(valid_loader)\n","\n","images, labels = dataiter.next()\n","\n","images.size() #배치사이즈:32,  이미지 너비: 100, 시퀀스 크기 : 715"],"metadata":{"id":"gb4DqC1sVrpZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f74c7746-ef85-4eb2-eb03-ebb92e2b922d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 100, 715])"]},"metadata":{},"execution_count":103}]},{"cell_type":"code","source":["train_loss_arr = []\n","valid_loss_arr = []\n","\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","criterion = nn.CrossEntropyLoss()\n","\n","for epoch in range(8):\n","    start = time.time()\n","    train_avg_loss = 0\n","    model.train()\n","\n","    running_corrects = 0\n","    \n","    for image, label in train_loader:\n","        # ------- assign train data\n","        image = np.swapaxes(image,1,2 )\n","\n","        x = image.to(device)\n","        x = torch.tensor(x, dtype=torch.float32)\n","        label = label.to(device)\n","        label = torch.tensor(label, dtype=torch.float32)\n","        # ------- forward prop\n","        optimizer.zero_grad()\n","        output = model(x.float())\n","        _, preds = torch.max(output, 1)\n","        # ------- backward prop\n","        loss = criterion(output.float().cuda(), label.type(torch.LongTensor).cuda())\n","        loss.backward()\n","        optimizer.step()\n","        # ------- get train performance\n","        \n","        train_avg_loss += loss / (len(train_loader))\n","        running_corrects += (preds.cuda() == label.data.cuda()).sum().item()\n","        running_accuracy = running_corrects / (len(train_loader))\n","    train_loss_arr.append(train_avg_loss)\n","    print(f'Epoch : {epoch+1}/{epochs}, train_loss : {train_avg_loss:.4f}, train_acc: {running_accuracy:.4f}', sep='\\n')\n","\n","\n","    model.eval()\n","    with torch.no_grad():\n","      valid_avg_loss =0\n","      val_corrects = 0\n","      for image, label in valid_loader:\n","        # ------- assign valid data\n","        image = np.swapaxes(image,1,2 )\n","        image = image.to(device)\n","        label = label.to(device)\n","        # ------- forward prop\n","        val_output = model(image.float())\n","        _, val_preds = torch.max(val_output, 1)\n","        val_loss = criterion(val_output.float().cuda(), label.type(torch.LongTensor).cuda())\n","        # ------- get valid performance\n","        val_corrects += (val_preds.cuda() == label.data.cuda()).sum().item()\n","        val_accuracy = val_corrects / (len(valid_loader))\n","        valid_avg_loss += val_loss / (len(valid_loader)) # val_loss / total_Iteration\n","      valid_loss_arr.append(valid_avg_loss) \n","      print(f'val_loss : {valid_avg_loss:.4f}, valid_acc : {val_accuracy:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fyGkRZEi_E59","outputId":"76725933-4da0-4ecf-990e-453843b38449"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch : 1/10, train_loss : 4.1424, train_acc: 0.4880\n","val_loss : 4.1428, valid_acc : 0.3333\n","Epoch : 2/10, train_loss : 4.1400, train_acc: 0.7680\n","val_loss : 4.1423, valid_acc : 0.4667\n","Epoch : 3/10, train_loss : 4.1399, train_acc: 0.7440\n","val_loss : 4.1414, valid_acc : 0.6667\n","Epoch : 4/10, train_loss : 4.1386, train_acc: 0.7600\n","val_loss : 4.1420, valid_acc : 0.8000\n","Epoch : 5/10, train_loss : 4.1396, train_acc: 0.7760\n","val_loss : 4.1434, valid_acc : 0.6667\n","Epoch : 6/10, train_loss : 4.1389, train_acc: 0.8480\n","val_loss : 4.1421, valid_acc : 0.6667\n","Epoch : 7/10, train_loss : 4.1389, train_acc: 0.7760\n","val_loss : 4.1416, valid_acc : 0.8000\n","Epoch : 8/10, train_loss : 4.1389, train_acc: 0.7200\n","val_loss : 4.1417, valid_acc : 0.8000\n"]}]},{"cell_type":"code","source":["test_loader =  torch.utils.data.DataLoader(partition['test'], \n","                                              batch_size=32, \n","                                              shuffle=False, num_workers=2,drop_last=True)\n","\n","\n","dataiter = iter(valid_loader)\n","\n","images, labels = dataiter.next()\n","\n","images.size() #배치사이즈:32,  이미지 너비: 100, 시퀀스 크기 : 715"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-QAYMnv1hijq","outputId":"202359f1-ba94-4202-a20a-b3845d32a7dc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 100, 715])"]},"metadata":{},"execution_count":106}]},{"cell_type":"code","source":["with torch.no_grad():\n","    start = time.time()\n","    test_corrects=0\n","    test_avg_loss = 0\n","    model.eval()\n","    for image, label in test_loader:\n","        # ------- assign valid data\n","        image = np.swapaxes(image,1,2 )\n","        image = image.to(device)\n","        label = label.to(device)\n","        # ------- forward prop\n","        test_output = model(image.float())\n","        _, test_preds = torch.max(val_output, 1)\n","        test_loss = criterion(test_output.float().cuda(), label.type(torch.LongTensor).cuda())\n","        # ------- get valid performance\n","        test_corrects += (test_preds.cuda() == label.data.cuda()).sum().item()\n","        test_accuracy = test_corrects / (len(test_loader))\n","        test_avg_loss += test_loss / (len(test_loader))\n","    print(f'test_loss : {test_avg_loss:.4f}, test_acc : {test_accuracy:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2wemtwNNhYGP","outputId":"b2246551-2a31-4a81-e1a4-4d304a73a14e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["test_loss : 4.1401, test_acc : 0.6000\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"bCCi4vY5lO5L"},"execution_count":null,"outputs":[]}]}